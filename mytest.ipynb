{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1fe17a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  24\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4012 - mean_squared_error: 0.9078\n",
      "Epoch 1: val_loss improved from inf to 0.30705, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 68s 2s/step - loss: 0.4012 - mean_squared_error: 0.9078 - val_loss: 0.3070 - val_mean_squared_error: 0.6848\n",
      "Epoch 2/150\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2502 - mean_squared_error: 0.5413\n",
      "Epoch 2: val_loss improved from 0.30705 to 0.18510, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 0.2500 - mean_squared_error: 0.5408 - val_loss: 0.1851 - val_mean_squared_error: 0.3843\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1396 - mean_squared_error: 0.2871\n",
      "Epoch 3: val_loss improved from 0.18510 to 0.14133, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 0.1396 - mean_squared_error: 0.2871 - val_loss: 0.1413 - val_mean_squared_error: 0.2895\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.2208\n",
      "Epoch 4: val_loss improved from 0.14133 to 0.12201, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 0.1081 - mean_squared_error: 0.2208 - val_loss: 0.1220 - val_mean_squared_error: 0.2482\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0978 - mean_squared_error: 0.2000\n",
      "Epoch 5: val_loss improved from 0.12201 to 0.12017, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.0978 - mean_squared_error: 0.2000 - val_loss: 0.1202 - val_mean_squared_error: 0.2447\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0934 - mean_squared_error: 0.1909\n",
      "Epoch 6: val_loss did not improve from 0.12017\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.0934 - mean_squared_error: 0.1909 - val_loss: 0.1220 - val_mean_squared_error: 0.2498\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0929 - mean_squared_error: 0.1905\n",
      "Epoch 7: val_loss did not improve from 0.12017\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.0929 - mean_squared_error: 0.1905 - val_loss: 0.1268 - val_mean_squared_error: 0.2603\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0914 - mean_squared_error: 0.1867\n",
      "Epoch 8: val_loss improved from 0.12017 to 0.11900, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.0914 - mean_squared_error: 0.1867 - val_loss: 0.1190 - val_mean_squared_error: 0.2430\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0890 - mean_squared_error: 0.1819\n",
      "Epoch 9: val_loss did not improve from 0.11900\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.0890 - mean_squared_error: 0.1819 - val_loss: 0.1233 - val_mean_squared_error: 0.2528\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0898 - mean_squared_error: 0.1845\n",
      "Epoch 10: val_loss did not improve from 0.11900\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0898 - mean_squared_error: 0.1845 - val_loss: 0.1195 - val_mean_squared_error: 0.2444\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0862 - mean_squared_error: 0.1767\n",
      "Epoch 11: val_loss improved from 0.11900 to 0.11845, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 0.0862 - mean_squared_error: 0.1767 - val_loss: 0.1185 - val_mean_squared_error: 0.2422\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0834 - mean_squared_error: 0.1704\n",
      "Epoch 12: val_loss improved from 0.11845 to 0.11632, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 0.0834 - mean_squared_error: 0.1704 - val_loss: 0.1163 - val_mean_squared_error: 0.2376\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0832 - mean_squared_error: 0.1703\n",
      "Epoch 13: val_loss did not improve from 0.11632\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0832 - mean_squared_error: 0.1703 - val_loss: 0.1173 - val_mean_squared_error: 0.2400\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0825 - mean_squared_error: 0.1692\n",
      "Epoch 14: val_loss improved from 0.11632 to 0.11217, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.0825 - mean_squared_error: 0.1692 - val_loss: 0.1122 - val_mean_squared_error: 0.2286\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0838 - mean_squared_error: 0.1714\n",
      "Epoch 15: val_loss did not improve from 0.11217\n",
      "10/10 [==============================] - 3s 250ms/step - loss: 0.0838 - mean_squared_error: 0.1714 - val_loss: 0.1191 - val_mean_squared_error: 0.2435\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0809 - mean_squared_error: 0.1655\n",
      "Epoch 16: val_loss did not improve from 0.11217\n",
      "10/10 [==============================] - 2s 247ms/step - loss: 0.0809 - mean_squared_error: 0.1655 - val_loss: 0.1134 - val_mean_squared_error: 0.2323\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0839 - mean_squared_error: 0.1721\n",
      "Epoch 17: val_loss did not improve from 0.11217\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0839 - mean_squared_error: 0.1721 - val_loss: 0.1145 - val_mean_squared_error: 0.2337\n",
      "Epoch 18/150\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0809 - mean_squared_error: 0.1656\n",
      "Epoch 18: val_loss improved from 0.11217 to 0.11116, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.0809 - mean_squared_error: 0.1657 - val_loss: 0.1112 - val_mean_squared_error: 0.2275\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0809 - mean_squared_error: 0.1659\n",
      "Epoch 19: val_loss improved from 0.11116 to 0.11108, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 0.0809 - mean_squared_error: 0.1659 - val_loss: 0.1111 - val_mean_squared_error: 0.2274\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0789 - mean_squared_error: 0.1618\n",
      "Epoch 20: val_loss did not improve from 0.11108\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.0789 - mean_squared_error: 0.1618 - val_loss: 0.1152 - val_mean_squared_error: 0.2361\n",
      "Epoch 21/150\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0814 - mean_squared_error: 0.1664\n",
      "Epoch 21: val_loss did not improve from 0.11108\n",
      "10/10 [==============================] - 3s 252ms/step - loss: 0.0811 - mean_squared_error: 0.1658 - val_loss: 0.1128 - val_mean_squared_error: 0.2309\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0774 - mean_squared_error: 0.1587\n",
      "Epoch 22: val_loss did not improve from 0.11108\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0774 - mean_squared_error: 0.1587 - val_loss: 0.1120 - val_mean_squared_error: 0.2292\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0777 - mean_squared_error: 0.1589\n",
      "Epoch 23: val_loss improved from 0.11108 to 0.10921, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 264ms/step - loss: 0.0777 - mean_squared_error: 0.1589 - val_loss: 0.1092 - val_mean_squared_error: 0.2234\n",
      "Epoch 24/150\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0774 - mean_squared_error: 0.1585\n",
      "Epoch 24: val_loss did not improve from 0.10921\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.0772 - mean_squared_error: 0.1581 - val_loss: 0.1106 - val_mean_squared_error: 0.2260\n",
      "Epoch 25/150\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0764 - mean_squared_error: 0.1563\n",
      "Epoch 25: val_loss did not improve from 0.10921\n",
      "10/10 [==============================] - 2s 247ms/step - loss: 0.0762 - mean_squared_error: 0.1559 - val_loss: 0.1136 - val_mean_squared_error: 0.2329\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0751 - mean_squared_error: 0.1540\n",
      "Epoch 26: val_loss improved from 0.10921 to 0.10804, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.0751 - mean_squared_error: 0.1540 - val_loss: 0.1080 - val_mean_squared_error: 0.2210\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0755 - mean_squared_error: 0.1545\n",
      "Epoch 27: val_loss did not improve from 0.10804\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0755 - mean_squared_error: 0.1545 - val_loss: 0.1195 - val_mean_squared_error: 0.2452\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0794 - mean_squared_error: 0.1621\n",
      "Epoch 28: val_loss did not improve from 0.10804\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0794 - mean_squared_error: 0.1621 - val_loss: 0.1109 - val_mean_squared_error: 0.2275\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0752 - mean_squared_error: 0.1539\n",
      "Epoch 29: val_loss did not improve from 0.10804\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.0752 - mean_squared_error: 0.1539 - val_loss: 0.1212 - val_mean_squared_error: 0.2487\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0788 - mean_squared_error: 0.1606\n",
      "Epoch 30: val_loss did not improve from 0.10804\n",
      "10/10 [==============================] - 2s 247ms/step - loss: 0.0788 - mean_squared_error: 0.1606 - val_loss: 0.1118 - val_mean_squared_error: 0.2300\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0766 - mean_squared_error: 0.1565\n",
      "Epoch 31: val_loss did not improve from 0.10804\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0766 - mean_squared_error: 0.1565 - val_loss: 0.1246 - val_mean_squared_error: 0.2559\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0745 - mean_squared_error: 0.1526\n",
      "Epoch 32: val_loss improved from 0.10804 to 0.10653, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 264ms/step - loss: 0.0745 - mean_squared_error: 0.1526 - val_loss: 0.1065 - val_mean_squared_error: 0.2193\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0734 - mean_squared_error: 0.1503\n",
      "Epoch 33: val_loss did not improve from 0.10653\n",
      "10/10 [==============================] - 3s 255ms/step - loss: 0.0734 - mean_squared_error: 0.1503 - val_loss: 0.1135 - val_mean_squared_error: 0.2315\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0740 - mean_squared_error: 0.1508\n",
      "Epoch 34: val_loss did not improve from 0.10653\n",
      "10/10 [==============================] - 3s 255ms/step - loss: 0.0740 - mean_squared_error: 0.1508 - val_loss: 0.1097 - val_mean_squared_error: 0.2245\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0714 - mean_squared_error: 0.1464\n",
      "Epoch 35: val_loss did not improve from 0.10653\n",
      "10/10 [==============================] - 3s 251ms/step - loss: 0.0714 - mean_squared_error: 0.1464 - val_loss: 0.1120 - val_mean_squared_error: 0.2294\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0711 - mean_squared_error: 0.1455\n",
      "Epoch 36: val_loss did not improve from 0.10653\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0711 - mean_squared_error: 0.1455 - val_loss: 0.1121 - val_mean_squared_error: 0.2297\n",
      "Epoch 37/150\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0706 - mean_squared_error: 0.1445\n",
      "Epoch 37: val_loss did not improve from 0.10653\n",
      "10/10 [==============================] - 3s 254ms/step - loss: 0.0705 - mean_squared_error: 0.1443 - val_loss: 0.1086 - val_mean_squared_error: 0.2221\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0723 - mean_squared_error: 0.1476\n",
      "Epoch 38: val_loss did not improve from 0.10653\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 0.0723 - mean_squared_error: 0.1476 - val_loss: 0.1160 - val_mean_squared_error: 0.2374\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0713 - mean_squared_error: 0.1452\n",
      "Epoch 39: val_loss did not improve from 0.10653\n",
      "10/10 [==============================] - 3s 255ms/step - loss: 0.0713 - mean_squared_error: 0.1452 - val_loss: 0.1083 - val_mean_squared_error: 0.2217\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0692 - mean_squared_error: 0.1413\n",
      "Epoch 40: val_loss did not improve from 0.10653\n",
      "10/10 [==============================] - 3s 256ms/step - loss: 0.0692 - mean_squared_error: 0.1413 - val_loss: 0.1137 - val_mean_squared_error: 0.2331\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0684 - mean_squared_error: 0.1394\n",
      "Epoch 41: val_loss did not improve from 0.10653\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0684 - mean_squared_error: 0.1394 - val_loss: 0.1089 - val_mean_squared_error: 0.2231\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0688 - mean_squared_error: 0.1406\n",
      "Epoch 42: val_loss did not improve from 0.10653\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.0688 - mean_squared_error: 0.1406 - val_loss: 0.1151 - val_mean_squared_error: 0.2355\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0714 - mean_squared_error: 0.1454\n",
      "Epoch 43: val_loss did not improve from 0.10653\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0714 - mean_squared_error: 0.1454 - val_loss: 0.1119 - val_mean_squared_error: 0.2299\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0689 - mean_squared_error: 0.1409\n",
      "Epoch 44: val_loss did not improve from 0.10653\n",
      "10/10 [==============================] - 3s 250ms/step - loss: 0.0689 - mean_squared_error: 0.1409 - val_loss: 0.1109 - val_mean_squared_error: 0.2270\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0678 - mean_squared_error: 0.1386\n",
      "Epoch 45: val_loss did not improve from 0.10653\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.0678 - mean_squared_error: 0.1386 - val_loss: 0.1170 - val_mean_squared_error: 0.2398\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0699 - mean_squared_error: 0.1428\n",
      "Epoch 46: val_loss improved from 0.10653 to 0.10310, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.0699 - mean_squared_error: 0.1428 - val_loss: 0.1031 - val_mean_squared_error: 0.2110\n",
      "Epoch 47/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.0680 - mean_squared_error: 0.1389\n",
      "Epoch 47: val_loss improved from 0.10310 to 0.10280, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.0680 - mean_squared_error: 0.1389 - val_loss: 0.1028 - val_mean_squared_error: 0.2101\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0682 - mean_squared_error: 0.1395\n",
      "Epoch 48: val_loss did not improve from 0.10280\n",
      "10/10 [==============================] - 2s 247ms/step - loss: 0.0682 - mean_squared_error: 0.1395 - val_loss: 0.1139 - val_mean_squared_error: 0.2330\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0664 - mean_squared_error: 0.1354\n",
      "Epoch 49: val_loss did not improve from 0.10280\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0664 - mean_squared_error: 0.1354 - val_loss: 0.1104 - val_mean_squared_error: 0.2261\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0652 - mean_squared_error: 0.1332\n",
      "Epoch 50: val_loss did not improve from 0.10280\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0652 - mean_squared_error: 0.1332 - val_loss: 0.1095 - val_mean_squared_error: 0.2237\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0666 - mean_squared_error: 0.1356\n",
      "Epoch 51: val_loss did not improve from 0.10280\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.0666 - mean_squared_error: 0.1356 - val_loss: 0.1078 - val_mean_squared_error: 0.2202\n",
      "Epoch 52/150\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0649 - mean_squared_error: 0.1324\n",
      "Epoch 52: val_loss did not improve from 0.10280\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0652 - mean_squared_error: 0.1331 - val_loss: 0.1176 - val_mean_squared_error: 0.2420\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0638 - mean_squared_error: 0.1304\n",
      "Epoch 53: val_loss did not improve from 0.10280\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0638 - mean_squared_error: 0.1304 - val_loss: 0.1123 - val_mean_squared_error: 0.2299\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0639 - mean_squared_error: 0.1302\n",
      "Epoch 54: val_loss improved from 0.10280 to 0.09997, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 0.0639 - mean_squared_error: 0.1302 - val_loss: 0.1000 - val_mean_squared_error: 0.2042\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0636 - mean_squared_error: 0.1298\n",
      "Epoch 55: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0636 - mean_squared_error: 0.1298 - val_loss: 0.1115 - val_mean_squared_error: 0.2281\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0626 - mean_squared_error: 0.1280\n",
      "Epoch 56: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.0626 - mean_squared_error: 0.1280 - val_loss: 0.1069 - val_mean_squared_error: 0.2185\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0628 - mean_squared_error: 0.1278\n",
      "Epoch 57: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 255ms/step - loss: 0.0628 - mean_squared_error: 0.1278 - val_loss: 0.1184 - val_mean_squared_error: 0.2425\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0617 - mean_squared_error: 0.1262\n",
      "Epoch 58: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.0617 - mean_squared_error: 0.1262 - val_loss: 0.1032 - val_mean_squared_error: 0.2110\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0609 - mean_squared_error: 0.1244\n",
      "Epoch 59: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.0609 - mean_squared_error: 0.1244 - val_loss: 0.1094 - val_mean_squared_error: 0.2232\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0595 - mean_squared_error: 0.1213\n",
      "Epoch 60: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.0595 - mean_squared_error: 0.1213 - val_loss: 0.1135 - val_mean_squared_error: 0.2333\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0596 - mean_squared_error: 0.1214\n",
      "Epoch 61: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0596 - mean_squared_error: 0.1214 - val_loss: 0.1101 - val_mean_squared_error: 0.2253\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0591 - mean_squared_error: 0.1208\n",
      "Epoch 62: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0591 - mean_squared_error: 0.1208 - val_loss: 0.1118 - val_mean_squared_error: 0.2293\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0575 - mean_squared_error: 0.1173\n",
      "Epoch 63: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0575 - mean_squared_error: 0.1173 - val_loss: 0.1125 - val_mean_squared_error: 0.2303\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0567 - mean_squared_error: 0.1157\n",
      "Epoch 64: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.0567 - mean_squared_error: 0.1157 - val_loss: 0.1074 - val_mean_squared_error: 0.2209\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0568 - mean_squared_error: 0.1160\n",
      "Epoch 65: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.0568 - mean_squared_error: 0.1160 - val_loss: 0.1155 - val_mean_squared_error: 0.2369\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0570 - mean_squared_error: 0.1164\n",
      "Epoch 66: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0570 - mean_squared_error: 0.1164 - val_loss: 0.1120 - val_mean_squared_error: 0.2296\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0564 - mean_squared_error: 0.1151\n",
      "Epoch 67: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.0564 - mean_squared_error: 0.1151 - val_loss: 0.1103 - val_mean_squared_error: 0.2272\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0552 - mean_squared_error: 0.1127\n",
      "Epoch 68: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0552 - mean_squared_error: 0.1127 - val_loss: 0.1115 - val_mean_squared_error: 0.2281\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0544 - mean_squared_error: 0.1110\n",
      "Epoch 69: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.0544 - mean_squared_error: 0.1110 - val_loss: 0.1158 - val_mean_squared_error: 0.2392\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0537 - mean_squared_error: 0.1097\n",
      "Epoch 70: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0537 - mean_squared_error: 0.1097 - val_loss: 0.1140 - val_mean_squared_error: 0.2354\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0530 - mean_squared_error: 0.1082\n",
      "Epoch 71: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0530 - mean_squared_error: 0.1082 - val_loss: 0.1103 - val_mean_squared_error: 0.2265\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0537 - mean_squared_error: 0.1094\n",
      "Epoch 72: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0537 - mean_squared_error: 0.1094 - val_loss: 0.1180 - val_mean_squared_error: 0.2444\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0543 - mean_squared_error: 0.1110\n",
      "Epoch 73: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0543 - mean_squared_error: 0.1110 - val_loss: 0.1169 - val_mean_squared_error: 0.2403\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0536 - mean_squared_error: 0.1092\n",
      "Epoch 74: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0536 - mean_squared_error: 0.1092 - val_loss: 0.1122 - val_mean_squared_error: 0.2309\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0519 - mean_squared_error: 0.1062\n",
      "Epoch 75: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0519 - mean_squared_error: 0.1062 - val_loss: 0.1203 - val_mean_squared_error: 0.2483\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0505 - mean_squared_error: 0.1031\n",
      "Epoch 76: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0505 - mean_squared_error: 0.1031 - val_loss: 0.1231 - val_mean_squared_error: 0.2546\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0510 - mean_squared_error: 0.1041\n",
      "Epoch 77: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.0510 - mean_squared_error: 0.1041 - val_loss: 0.1197 - val_mean_squared_error: 0.2484\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0498 - mean_squared_error: 0.1018\n",
      "Epoch 78: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0498 - mean_squared_error: 0.1018 - val_loss: 0.1147 - val_mean_squared_error: 0.2366\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0486 - mean_squared_error: 0.0993\n",
      "Epoch 79: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0486 - mean_squared_error: 0.0993 - val_loss: 0.1171 - val_mean_squared_error: 0.2437\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0487 - mean_squared_error: 0.0998\n",
      "Epoch 80: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0487 - mean_squared_error: 0.0998 - val_loss: 0.1195 - val_mean_squared_error: 0.2471\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0473 - mean_squared_error: 0.0965\n",
      "Epoch 81: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0473 - mean_squared_error: 0.0965 - val_loss: 0.1189 - val_mean_squared_error: 0.2462\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0470 - mean_squared_error: 0.0959\n",
      "Epoch 82: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.0470 - mean_squared_error: 0.0959 - val_loss: 0.1244 - val_mean_squared_error: 0.2583\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0461 - mean_squared_error: 0.0941\n",
      "Epoch 83: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.0461 - mean_squared_error: 0.0941 - val_loss: 0.1155 - val_mean_squared_error: 0.2398\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0446 - mean_squared_error: 0.0913\n",
      "Epoch 84: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.0446 - mean_squared_error: 0.0913 - val_loss: 0.1196 - val_mean_squared_error: 0.2492\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0439 - mean_squared_error: 0.0899\n",
      "Epoch 85: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.0439 - mean_squared_error: 0.0899 - val_loss: 0.1158 - val_mean_squared_error: 0.2401\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0447 - mean_squared_error: 0.0911\n",
      "Epoch 86: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 256ms/step - loss: 0.0447 - mean_squared_error: 0.0911 - val_loss: 0.1160 - val_mean_squared_error: 0.2414\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0449 - mean_squared_error: 0.0915\n",
      "Epoch 87: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.0449 - mean_squared_error: 0.0915 - val_loss: 0.1157 - val_mean_squared_error: 0.2390\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0487 - mean_squared_error: 0.0995\n",
      "Epoch 88: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 256ms/step - loss: 0.0487 - mean_squared_error: 0.0995 - val_loss: 0.1312 - val_mean_squared_error: 0.2736\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0469 - mean_squared_error: 0.0959\n",
      "Epoch 89: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0469 - mean_squared_error: 0.0959 - val_loss: 0.1213 - val_mean_squared_error: 0.2515\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0426 - mean_squared_error: 0.0871\n",
      "Epoch 90: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.0426 - mean_squared_error: 0.0871 - val_loss: 0.1236 - val_mean_squared_error: 0.2587\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0414 - mean_squared_error: 0.0848\n",
      "Epoch 91: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.0414 - mean_squared_error: 0.0848 - val_loss: 0.1293 - val_mean_squared_error: 0.2694\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0412 - mean_squared_error: 0.0841\n",
      "Epoch 92: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 0.0412 - mean_squared_error: 0.0841 - val_loss: 0.1251 - val_mean_squared_error: 0.2622\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0410 - mean_squared_error: 0.0836\n",
      "Epoch 93: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 256ms/step - loss: 0.0410 - mean_squared_error: 0.0836 - val_loss: 0.1243 - val_mean_squared_error: 0.2600\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0421 - mean_squared_error: 0.0860\n",
      "Epoch 94: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 256ms/step - loss: 0.0421 - mean_squared_error: 0.0860 - val_loss: 0.1279 - val_mean_squared_error: 0.2679\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0414 - mean_squared_error: 0.0845\n",
      "Epoch 95: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0414 - mean_squared_error: 0.0845 - val_loss: 0.1231 - val_mean_squared_error: 0.2580\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0803\n",
      "Epoch 96: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0393 - mean_squared_error: 0.0803 - val_loss: 0.1221 - val_mean_squared_error: 0.2537\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.0798\n",
      "Epoch 97: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.0390 - mean_squared_error: 0.0798 - val_loss: 0.1260 - val_mean_squared_error: 0.2645\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0376 - mean_squared_error: 0.0768\n",
      "Epoch 98: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0376 - mean_squared_error: 0.0768 - val_loss: 0.1288 - val_mean_squared_error: 0.2705\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0365 - mean_squared_error: 0.0747\n",
      "Epoch 99: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.0365 - mean_squared_error: 0.0747 - val_loss: 0.1288 - val_mean_squared_error: 0.2703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.0798\n",
      "Epoch 100: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0390 - mean_squared_error: 0.0798 - val_loss: 0.1181 - val_mean_squared_error: 0.2463\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0800\n",
      "Epoch 101: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.0392 - mean_squared_error: 0.0800 - val_loss: 0.1210 - val_mean_squared_error: 0.2520\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0373 - mean_squared_error: 0.0764\n",
      "Epoch 102: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.0373 - mean_squared_error: 0.0764 - val_loss: 0.1299 - val_mean_squared_error: 0.2732\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0345 - mean_squared_error: 0.0706\n",
      "Epoch 103: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0345 - mean_squared_error: 0.0706 - val_loss: 0.1248 - val_mean_squared_error: 0.2618\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0343 - mean_squared_error: 0.0700\n",
      "Epoch 104: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0343 - mean_squared_error: 0.0700 - val_loss: 0.1207 - val_mean_squared_error: 0.2517\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0336 - mean_squared_error: 0.0688\n",
      "Epoch 105: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0336 - mean_squared_error: 0.0688 - val_loss: 0.1284 - val_mean_squared_error: 0.2687\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0326 - mean_squared_error: 0.0667\n",
      "Epoch 106: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.0326 - mean_squared_error: 0.0667 - val_loss: 0.1239 - val_mean_squared_error: 0.2605\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0307 - mean_squared_error: 0.0630\n",
      "Epoch 107: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0307 - mean_squared_error: 0.0630 - val_loss: 0.1252 - val_mean_squared_error: 0.2622\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0312 - mean_squared_error: 0.0641\n",
      "Epoch 108: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.0312 - mean_squared_error: 0.0641 - val_loss: 0.1247 - val_mean_squared_error: 0.2622\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0304 - mean_squared_error: 0.0625\n",
      "Epoch 109: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0304 - mean_squared_error: 0.0625 - val_loss: 0.1272 - val_mean_squared_error: 0.2691\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0306 - mean_squared_error: 0.0629\n",
      "Epoch 110: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 256ms/step - loss: 0.0306 - mean_squared_error: 0.0629 - val_loss: 0.1254 - val_mean_squared_error: 0.2624\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0299 - mean_squared_error: 0.0614\n",
      "Epoch 111: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 0.0299 - mean_squared_error: 0.0614 - val_loss: 0.1264 - val_mean_squared_error: 0.2659\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0287 - mean_squared_error: 0.0589\n",
      "Epoch 112: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0287 - mean_squared_error: 0.0589 - val_loss: 0.1280 - val_mean_squared_error: 0.2694\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0279 - mean_squared_error: 0.0573\n",
      "Epoch 113: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.0279 - mean_squared_error: 0.0573 - val_loss: 0.1357 - val_mean_squared_error: 0.2868\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0289 - mean_squared_error: 0.0592\n",
      "Epoch 114: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0289 - mean_squared_error: 0.0592 - val_loss: 0.1255 - val_mean_squared_error: 0.2635\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0269 - mean_squared_error: 0.0556\n",
      "Epoch 115: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0269 - mean_squared_error: 0.0556 - val_loss: 0.1303 - val_mean_squared_error: 0.2742\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0255 - mean_squared_error: 0.0526\n",
      "Epoch 116: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 0.0255 - mean_squared_error: 0.0526 - val_loss: 0.1298 - val_mean_squared_error: 0.2728\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0263 - mean_squared_error: 0.0542\n",
      "Epoch 117: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 0.0263 - mean_squared_error: 0.0542 - val_loss: 0.1384 - val_mean_squared_error: 0.2954\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0517\n",
      "Epoch 118: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 0.0251 - mean_squared_error: 0.0517 - val_loss: 0.1338 - val_mean_squared_error: 0.2830\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0250 - mean_squared_error: 0.0516\n",
      "Epoch 119: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 251ms/step - loss: 0.0250 - mean_squared_error: 0.0516 - val_loss: 0.1378 - val_mean_squared_error: 0.2918\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0502\n",
      "Epoch 120: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0243 - mean_squared_error: 0.0502 - val_loss: 0.1356 - val_mean_squared_error: 0.2882\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0235 - mean_squared_error: 0.0485\n",
      "Epoch 121: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 249ms/step - loss: 0.0235 - mean_squared_error: 0.0485 - val_loss: 0.1415 - val_mean_squared_error: 0.3022\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0238 - mean_squared_error: 0.0491\n",
      "Epoch 122: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 252ms/step - loss: 0.0238 - mean_squared_error: 0.0491 - val_loss: 0.1354 - val_mean_squared_error: 0.2870\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0230 - mean_squared_error: 0.0476\n",
      "Epoch 123: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0230 - mean_squared_error: 0.0476 - val_loss: 0.1412 - val_mean_squared_error: 0.3022\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0236 - mean_squared_error: 0.0490\n",
      "Epoch 124: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.0236 - mean_squared_error: 0.0490 - val_loss: 0.1423 - val_mean_squared_error: 0.3026\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0228 - mean_squared_error: 0.0473\n",
      "Epoch 125: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0228 - mean_squared_error: 0.0473 - val_loss: 0.1459 - val_mean_squared_error: 0.3142\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0239 - mean_squared_error: 0.0494\n",
      "Epoch 126: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0239 - mean_squared_error: 0.0494 - val_loss: 0.1386 - val_mean_squared_error: 0.2944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0464\n",
      "Epoch 127: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0224 - mean_squared_error: 0.0464 - val_loss: 0.1501 - val_mean_squared_error: 0.3235\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0465\n",
      "Epoch 128: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0224 - mean_squared_error: 0.0465 - val_loss: 0.1395 - val_mean_squared_error: 0.2962\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0219 - mean_squared_error: 0.0453\n",
      "Epoch 129: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.0219 - mean_squared_error: 0.0453 - val_loss: 0.1406 - val_mean_squared_error: 0.2990\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0211 - mean_squared_error: 0.0438\n",
      "Epoch 130: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0211 - mean_squared_error: 0.0438 - val_loss: 0.1376 - val_mean_squared_error: 0.2920\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0203 - mean_squared_error: 0.0422\n",
      "Epoch 131: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 251ms/step - loss: 0.0203 - mean_squared_error: 0.0422 - val_loss: 0.1436 - val_mean_squared_error: 0.3069\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0402\n",
      "Epoch 132: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0193 - mean_squared_error: 0.0402 - val_loss: 0.1407 - val_mean_squared_error: 0.2992\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.0391\n",
      "Epoch 133: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.0188 - mean_squared_error: 0.0391 - val_loss: 0.1406 - val_mean_squared_error: 0.3018\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0190 - mean_squared_error: 0.0395\n",
      "Epoch 134: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0190 - mean_squared_error: 0.0395 - val_loss: 0.1408 - val_mean_squared_error: 0.2994\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0186 - mean_squared_error: 0.0388\n",
      "Epoch 135: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0186 - mean_squared_error: 0.0388 - val_loss: 0.1511 - val_mean_squared_error: 0.3252\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0226 - mean_squared_error: 0.0468\n",
      "Epoch 136: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0226 - mean_squared_error: 0.0468 - val_loss: 0.1359 - val_mean_squared_error: 0.2897\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0208 - mean_squared_error: 0.0432\n",
      "Epoch 137: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0208 - mean_squared_error: 0.0432 - val_loss: 0.1473 - val_mean_squared_error: 0.3164\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0201 - mean_squared_error: 0.0417\n",
      "Epoch 138: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.0201 - mean_squared_error: 0.0417 - val_loss: 0.1386 - val_mean_squared_error: 0.2924\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0394\n",
      "Epoch 139: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0189 - mean_squared_error: 0.0394 - val_loss: 0.1443 - val_mean_squared_error: 0.3079\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0377\n",
      "Epoch 140: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0181 - mean_squared_error: 0.0377 - val_loss: 0.1460 - val_mean_squared_error: 0.3113\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0367\n",
      "Epoch 141: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 250ms/step - loss: 0.0175 - mean_squared_error: 0.0367 - val_loss: 0.1424 - val_mean_squared_error: 0.3035\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0360\n",
      "Epoch 142: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 3s 250ms/step - loss: 0.0172 - mean_squared_error: 0.0360 - val_loss: 0.1421 - val_mean_squared_error: 0.3018\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0170 - mean_squared_error: 0.0355\n",
      "Epoch 143: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0170 - mean_squared_error: 0.0355 - val_loss: 0.1417 - val_mean_squared_error: 0.2993\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0170 - mean_squared_error: 0.0357\n",
      "Epoch 144: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 232ms/step - loss: 0.0170 - mean_squared_error: 0.0357 - val_loss: 0.1454 - val_mean_squared_error: 0.3098\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0339\n",
      "Epoch 145: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.0162 - mean_squared_error: 0.0339 - val_loss: 0.1398 - val_mean_squared_error: 0.2963\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0337\n",
      "Epoch 146: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0161 - mean_squared_error: 0.0337 - val_loss: 0.1464 - val_mean_squared_error: 0.3119\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0156 - mean_squared_error: 0.0329\n",
      "Epoch 147: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0156 - mean_squared_error: 0.0329 - val_loss: 0.1438 - val_mean_squared_error: 0.3044\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0324\n",
      "Epoch 148: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 0.0154 - mean_squared_error: 0.0324 - val_loss: 0.1496 - val_mean_squared_error: 0.3219\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0329\n",
      "Epoch 149: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 0.0157 - mean_squared_error: 0.0329 - val_loss: 0.1463 - val_mean_squared_error: 0.3131\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0312\n",
      "Epoch 150: val_loss did not improve from 0.09997\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 0.0148 - mean_squared_error: 0.0312 - val_loss: 0.1435 - val_mean_squared_error: 0.3050\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001995E262CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "5/5 [==============================] - 10s 26ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  48\n",
      "PREDICT_STEPS :  24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3928 - mean_squared_error: 0.8844\n",
      "Epoch 1: val_loss improved from inf to 0.30704, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 66s 2s/step - loss: 0.3928 - mean_squared_error: 0.8844 - val_loss: 0.3070 - val_mean_squared_error: 0.6780\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2311 - mean_squared_error: 0.4955\n",
      "Epoch 2: val_loss improved from 0.30704 to 0.17396, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.2311 - mean_squared_error: 0.4955 - val_loss: 0.1740 - val_mean_squared_error: 0.3609\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1346 - mean_squared_error: 0.2772\n",
      "Epoch 3: val_loss improved from 0.17396 to 0.13905, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.1346 - mean_squared_error: 0.2772 - val_loss: 0.1391 - val_mean_squared_error: 0.2843\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1092 - mean_squared_error: 0.2232\n",
      "Epoch 4: val_loss improved from 0.13905 to 0.12257, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.1092 - mean_squared_error: 0.2232 - val_loss: 0.1226 - val_mean_squared_error: 0.2490\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0998 - mean_squared_error: 0.2039\n",
      "Epoch 5: val_loss improved from 0.12257 to 0.12160, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.0998 - mean_squared_error: 0.2039 - val_loss: 0.1216 - val_mean_squared_error: 0.2470\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0939 - mean_squared_error: 0.1918\n",
      "Epoch 6: val_loss improved from 0.12160 to 0.11725, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.0939 - mean_squared_error: 0.1918 - val_loss: 0.1172 - val_mean_squared_error: 0.2386\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0927 - mean_squared_error: 0.1893\n",
      "Epoch 7: val_loss did not improve from 0.11725\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0927 - mean_squared_error: 0.1893 - val_loss: 0.1263 - val_mean_squared_error: 0.2584\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0895 - mean_squared_error: 0.1830\n",
      "Epoch 8: val_loss improved from 0.11725 to 0.11321, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.0895 - mean_squared_error: 0.1830 - val_loss: 0.1132 - val_mean_squared_error: 0.2310\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0841 - mean_squared_error: 0.1720\n",
      "Epoch 9: val_loss did not improve from 0.11321\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0841 - mean_squared_error: 0.1720 - val_loss: 0.1191 - val_mean_squared_error: 0.2428\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0831 - mean_squared_error: 0.1698\n",
      "Epoch 10: val_loss improved from 0.11321 to 0.10751, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.0831 - mean_squared_error: 0.1698 - val_loss: 0.1075 - val_mean_squared_error: 0.2188\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0818 - mean_squared_error: 0.1671\n",
      "Epoch 11: val_loss did not improve from 0.10751\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0818 - mean_squared_error: 0.1671 - val_loss: 0.1176 - val_mean_squared_error: 0.2399\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0790 - mean_squared_error: 0.1616\n",
      "Epoch 12: val_loss did not improve from 0.10751\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0790 - mean_squared_error: 0.1616 - val_loss: 0.1138 - val_mean_squared_error: 0.2326\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0773 - mean_squared_error: 0.1580\n",
      "Epoch 13: val_loss did not improve from 0.10751\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.0773 - mean_squared_error: 0.1580 - val_loss: 0.1077 - val_mean_squared_error: 0.2191\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0781 - mean_squared_error: 0.1598\n",
      "Epoch 14: val_loss did not improve from 0.10751\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0781 - mean_squared_error: 0.1598 - val_loss: 0.1154 - val_mean_squared_error: 0.2359\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0794 - mean_squared_error: 0.1623\n",
      "Epoch 15: val_loss did not improve from 0.10751\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0794 - mean_squared_error: 0.1623 - val_loss: 0.1127 - val_mean_squared_error: 0.2298\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0776 - mean_squared_error: 0.1584\n",
      "Epoch 16: val_loss did not improve from 0.10751\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0776 - mean_squared_error: 0.1584 - val_loss: 0.1153 - val_mean_squared_error: 0.2360\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0787 - mean_squared_error: 0.1608\n",
      "Epoch 17: val_loss did not improve from 0.10751\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0787 - mean_squared_error: 0.1608 - val_loss: 0.1101 - val_mean_squared_error: 0.2238\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0755 - mean_squared_error: 0.1541\n",
      "Epoch 18: val_loss improved from 0.10751 to 0.10286, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.0755 - mean_squared_error: 0.1541 - val_loss: 0.1029 - val_mean_squared_error: 0.2101\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0758 - mean_squared_error: 0.1549\n",
      "Epoch 19: val_loss did not improve from 0.10286\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.0758 - mean_squared_error: 0.1549 - val_loss: 0.1139 - val_mean_squared_error: 0.2310\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0737 - mean_squared_error: 0.1503\n",
      "Epoch 20: val_loss did not improve from 0.10286\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0737 - mean_squared_error: 0.1503 - val_loss: 0.1149 - val_mean_squared_error: 0.2364\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0757 - mean_squared_error: 0.1546\n",
      "Epoch 21: val_loss did not improve from 0.10286\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0757 - mean_squared_error: 0.1546 - val_loss: 0.1091 - val_mean_squared_error: 0.2213\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0736 - mean_squared_error: 0.1499\n",
      "Epoch 22: val_loss did not improve from 0.10286\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.0736 - mean_squared_error: 0.1499 - val_loss: 0.1069 - val_mean_squared_error: 0.2187\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0727 - mean_squared_error: 0.1483\n",
      "Epoch 23: val_loss did not improve from 0.10286\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0727 - mean_squared_error: 0.1483 - val_loss: 0.1102 - val_mean_squared_error: 0.2240\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0742 - mean_squared_error: 0.1517\n",
      "Epoch 24: val_loss did not improve from 0.10286\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0742 - mean_squared_error: 0.1517 - val_loss: 0.1103 - val_mean_squared_error: 0.2237\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0725 - mean_squared_error: 0.1479\n",
      "Epoch 25: val_loss did not improve from 0.10286\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0725 - mean_squared_error: 0.1479 - val_loss: 0.1143 - val_mean_squared_error: 0.2339\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0722 - mean_squared_error: 0.1475\n",
      "Epoch 26: val_loss did not improve from 0.10286\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0722 - mean_squared_error: 0.1475 - val_loss: 0.1047 - val_mean_squared_error: 0.2136\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0722 - mean_squared_error: 0.1477\n",
      "Epoch 27: val_loss did not improve from 0.10286\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0722 - mean_squared_error: 0.1477 - val_loss: 0.1093 - val_mean_squared_error: 0.2219\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0704 - mean_squared_error: 0.1438\n",
      "Epoch 28: val_loss did not improve from 0.10286\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.0704 - mean_squared_error: 0.1438 - val_loss: 0.1039 - val_mean_squared_error: 0.2115\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0693 - mean_squared_error: 0.1414\n",
      "Epoch 29: val_loss did not improve from 0.10286\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0693 - mean_squared_error: 0.1414 - val_loss: 0.1154 - val_mean_squared_error: 0.2363\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0687 - mean_squared_error: 0.1403\n",
      "Epoch 30: val_loss improved from 0.10286 to 0.10227, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.0687 - mean_squared_error: 0.1403 - val_loss: 0.1023 - val_mean_squared_error: 0.2074\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0683 - mean_squared_error: 0.1396\n",
      "Epoch 31: val_loss did not improve from 0.10227\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.0683 - mean_squared_error: 0.1396 - val_loss: 0.1097 - val_mean_squared_error: 0.2240\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0664 - mean_squared_error: 0.1357\n",
      "Epoch 32: val_loss did not improve from 0.10227\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0664 - mean_squared_error: 0.1357 - val_loss: 0.1062 - val_mean_squared_error: 0.2162\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0674 - mean_squared_error: 0.1376\n",
      "Epoch 33: val_loss did not improve from 0.10227\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.0674 - mean_squared_error: 0.1376 - val_loss: 0.1059 - val_mean_squared_error: 0.2160\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0681 - mean_squared_error: 0.1388\n",
      "Epoch 34: val_loss improved from 0.10227 to 0.09811, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 0.0681 - mean_squared_error: 0.1388 - val_loss: 0.0981 - val_mean_squared_error: 0.2005\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0666 - mean_squared_error: 0.1361\n",
      "Epoch 35: val_loss did not improve from 0.09811\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0666 - mean_squared_error: 0.1361 - val_loss: 0.1053 - val_mean_squared_error: 0.2158\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0648 - mean_squared_error: 0.1323\n",
      "Epoch 36: val_loss did not improve from 0.09811\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0648 - mean_squared_error: 0.1323 - val_loss: 0.1023 - val_mean_squared_error: 0.2080\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0674 - mean_squared_error: 0.1374\n",
      "Epoch 37: val_loss did not improve from 0.09811\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0674 - mean_squared_error: 0.1374 - val_loss: 0.1050 - val_mean_squared_error: 0.2127\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0672 - mean_squared_error: 0.1373\n",
      "Epoch 38: val_loss did not improve from 0.09811\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0672 - mean_squared_error: 0.1373 - val_loss: 0.1070 - val_mean_squared_error: 0.2189\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0659 - mean_squared_error: 0.1342\n",
      "Epoch 39: val_loss improved from 0.09811 to 0.09745, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.0659 - mean_squared_error: 0.1342 - val_loss: 0.0974 - val_mean_squared_error: 0.1982\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0634 - mean_squared_error: 0.1296\n",
      "Epoch 40: val_loss did not improve from 0.09745\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0634 - mean_squared_error: 0.1296 - val_loss: 0.1048 - val_mean_squared_error: 0.2134\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0650 - mean_squared_error: 0.1328\n",
      "Epoch 41: val_loss did not improve from 0.09745\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0650 - mean_squared_error: 0.1328 - val_loss: 0.1114 - val_mean_squared_error: 0.2285\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0669 - mean_squared_error: 0.1365\n",
      "Epoch 42: val_loss improved from 0.09745 to 0.09640, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.0669 - mean_squared_error: 0.1365 - val_loss: 0.0964 - val_mean_squared_error: 0.1957\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0632 - mean_squared_error: 0.1290\n",
      "Epoch 43: val_loss did not improve from 0.09640\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.0632 - mean_squared_error: 0.1290 - val_loss: 0.1001 - val_mean_squared_error: 0.2045\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0629 - mean_squared_error: 0.1287\n",
      "Epoch 44: val_loss did not improve from 0.09640\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0629 - mean_squared_error: 0.1287 - val_loss: 0.1167 - val_mean_squared_error: 0.2374\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0638 - mean_squared_error: 0.1306\n",
      "Epoch 45: val_loss did not improve from 0.09640\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0638 - mean_squared_error: 0.1306 - val_loss: 0.1030 - val_mean_squared_error: 0.2109\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0605 - mean_squared_error: 0.1234\n",
      "Epoch 46: val_loss did not improve from 0.09640\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0605 - mean_squared_error: 0.1234 - val_loss: 0.0981 - val_mean_squared_error: 0.1993\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0593 - mean_squared_error: 0.1211\n",
      "Epoch 47: val_loss did not improve from 0.09640\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0593 - mean_squared_error: 0.1211 - val_loss: 0.1035 - val_mean_squared_error: 0.2108\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0598 - mean_squared_error: 0.1223\n",
      "Epoch 48: val_loss did not improve from 0.09640\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0598 - mean_squared_error: 0.1223 - val_loss: 0.1096 - val_mean_squared_error: 0.2243\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.0590 - mean_squared_error: 0.1202\n",
      "Epoch 49: val_loss did not improve from 0.09640\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0590 - mean_squared_error: 0.1202 - val_loss: 0.0976 - val_mean_squared_error: 0.1986\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0569 - mean_squared_error: 0.1161\n",
      "Epoch 50: val_loss did not improve from 0.09640\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0569 - mean_squared_error: 0.1161 - val_loss: 0.1017 - val_mean_squared_error: 0.2072\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0571 - mean_squared_error: 0.1165\n",
      "Epoch 51: val_loss did not improve from 0.09640\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.0571 - mean_squared_error: 0.1165 - val_loss: 0.1032 - val_mean_squared_error: 0.2106\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0549 - mean_squared_error: 0.1122\n",
      "Epoch 52: val_loss did not improve from 0.09640\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.0549 - mean_squared_error: 0.1122 - val_loss: 0.1009 - val_mean_squared_error: 0.2052\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0546 - mean_squared_error: 0.1116\n",
      "Epoch 53: val_loss did not improve from 0.09640\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0546 - mean_squared_error: 0.1116 - val_loss: 0.1032 - val_mean_squared_error: 0.2103\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0551 - mean_squared_error: 0.1124\n",
      "Epoch 54: val_loss improved from 0.09640 to 0.09393, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.0551 - mean_squared_error: 0.1124 - val_loss: 0.0939 - val_mean_squared_error: 0.1911\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0571 - mean_squared_error: 0.1169\n",
      "Epoch 55: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0571 - mean_squared_error: 0.1169 - val_loss: 0.1065 - val_mean_squared_error: 0.2180\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0553 - mean_squared_error: 0.1131\n",
      "Epoch 56: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0553 - mean_squared_error: 0.1131 - val_loss: 0.0949 - val_mean_squared_error: 0.1931\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0543 - mean_squared_error: 0.1112\n",
      "Epoch 57: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0543 - mean_squared_error: 0.1112 - val_loss: 0.1126 - val_mean_squared_error: 0.2296\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0534 - mean_squared_error: 0.1090\n",
      "Epoch 58: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0534 - mean_squared_error: 0.1090 - val_loss: 0.1016 - val_mean_squared_error: 0.2064\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0520 - mean_squared_error: 0.1064\n",
      "Epoch 59: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.0520 - mean_squared_error: 0.1064 - val_loss: 0.0998 - val_mean_squared_error: 0.2039\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0498 - mean_squared_error: 0.1018\n",
      "Epoch 60: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0498 - mean_squared_error: 0.1018 - val_loss: 0.1001 - val_mean_squared_error: 0.2040\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0499 - mean_squared_error: 0.1019\n",
      "Epoch 61: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.0499 - mean_squared_error: 0.1019 - val_loss: 0.1080 - val_mean_squared_error: 0.2207\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0494 - mean_squared_error: 0.1009\n",
      "Epoch 62: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0494 - mean_squared_error: 0.1009 - val_loss: 0.1048 - val_mean_squared_error: 0.2130\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0484 - mean_squared_error: 0.0987\n",
      "Epoch 63: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0484 - mean_squared_error: 0.0987 - val_loss: 0.1039 - val_mean_squared_error: 0.2124\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0491 - mean_squared_error: 0.1002\n",
      "Epoch 64: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0491 - mean_squared_error: 0.1002 - val_loss: 0.1060 - val_mean_squared_error: 0.2171\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0485 - mean_squared_error: 0.0991\n",
      "Epoch 65: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0485 - mean_squared_error: 0.0991 - val_loss: 0.0966 - val_mean_squared_error: 0.1967\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0489 - mean_squared_error: 0.0999\n",
      "Epoch 66: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0489 - mean_squared_error: 0.0999 - val_loss: 0.1038 - val_mean_squared_error: 0.2119\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0457 - mean_squared_error: 0.0933\n",
      "Epoch 67: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0457 - mean_squared_error: 0.0933 - val_loss: 0.1044 - val_mean_squared_error: 0.2128\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0448 - mean_squared_error: 0.0917\n",
      "Epoch 68: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.0448 - mean_squared_error: 0.0917 - val_loss: 0.1062 - val_mean_squared_error: 0.2168\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0435 - mean_squared_error: 0.0889\n",
      "Epoch 69: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.0435 - mean_squared_error: 0.0889 - val_loss: 0.1019 - val_mean_squared_error: 0.2077\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0440 - mean_squared_error: 0.0900\n",
      "Epoch 70: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0440 - mean_squared_error: 0.0900 - val_loss: 0.0973 - val_mean_squared_error: 0.1979\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.0921\n",
      "Epoch 71: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0450 - mean_squared_error: 0.0921 - val_loss: 0.1081 - val_mean_squared_error: 0.2205\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0433 - mean_squared_error: 0.0887\n",
      "Epoch 72: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0433 - mean_squared_error: 0.0887 - val_loss: 0.1082 - val_mean_squared_error: 0.2221\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0428 - mean_squared_error: 0.0874\n",
      "Epoch 73: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.0428 - mean_squared_error: 0.0874 - val_loss: 0.1019 - val_mean_squared_error: 0.2076\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0412 - mean_squared_error: 0.0843\n",
      "Epoch 74: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0412 - mean_squared_error: 0.0843 - val_loss: 0.1109 - val_mean_squared_error: 0.2261\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0829\n",
      "Epoch 75: val_loss did not improve from 0.09393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0405 - mean_squared_error: 0.0829 - val_loss: 0.1114 - val_mean_squared_error: 0.2282\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0411 - mean_squared_error: 0.0842\n",
      "Epoch 76: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0411 - mean_squared_error: 0.0842 - val_loss: 0.1071 - val_mean_squared_error: 0.2190\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0395 - mean_squared_error: 0.0807\n",
      "Epoch 77: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0395 - mean_squared_error: 0.0807 - val_loss: 0.1015 - val_mean_squared_error: 0.2074\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0412 - mean_squared_error: 0.0844\n",
      "Epoch 78: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0412 - mean_squared_error: 0.0844 - val_loss: 0.1088 - val_mean_squared_error: 0.2234\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0382 - mean_squared_error: 0.0782\n",
      "Epoch 79: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0382 - mean_squared_error: 0.0782 - val_loss: 0.1059 - val_mean_squared_error: 0.2168\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0363 - mean_squared_error: 0.0745\n",
      "Epoch 80: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0363 - mean_squared_error: 0.0745 - val_loss: 0.1169 - val_mean_squared_error: 0.2396\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0365 - mean_squared_error: 0.0748\n",
      "Epoch 81: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0365 - mean_squared_error: 0.0748 - val_loss: 0.1088 - val_mean_squared_error: 0.2232\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0351 - mean_squared_error: 0.0720\n",
      "Epoch 82: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.0351 - mean_squared_error: 0.0720 - val_loss: 0.1132 - val_mean_squared_error: 0.2327\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0371 - mean_squared_error: 0.0759\n",
      "Epoch 83: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0371 - mean_squared_error: 0.0759 - val_loss: 0.1106 - val_mean_squared_error: 0.2272\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0350 - mean_squared_error: 0.0719\n",
      "Epoch 84: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0350 - mean_squared_error: 0.0719 - val_loss: 0.1115 - val_mean_squared_error: 0.2285\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0342 - mean_squared_error: 0.0703\n",
      "Epoch 85: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0342 - mean_squared_error: 0.0703 - val_loss: 0.1179 - val_mean_squared_error: 0.2425\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0339 - mean_squared_error: 0.0696\n",
      "Epoch 86: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0339 - mean_squared_error: 0.0696 - val_loss: 0.1098 - val_mean_squared_error: 0.2259\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0329 - mean_squared_error: 0.0675\n",
      "Epoch 87: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.0329 - mean_squared_error: 0.0675 - val_loss: 0.1129 - val_mean_squared_error: 0.2314\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0317 - mean_squared_error: 0.0652\n",
      "Epoch 88: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0317 - mean_squared_error: 0.0652 - val_loss: 0.1120 - val_mean_squared_error: 0.2302\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0309 - mean_squared_error: 0.0635\n",
      "Epoch 89: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0309 - mean_squared_error: 0.0635 - val_loss: 0.1162 - val_mean_squared_error: 0.2388\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0305 - mean_squared_error: 0.0627\n",
      "Epoch 90: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0305 - mean_squared_error: 0.0627 - val_loss: 0.1087 - val_mean_squared_error: 0.2238\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0315 - mean_squared_error: 0.0648\n",
      "Epoch 91: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0315 - mean_squared_error: 0.0648 - val_loss: 0.1108 - val_mean_squared_error: 0.2275\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0308 - mean_squared_error: 0.0632\n",
      "Epoch 92: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0308 - mean_squared_error: 0.0632 - val_loss: 0.1120 - val_mean_squared_error: 0.2295\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0318 - mean_squared_error: 0.0653\n",
      "Epoch 93: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0318 - mean_squared_error: 0.0653 - val_loss: 0.1121 - val_mean_squared_error: 0.2296\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0296 - mean_squared_error: 0.0611\n",
      "Epoch 94: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0296 - mean_squared_error: 0.0611 - val_loss: 0.1161 - val_mean_squared_error: 0.2393\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0285 - mean_squared_error: 0.0588\n",
      "Epoch 95: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0285 - mean_squared_error: 0.0588 - val_loss: 0.1097 - val_mean_squared_error: 0.2257\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0304 - mean_squared_error: 0.0626\n",
      "Epoch 96: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0304 - mean_squared_error: 0.0626 - val_loss: 0.1160 - val_mean_squared_error: 0.2397\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0601\n",
      "Epoch 97: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0292 - mean_squared_error: 0.0601 - val_loss: 0.1132 - val_mean_squared_error: 0.2331\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0303 - mean_squared_error: 0.0623\n",
      "Epoch 98: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0303 - mean_squared_error: 0.0623 - val_loss: 0.1140 - val_mean_squared_error: 0.2354\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0293 - mean_squared_error: 0.0604\n",
      "Epoch 99: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0293 - mean_squared_error: 0.0604 - val_loss: 0.1118 - val_mean_squared_error: 0.2301\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0273 - mean_squared_error: 0.0564\n",
      "Epoch 100: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0273 - mean_squared_error: 0.0564 - val_loss: 0.1198 - val_mean_squared_error: 0.2480\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0253 - mean_squared_error: 0.0523\n",
      "Epoch 101: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0253 - mean_squared_error: 0.0523 - val_loss: 0.1153 - val_mean_squared_error: 0.2375\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0253 - mean_squared_error: 0.0523\n",
      "Epoch 102: val_loss did not improve from 0.09393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0253 - mean_squared_error: 0.0523 - val_loss: 0.1196 - val_mean_squared_error: 0.2463\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0258 - mean_squared_error: 0.0533\n",
      "Epoch 103: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.0258 - mean_squared_error: 0.0533 - val_loss: 0.1137 - val_mean_squared_error: 0.2342\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0520\n",
      "Epoch 104: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0251 - mean_squared_error: 0.0520 - val_loss: 0.1138 - val_mean_squared_error: 0.2346\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0231 - mean_squared_error: 0.0480\n",
      "Epoch 105: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0231 - mean_squared_error: 0.0480 - val_loss: 0.1149 - val_mean_squared_error: 0.2370\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0465\n",
      "Epoch 106: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0224 - mean_squared_error: 0.0465 - val_loss: 0.1108 - val_mean_squared_error: 0.2284\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0230 - mean_squared_error: 0.0477\n",
      "Epoch 107: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0230 - mean_squared_error: 0.0477 - val_loss: 0.1196 - val_mean_squared_error: 0.2466\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0220 - mean_squared_error: 0.0457\n",
      "Epoch 108: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0220 - mean_squared_error: 0.0457 - val_loss: 0.1166 - val_mean_squared_error: 0.2402\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0210 - mean_squared_error: 0.0437\n",
      "Epoch 109: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0210 - mean_squared_error: 0.0437 - val_loss: 0.1160 - val_mean_squared_error: 0.2397\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0208 - mean_squared_error: 0.0433\n",
      "Epoch 110: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0208 - mean_squared_error: 0.0433 - val_loss: 0.1164 - val_mean_squared_error: 0.2398\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0203 - mean_squared_error: 0.0423\n",
      "Epoch 111: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0203 - mean_squared_error: 0.0423 - val_loss: 0.1170 - val_mean_squared_error: 0.2425\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0404\n",
      "Epoch 112: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.0193 - mean_squared_error: 0.0404 - val_loss: 0.1176 - val_mean_squared_error: 0.2429\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.0393\n",
      "Epoch 113: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0188 - mean_squared_error: 0.0393 - val_loss: 0.1208 - val_mean_squared_error: 0.2499\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0195 - mean_squared_error: 0.0407\n",
      "Epoch 114: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0195 - mean_squared_error: 0.0407 - val_loss: 0.1121 - val_mean_squared_error: 0.2308\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0387\n",
      "Epoch 115: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0185 - mean_squared_error: 0.0387 - val_loss: 0.1189 - val_mean_squared_error: 0.2452\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0403\n",
      "Epoch 116: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0193 - mean_squared_error: 0.0403 - val_loss: 0.1143 - val_mean_squared_error: 0.2359\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0421\n",
      "Epoch 117: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.0202 - mean_squared_error: 0.0421 - val_loss: 0.1185 - val_mean_squared_error: 0.2444\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.0403\n",
      "Epoch 118: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0192 - mean_squared_error: 0.0403 - val_loss: 0.1146 - val_mean_squared_error: 0.2361\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0388\n",
      "Epoch 119: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0185 - mean_squared_error: 0.0388 - val_loss: 0.1188 - val_mean_squared_error: 0.2457\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0176 - mean_squared_error: 0.0368\n",
      "Epoch 120: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.0176 - mean_squared_error: 0.0368 - val_loss: 0.1166 - val_mean_squared_error: 0.2406\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0352\n",
      "Epoch 121: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.0167 - mean_squared_error: 0.0352 - val_loss: 0.1160 - val_mean_squared_error: 0.2400\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0342\n",
      "Epoch 122: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0163 - mean_squared_error: 0.0342 - val_loss: 0.1191 - val_mean_squared_error: 0.2469\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0338\n",
      "Epoch 123: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0161 - mean_squared_error: 0.0338 - val_loss: 0.1174 - val_mean_squared_error: 0.2426\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0339\n",
      "Epoch 124: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.0161 - mean_squared_error: 0.0339 - val_loss: 0.1203 - val_mean_squared_error: 0.2497\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0336\n",
      "Epoch 125: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0160 - mean_squared_error: 0.0336 - val_loss: 0.1202 - val_mean_squared_error: 0.2495\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0332\n",
      "Epoch 126: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0157 - mean_squared_error: 0.0332 - val_loss: 0.1218 - val_mean_squared_error: 0.2521\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0319\n",
      "Epoch 127: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0152 - mean_squared_error: 0.0319 - val_loss: 0.1218 - val_mean_squared_error: 0.2524\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0311\n",
      "Epoch 128: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0147 - mean_squared_error: 0.0311 - val_loss: 0.1217 - val_mean_squared_error: 0.2526\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0310\n",
      "Epoch 129: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0147 - mean_squared_error: 0.0310 - val_loss: 0.1198 - val_mean_squared_error: 0.2482\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0320\n",
      "Epoch 130: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0151 - mean_squared_error: 0.0320 - val_loss: 0.1202 - val_mean_squared_error: 0.2495\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0308\n",
      "Epoch 131: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0146 - mean_squared_error: 0.0308 - val_loss: 0.1184 - val_mean_squared_error: 0.2455\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0297\n",
      "Epoch 132: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0140 - mean_squared_error: 0.0297 - val_loss: 0.1208 - val_mean_squared_error: 0.2506\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0293\n",
      "Epoch 133: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0138 - mean_squared_error: 0.0293 - val_loss: 0.1209 - val_mean_squared_error: 0.2509\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0284\n",
      "Epoch 134: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.0133 - mean_squared_error: 0.0284 - val_loss: 0.1211 - val_mean_squared_error: 0.2518\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0277\n",
      "Epoch 135: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0130 - mean_squared_error: 0.0277 - val_loss: 0.1197 - val_mean_squared_error: 0.2481\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0275\n",
      "Epoch 136: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0129 - mean_squared_error: 0.0275 - val_loss: 0.1184 - val_mean_squared_error: 0.2459\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0271\n",
      "Epoch 137: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0127 - mean_squared_error: 0.0271 - val_loss: 0.1186 - val_mean_squared_error: 0.2460\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0272\n",
      "Epoch 138: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0127 - mean_squared_error: 0.0272 - val_loss: 0.1217 - val_mean_squared_error: 0.2530\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0269\n",
      "Epoch 139: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0126 - mean_squared_error: 0.0269 - val_loss: 0.1191 - val_mean_squared_error: 0.2473\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0272\n",
      "Epoch 140: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0127 - mean_squared_error: 0.0272 - val_loss: 0.1195 - val_mean_squared_error: 0.2480\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0266\n",
      "Epoch 141: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0125 - mean_squared_error: 0.0266 - val_loss: 0.1188 - val_mean_squared_error: 0.2467\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0259\n",
      "Epoch 142: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0121 - mean_squared_error: 0.0259 - val_loss: 0.1211 - val_mean_squared_error: 0.2523\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0262\n",
      "Epoch 143: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0123 - mean_squared_error: 0.0262 - val_loss: 0.1207 - val_mean_squared_error: 0.2514\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0252\n",
      "Epoch 144: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0118 - mean_squared_error: 0.0252 - val_loss: 0.1196 - val_mean_squared_error: 0.2488\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0268\n",
      "Epoch 145: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0126 - mean_squared_error: 0.0268 - val_loss: 0.1191 - val_mean_squared_error: 0.2478\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0273\n",
      "Epoch 146: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0128 - mean_squared_error: 0.0273 - val_loss: 0.1219 - val_mean_squared_error: 0.2531\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0259\n",
      "Epoch 147: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.0121 - mean_squared_error: 0.0259 - val_loss: 0.1235 - val_mean_squared_error: 0.2566\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0256\n",
      "Epoch 148: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0120 - mean_squared_error: 0.0256 - val_loss: 0.1234 - val_mean_squared_error: 0.2579\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0249\n",
      "Epoch 149: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0116 - mean_squared_error: 0.0249 - val_loss: 0.1249 - val_mean_squared_error: 0.2606\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0242\n",
      "Epoch 150: val_loss did not improve from 0.09393\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.0113 - mean_squared_error: 0.0242 - val_loss: 0.1209 - val_mean_squared_error: 0.2523\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000198FFDD9430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "5/5 [==============================] - 10s 32ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  72\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4000 - mean_squared_error: 0.9013\n",
      "Epoch 1: val_loss improved from inf to 0.29151, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 72s 2s/step - loss: 0.4000 - mean_squared_error: 0.9013 - val_loss: 0.2915 - val_mean_squared_error: 0.6432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3296 - mean_squared_error: 0.7190\n",
      "Epoch 2: val_loss improved from 0.29151 to 0.28727, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.3296 - mean_squared_error: 0.7190 - val_loss: 0.2873 - val_mean_squared_error: 0.6197\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2971 - mean_squared_error: 0.6338\n",
      "Epoch 3: val_loss improved from 0.28727 to 0.24146, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 564ms/step - loss: 0.2971 - mean_squared_error: 0.6338 - val_loss: 0.2415 - val_mean_squared_error: 0.5069\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1864 - mean_squared_error: 0.3884\n",
      "Epoch 4: val_loss improved from 0.24146 to 0.15022, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 558ms/step - loss: 0.1864 - mean_squared_error: 0.3884 - val_loss: 0.1502 - val_mean_squared_error: 0.3083\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1137 - mean_squared_error: 0.2329\n",
      "Epoch 5: val_loss improved from 0.15022 to 0.12286, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.1137 - mean_squared_error: 0.2329 - val_loss: 0.1229 - val_mean_squared_error: 0.2501\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1043 - mean_squared_error: 0.2123\n",
      "Epoch 6: val_loss did not improve from 0.12286\n",
      "10/10 [==============================] - 5s 534ms/step - loss: 0.1043 - mean_squared_error: 0.2123 - val_loss: 0.1247 - val_mean_squared_error: 0.2540\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0944 - mean_squared_error: 0.1927\n",
      "Epoch 7: val_loss improved from 0.12286 to 0.11464, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.0944 - mean_squared_error: 0.1927 - val_loss: 0.1146 - val_mean_squared_error: 0.2337\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0913 - mean_squared_error: 0.1870\n",
      "Epoch 8: val_loss did not improve from 0.11464\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0913 - mean_squared_error: 0.1870 - val_loss: 0.1161 - val_mean_squared_error: 0.2380\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0885 - mean_squared_error: 0.1814\n",
      "Epoch 9: val_loss did not improve from 0.11464\n",
      "10/10 [==============================] - 5s 534ms/step - loss: 0.0885 - mean_squared_error: 0.1814 - val_loss: 0.1150 - val_mean_squared_error: 0.2351\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0849 - mean_squared_error: 0.1735\n",
      "Epoch 10: val_loss did not improve from 0.11464\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0849 - mean_squared_error: 0.1735 - val_loss: 0.1174 - val_mean_squared_error: 0.2400\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0845 - mean_squared_error: 0.1727\n",
      "Epoch 11: val_loss did not improve from 0.11464\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 0.0845 - mean_squared_error: 0.1727 - val_loss: 0.1158 - val_mean_squared_error: 0.2374\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0814 - mean_squared_error: 0.1663\n",
      "Epoch 12: val_loss improved from 0.11464 to 0.11139, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.0814 - mean_squared_error: 0.1663 - val_loss: 0.1114 - val_mean_squared_error: 0.2269\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0792 - mean_squared_error: 0.1620\n",
      "Epoch 13: val_loss did not improve from 0.11139\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0792 - mean_squared_error: 0.1620 - val_loss: 0.1123 - val_mean_squared_error: 0.2301\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0803 - mean_squared_error: 0.1640\n",
      "Epoch 14: val_loss improved from 0.11139 to 0.11084, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.0803 - mean_squared_error: 0.1640 - val_loss: 0.1108 - val_mean_squared_error: 0.2267\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0787 - mean_squared_error: 0.1605\n",
      "Epoch 15: val_loss improved from 0.11084 to 0.10902, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 5s 551ms/step - loss: 0.0787 - mean_squared_error: 0.1605 - val_loss: 0.1090 - val_mean_squared_error: 0.2218\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0770 - mean_squared_error: 0.1575\n",
      "Epoch 16: val_loss improved from 0.10902 to 0.10706, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.0770 - mean_squared_error: 0.1575 - val_loss: 0.1071 - val_mean_squared_error: 0.2173\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0748 - mean_squared_error: 0.1529\n",
      "Epoch 17: val_loss improved from 0.10706 to 0.10319, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 551ms/step - loss: 0.0748 - mean_squared_error: 0.1529 - val_loss: 0.1032 - val_mean_squared_error: 0.2102\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0757 - mean_squared_error: 0.1549\n",
      "Epoch 18: val_loss did not improve from 0.10319\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0757 - mean_squared_error: 0.1549 - val_loss: 0.1112 - val_mean_squared_error: 0.2267\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0748 - mean_squared_error: 0.1526\n",
      "Epoch 19: val_loss improved from 0.10319 to 0.10100, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 552ms/step - loss: 0.0748 - mean_squared_error: 0.1526 - val_loss: 0.1010 - val_mean_squared_error: 0.2052\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0738 - mean_squared_error: 0.1507\n",
      "Epoch 20: val_loss improved from 0.10100 to 0.09922, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 5s 551ms/step - loss: 0.0738 - mean_squared_error: 0.1507 - val_loss: 0.0992 - val_mean_squared_error: 0.2020\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0717 - mean_squared_error: 0.1467\n",
      "Epoch 21: val_loss did not improve from 0.09922\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 0.0717 - mean_squared_error: 0.1467 - val_loss: 0.1041 - val_mean_squared_error: 0.2112\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0696 - mean_squared_error: 0.1420\n",
      "Epoch 22: val_loss improved from 0.09922 to 0.09811, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 5s 548ms/step - loss: 0.0696 - mean_squared_error: 0.1420 - val_loss: 0.0981 - val_mean_squared_error: 0.1993\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0681 - mean_squared_error: 0.1388\n",
      "Epoch 23: val_loss improved from 0.09811 to 0.09712, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 552ms/step - loss: 0.0681 - mean_squared_error: 0.1388 - val_loss: 0.0971 - val_mean_squared_error: 0.1971\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0671 - mean_squared_error: 0.1371\n",
      "Epoch 24: val_loss did not improve from 0.09712\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 0.0671 - mean_squared_error: 0.1371 - val_loss: 0.0993 - val_mean_squared_error: 0.2019\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0671 - mean_squared_error: 0.1369\n",
      "Epoch 25: val_loss did not improve from 0.09712\n",
      "10/10 [==============================] - 5s 536ms/step - loss: 0.0671 - mean_squared_error: 0.1369 - val_loss: 0.0997 - val_mean_squared_error: 0.2023\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0662 - mean_squared_error: 0.1352\n",
      "Epoch 26: val_loss improved from 0.09712 to 0.09653, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.0662 - mean_squared_error: 0.1352 - val_loss: 0.0965 - val_mean_squared_error: 0.1960\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0661 - mean_squared_error: 0.1350\n",
      "Epoch 27: val_loss did not improve from 0.09653\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0661 - mean_squared_error: 0.1350 - val_loss: 0.0992 - val_mean_squared_error: 0.2014\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0650 - mean_squared_error: 0.1328\n",
      "Epoch 28: val_loss did not improve from 0.09653\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0650 - mean_squared_error: 0.1328 - val_loss: 0.1030 - val_mean_squared_error: 0.2090\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0679 - mean_squared_error: 0.1386\n",
      "Epoch 29: val_loss improved from 0.09653 to 0.09573, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 552ms/step - loss: 0.0679 - mean_squared_error: 0.1386 - val_loss: 0.0957 - val_mean_squared_error: 0.1949\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0701 - mean_squared_error: 0.1432\n",
      "Epoch 30: val_loss did not improve from 0.09573\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 0.0701 - mean_squared_error: 0.1432 - val_loss: 0.1064 - val_mean_squared_error: 0.2161\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0666 - mean_squared_error: 0.1363\n",
      "Epoch 31: val_loss did not improve from 0.09573\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 0.0666 - mean_squared_error: 0.1363 - val_loss: 0.0972 - val_mean_squared_error: 0.1976\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0652 - mean_squared_error: 0.1331\n",
      "Epoch 32: val_loss did not improve from 0.09573\n",
      "10/10 [==============================] - 5s 534ms/step - loss: 0.0652 - mean_squared_error: 0.1331 - val_loss: 0.0973 - val_mean_squared_error: 0.1976\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0626 - mean_squared_error: 0.1279\n",
      "Epoch 33: val_loss did not improve from 0.09573\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 0.0626 - mean_squared_error: 0.1279 - val_loss: 0.0967 - val_mean_squared_error: 0.1960\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0635 - mean_squared_error: 0.1295\n",
      "Epoch 34: val_loss improved from 0.09573 to 0.09476, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 5s 551ms/step - loss: 0.0635 - mean_squared_error: 0.1295 - val_loss: 0.0948 - val_mean_squared_error: 0.1922\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0622 - mean_squared_error: 0.1269\n",
      "Epoch 35: val_loss did not improve from 0.09476\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0622 - mean_squared_error: 0.1269 - val_loss: 0.0962 - val_mean_squared_error: 0.1951\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0655 - mean_squared_error: 0.1338\n",
      "Epoch 36: val_loss did not improve from 0.09476\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 0.0655 - mean_squared_error: 0.1338 - val_loss: 0.1004 - val_mean_squared_error: 0.2038\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0664 - mean_squared_error: 0.1355\n",
      "Epoch 37: val_loss did not improve from 0.09476\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 0.0664 - mean_squared_error: 0.1355 - val_loss: 0.1008 - val_mean_squared_error: 0.2052\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0637 - mean_squared_error: 0.1297\n",
      "Epoch 38: val_loss improved from 0.09476 to 0.09369, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 559ms/step - loss: 0.0637 - mean_squared_error: 0.1297 - val_loss: 0.0937 - val_mean_squared_error: 0.1899\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0619 - mean_squared_error: 0.1261\n",
      "Epoch 39: val_loss did not improve from 0.09369\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 0.0619 - mean_squared_error: 0.1261 - val_loss: 0.0949 - val_mean_squared_error: 0.1926\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0606 - mean_squared_error: 0.1234\n",
      "Epoch 40: val_loss did not improve from 0.09369\n",
      "10/10 [==============================] - 5s 534ms/step - loss: 0.0606 - mean_squared_error: 0.1234 - val_loss: 0.0964 - val_mean_squared_error: 0.1961\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0614 - mean_squared_error: 0.1252\n",
      "Epoch 41: val_loss did not improve from 0.09369\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0614 - mean_squared_error: 0.1252 - val_loss: 0.0996 - val_mean_squared_error: 0.2019\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0603 - mean_squared_error: 0.1230\n",
      "Epoch 42: val_loss did not improve from 0.09369\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 0.0603 - mean_squared_error: 0.1230 - val_loss: 0.0961 - val_mean_squared_error: 0.1946\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0616 - mean_squared_error: 0.1256\n",
      "Epoch 43: val_loss did not improve from 0.09369\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0616 - mean_squared_error: 0.1256 - val_loss: 0.0940 - val_mean_squared_error: 0.1905\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0595 - mean_squared_error: 0.1216\n",
      "Epoch 44: val_loss did not improve from 0.09369\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 0.0595 - mean_squared_error: 0.1216 - val_loss: 0.1000 - val_mean_squared_error: 0.2025\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0586 - mean_squared_error: 0.1196\n",
      "Epoch 45: val_loss improved from 0.09369 to 0.09324, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.0586 - mean_squared_error: 0.1196 - val_loss: 0.0932 - val_mean_squared_error: 0.1893\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0578 - mean_squared_error: 0.1180\n",
      "Epoch 46: val_loss did not improve from 0.09324\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 0.0578 - mean_squared_error: 0.1180 - val_loss: 0.0993 - val_mean_squared_error: 0.2011\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0567 - mean_squared_error: 0.1156\n",
      "Epoch 47: val_loss did not improve from 0.09324\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 0.0567 - mean_squared_error: 0.1156 - val_loss: 0.0938 - val_mean_squared_error: 0.1907\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0578 - mean_squared_error: 0.1181\n",
      "Epoch 48: val_loss did not improve from 0.09324\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0578 - mean_squared_error: 0.1181 - val_loss: 0.0969 - val_mean_squared_error: 0.1965\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0566 - mean_squared_error: 0.1153\n",
      "Epoch 49: val_loss improved from 0.09324 to 0.09256, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 567ms/step - loss: 0.0566 - mean_squared_error: 0.1153 - val_loss: 0.0926 - val_mean_squared_error: 0.1875\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0570 - mean_squared_error: 0.1162\n",
      "Epoch 50: val_loss did not improve from 0.09256\n",
      "10/10 [==============================] - 5s 536ms/step - loss: 0.0570 - mean_squared_error: 0.1162 - val_loss: 0.0963 - val_mean_squared_error: 0.1948\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0563 - mean_squared_error: 0.1147\n",
      "Epoch 51: val_loss did not improve from 0.09256\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 0.0563 - mean_squared_error: 0.1147 - val_loss: 0.0986 - val_mean_squared_error: 0.1995\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0557 - mean_squared_error: 0.1136\n",
      "Epoch 52: val_loss improved from 0.09256 to 0.09198, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 6s 566ms/step - loss: 0.0557 - mean_squared_error: 0.1136 - val_loss: 0.0920 - val_mean_squared_error: 0.1863\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0545 - mean_squared_error: 0.1112\n",
      "Epoch 53: val_loss did not improve from 0.09198\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0545 - mean_squared_error: 0.1112 - val_loss: 0.0968 - val_mean_squared_error: 0.1960\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0549 - mean_squared_error: 0.1119\n",
      "Epoch 54: val_loss did not improve from 0.09198\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0549 - mean_squared_error: 0.1119 - val_loss: 0.0925 - val_mean_squared_error: 0.1874\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0553 - mean_squared_error: 0.1127\n",
      "Epoch 55: val_loss did not improve from 0.09198\n",
      "10/10 [==============================] - 5s 530ms/step - loss: 0.0553 - mean_squared_error: 0.1127 - val_loss: 0.0921 - val_mean_squared_error: 0.1862\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0533 - mean_squared_error: 0.1086\n",
      "Epoch 56: val_loss did not improve from 0.09198\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0533 - mean_squared_error: 0.1086 - val_loss: 0.0952 - val_mean_squared_error: 0.1931\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0520 - mean_squared_error: 0.1061\n",
      "Epoch 57: val_loss did not improve from 0.09198\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0520 - mean_squared_error: 0.1061 - val_loss: 0.0943 - val_mean_squared_error: 0.1913\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0513 - mean_squared_error: 0.1047\n",
      "Epoch 58: val_loss did not improve from 0.09198\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0513 - mean_squared_error: 0.1047 - val_loss: 0.0996 - val_mean_squared_error: 0.2015\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0527 - mean_squared_error: 0.1075\n",
      "Epoch 59: val_loss did not improve from 0.09198\n",
      "10/10 [==============================] - 5s 539ms/step - loss: 0.0527 - mean_squared_error: 0.1075 - val_loss: 0.0983 - val_mean_squared_error: 0.1993\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0508 - mean_squared_error: 0.1035\n",
      "Epoch 60: val_loss did not improve from 0.09198\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0508 - mean_squared_error: 0.1035 - val_loss: 0.0954 - val_mean_squared_error: 0.1946\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0502 - mean_squared_error: 0.1025\n",
      "Epoch 61: val_loss did not improve from 0.09198\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0502 - mean_squared_error: 0.1025 - val_loss: 0.0992 - val_mean_squared_error: 0.2003\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0483 - mean_squared_error: 0.0986\n",
      "Epoch 62: val_loss did not improve from 0.09198\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0483 - mean_squared_error: 0.0986 - val_loss: 0.0934 - val_mean_squared_error: 0.1899\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0469 - mean_squared_error: 0.0958\n",
      "Epoch 63: val_loss did not improve from 0.09198\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0469 - mean_squared_error: 0.0958 - val_loss: 0.0930 - val_mean_squared_error: 0.1894\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0464 - mean_squared_error: 0.0947\n",
      "Epoch 64: val_loss did not improve from 0.09198\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0464 - mean_squared_error: 0.0947 - val_loss: 0.0973 - val_mean_squared_error: 0.1965\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0493 - mean_squared_error: 0.1005\n",
      "Epoch 65: val_loss did not improve from 0.09198\n",
      "10/10 [==============================] - 5s 536ms/step - loss: 0.0493 - mean_squared_error: 0.1005 - val_loss: 0.0971 - val_mean_squared_error: 0.1973\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0481 - mean_squared_error: 0.0980\n",
      "Epoch 66: val_loss improved from 0.09198 to 0.09086, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 5s 552ms/step - loss: 0.0481 - mean_squared_error: 0.0980 - val_loss: 0.0909 - val_mean_squared_error: 0.1853\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0471 - mean_squared_error: 0.0962\n",
      "Epoch 67: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 536ms/step - loss: 0.0471 - mean_squared_error: 0.0962 - val_loss: 0.0958 - val_mean_squared_error: 0.1946\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0454 - mean_squared_error: 0.0927\n",
      "Epoch 68: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 543ms/step - loss: 0.0454 - mean_squared_error: 0.0927 - val_loss: 0.0991 - val_mean_squared_error: 0.2015\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0447 - mean_squared_error: 0.0913\n",
      "Epoch 69: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0447 - mean_squared_error: 0.0913 - val_loss: 0.0965 - val_mean_squared_error: 0.1956\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.0921\n",
      "Epoch 70: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 543ms/step - loss: 0.0450 - mean_squared_error: 0.0921 - val_loss: 0.0988 - val_mean_squared_error: 0.2008\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0454 - mean_squared_error: 0.0924\n",
      "Epoch 71: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 534ms/step - loss: 0.0454 - mean_squared_error: 0.0924 - val_loss: 0.1018 - val_mean_squared_error: 0.2073\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0421 - mean_squared_error: 0.0860\n",
      "Epoch 72: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0421 - mean_squared_error: 0.0860 - val_loss: 0.1036 - val_mean_squared_error: 0.2108\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0411 - mean_squared_error: 0.0840\n",
      "Epoch 73: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 540ms/step - loss: 0.0411 - mean_squared_error: 0.0840 - val_loss: 0.0997 - val_mean_squared_error: 0.2028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0408 - mean_squared_error: 0.0834\n",
      "Epoch 74: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 544ms/step - loss: 0.0408 - mean_squared_error: 0.0834 - val_loss: 0.0986 - val_mean_squared_error: 0.2006\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0805\n",
      "Epoch 75: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 547ms/step - loss: 0.0394 - mean_squared_error: 0.0805 - val_loss: 0.0958 - val_mean_squared_error: 0.1949\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0383 - mean_squared_error: 0.0784\n",
      "Epoch 76: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 542ms/step - loss: 0.0383 - mean_squared_error: 0.0784 - val_loss: 0.1019 - val_mean_squared_error: 0.2071\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0794\n",
      "Epoch 77: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 545ms/step - loss: 0.0388 - mean_squared_error: 0.0794 - val_loss: 0.0929 - val_mean_squared_error: 0.1891\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0376 - mean_squared_error: 0.0769\n",
      "Epoch 78: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 541ms/step - loss: 0.0376 - mean_squared_error: 0.0769 - val_loss: 0.1020 - val_mean_squared_error: 0.2082\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0373 - mean_squared_error: 0.0764\n",
      "Epoch 79: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 542ms/step - loss: 0.0373 - mean_squared_error: 0.0764 - val_loss: 0.0997 - val_mean_squared_error: 0.2024\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0363 - mean_squared_error: 0.0744\n",
      "Epoch 80: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 541ms/step - loss: 0.0363 - mean_squared_error: 0.0744 - val_loss: 0.1009 - val_mean_squared_error: 0.2066\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0352 - mean_squared_error: 0.0721\n",
      "Epoch 81: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 544ms/step - loss: 0.0352 - mean_squared_error: 0.0721 - val_loss: 0.1010 - val_mean_squared_error: 0.2051\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0346 - mean_squared_error: 0.0711\n",
      "Epoch 82: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 545ms/step - loss: 0.0346 - mean_squared_error: 0.0711 - val_loss: 0.1018 - val_mean_squared_error: 0.2081\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0363 - mean_squared_error: 0.0744\n",
      "Epoch 83: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0363 - mean_squared_error: 0.0744 - val_loss: 0.1006 - val_mean_squared_error: 0.2043\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0340 - mean_squared_error: 0.0697\n",
      "Epoch 84: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0340 - mean_squared_error: 0.0697 - val_loss: 0.1065 - val_mean_squared_error: 0.2163\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0335 - mean_squared_error: 0.0688\n",
      "Epoch 85: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0335 - mean_squared_error: 0.0688 - val_loss: 0.1042 - val_mean_squared_error: 0.2140\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0333 - mean_squared_error: 0.0684\n",
      "Epoch 86: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 539ms/step - loss: 0.0333 - mean_squared_error: 0.0684 - val_loss: 0.0984 - val_mean_squared_error: 0.2013\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0332 - mean_squared_error: 0.0681\n",
      "Epoch 87: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 544ms/step - loss: 0.0332 - mean_squared_error: 0.0681 - val_loss: 0.1081 - val_mean_squared_error: 0.2207\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0317 - mean_squared_error: 0.0651\n",
      "Epoch 88: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 542ms/step - loss: 0.0317 - mean_squared_error: 0.0651 - val_loss: 0.1084 - val_mean_squared_error: 0.2211\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0314 - mean_squared_error: 0.0646\n",
      "Epoch 89: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 543ms/step - loss: 0.0314 - mean_squared_error: 0.0646 - val_loss: 0.1041 - val_mean_squared_error: 0.2128\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0304 - mean_squared_error: 0.0625\n",
      "Epoch 90: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 543ms/step - loss: 0.0304 - mean_squared_error: 0.0625 - val_loss: 0.1085 - val_mean_squared_error: 0.2214\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0309 - mean_squared_error: 0.0634\n",
      "Epoch 91: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 541ms/step - loss: 0.0309 - mean_squared_error: 0.0634 - val_loss: 0.1114 - val_mean_squared_error: 0.2288\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0290 - mean_squared_error: 0.0598\n",
      "Epoch 92: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0290 - mean_squared_error: 0.0598 - val_loss: 0.1089 - val_mean_squared_error: 0.2225\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0602\n",
      "Epoch 93: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 539ms/step - loss: 0.0292 - mean_squared_error: 0.0602 - val_loss: 0.1072 - val_mean_squared_error: 0.2187\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0302 - mean_squared_error: 0.0621\n",
      "Epoch 94: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 521ms/step - loss: 0.0302 - mean_squared_error: 0.0621 - val_loss: 0.1123 - val_mean_squared_error: 0.2290\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0280 - mean_squared_error: 0.0578\n",
      "Epoch 95: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 540ms/step - loss: 0.0280 - mean_squared_error: 0.0578 - val_loss: 0.1087 - val_mean_squared_error: 0.2223\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0269 - mean_squared_error: 0.0557\n",
      "Epoch 96: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 546ms/step - loss: 0.0269 - mean_squared_error: 0.0557 - val_loss: 0.1047 - val_mean_squared_error: 0.2142\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0263 - mean_squared_error: 0.0542\n",
      "Epoch 97: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 540ms/step - loss: 0.0263 - mean_squared_error: 0.0542 - val_loss: 0.1120 - val_mean_squared_error: 0.2291\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0258 - mean_squared_error: 0.0534\n",
      "Epoch 98: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 541ms/step - loss: 0.0258 - mean_squared_error: 0.0534 - val_loss: 0.1057 - val_mean_squared_error: 0.2155\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0257 - mean_squared_error: 0.0531\n",
      "Epoch 99: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 539ms/step - loss: 0.0257 - mean_squared_error: 0.0531 - val_loss: 0.1100 - val_mean_squared_error: 0.2253\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0519\n",
      "Epoch 100: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 540ms/step - loss: 0.0251 - mean_squared_error: 0.0519 - val_loss: 0.1112 - val_mean_squared_error: 0.2278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0244 - mean_squared_error: 0.0504\n",
      "Epoch 101: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 543ms/step - loss: 0.0244 - mean_squared_error: 0.0504 - val_loss: 0.1074 - val_mean_squared_error: 0.2194\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0242 - mean_squared_error: 0.0502\n",
      "Epoch 102: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 519ms/step - loss: 0.0242 - mean_squared_error: 0.0502 - val_loss: 0.1048 - val_mean_squared_error: 0.2144\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0232 - mean_squared_error: 0.0480\n",
      "Epoch 103: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 540ms/step - loss: 0.0232 - mean_squared_error: 0.0480 - val_loss: 0.1108 - val_mean_squared_error: 0.2269\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0231 - mean_squared_error: 0.0478\n",
      "Epoch 104: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0231 - mean_squared_error: 0.0478 - val_loss: 0.1150 - val_mean_squared_error: 0.2355\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0240 - mean_squared_error: 0.0497\n",
      "Epoch 105: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 543ms/step - loss: 0.0240 - mean_squared_error: 0.0497 - val_loss: 0.1094 - val_mean_squared_error: 0.2243\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0237 - mean_squared_error: 0.0492\n",
      "Epoch 106: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 540ms/step - loss: 0.0237 - mean_squared_error: 0.0492 - val_loss: 0.1101 - val_mean_squared_error: 0.2248\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0232 - mean_squared_error: 0.0481\n",
      "Epoch 107: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0232 - mean_squared_error: 0.0481 - val_loss: 0.1049 - val_mean_squared_error: 0.2144\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0226 - mean_squared_error: 0.0469\n",
      "Epoch 108: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0226 - mean_squared_error: 0.0469 - val_loss: 0.1106 - val_mean_squared_error: 0.2277\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0228 - mean_squared_error: 0.0472\n",
      "Epoch 109: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0228 - mean_squared_error: 0.0472 - val_loss: 0.1126 - val_mean_squared_error: 0.2302\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0212 - mean_squared_error: 0.0440\n",
      "Epoch 110: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 539ms/step - loss: 0.0212 - mean_squared_error: 0.0440 - val_loss: 0.1113 - val_mean_squared_error: 0.2284\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0420\n",
      "Epoch 111: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 522ms/step - loss: 0.0202 - mean_squared_error: 0.0420 - val_loss: 0.1112 - val_mean_squared_error: 0.2279\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0199 - mean_squared_error: 0.0414\n",
      "Epoch 112: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0199 - mean_squared_error: 0.0414 - val_loss: 0.1186 - val_mean_squared_error: 0.2433\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0208 - mean_squared_error: 0.0434\n",
      "Epoch 113: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 536ms/step - loss: 0.0208 - mean_squared_error: 0.0434 - val_loss: 0.1156 - val_mean_squared_error: 0.2368\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0444\n",
      "Epoch 114: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0213 - mean_squared_error: 0.0444 - val_loss: 0.1129 - val_mean_squared_error: 0.2306\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0221 - mean_squared_error: 0.0460\n",
      "Epoch 115: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0221 - mean_squared_error: 0.0460 - val_loss: 0.1090 - val_mean_squared_error: 0.2227\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0218 - mean_squared_error: 0.0454\n",
      "Epoch 116: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0218 - mean_squared_error: 0.0454 - val_loss: 0.1133 - val_mean_squared_error: 0.2333\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0205 - mean_squared_error: 0.0426\n",
      "Epoch 117: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0205 - mean_squared_error: 0.0426 - val_loss: 0.1109 - val_mean_squared_error: 0.2273\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0395\n",
      "Epoch 118: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0189 - mean_squared_error: 0.0395 - val_loss: 0.1088 - val_mean_squared_error: 0.2235\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0191 - mean_squared_error: 0.0400\n",
      "Epoch 119: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0191 - mean_squared_error: 0.0400 - val_loss: 0.1130 - val_mean_squared_error: 0.2322\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0395\n",
      "Epoch 120: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 529ms/step - loss: 0.0189 - mean_squared_error: 0.0395 - val_loss: 0.1093 - val_mean_squared_error: 0.2231\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0198 - mean_squared_error: 0.0413\n",
      "Epoch 121: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 0.0198 - mean_squared_error: 0.0413 - val_loss: 0.1134 - val_mean_squared_error: 0.2326\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0385\n",
      "Epoch 122: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 0.0185 - mean_squared_error: 0.0385 - val_loss: 0.1106 - val_mean_squared_error: 0.2279\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0379\n",
      "Epoch 123: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0181 - mean_squared_error: 0.0379 - val_loss: 0.1105 - val_mean_squared_error: 0.2261\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0361\n",
      "Epoch 124: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 539ms/step - loss: 0.0172 - mean_squared_error: 0.0361 - val_loss: 0.1125 - val_mean_squared_error: 0.2308\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0353\n",
      "Epoch 125: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0168 - mean_squared_error: 0.0353 - val_loss: 0.1148 - val_mean_squared_error: 0.2356\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0340\n",
      "Epoch 126: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0162 - mean_squared_error: 0.0340 - val_loss: 0.1110 - val_mean_squared_error: 0.2274\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0340\n",
      "Epoch 127: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 0.0161 - mean_squared_error: 0.0340 - val_loss: 0.1114 - val_mean_squared_error: 0.2284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0339\n",
      "Epoch 128: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0161 - mean_squared_error: 0.0339 - val_loss: 0.1144 - val_mean_squared_error: 0.2348\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0332\n",
      "Epoch 129: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 536ms/step - loss: 0.0157 - mean_squared_error: 0.0332 - val_loss: 0.1157 - val_mean_squared_error: 0.2370\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0153 - mean_squared_error: 0.0324\n",
      "Epoch 130: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0153 - mean_squared_error: 0.0324 - val_loss: 0.1146 - val_mean_squared_error: 0.2350\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0310\n",
      "Epoch 131: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 0.0146 - mean_squared_error: 0.0310 - val_loss: 0.1159 - val_mean_squared_error: 0.2383\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0323\n",
      "Epoch 132: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 540ms/step - loss: 0.0152 - mean_squared_error: 0.0323 - val_loss: 0.1131 - val_mean_squared_error: 0.2323\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0314\n",
      "Epoch 133: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 539ms/step - loss: 0.0148 - mean_squared_error: 0.0314 - val_loss: 0.1165 - val_mean_squared_error: 0.2390\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0304\n",
      "Epoch 134: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 0.0144 - mean_squared_error: 0.0304 - val_loss: 0.1170 - val_mean_squared_error: 0.2398\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0293\n",
      "Epoch 135: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0138 - mean_squared_error: 0.0293 - val_loss: 0.1151 - val_mean_squared_error: 0.2363\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0287\n",
      "Epoch 136: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 532ms/step - loss: 0.0135 - mean_squared_error: 0.0287 - val_loss: 0.1160 - val_mean_squared_error: 0.2379\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0287\n",
      "Epoch 137: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0135 - mean_squared_error: 0.0287 - val_loss: 0.1182 - val_mean_squared_error: 0.2427\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0281\n",
      "Epoch 138: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 539ms/step - loss: 0.0132 - mean_squared_error: 0.0281 - val_loss: 0.1132 - val_mean_squared_error: 0.2321\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0273\n",
      "Epoch 139: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 541ms/step - loss: 0.0128 - mean_squared_error: 0.0273 - val_loss: 0.1194 - val_mean_squared_error: 0.2452\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0268\n",
      "Epoch 140: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 541ms/step - loss: 0.0125 - mean_squared_error: 0.0268 - val_loss: 0.1188 - val_mean_squared_error: 0.2438\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0263\n",
      "Epoch 141: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 543ms/step - loss: 0.0122 - mean_squared_error: 0.0263 - val_loss: 0.1209 - val_mean_squared_error: 0.2484\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0261\n",
      "Epoch 142: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 540ms/step - loss: 0.0122 - mean_squared_error: 0.0261 - val_loss: 0.1204 - val_mean_squared_error: 0.2472\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0258\n",
      "Epoch 143: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 543ms/step - loss: 0.0120 - mean_squared_error: 0.0258 - val_loss: 0.1187 - val_mean_squared_error: 0.2438\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0258\n",
      "Epoch 144: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 544ms/step - loss: 0.0120 - mean_squared_error: 0.0258 - val_loss: 0.1206 - val_mean_squared_error: 0.2483\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0262\n",
      "Epoch 145: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 541ms/step - loss: 0.0122 - mean_squared_error: 0.0262 - val_loss: 0.1197 - val_mean_squared_error: 0.2460\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0250\n",
      "Epoch 146: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 543ms/step - loss: 0.0117 - mean_squared_error: 0.0250 - val_loss: 0.1183 - val_mean_squared_error: 0.2427\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0251\n",
      "Epoch 147: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0117 - mean_squared_error: 0.0251 - val_loss: 0.1203 - val_mean_squared_error: 0.2470\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0258\n",
      "Epoch 148: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0120 - mean_squared_error: 0.0258 - val_loss: 0.1227 - val_mean_squared_error: 0.2521\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0261\n",
      "Epoch 149: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0122 - mean_squared_error: 0.0261 - val_loss: 0.1216 - val_mean_squared_error: 0.2501\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0251\n",
      "Epoch 150: val_loss did not improve from 0.09086\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.0117 - mean_squared_error: 0.0251 - val_loss: 0.1197 - val_mean_squared_error: 0.2458\n",
      "5/5 [==============================] - 10s 60ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  96\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4023 - mean_squared_error: 0.9086\n",
      "Epoch 1: val_loss improved from inf to 0.27472, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 70s 2s/step - loss: 0.4023 - mean_squared_error: 0.9086 - val_loss: 0.2747 - val_mean_squared_error: 0.6065\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2534 - mean_squared_error: 0.5532\n",
      "Epoch 2: val_loss improved from 0.27472 to 0.18961, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 782ms/step - loss: 0.2534 - mean_squared_error: 0.5532 - val_loss: 0.1896 - val_mean_squared_error: 0.3961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1544 - mean_squared_error: 0.3186\n",
      "Epoch 3: val_loss improved from 0.18961 to 0.14930, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 758ms/step - loss: 0.1544 - mean_squared_error: 0.3186 - val_loss: 0.1493 - val_mean_squared_error: 0.3055\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1189 - mean_squared_error: 0.2442\n",
      "Epoch 4: val_loss improved from 0.14930 to 0.13023, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 767ms/step - loss: 0.1189 - mean_squared_error: 0.2442 - val_loss: 0.1302 - val_mean_squared_error: 0.2651\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1046 - mean_squared_error: 0.2136\n",
      "Epoch 5: val_loss improved from 0.13023 to 0.12094, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 765ms/step - loss: 0.1046 - mean_squared_error: 0.2136 - val_loss: 0.1209 - val_mean_squared_error: 0.2455\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0967 - mean_squared_error: 0.1972\n",
      "Epoch 6: val_loss improved from 0.12094 to 0.11578, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 763ms/step - loss: 0.0967 - mean_squared_error: 0.1972 - val_loss: 0.1158 - val_mean_squared_error: 0.2349\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0968 - mean_squared_error: 0.1979\n",
      "Epoch 7: val_loss did not improve from 0.11578\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.0968 - mean_squared_error: 0.1979 - val_loss: 0.1283 - val_mean_squared_error: 0.2617\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0897 - mean_squared_error: 0.1829\n",
      "Epoch 8: val_loss improved from 0.11578 to 0.11459, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 763ms/step - loss: 0.0897 - mean_squared_error: 0.1829 - val_loss: 0.1146 - val_mean_squared_error: 0.2329\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0862 - mean_squared_error: 0.1761\n",
      "Epoch 9: val_loss did not improve from 0.11459\n",
      "10/10 [==============================] - 7s 747ms/step - loss: 0.0862 - mean_squared_error: 0.1761 - val_loss: 0.1186 - val_mean_squared_error: 0.2420\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0859 - mean_squared_error: 0.1757\n",
      "Epoch 10: val_loss did not improve from 0.11459\n",
      "10/10 [==============================] - 7s 742ms/step - loss: 0.0859 - mean_squared_error: 0.1757 - val_loss: 0.1193 - val_mean_squared_error: 0.2437\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0844 - mean_squared_error: 0.1728\n",
      "Epoch 11: val_loss did not improve from 0.11459\n",
      "10/10 [==============================] - 7s 742ms/step - loss: 0.0844 - mean_squared_error: 0.1728 - val_loss: 0.1195 - val_mean_squared_error: 0.2440\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0844 - mean_squared_error: 0.1725\n",
      "Epoch 12: val_loss improved from 0.11459 to 0.10971, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 759ms/step - loss: 0.0844 - mean_squared_error: 0.1725 - val_loss: 0.1097 - val_mean_squared_error: 0.2235\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0846 - mean_squared_error: 0.1735\n",
      "Epoch 13: val_loss did not improve from 0.10971\n",
      "10/10 [==============================] - 7s 740ms/step - loss: 0.0846 - mean_squared_error: 0.1735 - val_loss: 0.1235 - val_mean_squared_error: 0.2526\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0853 - mean_squared_error: 0.1741\n",
      "Epoch 14: val_loss did not improve from 0.10971\n",
      "10/10 [==============================] - 7s 740ms/step - loss: 0.0853 - mean_squared_error: 0.1741 - val_loss: 0.1114 - val_mean_squared_error: 0.2273\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0824 - mean_squared_error: 0.1686\n",
      "Epoch 15: val_loss improved from 0.10971 to 0.10948, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 762ms/step - loss: 0.0824 - mean_squared_error: 0.1686 - val_loss: 0.1095 - val_mean_squared_error: 0.2232\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0810 - mean_squared_error: 0.1663\n",
      "Epoch 16: val_loss did not improve from 0.10948\n",
      "10/10 [==============================] - 7s 733ms/step - loss: 0.0810 - mean_squared_error: 0.1663 - val_loss: 0.1150 - val_mean_squared_error: 0.2346\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0795 - mean_squared_error: 0.1628\n",
      "Epoch 17: val_loss improved from 0.10948 to 0.10837, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 765ms/step - loss: 0.0795 - mean_squared_error: 0.1628 - val_loss: 0.1084 - val_mean_squared_error: 0.2204\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0789 - mean_squared_error: 0.1616\n",
      "Epoch 18: val_loss did not improve from 0.10837\n",
      "10/10 [==============================] - 7s 732ms/step - loss: 0.0789 - mean_squared_error: 0.1616 - val_loss: 0.1094 - val_mean_squared_error: 0.2229\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0776 - mean_squared_error: 0.1592\n",
      "Epoch 19: val_loss did not improve from 0.10837\n",
      "10/10 [==============================] - 7s 738ms/step - loss: 0.0776 - mean_squared_error: 0.1592 - val_loss: 0.1199 - val_mean_squared_error: 0.2451\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0800 - mean_squared_error: 0.1631\n",
      "Epoch 20: val_loss improved from 0.10837 to 0.10383, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 760ms/step - loss: 0.0800 - mean_squared_error: 0.1631 - val_loss: 0.1038 - val_mean_squared_error: 0.2112\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0756 - mean_squared_error: 0.1548\n",
      "Epoch 21: val_loss did not improve from 0.10383\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.0756 - mean_squared_error: 0.1548 - val_loss: 0.1114 - val_mean_squared_error: 0.2275\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0743 - mean_squared_error: 0.1520\n",
      "Epoch 22: val_loss improved from 0.10383 to 0.10270, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 761ms/step - loss: 0.0743 - mean_squared_error: 0.1520 - val_loss: 0.1027 - val_mean_squared_error: 0.2100\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0771 - mean_squared_error: 0.1576\n",
      "Epoch 23: val_loss did not improve from 0.10270\n",
      "10/10 [==============================] - 7s 740ms/step - loss: 0.0771 - mean_squared_error: 0.1576 - val_loss: 0.1197 - val_mean_squared_error: 0.2433\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0737 - mean_squared_error: 0.1505\n",
      "Epoch 24: val_loss improved from 0.10270 to 0.09791, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 758ms/step - loss: 0.0737 - mean_squared_error: 0.1505 - val_loss: 0.0979 - val_mean_squared_error: 0.1987\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0714 - mean_squared_error: 0.1458\n",
      "Epoch 25: val_loss did not improve from 0.09791\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.0714 - mean_squared_error: 0.1458 - val_loss: 0.1113 - val_mean_squared_error: 0.2270\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0688 - mean_squared_error: 0.1402\n",
      "Epoch 26: val_loss improved from 0.09791 to 0.09755, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 766ms/step - loss: 0.0688 - mean_squared_error: 0.1402 - val_loss: 0.0975 - val_mean_squared_error: 0.1987\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0691 - mean_squared_error: 0.1409\n",
      "Epoch 27: val_loss improved from 0.09755 to 0.09668, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 752ms/step - loss: 0.0691 - mean_squared_error: 0.1409 - val_loss: 0.0967 - val_mean_squared_error: 0.1965\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0652 - mean_squared_error: 0.1329\n",
      "Epoch 28: val_loss did not improve from 0.09668\n",
      "10/10 [==============================] - 7s 742ms/step - loss: 0.0652 - mean_squared_error: 0.1329 - val_loss: 0.0997 - val_mean_squared_error: 0.2052\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0662 - mean_squared_error: 0.1350\n",
      "Epoch 29: val_loss did not improve from 0.09668\n",
      "10/10 [==============================] - 7s 739ms/step - loss: 0.0662 - mean_squared_error: 0.1350 - val_loss: 0.1050 - val_mean_squared_error: 0.2158\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0642 - mean_squared_error: 0.1309\n",
      "Epoch 30: val_loss did not improve from 0.09668\n",
      "10/10 [==============================] - 7s 737ms/step - loss: 0.0642 - mean_squared_error: 0.1309 - val_loss: 0.1095 - val_mean_squared_error: 0.2245\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0691 - mean_squared_error: 0.1404\n",
      "Epoch 31: val_loss improved from 0.09668 to 0.08526, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 8s 758ms/step - loss: 0.0691 - mean_squared_error: 0.1404 - val_loss: 0.0853 - val_mean_squared_error: 0.1739\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0644 - mean_squared_error: 0.1313\n",
      "Epoch 32: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0644 - mean_squared_error: 0.1313 - val_loss: 0.1029 - val_mean_squared_error: 0.2110\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0619 - mean_squared_error: 0.1261\n",
      "Epoch 33: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 735ms/step - loss: 0.0619 - mean_squared_error: 0.1261 - val_loss: 0.0903 - val_mean_squared_error: 0.1843\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0616 - mean_squared_error: 0.1254\n",
      "Epoch 34: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 735ms/step - loss: 0.0616 - mean_squared_error: 0.1254 - val_loss: 0.1027 - val_mean_squared_error: 0.2109\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0605 - mean_squared_error: 0.1232\n",
      "Epoch 35: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 739ms/step - loss: 0.0605 - mean_squared_error: 0.1232 - val_loss: 0.0888 - val_mean_squared_error: 0.1821\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0605 - mean_squared_error: 0.1234\n",
      "Epoch 36: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 738ms/step - loss: 0.0605 - mean_squared_error: 0.1234 - val_loss: 0.0995 - val_mean_squared_error: 0.2043\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0606 - mean_squared_error: 0.1232\n",
      "Epoch 37: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.0606 - mean_squared_error: 0.1232 - val_loss: 0.0965 - val_mean_squared_error: 0.1980\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0616 - mean_squared_error: 0.1257\n",
      "Epoch 38: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0616 - mean_squared_error: 0.1257 - val_loss: 0.0936 - val_mean_squared_error: 0.1906\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0617 - mean_squared_error: 0.1258\n",
      "Epoch 39: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.0617 - mean_squared_error: 0.1258 - val_loss: 0.0891 - val_mean_squared_error: 0.1817\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0625 - mean_squared_error: 0.1276\n",
      "Epoch 40: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 742ms/step - loss: 0.0625 - mean_squared_error: 0.1276 - val_loss: 0.1044 - val_mean_squared_error: 0.2138\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0586 - mean_squared_error: 0.1195\n",
      "Epoch 41: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.0586 - mean_squared_error: 0.1195 - val_loss: 0.0910 - val_mean_squared_error: 0.1855\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0591 - mean_squared_error: 0.1204\n",
      "Epoch 42: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.0591 - mean_squared_error: 0.1204 - val_loss: 0.0982 - val_mean_squared_error: 0.2008\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0577 - mean_squared_error: 0.1177\n",
      "Epoch 43: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0577 - mean_squared_error: 0.1177 - val_loss: 0.0921 - val_mean_squared_error: 0.1886\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0574 - mean_squared_error: 0.1170\n",
      "Epoch 44: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 736ms/step - loss: 0.0574 - mean_squared_error: 0.1170 - val_loss: 0.0900 - val_mean_squared_error: 0.1833\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0578 - mean_squared_error: 0.1179\n",
      "Epoch 45: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0578 - mean_squared_error: 0.1179 - val_loss: 0.0986 - val_mean_squared_error: 0.2021\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0606 - mean_squared_error: 0.1235\n",
      "Epoch 46: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.0606 - mean_squared_error: 0.1235 - val_loss: 0.0968 - val_mean_squared_error: 0.1979\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0576 - mean_squared_error: 0.1175\n",
      "Epoch 47: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0576 - mean_squared_error: 0.1175 - val_loss: 0.0924 - val_mean_squared_error: 0.1877\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0579 - mean_squared_error: 0.1180\n",
      "Epoch 48: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 737ms/step - loss: 0.0579 - mean_squared_error: 0.1180 - val_loss: 0.0944 - val_mean_squared_error: 0.1925\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0564 - mean_squared_error: 0.1151\n",
      "Epoch 49: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 748ms/step - loss: 0.0564 - mean_squared_error: 0.1151 - val_loss: 0.0915 - val_mean_squared_error: 0.1862\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0547 - mean_squared_error: 0.1115\n",
      "Epoch 50: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.0547 - mean_squared_error: 0.1115 - val_loss: 0.0913 - val_mean_squared_error: 0.1869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0574 - mean_squared_error: 0.1173\n",
      "Epoch 51: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 736ms/step - loss: 0.0574 - mean_squared_error: 0.1173 - val_loss: 0.1002 - val_mean_squared_error: 0.2040\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0555 - mean_squared_error: 0.1132\n",
      "Epoch 52: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0555 - mean_squared_error: 0.1132 - val_loss: 0.0920 - val_mean_squared_error: 0.1866\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0551 - mean_squared_error: 0.1126\n",
      "Epoch 53: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 736ms/step - loss: 0.0551 - mean_squared_error: 0.1126 - val_loss: 0.0921 - val_mean_squared_error: 0.1875\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0540 - mean_squared_error: 0.1101\n",
      "Epoch 54: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 738ms/step - loss: 0.0540 - mean_squared_error: 0.1101 - val_loss: 0.0985 - val_mean_squared_error: 0.2010\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0535 - mean_squared_error: 0.1092\n",
      "Epoch 55: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 747ms/step - loss: 0.0535 - mean_squared_error: 0.1092 - val_loss: 0.0944 - val_mean_squared_error: 0.1934\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0528 - mean_squared_error: 0.1078\n",
      "Epoch 56: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0528 - mean_squared_error: 0.1078 - val_loss: 0.0962 - val_mean_squared_error: 0.1967\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0525 - mean_squared_error: 0.1070\n",
      "Epoch 57: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.0525 - mean_squared_error: 0.1070 - val_loss: 0.1058 - val_mean_squared_error: 0.2163\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0533 - mean_squared_error: 0.1088\n",
      "Epoch 58: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.0533 - mean_squared_error: 0.1088 - val_loss: 0.0864 - val_mean_squared_error: 0.1760\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0519 - mean_squared_error: 0.1059\n",
      "Epoch 59: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 749ms/step - loss: 0.0519 - mean_squared_error: 0.1059 - val_loss: 0.0943 - val_mean_squared_error: 0.1929\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0523 - mean_squared_error: 0.1066\n",
      "Epoch 60: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.0523 - mean_squared_error: 0.1066 - val_loss: 0.0942 - val_mean_squared_error: 0.1927\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0529 - mean_squared_error: 0.1080\n",
      "Epoch 61: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.0529 - mean_squared_error: 0.1080 - val_loss: 0.0970 - val_mean_squared_error: 0.1975\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.1051\n",
      "Epoch 62: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0515 - mean_squared_error: 0.1051 - val_loss: 0.0956 - val_mean_squared_error: 0.1944\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0508 - mean_squared_error: 0.1036\n",
      "Epoch 63: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 747ms/step - loss: 0.0508 - mean_squared_error: 0.1036 - val_loss: 0.0915 - val_mean_squared_error: 0.1854\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0497 - mean_squared_error: 0.1016\n",
      "Epoch 64: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 740ms/step - loss: 0.0497 - mean_squared_error: 0.1016 - val_loss: 0.0914 - val_mean_squared_error: 0.1863\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0488 - mean_squared_error: 0.0997\n",
      "Epoch 65: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 721ms/step - loss: 0.0488 - mean_squared_error: 0.0997 - val_loss: 0.0945 - val_mean_squared_error: 0.1922\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0479 - mean_squared_error: 0.0977\n",
      "Epoch 66: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 742ms/step - loss: 0.0479 - mean_squared_error: 0.0977 - val_loss: 0.0934 - val_mean_squared_error: 0.1898\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0475 - mean_squared_error: 0.0969\n",
      "Epoch 67: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.0475 - mean_squared_error: 0.0969 - val_loss: 0.0953 - val_mean_squared_error: 0.1941\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0471 - mean_squared_error: 0.0962\n",
      "Epoch 68: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.0471 - mean_squared_error: 0.0962 - val_loss: 0.0952 - val_mean_squared_error: 0.1937\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0459 - mean_squared_error: 0.0939\n",
      "Epoch 69: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 720ms/step - loss: 0.0459 - mean_squared_error: 0.0939 - val_loss: 0.0897 - val_mean_squared_error: 0.1821\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0471 - mean_squared_error: 0.0962\n",
      "Epoch 70: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 748ms/step - loss: 0.0471 - mean_squared_error: 0.0962 - val_loss: 0.0955 - val_mean_squared_error: 0.1938\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0466 - mean_squared_error: 0.0954\n",
      "Epoch 71: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 750ms/step - loss: 0.0466 - mean_squared_error: 0.0954 - val_loss: 0.0939 - val_mean_squared_error: 0.1912\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0459 - mean_squared_error: 0.0939\n",
      "Epoch 72: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.0459 - mean_squared_error: 0.0939 - val_loss: 0.0918 - val_mean_squared_error: 0.1868\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0451 - mean_squared_error: 0.0921\n",
      "Epoch 73: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 732ms/step - loss: 0.0451 - mean_squared_error: 0.0921 - val_loss: 0.0922 - val_mean_squared_error: 0.1883\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0474 - mean_squared_error: 0.0968\n",
      "Epoch 74: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.0474 - mean_squared_error: 0.0968 - val_loss: 0.0914 - val_mean_squared_error: 0.1853\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0448 - mean_squared_error: 0.0915\n",
      "Epoch 75: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 747ms/step - loss: 0.0448 - mean_squared_error: 0.0915 - val_loss: 0.0967 - val_mean_squared_error: 0.1967\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0446 - mean_squared_error: 0.0911\n",
      "Epoch 76: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 748ms/step - loss: 0.0446 - mean_squared_error: 0.0911 - val_loss: 0.0995 - val_mean_squared_error: 0.2020\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0426 - mean_squared_error: 0.0868\n",
      "Epoch 77: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 8s 751ms/step - loss: 0.0426 - mean_squared_error: 0.0868 - val_loss: 0.0899 - val_mean_squared_error: 0.1830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0437 - mean_squared_error: 0.0894\n",
      "Epoch 78: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 748ms/step - loss: 0.0437 - mean_squared_error: 0.0894 - val_loss: 0.0922 - val_mean_squared_error: 0.1874\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0429 - mean_squared_error: 0.0879\n",
      "Epoch 79: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.0429 - mean_squared_error: 0.0879 - val_loss: 0.0921 - val_mean_squared_error: 0.1870\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0420 - mean_squared_error: 0.0860\n",
      "Epoch 80: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0420 - mean_squared_error: 0.0860 - val_loss: 0.0978 - val_mean_squared_error: 0.1998\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0431 - mean_squared_error: 0.0883\n",
      "Epoch 81: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0431 - mean_squared_error: 0.0883 - val_loss: 0.0906 - val_mean_squared_error: 0.1840\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0445 - mean_squared_error: 0.0908\n",
      "Epoch 82: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0445 - mean_squared_error: 0.0908 - val_loss: 0.0926 - val_mean_squared_error: 0.1876\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0419 - mean_squared_error: 0.0857\n",
      "Epoch 83: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0419 - mean_squared_error: 0.0857 - val_loss: 0.0910 - val_mean_squared_error: 0.1845\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0408 - mean_squared_error: 0.0834\n",
      "Epoch 84: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 748ms/step - loss: 0.0408 - mean_squared_error: 0.0834 - val_loss: 0.0950 - val_mean_squared_error: 0.1929\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0814\n",
      "Epoch 85: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.0398 - mean_squared_error: 0.0814 - val_loss: 0.0969 - val_mean_squared_error: 0.1969\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0374 - mean_squared_error: 0.0767\n",
      "Epoch 86: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 8s 752ms/step - loss: 0.0374 - mean_squared_error: 0.0767 - val_loss: 0.0935 - val_mean_squared_error: 0.1900\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0369 - mean_squared_error: 0.0757\n",
      "Epoch 87: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 750ms/step - loss: 0.0369 - mean_squared_error: 0.0757 - val_loss: 0.0927 - val_mean_squared_error: 0.1884\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0372 - mean_squared_error: 0.0763\n",
      "Epoch 88: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0372 - mean_squared_error: 0.0763 - val_loss: 0.0962 - val_mean_squared_error: 0.1964\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0359 - mean_squared_error: 0.0737\n",
      "Epoch 89: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.0359 - mean_squared_error: 0.0737 - val_loss: 0.0935 - val_mean_squared_error: 0.1897\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0362 - mean_squared_error: 0.0744\n",
      "Epoch 90: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0362 - mean_squared_error: 0.0744 - val_loss: 0.0990 - val_mean_squared_error: 0.2026\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0356 - mean_squared_error: 0.0730\n",
      "Epoch 91: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 738ms/step - loss: 0.0356 - mean_squared_error: 0.0730 - val_loss: 0.0949 - val_mean_squared_error: 0.1940\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0352 - mean_squared_error: 0.0721\n",
      "Epoch 92: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 750ms/step - loss: 0.0352 - mean_squared_error: 0.0721 - val_loss: 0.0967 - val_mean_squared_error: 0.1963\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0334 - mean_squared_error: 0.0686\n",
      "Epoch 93: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 748ms/step - loss: 0.0334 - mean_squared_error: 0.0686 - val_loss: 0.1049 - val_mean_squared_error: 0.2142\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0375 - mean_squared_error: 0.0768\n",
      "Epoch 94: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 8s 748ms/step - loss: 0.0375 - mean_squared_error: 0.0768 - val_loss: 0.0938 - val_mean_squared_error: 0.1917\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0368 - mean_squared_error: 0.0755\n",
      "Epoch 95: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.0368 - mean_squared_error: 0.0755 - val_loss: 0.0952 - val_mean_squared_error: 0.1947\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0353 - mean_squared_error: 0.0724\n",
      "Epoch 96: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0353 - mean_squared_error: 0.0724 - val_loss: 0.0980 - val_mean_squared_error: 0.1991\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0340 - mean_squared_error: 0.0697\n",
      "Epoch 97: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.0340 - mean_squared_error: 0.0697 - val_loss: 0.0993 - val_mean_squared_error: 0.2028\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0325 - mean_squared_error: 0.0669\n",
      "Epoch 98: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 8s 752ms/step - loss: 0.0325 - mean_squared_error: 0.0669 - val_loss: 0.1030 - val_mean_squared_error: 0.2100\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0314 - mean_squared_error: 0.0646\n",
      "Epoch 99: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.0314 - mean_squared_error: 0.0646 - val_loss: 0.0986 - val_mean_squared_error: 0.2010\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0296 - mean_squared_error: 0.0610\n",
      "Epoch 100: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.0296 - mean_squared_error: 0.0610 - val_loss: 0.0973 - val_mean_squared_error: 0.1982\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0293 - mean_squared_error: 0.0603\n",
      "Epoch 101: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 8s 753ms/step - loss: 0.0293 - mean_squared_error: 0.0603 - val_loss: 0.0996 - val_mean_squared_error: 0.2028\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0602\n",
      "Epoch 102: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 8s 753ms/step - loss: 0.0292 - mean_squared_error: 0.0602 - val_loss: 0.0995 - val_mean_squared_error: 0.2023\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0344 - mean_squared_error: 0.0704\n",
      "Epoch 103: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 8s 748ms/step - loss: 0.0344 - mean_squared_error: 0.0704 - val_loss: 0.1049 - val_mean_squared_error: 0.2163\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0305 - mean_squared_error: 0.0627\n",
      "Epoch 104: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.0305 - mean_squared_error: 0.0627 - val_loss: 0.0910 - val_mean_squared_error: 0.1848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0299 - mean_squared_error: 0.0614\n",
      "Epoch 105: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.0299 - mean_squared_error: 0.0614 - val_loss: 0.1030 - val_mean_squared_error: 0.2123\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0312 - mean_squared_error: 0.0642\n",
      "Epoch 106: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.0312 - mean_squared_error: 0.0642 - val_loss: 0.0942 - val_mean_squared_error: 0.1909\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0293 - mean_squared_error: 0.0602\n",
      "Epoch 107: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 738ms/step - loss: 0.0293 - mean_squared_error: 0.0602 - val_loss: 0.0992 - val_mean_squared_error: 0.2019\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0280 - mean_squared_error: 0.0578\n",
      "Epoch 108: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 731ms/step - loss: 0.0280 - mean_squared_error: 0.0578 - val_loss: 0.0995 - val_mean_squared_error: 0.2035\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0274 - mean_squared_error: 0.0565\n",
      "Epoch 109: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0274 - mean_squared_error: 0.0565 - val_loss: 0.1016 - val_mean_squared_error: 0.2080\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0305 - mean_squared_error: 0.0628\n",
      "Epoch 110: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.0305 - mean_squared_error: 0.0628 - val_loss: 0.0951 - val_mean_squared_error: 0.1938\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0285 - mean_squared_error: 0.0588\n",
      "Epoch 111: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0285 - mean_squared_error: 0.0588 - val_loss: 0.0984 - val_mean_squared_error: 0.2023\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0560\n",
      "Epoch 112: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 8s 749ms/step - loss: 0.0271 - mean_squared_error: 0.0560 - val_loss: 0.0985 - val_mean_squared_error: 0.2002\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0253 - mean_squared_error: 0.0523\n",
      "Epoch 113: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 748ms/step - loss: 0.0253 - mean_squared_error: 0.0523 - val_loss: 0.0978 - val_mean_squared_error: 0.2001\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0240 - mean_squared_error: 0.0497\n",
      "Epoch 114: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 8s 749ms/step - loss: 0.0240 - mean_squared_error: 0.0497 - val_loss: 0.1038 - val_mean_squared_error: 0.2120\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0237 - mean_squared_error: 0.0490\n",
      "Epoch 115: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 8s 752ms/step - loss: 0.0237 - mean_squared_error: 0.0490 - val_loss: 0.1002 - val_mean_squared_error: 0.2050\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0231 - mean_squared_error: 0.0479\n",
      "Epoch 116: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.0231 - mean_squared_error: 0.0479 - val_loss: 0.1006 - val_mean_squared_error: 0.2062\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0235 - mean_squared_error: 0.0487\n",
      "Epoch 117: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 738ms/step - loss: 0.0235 - mean_squared_error: 0.0487 - val_loss: 0.1003 - val_mean_squared_error: 0.2054\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0232 - mean_squared_error: 0.0480\n",
      "Epoch 118: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.0232 - mean_squared_error: 0.0480 - val_loss: 0.1027 - val_mean_squared_error: 0.2094\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0226 - mean_squared_error: 0.0470\n",
      "Epoch 119: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0226 - mean_squared_error: 0.0470 - val_loss: 0.1118 - val_mean_squared_error: 0.2287\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0284 - mean_squared_error: 0.0583\n",
      "Epoch 120: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.0284 - mean_squared_error: 0.0583 - val_loss: 0.1071 - val_mean_squared_error: 0.2212\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0252 - mean_squared_error: 0.0521\n",
      "Epoch 121: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.0252 - mean_squared_error: 0.0521 - val_loss: 0.1011 - val_mean_squared_error: 0.2066\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0233 - mean_squared_error: 0.0483\n",
      "Epoch 122: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.0233 - mean_squared_error: 0.0483 - val_loss: 0.0995 - val_mean_squared_error: 0.2037\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0227 - mean_squared_error: 0.0472\n",
      "Epoch 123: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0227 - mean_squared_error: 0.0472 - val_loss: 0.1015 - val_mean_squared_error: 0.2074\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0215 - mean_squared_error: 0.0447\n",
      "Epoch 124: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 740ms/step - loss: 0.0215 - mean_squared_error: 0.0447 - val_loss: 0.1042 - val_mean_squared_error: 0.2138\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0208 - mean_squared_error: 0.0431\n",
      "Epoch 125: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0208 - mean_squared_error: 0.0431 - val_loss: 0.1025 - val_mean_squared_error: 0.2092\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0195 - mean_squared_error: 0.0408\n",
      "Epoch 126: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 738ms/step - loss: 0.0195 - mean_squared_error: 0.0408 - val_loss: 0.1048 - val_mean_squared_error: 0.2152\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0191 - mean_squared_error: 0.0398\n",
      "Epoch 127: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0191 - mean_squared_error: 0.0398 - val_loss: 0.1038 - val_mean_squared_error: 0.2131\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0190 - mean_squared_error: 0.0397\n",
      "Epoch 128: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0190 - mean_squared_error: 0.0397 - val_loss: 0.1026 - val_mean_squared_error: 0.2097\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0183 - mean_squared_error: 0.0382\n",
      "Epoch 129: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 737ms/step - loss: 0.0183 - mean_squared_error: 0.0382 - val_loss: 0.1070 - val_mean_squared_error: 0.2200\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0184 - mean_squared_error: 0.0385\n",
      "Epoch 130: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0184 - mean_squared_error: 0.0385 - val_loss: 0.1095 - val_mean_squared_error: 0.2242\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0191 - mean_squared_error: 0.0399\n",
      "Epoch 131: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 738ms/step - loss: 0.0191 - mean_squared_error: 0.0399 - val_loss: 0.1056 - val_mean_squared_error: 0.2160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0386\n",
      "Epoch 132: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 0.0185 - mean_squared_error: 0.0386 - val_loss: 0.1043 - val_mean_squared_error: 0.2143\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0366\n",
      "Epoch 133: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 736ms/step - loss: 0.0175 - mean_squared_error: 0.0366 - val_loss: 0.1060 - val_mean_squared_error: 0.2172\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0360\n",
      "Epoch 134: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0172 - mean_squared_error: 0.0360 - val_loss: 0.1043 - val_mean_squared_error: 0.2135\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0361\n",
      "Epoch 135: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 738ms/step - loss: 0.0172 - mean_squared_error: 0.0361 - val_loss: 0.1072 - val_mean_squared_error: 0.2208\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0178 - mean_squared_error: 0.0374\n",
      "Epoch 136: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0178 - mean_squared_error: 0.0374 - val_loss: 0.1084 - val_mean_squared_error: 0.2233\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0170 - mean_squared_error: 0.0355\n",
      "Epoch 137: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.0170 - mean_squared_error: 0.0355 - val_loss: 0.1056 - val_mean_squared_error: 0.2167\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0343\n",
      "Epoch 138: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 748ms/step - loss: 0.0163 - mean_squared_error: 0.0343 - val_loss: 0.1058 - val_mean_squared_error: 0.2187\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0355\n",
      "Epoch 139: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 8s 755ms/step - loss: 0.0169 - mean_squared_error: 0.0355 - val_loss: 0.1070 - val_mean_squared_error: 0.2197\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0339\n",
      "Epoch 140: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0161 - mean_squared_error: 0.0339 - val_loss: 0.1091 - val_mean_squared_error: 0.2255\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0335\n",
      "Epoch 141: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0159 - mean_squared_error: 0.0335 - val_loss: 0.1084 - val_mean_squared_error: 0.2223\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0367\n",
      "Epoch 142: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 8s 753ms/step - loss: 0.0175 - mean_squared_error: 0.0367 - val_loss: 0.1146 - val_mean_squared_error: 0.2383\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0350\n",
      "Epoch 143: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 748ms/step - loss: 0.0167 - mean_squared_error: 0.0350 - val_loss: 0.1064 - val_mean_squared_error: 0.2188\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0341\n",
      "Epoch 144: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 0.0163 - mean_squared_error: 0.0341 - val_loss: 0.1076 - val_mean_squared_error: 0.2222\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0314\n",
      "Epoch 145: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.0149 - mean_squared_error: 0.0314 - val_loss: 0.1091 - val_mean_squared_error: 0.2266\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0312\n",
      "Epoch 146: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.0148 - mean_squared_error: 0.0312 - val_loss: 0.1076 - val_mean_squared_error: 0.2215\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0303\n",
      "Epoch 147: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 748ms/step - loss: 0.0143 - mean_squared_error: 0.0303 - val_loss: 0.1070 - val_mean_squared_error: 0.2208\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0320\n",
      "Epoch 148: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.0152 - mean_squared_error: 0.0320 - val_loss: 0.1115 - val_mean_squared_error: 0.2308\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0335\n",
      "Epoch 149: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 748ms/step - loss: 0.0159 - mean_squared_error: 0.0335 - val_loss: 0.1084 - val_mean_squared_error: 0.2235\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0312\n",
      "Epoch 150: val_loss did not improve from 0.08526\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.0148 - mean_squared_error: 0.0312 - val_loss: 0.1103 - val_mean_squared_error: 0.2277\n",
      "5/5 [==============================] - 10s 66ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  120\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4112 - mean_squared_error: 0.9322\n",
      "Epoch 1: val_loss improved from inf to 0.30456, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 71s 2s/step - loss: 0.4112 - mean_squared_error: 0.9322 - val_loss: 0.3046 - val_mean_squared_error: 0.6674\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2556 - mean_squared_error: 0.5611\n",
      "Epoch 2: val_loss improved from 0.30456 to 0.18333, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 970ms/step - loss: 0.2556 - mean_squared_error: 0.5611 - val_loss: 0.1833 - val_mean_squared_error: 0.3821\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1532 - mean_squared_error: 0.3192\n",
      "Epoch 3: val_loss improved from 0.18333 to 0.13375, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 974ms/step - loss: 0.1532 - mean_squared_error: 0.3192 - val_loss: 0.1337 - val_mean_squared_error: 0.2716\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1130 - mean_squared_error: 0.2308\n",
      "Epoch 4: val_loss improved from 0.13375 to 0.13239, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 979ms/step - loss: 0.1130 - mean_squared_error: 0.2308 - val_loss: 0.1324 - val_mean_squared_error: 0.2702\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0996 - mean_squared_error: 0.2034\n",
      "Epoch 5: val_loss improved from 0.13239 to 0.12009, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 10s 977ms/step - loss: 0.0996 - mean_squared_error: 0.2034 - val_loss: 0.1201 - val_mean_squared_error: 0.2449\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0928 - mean_squared_error: 0.1896\n",
      "Epoch 6: val_loss improved from 0.12009 to 0.11654, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 969ms/step - loss: 0.0928 - mean_squared_error: 0.1896 - val_loss: 0.1165 - val_mean_squared_error: 0.2375\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0893 - mean_squared_error: 0.1823\n",
      "Epoch 7: val_loss improved from 0.11654 to 0.11588, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 960ms/step - loss: 0.0893 - mean_squared_error: 0.1823 - val_loss: 0.1159 - val_mean_squared_error: 0.2361\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0865 - mean_squared_error: 0.1772\n",
      "Epoch 8: val_loss did not improve from 0.11588\n",
      "10/10 [==============================] - 10s 948ms/step - loss: 0.0865 - mean_squared_error: 0.1772 - val_loss: 0.1181 - val_mean_squared_error: 0.2421\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0853 - mean_squared_error: 0.1747\n",
      "Epoch 9: val_loss did not improve from 0.11588\n",
      "10/10 [==============================] - 9s 937ms/step - loss: 0.0853 - mean_squared_error: 0.1747 - val_loss: 0.1169 - val_mean_squared_error: 0.2395\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0833 - mean_squared_error: 0.1704\n",
      "Epoch 10: val_loss improved from 0.11588 to 0.11020, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 969ms/step - loss: 0.0833 - mean_squared_error: 0.1704 - val_loss: 0.1102 - val_mean_squared_error: 0.2248\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0860 - mean_squared_error: 0.1765\n",
      "Epoch 11: val_loss did not improve from 0.11020\n",
      "10/10 [==============================] - 9s 944ms/step - loss: 0.0860 - mean_squared_error: 0.1765 - val_loss: 0.1260 - val_mean_squared_error: 0.2586\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0876 - mean_squared_error: 0.1789\n",
      "Epoch 12: val_loss did not improve from 0.11020\n",
      "10/10 [==============================] - 10s 969ms/step - loss: 0.0876 - mean_squared_error: 0.1789 - val_loss: 0.1131 - val_mean_squared_error: 0.2303\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0812 - mean_squared_error: 0.1662\n",
      "Epoch 13: val_loss did not improve from 0.11020\n",
      "10/10 [==============================] - 10s 962ms/step - loss: 0.0812 - mean_squared_error: 0.1662 - val_loss: 0.1188 - val_mean_squared_error: 0.2434\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0824 - mean_squared_error: 0.1681\n",
      "Epoch 14: val_loss improved from 0.11020 to 0.10796, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 991ms/step - loss: 0.0824 - mean_squared_error: 0.1681 - val_loss: 0.1080 - val_mean_squared_error: 0.2205\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0796 - mean_squared_error: 0.1625\n",
      "Epoch 15: val_loss did not improve from 0.10796\n",
      "10/10 [==============================] - 10s 963ms/step - loss: 0.0796 - mean_squared_error: 0.1625 - val_loss: 0.1191 - val_mean_squared_error: 0.2441\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0797 - mean_squared_error: 0.1626\n",
      "Epoch 16: val_loss did not improve from 0.10796\n",
      "10/10 [==============================] - 10s 965ms/step - loss: 0.0797 - mean_squared_error: 0.1626 - val_loss: 0.1124 - val_mean_squared_error: 0.2290\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0796 - mean_squared_error: 0.1622\n",
      "Epoch 17: val_loss improved from 0.10796 to 0.10387, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 994ms/step - loss: 0.0796 - mean_squared_error: 0.1622 - val_loss: 0.1039 - val_mean_squared_error: 0.2118\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0796 - mean_squared_error: 0.1627\n",
      "Epoch 18: val_loss did not improve from 0.10387\n",
      "10/10 [==============================] - 10s 955ms/step - loss: 0.0796 - mean_squared_error: 0.1627 - val_loss: 0.1172 - val_mean_squared_error: 0.2390\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0792 - mean_squared_error: 0.1614\n",
      "Epoch 19: val_loss improved from 0.10387 to 0.10068, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 976ms/step - loss: 0.0792 - mean_squared_error: 0.1614 - val_loss: 0.1007 - val_mean_squared_error: 0.2036\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0745 - mean_squared_error: 0.1515\n",
      "Epoch 20: val_loss did not improve from 0.10068\n",
      "10/10 [==============================] - 9s 941ms/step - loss: 0.0745 - mean_squared_error: 0.1515 - val_loss: 0.1050 - val_mean_squared_error: 0.2129\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0714 - mean_squared_error: 0.1455\n",
      "Epoch 21: val_loss improved from 0.10068 to 0.09112, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 991ms/step - loss: 0.0714 - mean_squared_error: 0.1455 - val_loss: 0.0911 - val_mean_squared_error: 0.1845\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0665 - mean_squared_error: 0.1355\n",
      "Epoch 22: val_loss improved from 0.09112 to 0.09035, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 972ms/step - loss: 0.0665 - mean_squared_error: 0.1355 - val_loss: 0.0903 - val_mean_squared_error: 0.1835\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0611 - mean_squared_error: 0.1241\n",
      "Epoch 23: val_loss improved from 0.09035 to 0.07921, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 988ms/step - loss: 0.0611 - mean_squared_error: 0.1241 - val_loss: 0.0792 - val_mean_squared_error: 0.1595\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0590 - mean_squared_error: 0.1204\n",
      "Epoch 24: val_loss did not improve from 0.07921\n",
      "10/10 [==============================] - 10s 953ms/step - loss: 0.0590 - mean_squared_error: 0.1204 - val_loss: 0.0808 - val_mean_squared_error: 0.1633\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0538 - mean_squared_error: 0.1100\n",
      "Epoch 25: val_loss did not improve from 0.07921\n",
      "10/10 [==============================] - 10s 967ms/step - loss: 0.0538 - mean_squared_error: 0.1100 - val_loss: 0.0825 - val_mean_squared_error: 0.1665\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0523 - mean_squared_error: 0.1069\n",
      "Epoch 26: val_loss did not improve from 0.07921\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.0523 - mean_squared_error: 0.1069 - val_loss: 0.0793 - val_mean_squared_error: 0.1601\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0531 - mean_squared_error: 0.1085\n",
      "Epoch 27: val_loss did not improve from 0.07921\n",
      "10/10 [==============================] - 10s 965ms/step - loss: 0.0531 - mean_squared_error: 0.1085 - val_loss: 0.0798 - val_mean_squared_error: 0.1612\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0521 - mean_squared_error: 0.1064\n",
      "Epoch 28: val_loss did not improve from 0.07921\n",
      "10/10 [==============================] - 10s 983ms/step - loss: 0.0521 - mean_squared_error: 0.1064 - val_loss: 0.0993 - val_mean_squared_error: 0.2019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0609 - mean_squared_error: 0.1244\n",
      "Epoch 29: val_loss did not improve from 0.07921\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.0609 - mean_squared_error: 0.1244 - val_loss: 0.0843 - val_mean_squared_error: 0.1707\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0560 - mean_squared_error: 0.1142\n",
      "Epoch 30: val_loss did not improve from 0.07921\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.0560 - mean_squared_error: 0.1142 - val_loss: 0.0864 - val_mean_squared_error: 0.1742\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0525 - mean_squared_error: 0.1072\n",
      "Epoch 31: val_loss did not improve from 0.07921\n",
      "10/10 [==============================] - 10s 979ms/step - loss: 0.0525 - mean_squared_error: 0.1072 - val_loss: 0.0803 - val_mean_squared_error: 0.1619\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0514 - mean_squared_error: 0.1049\n",
      "Epoch 32: val_loss did not improve from 0.07921\n",
      "10/10 [==============================] - 10s 990ms/step - loss: 0.0514 - mean_squared_error: 0.1049 - val_loss: 0.0847 - val_mean_squared_error: 0.1712\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0506 - mean_squared_error: 0.1033\n",
      "Epoch 33: val_loss improved from 0.07921 to 0.07611, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0506 - mean_squared_error: 0.1033 - val_loss: 0.0761 - val_mean_squared_error: 0.1533\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0520 - mean_squared_error: 0.1060\n",
      "Epoch 34: val_loss did not improve from 0.07611\n",
      "10/10 [==============================] - 10s 981ms/step - loss: 0.0520 - mean_squared_error: 0.1060 - val_loss: 0.0780 - val_mean_squared_error: 0.1572\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0514 - mean_squared_error: 0.1048\n",
      "Epoch 35: val_loss did not improve from 0.07611\n",
      "10/10 [==============================] - 10s 986ms/step - loss: 0.0514 - mean_squared_error: 0.1048 - val_loss: 0.0781 - val_mean_squared_error: 0.1573\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0497 - mean_squared_error: 0.1016\n",
      "Epoch 36: val_loss improved from 0.07611 to 0.07212, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0497 - mean_squared_error: 0.1016 - val_loss: 0.0721 - val_mean_squared_error: 0.1452\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0493 - mean_squared_error: 0.1007\n",
      "Epoch 37: val_loss did not improve from 0.07212\n",
      "10/10 [==============================] - 10s 963ms/step - loss: 0.0493 - mean_squared_error: 0.1007 - val_loss: 0.0740 - val_mean_squared_error: 0.1492\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0557 - mean_squared_error: 0.1134\n",
      "Epoch 38: val_loss did not improve from 0.07212\n",
      "10/10 [==============================] - 10s 972ms/step - loss: 0.0557 - mean_squared_error: 0.1134 - val_loss: 0.0768 - val_mean_squared_error: 0.1549\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0553 - mean_squared_error: 0.1128\n",
      "Epoch 39: val_loss did not improve from 0.07212\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.0553 - mean_squared_error: 0.1128 - val_loss: 0.0948 - val_mean_squared_error: 0.1917\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0512 - mean_squared_error: 0.1043\n",
      "Epoch 40: val_loss did not improve from 0.07212\n",
      "10/10 [==============================] - 10s 969ms/step - loss: 0.0512 - mean_squared_error: 0.1043 - val_loss: 0.0794 - val_mean_squared_error: 0.1604\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0505 - mean_squared_error: 0.1030\n",
      "Epoch 41: val_loss improved from 0.07212 to 0.07052, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 10s 997ms/step - loss: 0.0505 - mean_squared_error: 0.1030 - val_loss: 0.0705 - val_mean_squared_error: 0.1418\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0496 - mean_squared_error: 0.1012\n",
      "Epoch 42: val_loss did not improve from 0.07052\n",
      "10/10 [==============================] - 10s 966ms/step - loss: 0.0496 - mean_squared_error: 0.1012 - val_loss: 0.0790 - val_mean_squared_error: 0.1591\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0477 - mean_squared_error: 0.0974\n",
      "Epoch 43: val_loss did not improve from 0.07052\n",
      "10/10 [==============================] - 10s 976ms/step - loss: 0.0477 - mean_squared_error: 0.0974 - val_loss: 0.0750 - val_mean_squared_error: 0.1512\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0478 - mean_squared_error: 0.0975\n",
      "Epoch 44: val_loss did not improve from 0.07052\n",
      "10/10 [==============================] - 10s 964ms/step - loss: 0.0478 - mean_squared_error: 0.0975 - val_loss: 0.0839 - val_mean_squared_error: 0.1696\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0530 - mean_squared_error: 0.1078\n",
      "Epoch 45: val_loss did not improve from 0.07052\n",
      "10/10 [==============================] - 10s 951ms/step - loss: 0.0530 - mean_squared_error: 0.1078 - val_loss: 0.0811 - val_mean_squared_error: 0.1633\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0513 - mean_squared_error: 0.1048\n",
      "Epoch 46: val_loss did not improve from 0.07052\n",
      "10/10 [==============================] - 10s 961ms/step - loss: 0.0513 - mean_squared_error: 0.1048 - val_loss: 0.0721 - val_mean_squared_error: 0.1453\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0481 - mean_squared_error: 0.0980\n",
      "Epoch 47: val_loss did not improve from 0.07052\n",
      "10/10 [==============================] - 10s 956ms/step - loss: 0.0481 - mean_squared_error: 0.0980 - val_loss: 0.0832 - val_mean_squared_error: 0.1676\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0463 - mean_squared_error: 0.0946\n",
      "Epoch 48: val_loss did not improve from 0.07052\n",
      "10/10 [==============================] - 10s 957ms/step - loss: 0.0463 - mean_squared_error: 0.0946 - val_loss: 0.0824 - val_mean_squared_error: 0.1663\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0459 - mean_squared_error: 0.0938\n",
      "Epoch 49: val_loss did not improve from 0.07052\n",
      "10/10 [==============================] - 10s 978ms/step - loss: 0.0459 - mean_squared_error: 0.0938 - val_loss: 0.0746 - val_mean_squared_error: 0.1503\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0453 - mean_squared_error: 0.0923\n",
      "Epoch 50: val_loss did not improve from 0.07052\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.0453 - mean_squared_error: 0.0923 - val_loss: 0.0711 - val_mean_squared_error: 0.1431\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0472 - mean_squared_error: 0.0966\n",
      "Epoch 51: val_loss did not improve from 0.07052\n",
      "10/10 [==============================] - 10s 972ms/step - loss: 0.0472 - mean_squared_error: 0.0966 - val_loss: 0.0788 - val_mean_squared_error: 0.1587\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0456 - mean_squared_error: 0.0930\n",
      "Epoch 52: val_loss did not improve from 0.07052\n",
      "10/10 [==============================] - 10s 972ms/step - loss: 0.0456 - mean_squared_error: 0.0930 - val_loss: 0.0730 - val_mean_squared_error: 0.1469\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0442 - mean_squared_error: 0.0902\n",
      "Epoch 53: val_loss did not improve from 0.07052\n",
      "10/10 [==============================] - 10s 979ms/step - loss: 0.0442 - mean_squared_error: 0.0902 - val_loss: 0.0826 - val_mean_squared_error: 0.1666\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0442 - mean_squared_error: 0.0903\n",
      "Epoch 54: val_loss improved from 0.07052 to 0.06954, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 10s 1s/step - loss: 0.0442 - mean_squared_error: 0.0903 - val_loss: 0.0695 - val_mean_squared_error: 0.1399\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0433 - mean_squared_error: 0.0884\n",
      "Epoch 55: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 980ms/step - loss: 0.0433 - mean_squared_error: 0.0884 - val_loss: 0.0789 - val_mean_squared_error: 0.1587\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0442 - mean_squared_error: 0.0901\n",
      "Epoch 56: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 979ms/step - loss: 0.0442 - mean_squared_error: 0.0901 - val_loss: 0.0709 - val_mean_squared_error: 0.1427\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0439 - mean_squared_error: 0.0895\n",
      "Epoch 57: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 981ms/step - loss: 0.0439 - mean_squared_error: 0.0895 - val_loss: 0.0819 - val_mean_squared_error: 0.1650\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0430 - mean_squared_error: 0.0879\n",
      "Epoch 58: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 988ms/step - loss: 0.0430 - mean_squared_error: 0.0879 - val_loss: 0.0715 - val_mean_squared_error: 0.1437\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0417 - mean_squared_error: 0.0852\n",
      "Epoch 59: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 967ms/step - loss: 0.0417 - mean_squared_error: 0.0852 - val_loss: 0.0766 - val_mean_squared_error: 0.1540\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0418 - mean_squared_error: 0.0854\n",
      "Epoch 60: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 965ms/step - loss: 0.0418 - mean_squared_error: 0.0854 - val_loss: 0.0736 - val_mean_squared_error: 0.1480\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0408 - mean_squared_error: 0.0834\n",
      "Epoch 61: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 969ms/step - loss: 0.0408 - mean_squared_error: 0.0834 - val_loss: 0.0719 - val_mean_squared_error: 0.1445\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0403 - mean_squared_error: 0.0823\n",
      "Epoch 62: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 981ms/step - loss: 0.0403 - mean_squared_error: 0.0823 - val_loss: 0.0773 - val_mean_squared_error: 0.1556\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0404 - mean_squared_error: 0.0825\n",
      "Epoch 63: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 967ms/step - loss: 0.0404 - mean_squared_error: 0.0825 - val_loss: 0.0778 - val_mean_squared_error: 0.1566\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0409 - mean_squared_error: 0.0834\n",
      "Epoch 64: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 983ms/step - loss: 0.0409 - mean_squared_error: 0.0834 - val_loss: 0.0801 - val_mean_squared_error: 0.1615\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0424 - mean_squared_error: 0.0865\n",
      "Epoch 65: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 974ms/step - loss: 0.0424 - mean_squared_error: 0.0865 - val_loss: 0.0732 - val_mean_squared_error: 0.1472\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0414 - mean_squared_error: 0.0845\n",
      "Epoch 66: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 975ms/step - loss: 0.0414 - mean_squared_error: 0.0845 - val_loss: 0.0709 - val_mean_squared_error: 0.1425\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0397 - mean_squared_error: 0.0810\n",
      "Epoch 67: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 986ms/step - loss: 0.0397 - mean_squared_error: 0.0810 - val_loss: 0.0782 - val_mean_squared_error: 0.1574\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0401 - mean_squared_error: 0.0819\n",
      "Epoch 68: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 976ms/step - loss: 0.0401 - mean_squared_error: 0.0819 - val_loss: 0.0735 - val_mean_squared_error: 0.1478\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0803\n",
      "Epoch 69: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 972ms/step - loss: 0.0393 - mean_squared_error: 0.0803 - val_loss: 0.0769 - val_mean_squared_error: 0.1548\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0380 - mean_squared_error: 0.0776\n",
      "Epoch 70: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 976ms/step - loss: 0.0380 - mean_squared_error: 0.0776 - val_loss: 0.0767 - val_mean_squared_error: 0.1545\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0385 - mean_squared_error: 0.0786\n",
      "Epoch 71: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.0385 - mean_squared_error: 0.0786 - val_loss: 0.0726 - val_mean_squared_error: 0.1459\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0784\n",
      "Epoch 72: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 970ms/step - loss: 0.0384 - mean_squared_error: 0.0784 - val_loss: 0.0785 - val_mean_squared_error: 0.1579\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0794\n",
      "Epoch 73: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 989ms/step - loss: 0.0389 - mean_squared_error: 0.0794 - val_loss: 0.0815 - val_mean_squared_error: 0.1642\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0380 - mean_squared_error: 0.0777\n",
      "Epoch 74: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 974ms/step - loss: 0.0380 - mean_squared_error: 0.0777 - val_loss: 0.0787 - val_mean_squared_error: 0.1583\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0382 - mean_squared_error: 0.0781\n",
      "Epoch 75: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 976ms/step - loss: 0.0382 - mean_squared_error: 0.0781 - val_loss: 0.0724 - val_mean_squared_error: 0.1456\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0367 - mean_squared_error: 0.0751\n",
      "Epoch 76: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 967ms/step - loss: 0.0367 - mean_squared_error: 0.0751 - val_loss: 0.0816 - val_mean_squared_error: 0.1643\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0363 - mean_squared_error: 0.0741\n",
      "Epoch 77: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 984ms/step - loss: 0.0363 - mean_squared_error: 0.0741 - val_loss: 0.0773 - val_mean_squared_error: 0.1556\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0442 - mean_squared_error: 0.0905\n",
      "Epoch 78: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 981ms/step - loss: 0.0442 - mean_squared_error: 0.0905 - val_loss: 0.0735 - val_mean_squared_error: 0.1480\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0401 - mean_squared_error: 0.0820\n",
      "Epoch 79: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 9s 923ms/step - loss: 0.0401 - mean_squared_error: 0.0820 - val_loss: 0.0770 - val_mean_squared_error: 0.1549\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0368 - mean_squared_error: 0.0752\n",
      "Epoch 80: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 960ms/step - loss: 0.0368 - mean_squared_error: 0.0752 - val_loss: 0.0798 - val_mean_squared_error: 0.1605\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0353 - mean_squared_error: 0.0722\n",
      "Epoch 81: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 946ms/step - loss: 0.0353 - mean_squared_error: 0.0722 - val_loss: 0.0782 - val_mean_squared_error: 0.1576\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0352 - mean_squared_error: 0.0721\n",
      "Epoch 82: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 9s 934ms/step - loss: 0.0352 - mean_squared_error: 0.0721 - val_loss: 0.0821 - val_mean_squared_error: 0.1653\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0376 - mean_squared_error: 0.0768\n",
      "Epoch 83: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 951ms/step - loss: 0.0376 - mean_squared_error: 0.0768 - val_loss: 0.0742 - val_mean_squared_error: 0.1493\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0368 - mean_squared_error: 0.0752\n",
      "Epoch 84: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 948ms/step - loss: 0.0368 - mean_squared_error: 0.0752 - val_loss: 0.0718 - val_mean_squared_error: 0.1444\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0346 - mean_squared_error: 0.0706\n",
      "Epoch 85: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 956ms/step - loss: 0.0346 - mean_squared_error: 0.0706 - val_loss: 0.0767 - val_mean_squared_error: 0.1543\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0341 - mean_squared_error: 0.0697\n",
      "Epoch 86: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 954ms/step - loss: 0.0341 - mean_squared_error: 0.0697 - val_loss: 0.0759 - val_mean_squared_error: 0.1527\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0340 - mean_squared_error: 0.0694\n",
      "Epoch 87: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 9s 934ms/step - loss: 0.0340 - mean_squared_error: 0.0694 - val_loss: 0.0736 - val_mean_squared_error: 0.1481\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0346 - mean_squared_error: 0.0710\n",
      "Epoch 88: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 957ms/step - loss: 0.0346 - mean_squared_error: 0.0710 - val_loss: 0.0831 - val_mean_squared_error: 0.1673\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0344 - mean_squared_error: 0.0703\n",
      "Epoch 89: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 960ms/step - loss: 0.0344 - mean_squared_error: 0.0703 - val_loss: 0.0812 - val_mean_squared_error: 0.1636\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0341 - mean_squared_error: 0.0699\n",
      "Epoch 90: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 958ms/step - loss: 0.0341 - mean_squared_error: 0.0699 - val_loss: 0.0778 - val_mean_squared_error: 0.1567\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0317 - mean_squared_error: 0.0650\n",
      "Epoch 91: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 9s 942ms/step - loss: 0.0317 - mean_squared_error: 0.0650 - val_loss: 0.0770 - val_mean_squared_error: 0.1550\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0318 - mean_squared_error: 0.0652\n",
      "Epoch 92: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 955ms/step - loss: 0.0318 - mean_squared_error: 0.0652 - val_loss: 0.0725 - val_mean_squared_error: 0.1457\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0369 - mean_squared_error: 0.0753\n",
      "Epoch 93: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 963ms/step - loss: 0.0369 - mean_squared_error: 0.0753 - val_loss: 0.0771 - val_mean_squared_error: 0.1550\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0345 - mean_squared_error: 0.0707\n",
      "Epoch 94: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 960ms/step - loss: 0.0345 - mean_squared_error: 0.0707 - val_loss: 0.0941 - val_mean_squared_error: 0.1898\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0330 - mean_squared_error: 0.0677\n",
      "Epoch 95: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 9s 911ms/step - loss: 0.0330 - mean_squared_error: 0.0677 - val_loss: 0.0794 - val_mean_squared_error: 0.1599\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0305 - mean_squared_error: 0.0626\n",
      "Epoch 96: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 9s 859ms/step - loss: 0.0305 - mean_squared_error: 0.0626 - val_loss: 0.0816 - val_mean_squared_error: 0.1645\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0303 - mean_squared_error: 0.0621\n",
      "Epoch 97: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 9s 915ms/step - loss: 0.0303 - mean_squared_error: 0.0621 - val_loss: 0.0774 - val_mean_squared_error: 0.1559\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0288 - mean_squared_error: 0.0591\n",
      "Epoch 98: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 970ms/step - loss: 0.0288 - mean_squared_error: 0.0591 - val_loss: 0.0868 - val_mean_squared_error: 0.1751\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0296 - mean_squared_error: 0.0608\n",
      "Epoch 99: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 958ms/step - loss: 0.0296 - mean_squared_error: 0.0608 - val_loss: 0.0749 - val_mean_squared_error: 0.1509\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0318 - mean_squared_error: 0.0653\n",
      "Epoch 100: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 960ms/step - loss: 0.0318 - mean_squared_error: 0.0653 - val_loss: 0.0789 - val_mean_squared_error: 0.1589\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0307 - mean_squared_error: 0.0630\n",
      "Epoch 101: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 962ms/step - loss: 0.0307 - mean_squared_error: 0.0630 - val_loss: 0.0869 - val_mean_squared_error: 0.1752\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0293 - mean_squared_error: 0.0602\n",
      "Epoch 102: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 955ms/step - loss: 0.0293 - mean_squared_error: 0.0602 - val_loss: 0.0833 - val_mean_squared_error: 0.1678\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0278 - mean_squared_error: 0.0571\n",
      "Epoch 103: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 963ms/step - loss: 0.0278 - mean_squared_error: 0.0571 - val_loss: 0.0807 - val_mean_squared_error: 0.1626\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0599\n",
      "Epoch 104: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 9s 937ms/step - loss: 0.0292 - mean_squared_error: 0.0599 - val_loss: 0.0824 - val_mean_squared_error: 0.1663\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0278 - mean_squared_error: 0.0573\n",
      "Epoch 105: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 9s 934ms/step - loss: 0.0278 - mean_squared_error: 0.0573 - val_loss: 0.0850 - val_mean_squared_error: 0.1713\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0283 - mean_squared_error: 0.0580\n",
      "Epoch 106: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 951ms/step - loss: 0.0283 - mean_squared_error: 0.0580 - val_loss: 0.0736 - val_mean_squared_error: 0.1481\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0270 - mean_squared_error: 0.0556\n",
      "Epoch 107: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 963ms/step - loss: 0.0270 - mean_squared_error: 0.0556 - val_loss: 0.0823 - val_mean_squared_error: 0.1659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0269 - mean_squared_error: 0.0556\n",
      "Epoch 108: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 969ms/step - loss: 0.0269 - mean_squared_error: 0.0556 - val_loss: 0.0824 - val_mean_squared_error: 0.1663\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0265 - mean_squared_error: 0.0547\n",
      "Epoch 109: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 960ms/step - loss: 0.0265 - mean_squared_error: 0.0547 - val_loss: 0.0818 - val_mean_squared_error: 0.1650\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0262 - mean_squared_error: 0.0540\n",
      "Epoch 110: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 973ms/step - loss: 0.0262 - mean_squared_error: 0.0540 - val_loss: 0.0807 - val_mean_squared_error: 0.1627\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0259 - mean_squared_error: 0.0535\n",
      "Epoch 111: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 967ms/step - loss: 0.0259 - mean_squared_error: 0.0535 - val_loss: 0.0878 - val_mean_squared_error: 0.1774\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0558\n",
      "Epoch 112: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 951ms/step - loss: 0.0271 - mean_squared_error: 0.0558 - val_loss: 0.0906 - val_mean_squared_error: 0.1830\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0265 - mean_squared_error: 0.0545\n",
      "Epoch 113: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 974ms/step - loss: 0.0265 - mean_squared_error: 0.0545 - val_loss: 0.0852 - val_mean_squared_error: 0.1719\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0252 - mean_squared_error: 0.0519\n",
      "Epoch 114: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 965ms/step - loss: 0.0252 - mean_squared_error: 0.0519 - val_loss: 0.0853 - val_mean_squared_error: 0.1720\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0239 - mean_squared_error: 0.0494\n",
      "Epoch 115: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 969ms/step - loss: 0.0239 - mean_squared_error: 0.0494 - val_loss: 0.0818 - val_mean_squared_error: 0.1651\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0244 - mean_squared_error: 0.0503\n",
      "Epoch 116: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 972ms/step - loss: 0.0244 - mean_squared_error: 0.0503 - val_loss: 0.0870 - val_mean_squared_error: 0.1758\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0242 - mean_squared_error: 0.0500\n",
      "Epoch 117: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 978ms/step - loss: 0.0242 - mean_squared_error: 0.0500 - val_loss: 0.0841 - val_mean_squared_error: 0.1697\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0236 - mean_squared_error: 0.0488\n",
      "Epoch 118: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 9s 944ms/step - loss: 0.0236 - mean_squared_error: 0.0488 - val_loss: 0.0882 - val_mean_squared_error: 0.1780\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0229 - mean_squared_error: 0.0475\n",
      "Epoch 119: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 955ms/step - loss: 0.0229 - mean_squared_error: 0.0475 - val_loss: 0.0876 - val_mean_squared_error: 0.1770\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0227 - mean_squared_error: 0.0469\n",
      "Epoch 120: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 969ms/step - loss: 0.0227 - mean_squared_error: 0.0469 - val_loss: 0.0882 - val_mean_squared_error: 0.1782\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0231 - mean_squared_error: 0.0478\n",
      "Epoch 121: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 965ms/step - loss: 0.0231 - mean_squared_error: 0.0478 - val_loss: 0.0924 - val_mean_squared_error: 0.1871\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0220 - mean_squared_error: 0.0455\n",
      "Epoch 122: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 962ms/step - loss: 0.0220 - mean_squared_error: 0.0455 - val_loss: 0.0816 - val_mean_squared_error: 0.1648\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0221 - mean_squared_error: 0.0458\n",
      "Epoch 123: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 961ms/step - loss: 0.0221 - mean_squared_error: 0.0458 - val_loss: 0.0924 - val_mean_squared_error: 0.1869\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0215 - mean_squared_error: 0.0447\n",
      "Epoch 124: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 963ms/step - loss: 0.0215 - mean_squared_error: 0.0447 - val_loss: 0.0897 - val_mean_squared_error: 0.1816\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0216 - mean_squared_error: 0.0447\n",
      "Epoch 125: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 986ms/step - loss: 0.0216 - mean_squared_error: 0.0447 - val_loss: 0.0925 - val_mean_squared_error: 0.1872\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0207 - mean_squared_error: 0.0428\n",
      "Epoch 126: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 981ms/step - loss: 0.0207 - mean_squared_error: 0.0428 - val_loss: 0.0926 - val_mean_squared_error: 0.1875\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0205 - mean_squared_error: 0.0426\n",
      "Epoch 127: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.0205 - mean_squared_error: 0.0426 - val_loss: 0.0915 - val_mean_squared_error: 0.1853\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0200 - mean_squared_error: 0.0417\n",
      "Epoch 128: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 967ms/step - loss: 0.0200 - mean_squared_error: 0.0417 - val_loss: 0.0904 - val_mean_squared_error: 0.1828\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0197 - mean_squared_error: 0.0409\n",
      "Epoch 129: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.0197 - mean_squared_error: 0.0409 - val_loss: 0.0856 - val_mean_squared_error: 0.1730\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0203 - mean_squared_error: 0.0421\n",
      "Epoch 130: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 955ms/step - loss: 0.0203 - mean_squared_error: 0.0421 - val_loss: 0.0908 - val_mean_squared_error: 0.1843\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0209 - mean_squared_error: 0.0435\n",
      "Epoch 131: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.0209 - mean_squared_error: 0.0435 - val_loss: 0.0850 - val_mean_squared_error: 0.1718\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0208 - mean_squared_error: 0.0431\n",
      "Epoch 132: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 979ms/step - loss: 0.0208 - mean_squared_error: 0.0431 - val_loss: 0.0974 - val_mean_squared_error: 0.1975\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0194 - mean_squared_error: 0.0403\n",
      "Epoch 133: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 965ms/step - loss: 0.0194 - mean_squared_error: 0.0403 - val_loss: 0.0945 - val_mean_squared_error: 0.1916\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0199 - mean_squared_error: 0.0414\n",
      "Epoch 134: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 955ms/step - loss: 0.0199 - mean_squared_error: 0.0414 - val_loss: 0.0856 - val_mean_squared_error: 0.1735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0200 - mean_squared_error: 0.0417\n",
      "Epoch 135: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 972ms/step - loss: 0.0200 - mean_squared_error: 0.0417 - val_loss: 0.0981 - val_mean_squared_error: 0.1992\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0204 - mean_squared_error: 0.0425\n",
      "Epoch 136: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 9s 941ms/step - loss: 0.0204 - mean_squared_error: 0.0425 - val_loss: 0.0953 - val_mean_squared_error: 0.1934\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0194 - mean_squared_error: 0.0405\n",
      "Epoch 137: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 953ms/step - loss: 0.0194 - mean_squared_error: 0.0405 - val_loss: 0.0926 - val_mean_squared_error: 0.1874\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0394\n",
      "Epoch 138: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 9s 939ms/step - loss: 0.0189 - mean_squared_error: 0.0394 - val_loss: 0.0894 - val_mean_squared_error: 0.1814\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0393\n",
      "Epoch 139: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 9s 941ms/step - loss: 0.0189 - mean_squared_error: 0.0393 - val_loss: 0.0919 - val_mean_squared_error: 0.1862\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0377\n",
      "Epoch 140: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 965ms/step - loss: 0.0181 - mean_squared_error: 0.0377 - val_loss: 0.0899 - val_mean_squared_error: 0.1820\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0176 - mean_squared_error: 0.0368\n",
      "Epoch 141: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 965ms/step - loss: 0.0176 - mean_squared_error: 0.0368 - val_loss: 0.0962 - val_mean_squared_error: 0.1950\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0366\n",
      "Epoch 142: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 971ms/step - loss: 0.0175 - mean_squared_error: 0.0366 - val_loss: 0.0871 - val_mean_squared_error: 0.1763\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0173 - mean_squared_error: 0.0364\n",
      "Epoch 143: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.0173 - mean_squared_error: 0.0364 - val_loss: 0.0898 - val_mean_squared_error: 0.1821\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0355\n",
      "Epoch 144: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 957ms/step - loss: 0.0169 - mean_squared_error: 0.0355 - val_loss: 0.0940 - val_mean_squared_error: 0.1905\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0177 - mean_squared_error: 0.0371\n",
      "Epoch 145: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 962ms/step - loss: 0.0177 - mean_squared_error: 0.0371 - val_loss: 0.0998 - val_mean_squared_error: 0.2026\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0354\n",
      "Epoch 146: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 969ms/step - loss: 0.0169 - mean_squared_error: 0.0354 - val_loss: 0.0902 - val_mean_squared_error: 0.1826\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0332\n",
      "Epoch 147: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 968ms/step - loss: 0.0157 - mean_squared_error: 0.0332 - val_loss: 0.0943 - val_mean_squared_error: 0.1912\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0334\n",
      "Epoch 148: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 969ms/step - loss: 0.0159 - mean_squared_error: 0.0334 - val_loss: 0.0940 - val_mean_squared_error: 0.1908\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0348\n",
      "Epoch 149: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.0166 - mean_squared_error: 0.0348 - val_loss: 0.0933 - val_mean_squared_error: 0.1889\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0340\n",
      "Epoch 150: val_loss did not improve from 0.06954\n",
      "10/10 [==============================] - 10s 970ms/step - loss: 0.0162 - mean_squared_error: 0.0340 - val_loss: 0.0971 - val_mean_squared_error: 0.1971\n",
      "5/5 [==============================] - 10s 94ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  144\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3953 - mean_squared_error: 0.8881\n",
      "Epoch 1: val_loss improved from inf to 0.30282, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 75s 2s/step - loss: 0.3953 - mean_squared_error: 0.8881 - val_loss: 0.3028 - val_mean_squared_error: 0.6437\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2371 - mean_squared_error: 0.5000\n",
      "Epoch 2: val_loss improved from 0.30282 to 0.17998, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2371 - mean_squared_error: 0.5000 - val_loss: 0.1800 - val_mean_squared_error: 0.3697\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1463 - mean_squared_error: 0.3011\n",
      "Epoch 3: val_loss improved from 0.17998 to 0.13641, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.1463 - mean_squared_error: 0.3011 - val_loss: 0.1364 - val_mean_squared_error: 0.2776\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1103 - mean_squared_error: 0.2249\n",
      "Epoch 4: val_loss improved from 0.13641 to 0.13099, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.1103 - mean_squared_error: 0.2249 - val_loss: 0.1310 - val_mean_squared_error: 0.2669\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1126 - mean_squared_error: 0.2306\n",
      "Epoch 5: val_loss did not improve from 0.13099\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.1126 - mean_squared_error: 0.2306 - val_loss: 0.1322 - val_mean_squared_error: 0.2696\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1006 - mean_squared_error: 0.2055\n",
      "Epoch 6: val_loss improved from 0.13099 to 0.11825, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.1006 - mean_squared_error: 0.2055 - val_loss: 0.1183 - val_mean_squared_error: 0.2393\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0970 - mean_squared_error: 0.1978\n",
      "Epoch 7: val_loss did not improve from 0.11825\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0970 - mean_squared_error: 0.1978 - val_loss: 0.1191 - val_mean_squared_error: 0.2419\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0928 - mean_squared_error: 0.1889\n",
      "Epoch 8: val_loss did not improve from 0.11825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 12s 1s/step - loss: 0.0928 - mean_squared_error: 0.1889 - val_loss: 0.1194 - val_mean_squared_error: 0.2433\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0888 - mean_squared_error: 0.1815\n",
      "Epoch 9: val_loss improved from 0.11825 to 0.11647, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0888 - mean_squared_error: 0.1815 - val_loss: 0.1165 - val_mean_squared_error: 0.2376\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0889 - mean_squared_error: 0.1810\n",
      "Epoch 10: val_loss improved from 0.11647 to 0.11047, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0889 - mean_squared_error: 0.1810 - val_loss: 0.1105 - val_mean_squared_error: 0.2242\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0861 - mean_squared_error: 0.1755\n",
      "Epoch 11: val_loss did not improve from 0.11047\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0861 - mean_squared_error: 0.1755 - val_loss: 0.1123 - val_mean_squared_error: 0.2297\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0834 - mean_squared_error: 0.1704\n",
      "Epoch 12: val_loss did not improve from 0.11047\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0834 - mean_squared_error: 0.1704 - val_loss: 0.1136 - val_mean_squared_error: 0.2332\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0820 - mean_squared_error: 0.1679\n",
      "Epoch 13: val_loss did not improve from 0.11047\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0820 - mean_squared_error: 0.1679 - val_loss: 0.1155 - val_mean_squared_error: 0.2358\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0812 - mean_squared_error: 0.1654\n",
      "Epoch 14: val_loss did not improve from 0.11047\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0812 - mean_squared_error: 0.1654 - val_loss: 0.1124 - val_mean_squared_error: 0.2296\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0829 - mean_squared_error: 0.1698\n",
      "Epoch 15: val_loss did not improve from 0.11047\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0829 - mean_squared_error: 0.1698 - val_loss: 0.1189 - val_mean_squared_error: 0.2424\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0803 - mean_squared_error: 0.1632\n",
      "Epoch 16: val_loss improved from 0.11047 to 0.09781, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0803 - mean_squared_error: 0.1632 - val_loss: 0.0978 - val_mean_squared_error: 0.1986\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0728 - mean_squared_error: 0.1484\n",
      "Epoch 17: val_loss did not improve from 0.09781\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0728 - mean_squared_error: 0.1484 - val_loss: 0.1288 - val_mean_squared_error: 0.2640\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0887 - mean_squared_error: 0.1807\n",
      "Epoch 18: val_loss did not improve from 0.09781\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0887 - mean_squared_error: 0.1807 - val_loss: 0.1087 - val_mean_squared_error: 0.2216\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0861 - mean_squared_error: 0.1766\n",
      "Epoch 19: val_loss did not improve from 0.09781\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0861 - mean_squared_error: 0.1766 - val_loss: 0.1181 - val_mean_squared_error: 0.2411\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0795 - mean_squared_error: 0.1622\n",
      "Epoch 20: val_loss did not improve from 0.09781\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0795 - mean_squared_error: 0.1622 - val_loss: 0.1092 - val_mean_squared_error: 0.2227\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0784 - mean_squared_error: 0.1596\n",
      "Epoch 21: val_loss did not improve from 0.09781\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0784 - mean_squared_error: 0.1596 - val_loss: 0.1082 - val_mean_squared_error: 0.2204\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0751 - mean_squared_error: 0.1531\n",
      "Epoch 22: val_loss did not improve from 0.09781\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0751 - mean_squared_error: 0.1531 - val_loss: 0.1078 - val_mean_squared_error: 0.2198\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0794 - mean_squared_error: 0.1623\n",
      "Epoch 23: val_loss did not improve from 0.09781\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0794 - mean_squared_error: 0.1623 - val_loss: 0.1169 - val_mean_squared_error: 0.2397\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0761 - mean_squared_error: 0.1555\n",
      "Epoch 24: val_loss did not improve from 0.09781\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0761 - mean_squared_error: 0.1555 - val_loss: 0.0983 - val_mean_squared_error: 0.2003\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0729 - mean_squared_error: 0.1493\n",
      "Epoch 25: val_loss did not improve from 0.09781\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0729 - mean_squared_error: 0.1493 - val_loss: 0.1075 - val_mean_squared_error: 0.2190\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0697 - mean_squared_error: 0.1424\n",
      "Epoch 26: val_loss did not improve from 0.09781\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0697 - mean_squared_error: 0.1424 - val_loss: 0.0993 - val_mean_squared_error: 0.2039\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0700 - mean_squared_error: 0.1432\n",
      "Epoch 27: val_loss did not improve from 0.09781\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0700 - mean_squared_error: 0.1432 - val_loss: 0.1077 - val_mean_squared_error: 0.2187\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0713 - mean_squared_error: 0.1456\n",
      "Epoch 28: val_loss improved from 0.09781 to 0.09645, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0713 - mean_squared_error: 0.1456 - val_loss: 0.0965 - val_mean_squared_error: 0.1974\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0671 - mean_squared_error: 0.1365\n",
      "Epoch 29: val_loss improved from 0.09645 to 0.08850, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0671 - mean_squared_error: 0.1365 - val_loss: 0.0885 - val_mean_squared_error: 0.1793\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0627 - mean_squared_error: 0.1280\n",
      "Epoch 30: val_loss did not improve from 0.08850\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0627 - mean_squared_error: 0.1280 - val_loss: 0.0934 - val_mean_squared_error: 0.1897\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0598 - mean_squared_error: 0.1218\n",
      "Epoch 31: val_loss did not improve from 0.08850\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0598 - mean_squared_error: 0.1218 - val_loss: 0.0909 - val_mean_squared_error: 0.1840\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0583 - mean_squared_error: 0.1190\n",
      "Epoch 32: val_loss did not improve from 0.08850\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0583 - mean_squared_error: 0.1190 - val_loss: 0.0887 - val_mean_squared_error: 0.1800\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0566 - mean_squared_error: 0.1153\n",
      "Epoch 33: val_loss improved from 0.08850 to 0.08371, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 12s 1s/step - loss: 0.0566 - mean_squared_error: 0.1153 - val_loss: 0.0837 - val_mean_squared_error: 0.1693\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0550 - mean_squared_error: 0.1121\n",
      "Epoch 34: val_loss improved from 0.08371 to 0.08234, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0550 - mean_squared_error: 0.1121 - val_loss: 0.0823 - val_mean_squared_error: 0.1666\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0552 - mean_squared_error: 0.1125\n",
      "Epoch 35: val_loss did not improve from 0.08234\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0552 - mean_squared_error: 0.1125 - val_loss: 0.0902 - val_mean_squared_error: 0.1835\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0544 - mean_squared_error: 0.1109\n",
      "Epoch 36: val_loss did not improve from 0.08234\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0544 - mean_squared_error: 0.1109 - val_loss: 0.0847 - val_mean_squared_error: 0.1720\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0566 - mean_squared_error: 0.1154\n",
      "Epoch 37: val_loss did not improve from 0.08234\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0566 - mean_squared_error: 0.1154 - val_loss: 0.0945 - val_mean_squared_error: 0.1918\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0605 - mean_squared_error: 0.1233\n",
      "Epoch 38: val_loss did not improve from 0.08234\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0605 - mean_squared_error: 0.1233 - val_loss: 0.0838 - val_mean_squared_error: 0.1691\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0598 - mean_squared_error: 0.1218\n",
      "Epoch 39: val_loss improved from 0.08234 to 0.08158, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0598 - mean_squared_error: 0.1218 - val_loss: 0.0816 - val_mean_squared_error: 0.1648\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0540 - mean_squared_error: 0.1099\n",
      "Epoch 40: val_loss did not improve from 0.08158\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0540 - mean_squared_error: 0.1099 - val_loss: 0.0821 - val_mean_squared_error: 0.1657\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0507 - mean_squared_error: 0.1034\n",
      "Epoch 41: val_loss improved from 0.08158 to 0.07926, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0507 - mean_squared_error: 0.1034 - val_loss: 0.0793 - val_mean_squared_error: 0.1604\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0490 - mean_squared_error: 0.1000\n",
      "Epoch 42: val_loss did not improve from 0.07926\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0490 - mean_squared_error: 0.1000 - val_loss: 0.0861 - val_mean_squared_error: 0.1743\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0521 - mean_squared_error: 0.1063\n",
      "Epoch 43: val_loss improved from 0.07926 to 0.07849, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0521 - mean_squared_error: 0.1063 - val_loss: 0.0785 - val_mean_squared_error: 0.1584\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0496 - mean_squared_error: 0.1011\n",
      "Epoch 44: val_loss did not improve from 0.07849\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0496 - mean_squared_error: 0.1011 - val_loss: 0.0872 - val_mean_squared_error: 0.1764\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0494 - mean_squared_error: 0.1008\n",
      "Epoch 45: val_loss did not improve from 0.07849\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0494 - mean_squared_error: 0.1008 - val_loss: 0.0803 - val_mean_squared_error: 0.1624\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0503 - mean_squared_error: 0.1028\n",
      "Epoch 46: val_loss did not improve from 0.07849\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0503 - mean_squared_error: 0.1028 - val_loss: 0.0882 - val_mean_squared_error: 0.1782\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0492 - mean_squared_error: 0.1005\n",
      "Epoch 47: val_loss did not improve from 0.07849\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0492 - mean_squared_error: 0.1005 - val_loss: 0.0871 - val_mean_squared_error: 0.1766\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0474 - mean_squared_error: 0.0967\n",
      "Epoch 48: val_loss did not improve from 0.07849\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0474 - mean_squared_error: 0.0967 - val_loss: 0.0845 - val_mean_squared_error: 0.1709\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0493 - mean_squared_error: 0.1006\n",
      "Epoch 49: val_loss did not improve from 0.07849\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0493 - mean_squared_error: 0.1006 - val_loss: 0.0802 - val_mean_squared_error: 0.1622\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0463 - mean_squared_error: 0.0945\n",
      "Epoch 50: val_loss did not improve from 0.07849\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0463 - mean_squared_error: 0.0945 - val_loss: 0.0872 - val_mean_squared_error: 0.1767\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0531 - mean_squared_error: 0.1084\n",
      "Epoch 51: val_loss improved from 0.07849 to 0.07593, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0531 - mean_squared_error: 0.1084 - val_loss: 0.0759 - val_mean_squared_error: 0.1527\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0490 - mean_squared_error: 0.0998\n",
      "Epoch 52: val_loss did not improve from 0.07593\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0490 - mean_squared_error: 0.0998 - val_loss: 0.0855 - val_mean_squared_error: 0.1745\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0486 - mean_squared_error: 0.0991\n",
      "Epoch 53: val_loss did not improve from 0.07593\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0486 - mean_squared_error: 0.0991 - val_loss: 0.0790 - val_mean_squared_error: 0.1589\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0490 - mean_squared_error: 0.0999\n",
      "Epoch 54: val_loss did not improve from 0.07593\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0490 - mean_squared_error: 0.0999 - val_loss: 0.0816 - val_mean_squared_error: 0.1657\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0475 - mean_squared_error: 0.0967\n",
      "Epoch 55: val_loss did not improve from 0.07593\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0475 - mean_squared_error: 0.0967 - val_loss: 0.0861 - val_mean_squared_error: 0.1737\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0478 - mean_squared_error: 0.0976\n",
      "Epoch 56: val_loss improved from 0.07593 to 0.07528, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0478 - mean_squared_error: 0.0976 - val_loss: 0.0753 - val_mean_squared_error: 0.1518\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0465 - mean_squared_error: 0.0950\n",
      "Epoch 57: val_loss did not improve from 0.07528\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0465 - mean_squared_error: 0.0950 - val_loss: 0.0898 - val_mean_squared_error: 0.1814\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.0482 - mean_squared_error: 0.0984\n",
      "Epoch 58: val_loss did not improve from 0.07528\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0482 - mean_squared_error: 0.0984 - val_loss: 0.0851 - val_mean_squared_error: 0.1723\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0478 - mean_squared_error: 0.0975\n",
      "Epoch 59: val_loss improved from 0.07528 to 0.07410, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0478 - mean_squared_error: 0.0975 - val_loss: 0.0741 - val_mean_squared_error: 0.1493\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0473 - mean_squared_error: 0.0962\n",
      "Epoch 60: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0473 - mean_squared_error: 0.0962 - val_loss: 0.0817 - val_mean_squared_error: 0.1647\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0459 - mean_squared_error: 0.0936\n",
      "Epoch 61: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0459 - mean_squared_error: 0.0936 - val_loss: 0.0786 - val_mean_squared_error: 0.1590\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.0919\n",
      "Epoch 62: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0450 - mean_squared_error: 0.0919 - val_loss: 0.0865 - val_mean_squared_error: 0.1747\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0467 - mean_squared_error: 0.0952\n",
      "Epoch 63: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0467 - mean_squared_error: 0.0952 - val_loss: 0.0787 - val_mean_squared_error: 0.1587\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0446 - mean_squared_error: 0.0911\n",
      "Epoch 64: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0446 - mean_squared_error: 0.0911 - val_loss: 0.0818 - val_mean_squared_error: 0.1651\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0466 - mean_squared_error: 0.0949\n",
      "Epoch 65: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0466 - mean_squared_error: 0.0949 - val_loss: 0.0817 - val_mean_squared_error: 0.1645\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0456 - mean_squared_error: 0.0931\n",
      "Epoch 66: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0456 - mean_squared_error: 0.0931 - val_loss: 0.0766 - val_mean_squared_error: 0.1551\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0467 - mean_squared_error: 0.0952\n",
      "Epoch 67: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0467 - mean_squared_error: 0.0952 - val_loss: 0.0910 - val_mean_squared_error: 0.1838\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0439 - mean_squared_error: 0.0896\n",
      "Epoch 68: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0439 - mean_squared_error: 0.0896 - val_loss: 0.0782 - val_mean_squared_error: 0.1578\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0436 - mean_squared_error: 0.0889\n",
      "Epoch 69: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0436 - mean_squared_error: 0.0889 - val_loss: 0.0807 - val_mean_squared_error: 0.1625\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0429 - mean_squared_error: 0.0876\n",
      "Epoch 70: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0429 - mean_squared_error: 0.0876 - val_loss: 0.0828 - val_mean_squared_error: 0.1676\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0428 - mean_squared_error: 0.0874\n",
      "Epoch 71: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0428 - mean_squared_error: 0.0874 - val_loss: 0.0788 - val_mean_squared_error: 0.1594\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0442 - mean_squared_error: 0.0901\n",
      "Epoch 72: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0442 - mean_squared_error: 0.0901 - val_loss: 0.0859 - val_mean_squared_error: 0.1733\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0423 - mean_squared_error: 0.0864\n",
      "Epoch 73: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0423 - mean_squared_error: 0.0864 - val_loss: 0.0794 - val_mean_squared_error: 0.1601\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0425 - mean_squared_error: 0.0867\n",
      "Epoch 74: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0425 - mean_squared_error: 0.0867 - val_loss: 0.0788 - val_mean_squared_error: 0.1600\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0429 - mean_squared_error: 0.0877\n",
      "Epoch 75: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0429 - mean_squared_error: 0.0877 - val_loss: 0.0762 - val_mean_squared_error: 0.1536\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0434 - mean_squared_error: 0.0884\n",
      "Epoch 76: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0434 - mean_squared_error: 0.0884 - val_loss: 0.0815 - val_mean_squared_error: 0.1641\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0435 - mean_squared_error: 0.0888\n",
      "Epoch 77: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0435 - mean_squared_error: 0.0888 - val_loss: 0.0763 - val_mean_squared_error: 0.1537\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0426 - mean_squared_error: 0.0870\n",
      "Epoch 78: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0426 - mean_squared_error: 0.0870 - val_loss: 0.0751 - val_mean_squared_error: 0.1519\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0431 - mean_squared_error: 0.0879\n",
      "Epoch 79: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0431 - mean_squared_error: 0.0879 - val_loss: 0.0759 - val_mean_squared_error: 0.1523\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0421 - mean_squared_error: 0.0860\n",
      "Epoch 80: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0421 - mean_squared_error: 0.0860 - val_loss: 0.0808 - val_mean_squared_error: 0.1627\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0397 - mean_squared_error: 0.0811\n",
      "Epoch 81: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0397 - mean_squared_error: 0.0811 - val_loss: 0.0786 - val_mean_squared_error: 0.1587\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0801\n",
      "Epoch 82: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0392 - mean_squared_error: 0.0801 - val_loss: 0.0841 - val_mean_squared_error: 0.1699\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0395 - mean_squared_error: 0.0807\n",
      "Epoch 83: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0395 - mean_squared_error: 0.0807 - val_loss: 0.0785 - val_mean_squared_error: 0.1588\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0399 - mean_squared_error: 0.0815\n",
      "Epoch 84: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0399 - mean_squared_error: 0.0815 - val_loss: 0.0867 - val_mean_squared_error: 0.1747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0799\n",
      "Epoch 85: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0391 - mean_squared_error: 0.0799 - val_loss: 0.0802 - val_mean_squared_error: 0.1618\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0383 - mean_squared_error: 0.0783\n",
      "Epoch 86: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0383 - mean_squared_error: 0.0783 - val_loss: 0.0844 - val_mean_squared_error: 0.1705\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0800\n",
      "Epoch 87: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0392 - mean_squared_error: 0.0800 - val_loss: 0.0787 - val_mean_squared_error: 0.1588\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0800\n",
      "Epoch 88: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0392 - mean_squared_error: 0.0800 - val_loss: 0.0800 - val_mean_squared_error: 0.1616\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0403 - mean_squared_error: 0.0822\n",
      "Epoch 89: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0403 - mean_squared_error: 0.0822 - val_loss: 0.0783 - val_mean_squared_error: 0.1576\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0402 - mean_squared_error: 0.0822\n",
      "Epoch 90: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0402 - mean_squared_error: 0.0822 - val_loss: 0.0797 - val_mean_squared_error: 0.1604\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0383 - mean_squared_error: 0.0783\n",
      "Epoch 91: val_loss did not improve from 0.07410\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0383 - mean_squared_error: 0.0783 - val_loss: 0.0837 - val_mean_squared_error: 0.1702\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0379 - mean_squared_error: 0.0774\n",
      "Epoch 92: val_loss improved from 0.07410 to 0.07236, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0379 - mean_squared_error: 0.0774 - val_loss: 0.0724 - val_mean_squared_error: 0.1456\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0376 - mean_squared_error: 0.0768\n",
      "Epoch 93: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0376 - mean_squared_error: 0.0768 - val_loss: 0.0944 - val_mean_squared_error: 0.1916\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0801\n",
      "Epoch 94: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0392 - mean_squared_error: 0.0801 - val_loss: 0.0788 - val_mean_squared_error: 0.1590\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0367 - mean_squared_error: 0.0751\n",
      "Epoch 95: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0367 - mean_squared_error: 0.0751 - val_loss: 0.0821 - val_mean_squared_error: 0.1665\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0387 - mean_squared_error: 0.0790\n",
      "Epoch 96: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0387 - mean_squared_error: 0.0790 - val_loss: 0.0740 - val_mean_squared_error: 0.1490\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0376 - mean_squared_error: 0.0767\n",
      "Epoch 97: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0376 - mean_squared_error: 0.0767 - val_loss: 0.0786 - val_mean_squared_error: 0.1588\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0437 - mean_squared_error: 0.0892\n",
      "Epoch 98: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0437 - mean_squared_error: 0.0892 - val_loss: 0.0849 - val_mean_squared_error: 0.1711\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0385 - mean_squared_error: 0.0787\n",
      "Epoch 99: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0385 - mean_squared_error: 0.0787 - val_loss: 0.0836 - val_mean_squared_error: 0.1689\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0372 - mean_squared_error: 0.0760\n",
      "Epoch 100: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0372 - mean_squared_error: 0.0760 - val_loss: 0.0776 - val_mean_squared_error: 0.1570\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.0724\n",
      "Epoch 101: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0354 - mean_squared_error: 0.0724 - val_loss: 0.0735 - val_mean_squared_error: 0.1481\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0357 - mean_squared_error: 0.0729\n",
      "Epoch 102: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0357 - mean_squared_error: 0.0729 - val_loss: 0.0793 - val_mean_squared_error: 0.1597\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0349 - mean_squared_error: 0.0715\n",
      "Epoch 103: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0349 - mean_squared_error: 0.0715 - val_loss: 0.0833 - val_mean_squared_error: 0.1681\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0368 - mean_squared_error: 0.0752\n",
      "Epoch 104: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0368 - mean_squared_error: 0.0752 - val_loss: 0.0767 - val_mean_squared_error: 0.1546\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0361 - mean_squared_error: 0.0737\n",
      "Epoch 105: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0361 - mean_squared_error: 0.0737 - val_loss: 0.0791 - val_mean_squared_error: 0.1590\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0347 - mean_squared_error: 0.0709\n",
      "Epoch 106: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0347 - mean_squared_error: 0.0709 - val_loss: 0.0758 - val_mean_squared_error: 0.1530\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0344 - mean_squared_error: 0.0706\n",
      "Epoch 107: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0344 - mean_squared_error: 0.0706 - val_loss: 0.0801 - val_mean_squared_error: 0.1617\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0329 - mean_squared_error: 0.0675\n",
      "Epoch 108: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0329 - mean_squared_error: 0.0675 - val_loss: 0.0793 - val_mean_squared_error: 0.1600\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0339 - mean_squared_error: 0.0695\n",
      "Epoch 109: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0339 - mean_squared_error: 0.0695 - val_loss: 0.0773 - val_mean_squared_error: 0.1554\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0355 - mean_squared_error: 0.0728\n",
      "Epoch 110: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0355 - mean_squared_error: 0.0728 - val_loss: 0.0762 - val_mean_squared_error: 0.1537\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0342 - mean_squared_error: 0.0701\n",
      "Epoch 111: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0342 - mean_squared_error: 0.0701 - val_loss: 0.0745 - val_mean_squared_error: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0330 - mean_squared_error: 0.0676\n",
      "Epoch 112: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0330 - mean_squared_error: 0.0676 - val_loss: 0.0780 - val_mean_squared_error: 0.1571\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0317 - mean_squared_error: 0.0650\n",
      "Epoch 113: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0317 - mean_squared_error: 0.0650 - val_loss: 0.0785 - val_mean_squared_error: 0.1586\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0312 - mean_squared_error: 0.0640\n",
      "Epoch 114: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0312 - mean_squared_error: 0.0640 - val_loss: 0.0762 - val_mean_squared_error: 0.1536\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0300 - mean_squared_error: 0.0616\n",
      "Epoch 115: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0300 - mean_squared_error: 0.0616 - val_loss: 0.0804 - val_mean_squared_error: 0.1625\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0305 - mean_squared_error: 0.0625\n",
      "Epoch 116: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0305 - mean_squared_error: 0.0625 - val_loss: 0.0767 - val_mean_squared_error: 0.1546\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0296 - mean_squared_error: 0.0607\n",
      "Epoch 117: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0296 - mean_squared_error: 0.0607 - val_loss: 0.0776 - val_mean_squared_error: 0.1564\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0312 - mean_squared_error: 0.0639\n",
      "Epoch 118: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0312 - mean_squared_error: 0.0639 - val_loss: 0.0810 - val_mean_squared_error: 0.1643\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0311 - mean_squared_error: 0.0637\n",
      "Epoch 119: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0311 - mean_squared_error: 0.0637 - val_loss: 0.0814 - val_mean_squared_error: 0.1644\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0295 - mean_squared_error: 0.0606\n",
      "Epoch 120: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0295 - mean_squared_error: 0.0606 - val_loss: 0.0817 - val_mean_squared_error: 0.1652\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0289 - mean_squared_error: 0.0593\n",
      "Epoch 121: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0289 - mean_squared_error: 0.0593 - val_loss: 0.0802 - val_mean_squared_error: 0.1620\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0352 - mean_squared_error: 0.0722\n",
      "Epoch 122: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0352 - mean_squared_error: 0.0722 - val_loss: 0.0848 - val_mean_squared_error: 0.1714\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0342 - mean_squared_error: 0.0699\n",
      "Epoch 123: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0342 - mean_squared_error: 0.0699 - val_loss: 0.0804 - val_mean_squared_error: 0.1621\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0340 - mean_squared_error: 0.0697\n",
      "Epoch 124: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0340 - mean_squared_error: 0.0697 - val_loss: 0.0853 - val_mean_squared_error: 0.1723\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0325 - mean_squared_error: 0.0667\n",
      "Epoch 125: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0325 - mean_squared_error: 0.0667 - val_loss: 0.0865 - val_mean_squared_error: 0.1753\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0315 - mean_squared_error: 0.0646\n",
      "Epoch 126: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0315 - mean_squared_error: 0.0646 - val_loss: 0.0806 - val_mean_squared_error: 0.1627\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0319 - mean_squared_error: 0.0653\n",
      "Epoch 127: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0319 - mean_squared_error: 0.0653 - val_loss: 0.0784 - val_mean_squared_error: 0.1579\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0296 - mean_squared_error: 0.0608\n",
      "Epoch 128: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0296 - mean_squared_error: 0.0608 - val_loss: 0.0814 - val_mean_squared_error: 0.1640\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0274 - mean_squared_error: 0.0565\n",
      "Epoch 129: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0274 - mean_squared_error: 0.0565 - val_loss: 0.0782 - val_mean_squared_error: 0.1580\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0270 - mean_squared_error: 0.0556\n",
      "Epoch 130: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0270 - mean_squared_error: 0.0556 - val_loss: 0.0773 - val_mean_squared_error: 0.1561\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0265 - mean_squared_error: 0.0546\n",
      "Epoch 131: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0265 - mean_squared_error: 0.0546 - val_loss: 0.0804 - val_mean_squared_error: 0.1625\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0270 - mean_squared_error: 0.0556\n",
      "Epoch 132: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0270 - mean_squared_error: 0.0556 - val_loss: 0.0882 - val_mean_squared_error: 0.1786\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0560\n",
      "Epoch 133: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0271 - mean_squared_error: 0.0560 - val_loss: 0.0843 - val_mean_squared_error: 0.1704\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0276 - mean_squared_error: 0.0569\n",
      "Epoch 134: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0276 - mean_squared_error: 0.0569 - val_loss: 0.0815 - val_mean_squared_error: 0.1647\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0262 - mean_squared_error: 0.0539\n",
      "Epoch 135: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0262 - mean_squared_error: 0.0539 - val_loss: 0.0803 - val_mean_squared_error: 0.1621\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0246 - mean_squared_error: 0.0508\n",
      "Epoch 136: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0246 - mean_squared_error: 0.0508 - val_loss: 0.0840 - val_mean_squared_error: 0.1700\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0250 - mean_squared_error: 0.0515\n",
      "Epoch 137: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0250 - mean_squared_error: 0.0515 - val_loss: 0.0789 - val_mean_squared_error: 0.1593\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0242 - mean_squared_error: 0.0499\n",
      "Epoch 138: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0242 - mean_squared_error: 0.0499 - val_loss: 0.0794 - val_mean_squared_error: 0.1601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0519\n",
      "Epoch 139: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0251 - mean_squared_error: 0.0519 - val_loss: 0.0900 - val_mean_squared_error: 0.1819\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0261 - mean_squared_error: 0.0537\n",
      "Epoch 140: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0261 - mean_squared_error: 0.0537 - val_loss: 0.0846 - val_mean_squared_error: 0.1707\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0250 - mean_squared_error: 0.0516\n",
      "Epoch 141: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0250 - mean_squared_error: 0.0516 - val_loss: 0.0805 - val_mean_squared_error: 0.1627\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0231 - mean_squared_error: 0.0476\n",
      "Epoch 142: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0231 - mean_squared_error: 0.0476 - val_loss: 0.0803 - val_mean_squared_error: 0.1621\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0231 - mean_squared_error: 0.0479\n",
      "Epoch 143: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0231 - mean_squared_error: 0.0479 - val_loss: 0.0853 - val_mean_squared_error: 0.1723\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0229 - mean_squared_error: 0.0475\n",
      "Epoch 144: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0229 - mean_squared_error: 0.0475 - val_loss: 0.0809 - val_mean_squared_error: 0.1632\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0232 - mean_squared_error: 0.0482\n",
      "Epoch 145: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0232 - mean_squared_error: 0.0482 - val_loss: 0.0819 - val_mean_squared_error: 0.1652\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0218 - mean_squared_error: 0.0453\n",
      "Epoch 146: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0218 - mean_squared_error: 0.0453 - val_loss: 0.0843 - val_mean_squared_error: 0.1706\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0214 - mean_squared_error: 0.0443\n",
      "Epoch 147: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0214 - mean_squared_error: 0.0443 - val_loss: 0.0784 - val_mean_squared_error: 0.1583\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0226 - mean_squared_error: 0.0467\n",
      "Epoch 148: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0226 - mean_squared_error: 0.0467 - val_loss: 0.0883 - val_mean_squared_error: 0.1784\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0235 - mean_squared_error: 0.0488\n",
      "Epoch 149: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0235 - mean_squared_error: 0.0488 - val_loss: 0.0872 - val_mean_squared_error: 0.1763\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0226 - mean_squared_error: 0.0468\n",
      "Epoch 150: val_loss did not improve from 0.07236\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.0226 - mean_squared_error: 0.0468 - val_loss: 0.0850 - val_mean_squared_error: 0.1716\n",
      "5/5 [==============================] - 10s 117ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  168\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4216 - mean_squared_error: 0.9579\n",
      "Epoch 1: val_loss improved from inf to 0.34219, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 73s 3s/step - loss: 0.4216 - mean_squared_error: 0.9579 - val_loss: 0.3422 - val_mean_squared_error: 0.7543\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3200 - mean_squared_error: 0.6986\n",
      "Epoch 2: val_loss improved from 0.34219 to 0.22737, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3200 - mean_squared_error: 0.6986 - val_loss: 0.2274 - val_mean_squared_error: 0.4790\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1937 - mean_squared_error: 0.4038\n",
      "Epoch 3: val_loss improved from 0.22737 to 0.15770, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1937 - mean_squared_error: 0.4038 - val_loss: 0.1577 - val_mean_squared_error: 0.3219\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1346 - mean_squared_error: 0.2790\n",
      "Epoch 4: val_loss improved from 0.15770 to 0.13715, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1346 - mean_squared_error: 0.2790 - val_loss: 0.1371 - val_mean_squared_error: 0.2798\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1114 - mean_squared_error: 0.2272\n",
      "Epoch 5: val_loss improved from 0.13715 to 0.12945, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1114 - mean_squared_error: 0.2272 - val_loss: 0.1294 - val_mean_squared_error: 0.2637\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1003 - mean_squared_error: 0.2053\n",
      "Epoch 6: val_loss did not improve from 0.12945\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1003 - mean_squared_error: 0.2053 - val_loss: 0.1365 - val_mean_squared_error: 0.2809\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.2094\n",
      "Epoch 7: val_loss improved from 0.12945 to 0.12028, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1026 - mean_squared_error: 0.2094 - val_loss: 0.1203 - val_mean_squared_error: 0.2450\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0991 - mean_squared_error: 0.2025\n",
      "Epoch 8: val_loss did not improve from 0.12028\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0991 - mean_squared_error: 0.2025 - val_loss: 0.1236 - val_mean_squared_error: 0.2522\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0948 - mean_squared_error: 0.1942\n",
      "Epoch 9: val_loss did not improve from 0.12028\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0948 - mean_squared_error: 0.1942 - val_loss: 0.1213 - val_mean_squared_error: 0.2475\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0901 - mean_squared_error: 0.1844\n",
      "Epoch 10: val_loss improved from 0.12028 to 0.11716, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0901 - mean_squared_error: 0.1844 - val_loss: 0.1172 - val_mean_squared_error: 0.2395\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0861 - mean_squared_error: 0.1760\n",
      "Epoch 11: val_loss did not improve from 0.11716\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0861 - mean_squared_error: 0.1760 - val_loss: 0.1190 - val_mean_squared_error: 0.2436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0842 - mean_squared_error: 0.1720\n",
      "Epoch 12: val_loss improved from 0.11716 to 0.11492, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0842 - mean_squared_error: 0.1720 - val_loss: 0.1149 - val_mean_squared_error: 0.2360\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0845 - mean_squared_error: 0.1738\n",
      "Epoch 13: val_loss did not improve from 0.11492\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0845 - mean_squared_error: 0.1738 - val_loss: 0.1192 - val_mean_squared_error: 0.2445\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0812 - mean_squared_error: 0.1661\n",
      "Epoch 14: val_loss improved from 0.11492 to 0.11186, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0812 - mean_squared_error: 0.1661 - val_loss: 0.1119 - val_mean_squared_error: 0.2286\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0842 - mean_squared_error: 0.1721\n",
      "Epoch 15: val_loss did not improve from 0.11186\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0842 - mean_squared_error: 0.1721 - val_loss: 0.1135 - val_mean_squared_error: 0.2319\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0823 - mean_squared_error: 0.1685\n",
      "Epoch 16: val_loss did not improve from 0.11186\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0823 - mean_squared_error: 0.1685 - val_loss: 0.1206 - val_mean_squared_error: 0.2494\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0820 - mean_squared_error: 0.1684\n",
      "Epoch 17: val_loss did not improve from 0.11186\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0820 - mean_squared_error: 0.1684 - val_loss: 0.1129 - val_mean_squared_error: 0.2316\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0789 - mean_squared_error: 0.1615\n",
      "Epoch 18: val_loss did not improve from 0.11186\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0789 - mean_squared_error: 0.1615 - val_loss: 0.1132 - val_mean_squared_error: 0.2322\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0776 - mean_squared_error: 0.1588\n",
      "Epoch 19: val_loss did not improve from 0.11186\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0776 - mean_squared_error: 0.1588 - val_loss: 0.1119 - val_mean_squared_error: 0.2290\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0755 - mean_squared_error: 0.1545\n",
      "Epoch 20: val_loss improved from 0.11186 to 0.11119, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0755 - mean_squared_error: 0.1545 - val_loss: 0.1112 - val_mean_squared_error: 0.2281\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0754 - mean_squared_error: 0.1538\n",
      "Epoch 21: val_loss improved from 0.11119 to 0.10988, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0754 - mean_squared_error: 0.1538 - val_loss: 0.1099 - val_mean_squared_error: 0.2254\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0734 - mean_squared_error: 0.1502\n",
      "Epoch 22: val_loss did not improve from 0.10988\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0734 - mean_squared_error: 0.1502 - val_loss: 0.1112 - val_mean_squared_error: 0.2274\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0729 - mean_squared_error: 0.1486\n",
      "Epoch 23: val_loss improved from 0.10988 to 0.10347, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0729 - mean_squared_error: 0.1486 - val_loss: 0.1035 - val_mean_squared_error: 0.2122\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0741 - mean_squared_error: 0.1516\n",
      "Epoch 24: val_loss did not improve from 0.10347\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0741 - mean_squared_error: 0.1516 - val_loss: 0.1107 - val_mean_squared_error: 0.2254\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0794 - mean_squared_error: 0.1618\n",
      "Epoch 25: val_loss did not improve from 0.10347\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0794 - mean_squared_error: 0.1618 - val_loss: 0.1228 - val_mean_squared_error: 0.2510\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0744 - mean_squared_error: 0.1522\n",
      "Epoch 26: val_loss improved from 0.10347 to 0.09978, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0744 - mean_squared_error: 0.1522 - val_loss: 0.0998 - val_mean_squared_error: 0.2033\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0699 - mean_squared_error: 0.1422\n",
      "Epoch 27: val_loss improved from 0.09978 to 0.09413, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0699 - mean_squared_error: 0.1422 - val_loss: 0.0941 - val_mean_squared_error: 0.1914\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0665 - mean_squared_error: 0.1354\n",
      "Epoch 28: val_loss did not improve from 0.09413\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0665 - mean_squared_error: 0.1354 - val_loss: 0.1024 - val_mean_squared_error: 0.2094\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0691 - mean_squared_error: 0.1408\n",
      "Epoch 29: val_loss did not improve from 0.09413\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0691 - mean_squared_error: 0.1408 - val_loss: 0.0962 - val_mean_squared_error: 0.1961\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0692 - mean_squared_error: 0.1409\n",
      "Epoch 30: val_loss did not improve from 0.09413\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0692 - mean_squared_error: 0.1409 - val_loss: 0.1076 - val_mean_squared_error: 0.2198\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0765 - mean_squared_error: 0.1562\n",
      "Epoch 31: val_loss did not improve from 0.09413\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0765 - mean_squared_error: 0.1562 - val_loss: 0.0963 - val_mean_squared_error: 0.1963\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0697 - mean_squared_error: 0.1421\n",
      "Epoch 32: val_loss did not improve from 0.09413\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0697 - mean_squared_error: 0.1421 - val_loss: 0.0968 - val_mean_squared_error: 0.1975\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0658 - mean_squared_error: 0.1343\n",
      "Epoch 33: val_loss improved from 0.09413 to 0.08966, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0658 - mean_squared_error: 0.1343 - val_loss: 0.0897 - val_mean_squared_error: 0.1824\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0626 - mean_squared_error: 0.1276\n",
      "Epoch 34: val_loss did not improve from 0.08966\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0626 - mean_squared_error: 0.1276 - val_loss: 0.0960 - val_mean_squared_error: 0.1953\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0606 - mean_squared_error: 0.1236\n",
      "Epoch 35: val_loss did not improve from 0.08966\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0606 - mean_squared_error: 0.1236 - val_loss: 0.0919 - val_mean_squared_error: 0.1872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0647 - mean_squared_error: 0.1317\n",
      "Epoch 36: val_loss improved from 0.08966 to 0.08799, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0647 - mean_squared_error: 0.1317 - val_loss: 0.0880 - val_mean_squared_error: 0.1794\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0606 - mean_squared_error: 0.1237\n",
      "Epoch 37: val_loss did not improve from 0.08799\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0606 - mean_squared_error: 0.1237 - val_loss: 0.0919 - val_mean_squared_error: 0.1869\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0605 - mean_squared_error: 0.1232\n",
      "Epoch 38: val_loss did not improve from 0.08799\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0605 - mean_squared_error: 0.1232 - val_loss: 0.0955 - val_mean_squared_error: 0.1940\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0583 - mean_squared_error: 0.1189\n",
      "Epoch 39: val_loss improved from 0.08799 to 0.08119, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0583 - mean_squared_error: 0.1189 - val_loss: 0.0812 - val_mean_squared_error: 0.1643\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0563 - mean_squared_error: 0.1146\n",
      "Epoch 40: val_loss did not improve from 0.08119\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0563 - mean_squared_error: 0.1146 - val_loss: 0.0876 - val_mean_squared_error: 0.1771\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0546 - mean_squared_error: 0.1114\n",
      "Epoch 41: val_loss did not improve from 0.08119\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0546 - mean_squared_error: 0.1114 - val_loss: 0.0818 - val_mean_squared_error: 0.1651\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0617 - mean_squared_error: 0.1266\n",
      "Epoch 42: val_loss did not improve from 0.08119\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0617 - mean_squared_error: 0.1266 - val_loss: 0.0969 - val_mean_squared_error: 0.1964\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0590 - mean_squared_error: 0.1207\n",
      "Epoch 43: val_loss did not improve from 0.08119\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0590 - mean_squared_error: 0.1207 - val_loss: 0.0878 - val_mean_squared_error: 0.1775\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0549 - mean_squared_error: 0.1120\n",
      "Epoch 44: val_loss did not improve from 0.08119\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0549 - mean_squared_error: 0.1120 - val_loss: 0.0904 - val_mean_squared_error: 0.1835\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0639 - mean_squared_error: 0.1308\n",
      "Epoch 45: val_loss improved from 0.08119 to 0.08045, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0639 - mean_squared_error: 0.1308 - val_loss: 0.0805 - val_mean_squared_error: 0.1627\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0587 - mean_squared_error: 0.1195\n",
      "Epoch 46: val_loss did not improve from 0.08045\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0587 - mean_squared_error: 0.1195 - val_loss: 0.0897 - val_mean_squared_error: 0.1814\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0565 - mean_squared_error: 0.1153\n",
      "Epoch 47: val_loss did not improve from 0.08045\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0565 - mean_squared_error: 0.1153 - val_loss: 0.0890 - val_mean_squared_error: 0.1802\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0571 - mean_squared_error: 0.1160\n",
      "Epoch 48: val_loss did not improve from 0.08045\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0571 - mean_squared_error: 0.1160 - val_loss: 0.0847 - val_mean_squared_error: 0.1713\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0530 - mean_squared_error: 0.1079\n",
      "Epoch 49: val_loss did not improve from 0.08045\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0530 - mean_squared_error: 0.1079 - val_loss: 0.0900 - val_mean_squared_error: 0.1824\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0527 - mean_squared_error: 0.1074\n",
      "Epoch 50: val_loss did not improve from 0.08045\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0527 - mean_squared_error: 0.1074 - val_loss: 0.0906 - val_mean_squared_error: 0.1836\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0520 - mean_squared_error: 0.1059\n",
      "Epoch 51: val_loss did not improve from 0.08045\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0520 - mean_squared_error: 0.1059 - val_loss: 0.0898 - val_mean_squared_error: 0.1821\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0523 - mean_squared_error: 0.1067\n",
      "Epoch 52: val_loss did not improve from 0.08045\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0523 - mean_squared_error: 0.1067 - val_loss: 0.0858 - val_mean_squared_error: 0.1735\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.1050\n",
      "Epoch 53: val_loss did not improve from 0.08045\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0515 - mean_squared_error: 0.1050 - val_loss: 0.0862 - val_mean_squared_error: 0.1741\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0512 - mean_squared_error: 0.1045\n",
      "Epoch 54: val_loss did not improve from 0.08045\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0512 - mean_squared_error: 0.1045 - val_loss: 0.0850 - val_mean_squared_error: 0.1713\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0501 - mean_squared_error: 0.1022\n",
      "Epoch 55: val_loss improved from 0.08045 to 0.07918, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0501 - mean_squared_error: 0.1022 - val_loss: 0.0792 - val_mean_squared_error: 0.1598\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0490 - mean_squared_error: 0.1000\n",
      "Epoch 56: val_loss did not improve from 0.07918\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0490 - mean_squared_error: 0.1000 - val_loss: 0.0818 - val_mean_squared_error: 0.1647\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0492 - mean_squared_error: 0.1005\n",
      "Epoch 57: val_loss did not improve from 0.07918\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0492 - mean_squared_error: 0.1005 - val_loss: 0.0940 - val_mean_squared_error: 0.1903\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0480 - mean_squared_error: 0.0977\n",
      "Epoch 58: val_loss did not improve from 0.07918\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0480 - mean_squared_error: 0.0977 - val_loss: 0.0850 - val_mean_squared_error: 0.1717\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0456 - mean_squared_error: 0.0931\n",
      "Epoch 59: val_loss did not improve from 0.07918\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0456 - mean_squared_error: 0.0931 - val_loss: 0.0828 - val_mean_squared_error: 0.1666\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0471 - mean_squared_error: 0.0960\n",
      "Epoch 60: val_loss did not improve from 0.07918\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0471 - mean_squared_error: 0.0960 - val_loss: 0.0804 - val_mean_squared_error: 0.1624\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0505 - mean_squared_error: 0.1030\n",
      "Epoch 61: val_loss did not improve from 0.07918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 14s 1s/step - loss: 0.0505 - mean_squared_error: 0.1030 - val_loss: 0.1007 - val_mean_squared_error: 0.2043\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0944\n",
      "Epoch 62: val_loss did not improve from 0.07918\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0462 - mean_squared_error: 0.0944 - val_loss: 0.0809 - val_mean_squared_error: 0.1630\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0483 - mean_squared_error: 0.0983\n",
      "Epoch 63: val_loss did not improve from 0.07918\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0483 - mean_squared_error: 0.0983 - val_loss: 0.0816 - val_mean_squared_error: 0.1653\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0464 - mean_squared_error: 0.0947\n",
      "Epoch 64: val_loss did not improve from 0.07918\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0464 - mean_squared_error: 0.0947 - val_loss: 0.0878 - val_mean_squared_error: 0.1772\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0458 - mean_squared_error: 0.0936\n",
      "Epoch 65: val_loss improved from 0.07918 to 0.07766, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0458 - mean_squared_error: 0.0936 - val_loss: 0.0777 - val_mean_squared_error: 0.1564\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0426 - mean_squared_error: 0.0870\n",
      "Epoch 66: val_loss did not improve from 0.07766\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0426 - mean_squared_error: 0.0870 - val_loss: 0.0828 - val_mean_squared_error: 0.1667\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0423 - mean_squared_error: 0.0865\n",
      "Epoch 67: val_loss improved from 0.07766 to 0.07740, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0423 - mean_squared_error: 0.0865 - val_loss: 0.0774 - val_mean_squared_error: 0.1558\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0424 - mean_squared_error: 0.0868\n",
      "Epoch 68: val_loss did not improve from 0.07740\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0424 - mean_squared_error: 0.0868 - val_loss: 0.0910 - val_mean_squared_error: 0.1844\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0474 - mean_squared_error: 0.0965\n",
      "Epoch 69: val_loss improved from 0.07740 to 0.07655, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0474 - mean_squared_error: 0.0965 - val_loss: 0.0765 - val_mean_squared_error: 0.1538\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0438 - mean_squared_error: 0.0895\n",
      "Epoch 70: val_loss did not improve from 0.07655\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0438 - mean_squared_error: 0.0895 - val_loss: 0.0826 - val_mean_squared_error: 0.1666\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0430 - mean_squared_error: 0.0878\n",
      "Epoch 71: val_loss did not improve from 0.07655\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0430 - mean_squared_error: 0.0878 - val_loss: 0.0849 - val_mean_squared_error: 0.1711\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0417 - mean_squared_error: 0.0852\n",
      "Epoch 72: val_loss improved from 0.07655 to 0.07411, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0417 - mean_squared_error: 0.0852 - val_loss: 0.0741 - val_mean_squared_error: 0.1490\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0427 - mean_squared_error: 0.0871\n",
      "Epoch 73: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0427 - mean_squared_error: 0.0871 - val_loss: 0.0930 - val_mean_squared_error: 0.1880\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0426 - mean_squared_error: 0.0871\n",
      "Epoch 74: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0426 - mean_squared_error: 0.0871 - val_loss: 0.0787 - val_mean_squared_error: 0.1587\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0411 - mean_squared_error: 0.0841\n",
      "Epoch 75: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0411 - mean_squared_error: 0.0841 - val_loss: 0.0797 - val_mean_squared_error: 0.1608\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0404 - mean_squared_error: 0.0825\n",
      "Epoch 76: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0404 - mean_squared_error: 0.0825 - val_loss: 0.0913 - val_mean_squared_error: 0.1841\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0815\n",
      "Epoch 77: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0398 - mean_squared_error: 0.0815 - val_loss: 0.0795 - val_mean_squared_error: 0.1603\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0380 - mean_squared_error: 0.0777\n",
      "Epoch 78: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0380 - mean_squared_error: 0.0777 - val_loss: 0.0801 - val_mean_squared_error: 0.1614\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0382 - mean_squared_error: 0.0780\n",
      "Epoch 79: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0382 - mean_squared_error: 0.0780 - val_loss: 0.0815 - val_mean_squared_error: 0.1642\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0798\n",
      "Epoch 80: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0391 - mean_squared_error: 0.0798 - val_loss: 0.0881 - val_mean_squared_error: 0.1777\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0793\n",
      "Epoch 81: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0388 - mean_squared_error: 0.0793 - val_loss: 0.0894 - val_mean_squared_error: 0.1806\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0795\n",
      "Epoch 82: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0389 - mean_squared_error: 0.0795 - val_loss: 0.0783 - val_mean_squared_error: 0.1581\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.0797\n",
      "Epoch 83: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0390 - mean_squared_error: 0.0797 - val_loss: 0.0868 - val_mean_squared_error: 0.1749\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0812\n",
      "Epoch 84: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0398 - mean_squared_error: 0.0812 - val_loss: 0.0820 - val_mean_squared_error: 0.1657\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0379 - mean_squared_error: 0.0775\n",
      "Epoch 85: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0379 - mean_squared_error: 0.0775 - val_loss: 0.0780 - val_mean_squared_error: 0.1571\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0749\n",
      "Epoch 86: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0366 - mean_squared_error: 0.0749 - val_loss: 0.0834 - val_mean_squared_error: 0.1679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0373 - mean_squared_error: 0.0763\n",
      "Epoch 87: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0373 - mean_squared_error: 0.0763 - val_loss: 0.0926 - val_mean_squared_error: 0.1872\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0404 - mean_squared_error: 0.0823\n",
      "Epoch 88: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0404 - mean_squared_error: 0.0823 - val_loss: 0.0791 - val_mean_squared_error: 0.1592\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0435 - mean_squared_error: 0.0888\n",
      "Epoch 89: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0435 - mean_squared_error: 0.0888 - val_loss: 0.0787 - val_mean_squared_error: 0.1594\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0418 - mean_squared_error: 0.0853\n",
      "Epoch 90: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0418 - mean_squared_error: 0.0853 - val_loss: 0.0895 - val_mean_squared_error: 0.1805\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0406 - mean_squared_error: 0.0827\n",
      "Epoch 91: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0406 - mean_squared_error: 0.0827 - val_loss: 0.0791 - val_mean_squared_error: 0.1596\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0370 - mean_squared_error: 0.0755\n",
      "Epoch 92: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0370 - mean_squared_error: 0.0755 - val_loss: 0.0836 - val_mean_squared_error: 0.1684\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0370 - mean_squared_error: 0.0756\n",
      "Epoch 93: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0370 - mean_squared_error: 0.0756 - val_loss: 0.0873 - val_mean_squared_error: 0.1765\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0373 - mean_squared_error: 0.0762\n",
      "Epoch 94: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0373 - mean_squared_error: 0.0762 - val_loss: 0.0825 - val_mean_squared_error: 0.1661\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0364 - mean_squared_error: 0.0744\n",
      "Epoch 95: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0364 - mean_squared_error: 0.0744 - val_loss: 0.0802 - val_mean_squared_error: 0.1617\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0351 - mean_squared_error: 0.0719\n",
      "Epoch 96: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0351 - mean_squared_error: 0.0719 - val_loss: 0.0889 - val_mean_squared_error: 0.1799\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0387 - mean_squared_error: 0.0791\n",
      "Epoch 97: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0387 - mean_squared_error: 0.0791 - val_loss: 0.0751 - val_mean_squared_error: 0.1515\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0364 - mean_squared_error: 0.0745\n",
      "Epoch 98: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0364 - mean_squared_error: 0.0745 - val_loss: 0.0853 - val_mean_squared_error: 0.1721\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0340 - mean_squared_error: 0.0696\n",
      "Epoch 99: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0340 - mean_squared_error: 0.0696 - val_loss: 0.0854 - val_mean_squared_error: 0.1726\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0358 - mean_squared_error: 0.0733\n",
      "Epoch 100: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0358 - mean_squared_error: 0.0733 - val_loss: 0.0832 - val_mean_squared_error: 0.1683\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0355 - mean_squared_error: 0.0726\n",
      "Epoch 101: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0355 - mean_squared_error: 0.0726 - val_loss: 0.0787 - val_mean_squared_error: 0.1590\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0336 - mean_squared_error: 0.0687\n",
      "Epoch 102: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0336 - mean_squared_error: 0.0687 - val_loss: 0.0855 - val_mean_squared_error: 0.1725\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0345 - mean_squared_error: 0.0706\n",
      "Epoch 103: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0345 - mean_squared_error: 0.0706 - val_loss: 0.0817 - val_mean_squared_error: 0.1654\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0347 - mean_squared_error: 0.0711\n",
      "Epoch 104: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0347 - mean_squared_error: 0.0711 - val_loss: 0.0863 - val_mean_squared_error: 0.1746\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0326 - mean_squared_error: 0.0667\n",
      "Epoch 105: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0326 - mean_squared_error: 0.0667 - val_loss: 0.0866 - val_mean_squared_error: 0.1750\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0372 - mean_squared_error: 0.0758\n",
      "Epoch 106: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0372 - mean_squared_error: 0.0758 - val_loss: 0.0934 - val_mean_squared_error: 0.1894\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0331 - mean_squared_error: 0.0677\n",
      "Epoch 107: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0331 - mean_squared_error: 0.0677 - val_loss: 0.0814 - val_mean_squared_error: 0.1647\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0314 - mean_squared_error: 0.0645\n",
      "Epoch 108: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0314 - mean_squared_error: 0.0645 - val_loss: 0.0778 - val_mean_squared_error: 0.1569\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0313 - mean_squared_error: 0.0642\n",
      "Epoch 109: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0313 - mean_squared_error: 0.0642 - val_loss: 0.0854 - val_mean_squared_error: 0.1726\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0294 - mean_squared_error: 0.0604\n",
      "Epoch 110: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0294 - mean_squared_error: 0.0604 - val_loss: 0.0860 - val_mean_squared_error: 0.1742\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0307 - mean_squared_error: 0.0630\n",
      "Epoch 111: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0307 - mean_squared_error: 0.0630 - val_loss: 0.0804 - val_mean_squared_error: 0.1626\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0303 - mean_squared_error: 0.0622\n",
      "Epoch 112: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0303 - mean_squared_error: 0.0622 - val_loss: 0.0802 - val_mean_squared_error: 0.1625\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0308 - mean_squared_error: 0.0633\n",
      "Epoch 113: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0308 - mean_squared_error: 0.0633 - val_loss: 0.0879 - val_mean_squared_error: 0.1781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0294 - mean_squared_error: 0.0603\n",
      "Epoch 114: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0294 - mean_squared_error: 0.0603 - val_loss: 0.0835 - val_mean_squared_error: 0.1695\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0320 - mean_squared_error: 0.0658\n",
      "Epoch 115: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0320 - mean_squared_error: 0.0658 - val_loss: 0.1116 - val_mean_squared_error: 0.2293\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.0726\n",
      "Epoch 116: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0354 - mean_squared_error: 0.0726 - val_loss: 0.0787 - val_mean_squared_error: 0.1586\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0341 - mean_squared_error: 0.0700\n",
      "Epoch 117: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0341 - mean_squared_error: 0.0700 - val_loss: 0.0787 - val_mean_squared_error: 0.1588\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0302 - mean_squared_error: 0.0620\n",
      "Epoch 118: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0302 - mean_squared_error: 0.0620 - val_loss: 0.0847 - val_mean_squared_error: 0.1711\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0283 - mean_squared_error: 0.0581\n",
      "Epoch 119: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0283 - mean_squared_error: 0.0581 - val_loss: 0.0850 - val_mean_squared_error: 0.1719\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0288 - mean_squared_error: 0.0590\n",
      "Epoch 120: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0288 - mean_squared_error: 0.0590 - val_loss: 0.0834 - val_mean_squared_error: 0.1683\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0289 - mean_squared_error: 0.0593\n",
      "Epoch 121: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0289 - mean_squared_error: 0.0593 - val_loss: 0.0797 - val_mean_squared_error: 0.1606\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0313 - mean_squared_error: 0.0643\n",
      "Epoch 122: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0313 - mean_squared_error: 0.0643 - val_loss: 0.0924 - val_mean_squared_error: 0.1870\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0303 - mean_squared_error: 0.0623\n",
      "Epoch 123: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0303 - mean_squared_error: 0.0623 - val_loss: 0.0907 - val_mean_squared_error: 0.1836\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0276 - mean_squared_error: 0.0568\n",
      "Epoch 124: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0276 - mean_squared_error: 0.0568 - val_loss: 0.0957 - val_mean_squared_error: 0.1942\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0313 - mean_squared_error: 0.0642\n",
      "Epoch 125: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0313 - mean_squared_error: 0.0642 - val_loss: 0.0833 - val_mean_squared_error: 0.1690\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0318 - mean_squared_error: 0.0650\n",
      "Epoch 126: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0318 - mean_squared_error: 0.0650 - val_loss: 0.0924 - val_mean_squared_error: 0.1872\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0307 - mean_squared_error: 0.0630\n",
      "Epoch 127: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0307 - mean_squared_error: 0.0630 - val_loss: 0.0917 - val_mean_squared_error: 0.1864\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0274 - mean_squared_error: 0.0563\n",
      "Epoch 128: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0274 - mean_squared_error: 0.0563 - val_loss: 0.0899 - val_mean_squared_error: 0.1819\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0270 - mean_squared_error: 0.0556\n",
      "Epoch 129: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0270 - mean_squared_error: 0.0556 - val_loss: 0.0834 - val_mean_squared_error: 0.1689\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0252 - mean_squared_error: 0.0520\n",
      "Epoch 130: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0252 - mean_squared_error: 0.0520 - val_loss: 0.0880 - val_mean_squared_error: 0.1783\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0260 - mean_squared_error: 0.0535\n",
      "Epoch 131: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0260 - mean_squared_error: 0.0535 - val_loss: 0.0877 - val_mean_squared_error: 0.1777\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0260 - mean_squared_error: 0.0536\n",
      "Epoch 132: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0260 - mean_squared_error: 0.0536 - val_loss: 0.0894 - val_mean_squared_error: 0.1812\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0260 - mean_squared_error: 0.0535\n",
      "Epoch 133: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0260 - mean_squared_error: 0.0535 - val_loss: 0.0931 - val_mean_squared_error: 0.1888\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0248 - mean_squared_error: 0.0513\n",
      "Epoch 134: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0248 - mean_squared_error: 0.0513 - val_loss: 0.0888 - val_mean_squared_error: 0.1805\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0256 - mean_squared_error: 0.0529\n",
      "Epoch 135: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0256 - mean_squared_error: 0.0529 - val_loss: 0.0879 - val_mean_squared_error: 0.1778\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0276 - mean_squared_error: 0.0566\n",
      "Epoch 136: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0276 - mean_squared_error: 0.0566 - val_loss: 0.0881 - val_mean_squared_error: 0.1788\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0279 - mean_squared_error: 0.0574\n",
      "Epoch 137: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0279 - mean_squared_error: 0.0574 - val_loss: 0.0937 - val_mean_squared_error: 0.1903\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0516\n",
      "Epoch 138: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0251 - mean_squared_error: 0.0516 - val_loss: 0.0817 - val_mean_squared_error: 0.1655\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0518\n",
      "Epoch 139: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0251 - mean_squared_error: 0.0518 - val_loss: 0.0930 - val_mean_squared_error: 0.1890\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0236 - mean_squared_error: 0.0488\n",
      "Epoch 140: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0236 - mean_squared_error: 0.0488 - val_loss: 0.0855 - val_mean_squared_error: 0.1735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0232 - mean_squared_error: 0.0479\n",
      "Epoch 141: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0232 - mean_squared_error: 0.0479 - val_loss: 0.0836 - val_mean_squared_error: 0.1696\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0518\n",
      "Epoch 142: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0251 - mean_squared_error: 0.0518 - val_loss: 0.0950 - val_mean_squared_error: 0.1930\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0240 - mean_squared_error: 0.0494\n",
      "Epoch 143: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0240 - mean_squared_error: 0.0494 - val_loss: 0.0910 - val_mean_squared_error: 0.1849\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0221 - mean_squared_error: 0.0458\n",
      "Epoch 144: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0221 - mean_squared_error: 0.0458 - val_loss: 0.0929 - val_mean_squared_error: 0.1891\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0219 - mean_squared_error: 0.0452\n",
      "Epoch 145: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0219 - mean_squared_error: 0.0452 - val_loss: 0.0915 - val_mean_squared_error: 0.1860\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0219 - mean_squared_error: 0.0453\n",
      "Epoch 146: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0219 - mean_squared_error: 0.0453 - val_loss: 0.0955 - val_mean_squared_error: 0.1945\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0464\n",
      "Epoch 147: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0224 - mean_squared_error: 0.0464 - val_loss: 0.0876 - val_mean_squared_error: 0.1779\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0215 - mean_squared_error: 0.0446\n",
      "Epoch 148: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0215 - mean_squared_error: 0.0446 - val_loss: 0.0943 - val_mean_squared_error: 0.1924\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0209 - mean_squared_error: 0.0434\n",
      "Epoch 149: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0209 - mean_squared_error: 0.0434 - val_loss: 0.0927 - val_mean_squared_error: 0.1886\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0222 - mean_squared_error: 0.0461\n",
      "Epoch 150: val_loss did not improve from 0.07411\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0222 - mean_squared_error: 0.0461 - val_loss: 0.0901 - val_mean_squared_error: 0.1830\n",
      "5/5 [==============================] - 14s 164ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  192\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4082 - mean_squared_error: 0.9231\n",
      "Epoch 1: val_loss improved from inf to 0.28574, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 74s 3s/step - loss: 0.4082 - mean_squared_error: 0.9231 - val_loss: 0.2857 - val_mean_squared_error: 0.6217\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2392 - mean_squared_error: 0.5191\n",
      "Epoch 2: val_loss improved from 0.28574 to 0.16350, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.2392 - mean_squared_error: 0.5191 - val_loss: 0.1635 - val_mean_squared_error: 0.3384\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1373 - mean_squared_error: 0.2834\n",
      "Epoch 3: val_loss improved from 0.16350 to 0.14219, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.1373 - mean_squared_error: 0.2834 - val_loss: 0.1422 - val_mean_squared_error: 0.2909\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1120 - mean_squared_error: 0.2294\n",
      "Epoch 4: val_loss improved from 0.14219 to 0.12964, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.1120 - mean_squared_error: 0.2294 - val_loss: 0.1296 - val_mean_squared_error: 0.2636\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.2112\n",
      "Epoch 5: val_loss improved from 0.12964 to 0.12823, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.1035 - mean_squared_error: 0.2112 - val_loss: 0.1282 - val_mean_squared_error: 0.2605\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1012 - mean_squared_error: 0.2067\n",
      "Epoch 6: val_loss improved from 0.12823 to 0.12531, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.1012 - mean_squared_error: 0.2067 - val_loss: 0.1253 - val_mean_squared_error: 0.2546\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0983 - mean_squared_error: 0.2001\n",
      "Epoch 7: val_loss improved from 0.12531 to 0.12525, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0983 - mean_squared_error: 0.2001 - val_loss: 0.1252 - val_mean_squared_error: 0.2549\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0932 - mean_squared_error: 0.1901\n",
      "Epoch 8: val_loss improved from 0.12525 to 0.11602, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0932 - mean_squared_error: 0.1901 - val_loss: 0.1160 - val_mean_squared_error: 0.2353\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0918 - mean_squared_error: 0.1873\n",
      "Epoch 9: val_loss did not improve from 0.11602\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0918 - mean_squared_error: 0.1873 - val_loss: 0.1260 - val_mean_squared_error: 0.2572\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0906 - mean_squared_error: 0.1843\n",
      "Epoch 10: val_loss did not improve from 0.11602\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0906 - mean_squared_error: 0.1843 - val_loss: 0.1207 - val_mean_squared_error: 0.2465\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0909 - mean_squared_error: 0.1858\n",
      "Epoch 11: val_loss did not improve from 0.11602\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0909 - mean_squared_error: 0.1858 - val_loss: 0.1220 - val_mean_squared_error: 0.2491\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0874 - mean_squared_error: 0.1787\n",
      "Epoch 12: val_loss improved from 0.11602 to 0.11429, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0874 - mean_squared_error: 0.1787 - val_loss: 0.1143 - val_mean_squared_error: 0.2334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0841 - mean_squared_error: 0.1723\n",
      "Epoch 13: val_loss did not improve from 0.11429\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0841 - mean_squared_error: 0.1723 - val_loss: 0.1160 - val_mean_squared_error: 0.2374\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0844 - mean_squared_error: 0.1730\n",
      "Epoch 14: val_loss did not improve from 0.11429\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0844 - mean_squared_error: 0.1730 - val_loss: 0.1194 - val_mean_squared_error: 0.2447\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0847 - mean_squared_error: 0.1735\n",
      "Epoch 15: val_loss did not improve from 0.11429\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0847 - mean_squared_error: 0.1735 - val_loss: 0.1156 - val_mean_squared_error: 0.2371\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0798 - mean_squared_error: 0.1631\n",
      "Epoch 16: val_loss improved from 0.11429 to 0.10423, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0798 - mean_squared_error: 0.1631 - val_loss: 0.1042 - val_mean_squared_error: 0.2119\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0890 - mean_squared_error: 0.1829\n",
      "Epoch 17: val_loss did not improve from 0.10423\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0890 - mean_squared_error: 0.1829 - val_loss: 0.1168 - val_mean_squared_error: 0.2387\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0774 - mean_squared_error: 0.1579\n",
      "Epoch 18: val_loss improved from 0.10423 to 0.10088, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0774 - mean_squared_error: 0.1579 - val_loss: 0.1009 - val_mean_squared_error: 0.2052\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0765 - mean_squared_error: 0.1563\n",
      "Epoch 19: val_loss improved from 0.10088 to 0.09737, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0765 - mean_squared_error: 0.1563 - val_loss: 0.0974 - val_mean_squared_error: 0.1982\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0793 - mean_squared_error: 0.1616\n",
      "Epoch 20: val_loss did not improve from 0.09737\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0793 - mean_squared_error: 0.1616 - val_loss: 0.1006 - val_mean_squared_error: 0.2041\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0730 - mean_squared_error: 0.1493\n",
      "Epoch 21: val_loss did not improve from 0.09737\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0730 - mean_squared_error: 0.1493 - val_loss: 0.1138 - val_mean_squared_error: 0.2321\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0889 - mean_squared_error: 0.1810\n",
      "Epoch 22: val_loss did not improve from 0.09737\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0889 - mean_squared_error: 0.1810 - val_loss: 0.1092 - val_mean_squared_error: 0.2222\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0833 - mean_squared_error: 0.1707\n",
      "Epoch 23: val_loss did not improve from 0.09737\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0833 - mean_squared_error: 0.1707 - val_loss: 0.0977 - val_mean_squared_error: 0.1986\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0760 - mean_squared_error: 0.1557\n",
      "Epoch 24: val_loss did not improve from 0.09737\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0760 - mean_squared_error: 0.1557 - val_loss: 0.1140 - val_mean_squared_error: 0.2324\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0753 - mean_squared_error: 0.1534\n",
      "Epoch 25: val_loss improved from 0.09737 to 0.08755, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0753 - mean_squared_error: 0.1534 - val_loss: 0.0875 - val_mean_squared_error: 0.1775\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0712 - mean_squared_error: 0.1460\n",
      "Epoch 26: val_loss did not improve from 0.08755\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0712 - mean_squared_error: 0.1460 - val_loss: 0.0950 - val_mean_squared_error: 0.1930\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0663 - mean_squared_error: 0.1357\n",
      "Epoch 27: val_loss did not improve from 0.08755\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0663 - mean_squared_error: 0.1357 - val_loss: 0.1027 - val_mean_squared_error: 0.2096\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0648 - mean_squared_error: 0.1323\n",
      "Epoch 28: val_loss did not improve from 0.08755\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0648 - mean_squared_error: 0.1323 - val_loss: 0.1006 - val_mean_squared_error: 0.2049\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0657 - mean_squared_error: 0.1345\n",
      "Epoch 29: val_loss did not improve from 0.08755\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0657 - mean_squared_error: 0.1345 - val_loss: 0.1024 - val_mean_squared_error: 0.2095\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0624 - mean_squared_error: 0.1271\n",
      "Epoch 30: val_loss did not improve from 0.08755\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0624 - mean_squared_error: 0.1271 - val_loss: 0.0878 - val_mean_squared_error: 0.1776\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0689 - mean_squared_error: 0.1402\n",
      "Epoch 31: val_loss did not improve from 0.08755\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0689 - mean_squared_error: 0.1402 - val_loss: 0.0947 - val_mean_squared_error: 0.1925\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0678 - mean_squared_error: 0.1382\n",
      "Epoch 32: val_loss did not improve from 0.08755\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.0678 - mean_squared_error: 0.1382 - val_loss: 0.0997 - val_mean_squared_error: 0.2026\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0668 - mean_squared_error: 0.1359\n",
      "Epoch 33: val_loss did not improve from 0.08755\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0668 - mean_squared_error: 0.1359 - val_loss: 0.0959 - val_mean_squared_error: 0.1952\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0636 - mean_squared_error: 0.1297\n",
      "Epoch 34: val_loss did not improve from 0.08755\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0636 - mean_squared_error: 0.1297 - val_loss: 0.0970 - val_mean_squared_error: 0.1965\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0593 - mean_squared_error: 0.1211\n",
      "Epoch 35: val_loss improved from 0.08755 to 0.08281, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0593 - mean_squared_error: 0.1211 - val_loss: 0.0828 - val_mean_squared_error: 0.1674\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0564 - mean_squared_error: 0.1150\n",
      "Epoch 36: val_loss did not improve from 0.08281\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0564 - mean_squared_error: 0.1150 - val_loss: 0.0994 - val_mean_squared_error: 0.2016\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0677 - mean_squared_error: 0.1374\n",
      "Epoch 37: val_loss did not improve from 0.08281\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0677 - mean_squared_error: 0.1374 - val_loss: 0.0947 - val_mean_squared_error: 0.1929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0734 - mean_squared_error: 0.1496\n",
      "Epoch 38: val_loss did not improve from 0.08281\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0734 - mean_squared_error: 0.1496 - val_loss: 0.0925 - val_mean_squared_error: 0.1872\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0646 - mean_squared_error: 0.1317\n",
      "Epoch 39: val_loss did not improve from 0.08281\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0646 - mean_squared_error: 0.1317 - val_loss: 0.0885 - val_mean_squared_error: 0.1788\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0589 - mean_squared_error: 0.1202\n",
      "Epoch 40: val_loss improved from 0.08281 to 0.08156, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0589 - mean_squared_error: 0.1202 - val_loss: 0.0816 - val_mean_squared_error: 0.1646\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0583 - mean_squared_error: 0.1187\n",
      "Epoch 41: val_loss improved from 0.08156 to 0.08087, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0583 - mean_squared_error: 0.1187 - val_loss: 0.0809 - val_mean_squared_error: 0.1633\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0586 - mean_squared_error: 0.1195\n",
      "Epoch 42: val_loss did not improve from 0.08087\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0586 - mean_squared_error: 0.1195 - val_loss: 0.0880 - val_mean_squared_error: 0.1778\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0609 - mean_squared_error: 0.1244\n",
      "Epoch 43: val_loss did not improve from 0.08087\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0609 - mean_squared_error: 0.1244 - val_loss: 0.0987 - val_mean_squared_error: 0.2007\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0561 - mean_squared_error: 0.1145\n",
      "Epoch 44: val_loss did not improve from 0.08087\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0561 - mean_squared_error: 0.1145 - val_loss: 0.0980 - val_mean_squared_error: 0.1996\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0628 - mean_squared_error: 0.1280\n",
      "Epoch 45: val_loss did not improve from 0.08087\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0628 - mean_squared_error: 0.1280 - val_loss: 0.0856 - val_mean_squared_error: 0.1731\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0563 - mean_squared_error: 0.1153\n",
      "Epoch 46: val_loss did not improve from 0.08087\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0563 - mean_squared_error: 0.1153 - val_loss: 0.0893 - val_mean_squared_error: 0.1803\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0566 - mean_squared_error: 0.1155\n",
      "Epoch 47: val_loss did not improve from 0.08087\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0566 - mean_squared_error: 0.1155 - val_loss: 0.0867 - val_mean_squared_error: 0.1749\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0528 - mean_squared_error: 0.1076\n",
      "Epoch 48: val_loss did not improve from 0.08087\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0528 - mean_squared_error: 0.1076 - val_loss: 0.0870 - val_mean_squared_error: 0.1758\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0557 - mean_squared_error: 0.1134\n",
      "Epoch 49: val_loss did not improve from 0.08087\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0557 - mean_squared_error: 0.1134 - val_loss: 0.0877 - val_mean_squared_error: 0.1769\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0547 - mean_squared_error: 0.1114\n",
      "Epoch 50: val_loss did not improve from 0.08087\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0547 - mean_squared_error: 0.1114 - val_loss: 0.0838 - val_mean_squared_error: 0.1699\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0546 - mean_squared_error: 0.1112\n",
      "Epoch 51: val_loss did not improve from 0.08087\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0546 - mean_squared_error: 0.1112 - val_loss: 0.0893 - val_mean_squared_error: 0.1802\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0528 - mean_squared_error: 0.1078\n",
      "Epoch 52: val_loss did not improve from 0.08087\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0528 - mean_squared_error: 0.1078 - val_loss: 0.0838 - val_mean_squared_error: 0.1697\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0526 - mean_squared_error: 0.1073\n",
      "Epoch 53: val_loss did not improve from 0.08087\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0526 - mean_squared_error: 0.1073 - val_loss: 0.0830 - val_mean_squared_error: 0.1676\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0538 - mean_squared_error: 0.1097\n",
      "Epoch 54: val_loss did not improve from 0.08087\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0538 - mean_squared_error: 0.1097 - val_loss: 0.0876 - val_mean_squared_error: 0.1769\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0536 - mean_squared_error: 0.1093\n",
      "Epoch 55: val_loss improved from 0.08087 to 0.08061, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0536 - mean_squared_error: 0.1093 - val_loss: 0.0806 - val_mean_squared_error: 0.1628\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0523 - mean_squared_error: 0.1066\n",
      "Epoch 56: val_loss did not improve from 0.08061\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0523 - mean_squared_error: 0.1066 - val_loss: 0.0847 - val_mean_squared_error: 0.1717\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0504 - mean_squared_error: 0.1030\n",
      "Epoch 57: val_loss did not improve from 0.08061\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0504 - mean_squared_error: 0.1030 - val_loss: 0.0866 - val_mean_squared_error: 0.1751\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0493 - mean_squared_error: 0.1006\n",
      "Epoch 58: val_loss did not improve from 0.08061\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0493 - mean_squared_error: 0.1006 - val_loss: 0.0897 - val_mean_squared_error: 0.1825\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0491 - mean_squared_error: 0.1001\n",
      "Epoch 59: val_loss did not improve from 0.08061\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0491 - mean_squared_error: 0.1001 - val_loss: 0.0874 - val_mean_squared_error: 0.1774\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0481 - mean_squared_error: 0.0982\n",
      "Epoch 60: val_loss did not improve from 0.08061\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0481 - mean_squared_error: 0.0982 - val_loss: 0.0847 - val_mean_squared_error: 0.1715\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0503 - mean_squared_error: 0.1027\n",
      "Epoch 61: val_loss did not improve from 0.08061\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0503 - mean_squared_error: 0.1027 - val_loss: 0.0866 - val_mean_squared_error: 0.1756\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0506 - mean_squared_error: 0.1032\n",
      "Epoch 62: val_loss did not improve from 0.08061\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0506 - mean_squared_error: 0.1032 - val_loss: 0.0904 - val_mean_squared_error: 0.1839\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0502 - mean_squared_error: 0.1023\n",
      "Epoch 63: val_loss did not improve from 0.08061\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0502 - mean_squared_error: 0.1023 - val_loss: 0.0993 - val_mean_squared_error: 0.2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0509 - mean_squared_error: 0.1038\n",
      "Epoch 64: val_loss did not improve from 0.08061\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0509 - mean_squared_error: 0.1038 - val_loss: 0.0855 - val_mean_squared_error: 0.1733\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0484 - mean_squared_error: 0.0988\n",
      "Epoch 65: val_loss did not improve from 0.08061\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0484 - mean_squared_error: 0.0988 - val_loss: 0.0921 - val_mean_squared_error: 0.1866\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0470 - mean_squared_error: 0.0958\n",
      "Epoch 66: val_loss did not improve from 0.08061\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0470 - mean_squared_error: 0.0958 - val_loss: 0.0942 - val_mean_squared_error: 0.1913\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0497 - mean_squared_error: 0.1014\n",
      "Epoch 67: val_loss improved from 0.08061 to 0.07776, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0497 - mean_squared_error: 0.1014 - val_loss: 0.0778 - val_mean_squared_error: 0.1568\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0489 - mean_squared_error: 0.0998\n",
      "Epoch 68: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0489 - mean_squared_error: 0.0998 - val_loss: 0.0844 - val_mean_squared_error: 0.1703\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0494 - mean_squared_error: 0.1008\n",
      "Epoch 69: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0494 - mean_squared_error: 0.1008 - val_loss: 0.0846 - val_mean_squared_error: 0.1712\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0490 - mean_squared_error: 0.0998\n",
      "Epoch 70: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0490 - mean_squared_error: 0.0998 - val_loss: 0.0805 - val_mean_squared_error: 0.1621\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0471 - mean_squared_error: 0.0962\n",
      "Epoch 71: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0471 - mean_squared_error: 0.0962 - val_loss: 0.0848 - val_mean_squared_error: 0.1717\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0463 - mean_squared_error: 0.0944\n",
      "Epoch 72: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0463 - mean_squared_error: 0.0944 - val_loss: 0.0901 - val_mean_squared_error: 0.1824\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0472 - mean_squared_error: 0.0962\n",
      "Epoch 73: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0472 - mean_squared_error: 0.0962 - val_loss: 0.0821 - val_mean_squared_error: 0.1659\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0461 - mean_squared_error: 0.0940\n",
      "Epoch 74: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0461 - mean_squared_error: 0.0940 - val_loss: 0.0842 - val_mean_squared_error: 0.1701\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0463 - mean_squared_error: 0.0945\n",
      "Epoch 75: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0463 - mean_squared_error: 0.0945 - val_loss: 0.0862 - val_mean_squared_error: 0.1744\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.0919\n",
      "Epoch 76: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0450 - mean_squared_error: 0.0919 - val_loss: 0.0915 - val_mean_squared_error: 0.1858\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0476 - mean_squared_error: 0.0970\n",
      "Epoch 77: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0476 - mean_squared_error: 0.0970 - val_loss: 0.0846 - val_mean_squared_error: 0.1708\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.0918\n",
      "Epoch 78: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0450 - mean_squared_error: 0.0918 - val_loss: 0.0796 - val_mean_squared_error: 0.1609\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0492 - mean_squared_error: 0.1004\n",
      "Epoch 79: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0492 - mean_squared_error: 0.1004 - val_loss: 0.0863 - val_mean_squared_error: 0.1744\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0943\n",
      "Epoch 80: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0462 - mean_squared_error: 0.0943 - val_loss: 0.0924 - val_mean_squared_error: 0.1871\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0941\n",
      "Epoch 81: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0462 - mean_squared_error: 0.0941 - val_loss: 0.0868 - val_mean_squared_error: 0.1752\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0445 - mean_squared_error: 0.0908\n",
      "Epoch 82: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0445 - mean_squared_error: 0.0908 - val_loss: 0.0806 - val_mean_squared_error: 0.1627\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0446 - mean_squared_error: 0.0911\n",
      "Epoch 83: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0446 - mean_squared_error: 0.0911 - val_loss: 0.0828 - val_mean_squared_error: 0.1670\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0446 - mean_squared_error: 0.0909\n",
      "Epoch 84: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0446 - mean_squared_error: 0.0909 - val_loss: 0.0846 - val_mean_squared_error: 0.1711\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0445 - mean_squared_error: 0.0908\n",
      "Epoch 85: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0445 - mean_squared_error: 0.0908 - val_loss: 0.0888 - val_mean_squared_error: 0.1800\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0449 - mean_squared_error: 0.0916\n",
      "Epoch 86: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0449 - mean_squared_error: 0.0916 - val_loss: 0.0853 - val_mean_squared_error: 0.1721\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0441 - mean_squared_error: 0.0901\n",
      "Epoch 87: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0441 - mean_squared_error: 0.0901 - val_loss: 0.0875 - val_mean_squared_error: 0.1774\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0465 - mean_squared_error: 0.0949\n",
      "Epoch 88: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0465 - mean_squared_error: 0.0949 - val_loss: 0.0794 - val_mean_squared_error: 0.1602\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0565 - mean_squared_error: 0.1152\n",
      "Epoch 89: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0565 - mean_squared_error: 0.1152 - val_loss: 0.1019 - val_mean_squared_error: 0.2090\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0470 - mean_squared_error: 0.0960\n",
      "Epoch 90: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0470 - mean_squared_error: 0.0960 - val_loss: 0.0850 - val_mean_squared_error: 0.1713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0443 - mean_squared_error: 0.0906\n",
      "Epoch 91: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0443 - mean_squared_error: 0.0906 - val_loss: 0.0846 - val_mean_squared_error: 0.1713\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0421 - mean_squared_error: 0.0859\n",
      "Epoch 92: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0421 - mean_squared_error: 0.0859 - val_loss: 0.0794 - val_mean_squared_error: 0.1597\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0408 - mean_squared_error: 0.0835\n",
      "Epoch 93: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0408 - mean_squared_error: 0.0835 - val_loss: 0.0839 - val_mean_squared_error: 0.1692\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0828\n",
      "Epoch 94: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0405 - mean_squared_error: 0.0828 - val_loss: 0.0815 - val_mean_squared_error: 0.1641\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0395 - mean_squared_error: 0.0807\n",
      "Epoch 95: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0395 - mean_squared_error: 0.0807 - val_loss: 0.0803 - val_mean_squared_error: 0.1619\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0404 - mean_squared_error: 0.0825\n",
      "Epoch 96: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0404 - mean_squared_error: 0.0825 - val_loss: 0.0903 - val_mean_squared_error: 0.1823\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0813\n",
      "Epoch 97: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0398 - mean_squared_error: 0.0813 - val_loss: 0.0829 - val_mean_squared_error: 0.1671\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.0798\n",
      "Epoch 98: val_loss did not improve from 0.07776\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0390 - mean_squared_error: 0.0798 - val_loss: 0.0825 - val_mean_squared_error: 0.1662\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0784\n",
      "Epoch 99: val_loss improved from 0.07776 to 0.07587, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0384 - mean_squared_error: 0.0784 - val_loss: 0.0759 - val_mean_squared_error: 0.1526\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0813\n",
      "Epoch 100: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0398 - mean_squared_error: 0.0813 - val_loss: 0.0861 - val_mean_squared_error: 0.1740\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0395 - mean_squared_error: 0.0806\n",
      "Epoch 101: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0395 - mean_squared_error: 0.0806 - val_loss: 0.0859 - val_mean_squared_error: 0.1733\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0413 - mean_squared_error: 0.0843\n",
      "Epoch 102: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0413 - mean_squared_error: 0.0843 - val_loss: 0.0897 - val_mean_squared_error: 0.1810\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0408 - mean_squared_error: 0.0833\n",
      "Epoch 103: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0408 - mean_squared_error: 0.0833 - val_loss: 0.0813 - val_mean_squared_error: 0.1637\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0800\n",
      "Epoch 104: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0392 - mean_squared_error: 0.0800 - val_loss: 0.0827 - val_mean_squared_error: 0.1662\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0456 - mean_squared_error: 0.0932\n",
      "Epoch 105: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0456 - mean_squared_error: 0.0932 - val_loss: 0.0862 - val_mean_squared_error: 0.1754\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0511 - mean_squared_error: 0.1046\n",
      "Epoch 106: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0511 - mean_squared_error: 0.1046 - val_loss: 0.0888 - val_mean_squared_error: 0.1810\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0455 - mean_squared_error: 0.0928\n",
      "Epoch 107: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0455 - mean_squared_error: 0.0928 - val_loss: 0.0762 - val_mean_squared_error: 0.1536\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0511 - mean_squared_error: 0.1042\n",
      "Epoch 108: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0511 - mean_squared_error: 0.1042 - val_loss: 0.0927 - val_mean_squared_error: 0.1880\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0500 - mean_squared_error: 0.1018\n",
      "Epoch 109: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0500 - mean_squared_error: 0.1018 - val_loss: 0.0850 - val_mean_squared_error: 0.1724\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0443 - mean_squared_error: 0.0904\n",
      "Epoch 110: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0443 - mean_squared_error: 0.0904 - val_loss: 0.0816 - val_mean_squared_error: 0.1643\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0420 - mean_squared_error: 0.0855\n",
      "Epoch 111: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0420 - mean_squared_error: 0.0855 - val_loss: 0.0820 - val_mean_squared_error: 0.1656\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0397 - mean_squared_error: 0.0812\n",
      "Epoch 112: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0397 - mean_squared_error: 0.0812 - val_loss: 0.0869 - val_mean_squared_error: 0.1757\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0402 - mean_squared_error: 0.0821\n",
      "Epoch 113: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0402 - mean_squared_error: 0.0821 - val_loss: 0.0761 - val_mean_squared_error: 0.1533\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0396 - mean_squared_error: 0.0809\n",
      "Epoch 114: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0396 - mean_squared_error: 0.0809 - val_loss: 0.0825 - val_mean_squared_error: 0.1665\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0372 - mean_squared_error: 0.0761\n",
      "Epoch 115: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0372 - mean_squared_error: 0.0761 - val_loss: 0.0846 - val_mean_squared_error: 0.1708\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0356 - mean_squared_error: 0.0729\n",
      "Epoch 116: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0356 - mean_squared_error: 0.0729 - val_loss: 0.0806 - val_mean_squared_error: 0.1624\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0349 - mean_squared_error: 0.0715\n",
      "Epoch 117: val_loss did not improve from 0.07587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 17s 2s/step - loss: 0.0349 - mean_squared_error: 0.0715 - val_loss: 0.0926 - val_mean_squared_error: 0.1875\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0379 - mean_squared_error: 0.0773\n",
      "Epoch 118: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0379 - mean_squared_error: 0.0773 - val_loss: 0.0777 - val_mean_squared_error: 0.1566\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0800\n",
      "Epoch 119: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0391 - mean_squared_error: 0.0800 - val_loss: 0.0955 - val_mean_squared_error: 0.1930\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0387 - mean_squared_error: 0.0790\n",
      "Epoch 120: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0387 - mean_squared_error: 0.0790 - val_loss: 0.0819 - val_mean_squared_error: 0.1651\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0372 - mean_squared_error: 0.0763\n",
      "Epoch 121: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0372 - mean_squared_error: 0.0763 - val_loss: 0.0907 - val_mean_squared_error: 0.1833\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0806\n",
      "Epoch 122: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0394 - mean_squared_error: 0.0806 - val_loss: 0.0867 - val_mean_squared_error: 0.1751\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0799\n",
      "Epoch 123: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0391 - mean_squared_error: 0.0799 - val_loss: 0.0811 - val_mean_squared_error: 0.1634\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0407 - mean_squared_error: 0.0830\n",
      "Epoch 124: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0407 - mean_squared_error: 0.0830 - val_loss: 0.0816 - val_mean_squared_error: 0.1644\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0370 - mean_squared_error: 0.0758\n",
      "Epoch 125: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0370 - mean_squared_error: 0.0758 - val_loss: 0.0829 - val_mean_squared_error: 0.1676\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0357 - mean_squared_error: 0.0731\n",
      "Epoch 126: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0357 - mean_squared_error: 0.0731 - val_loss: 0.0814 - val_mean_squared_error: 0.1640\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0348 - mean_squared_error: 0.0712\n",
      "Epoch 127: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0348 - mean_squared_error: 0.0712 - val_loss: 0.0832 - val_mean_squared_error: 0.1679\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0336 - mean_squared_error: 0.0690\n",
      "Epoch 128: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0336 - mean_squared_error: 0.0690 - val_loss: 0.0927 - val_mean_squared_error: 0.1880\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0336 - mean_squared_error: 0.0688\n",
      "Epoch 129: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0336 - mean_squared_error: 0.0688 - val_loss: 0.0817 - val_mean_squared_error: 0.1647\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0662\n",
      "Epoch 130: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0323 - mean_squared_error: 0.0662 - val_loss: 0.0781 - val_mean_squared_error: 0.1576\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0325 - mean_squared_error: 0.0667\n",
      "Epoch 131: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0325 - mean_squared_error: 0.0667 - val_loss: 0.0860 - val_mean_squared_error: 0.1737\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0316 - mean_squared_error: 0.0648\n",
      "Epoch 132: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0316 - mean_squared_error: 0.0648 - val_loss: 0.0856 - val_mean_squared_error: 0.1724\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0315 - mean_squared_error: 0.0647\n",
      "Epoch 133: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0315 - mean_squared_error: 0.0647 - val_loss: 0.0817 - val_mean_squared_error: 0.1648\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0321 - mean_squared_error: 0.0658\n",
      "Epoch 134: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0321 - mean_squared_error: 0.0658 - val_loss: 0.0846 - val_mean_squared_error: 0.1706\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0308 - mean_squared_error: 0.0631\n",
      "Epoch 135: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0308 - mean_squared_error: 0.0631 - val_loss: 0.0897 - val_mean_squared_error: 0.1817\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0311 - mean_squared_error: 0.0638\n",
      "Epoch 136: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0311 - mean_squared_error: 0.0638 - val_loss: 0.0846 - val_mean_squared_error: 0.1705\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0316 - mean_squared_error: 0.0648\n",
      "Epoch 137: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0316 - mean_squared_error: 0.0648 - val_loss: 0.0905 - val_mean_squared_error: 0.1833\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0319 - mean_squared_error: 0.0653\n",
      "Epoch 138: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0319 - mean_squared_error: 0.0653 - val_loss: 0.0815 - val_mean_squared_error: 0.1644\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0335 - mean_squared_error: 0.0687\n",
      "Epoch 139: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0335 - mean_squared_error: 0.0687 - val_loss: 0.0952 - val_mean_squared_error: 0.1920\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0345 - mean_squared_error: 0.0707\n",
      "Epoch 140: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0345 - mean_squared_error: 0.0707 - val_loss: 0.0916 - val_mean_squared_error: 0.1860\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0662\n",
      "Epoch 141: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0323 - mean_squared_error: 0.0662 - val_loss: 0.0918 - val_mean_squared_error: 0.1855\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0301 - mean_squared_error: 0.0618\n",
      "Epoch 142: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0301 - mean_squared_error: 0.0618 - val_loss: 0.0851 - val_mean_squared_error: 0.1718\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0309 - mean_squared_error: 0.0636\n",
      "Epoch 143: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0309 - mean_squared_error: 0.0636 - val_loss: 0.0848 - val_mean_squared_error: 0.1710\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0310 - mean_squared_error: 0.0636\n",
      "Epoch 144: val_loss did not improve from 0.07587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 17s 2s/step - loss: 0.0310 - mean_squared_error: 0.0636 - val_loss: 0.0874 - val_mean_squared_error: 0.1763\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0379 - mean_squared_error: 0.0775\n",
      "Epoch 145: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0379 - mean_squared_error: 0.0775 - val_loss: 0.0973 - val_mean_squared_error: 0.1994\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0339 - mean_squared_error: 0.0696\n",
      "Epoch 146: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0339 - mean_squared_error: 0.0696 - val_loss: 0.0874 - val_mean_squared_error: 0.1763\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0369 - mean_squared_error: 0.0754\n",
      "Epoch 147: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0369 - mean_squared_error: 0.0754 - val_loss: 0.0897 - val_mean_squared_error: 0.1805\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0346 - mean_squared_error: 0.0709\n",
      "Epoch 148: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0346 - mean_squared_error: 0.0709 - val_loss: 0.0821 - val_mean_squared_error: 0.1659\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0307 - mean_squared_error: 0.0632\n",
      "Epoch 149: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0307 - mean_squared_error: 0.0632 - val_loss: 0.0917 - val_mean_squared_error: 0.1866\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0299 - mean_squared_error: 0.0613\n",
      "Epoch 150: val_loss did not improve from 0.07587\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0299 - mean_squared_error: 0.0613 - val_loss: 0.0836 - val_mean_squared_error: 0.1688\n",
      "5/5 [==============================] - 14s 176ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  216\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3853 - mean_squared_error: 0.8689\n",
      "Epoch 1: val_loss improved from inf to 0.30034, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 81s 3s/step - loss: 0.3853 - mean_squared_error: 0.8689 - val_loss: 0.3003 - val_mean_squared_error: 0.6675\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2371 - mean_squared_error: 0.5116\n",
      "Epoch 2: val_loss improved from 0.30034 to 0.18870, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2371 - mean_squared_error: 0.5116 - val_loss: 0.1887 - val_mean_squared_error: 0.3918\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1524 - mean_squared_error: 0.3155\n",
      "Epoch 3: val_loss improved from 0.18870 to 0.13791, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.1524 - mean_squared_error: 0.3155 - val_loss: 0.1379 - val_mean_squared_error: 0.2806\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1243 - mean_squared_error: 0.2551\n",
      "Epoch 4: val_loss improved from 0.13791 to 0.13615, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.1243 - mean_squared_error: 0.2551 - val_loss: 0.1362 - val_mean_squared_error: 0.2777\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1123 - mean_squared_error: 0.2299\n",
      "Epoch 5: val_loss improved from 0.13615 to 0.13176, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.1123 - mean_squared_error: 0.2299 - val_loss: 0.1318 - val_mean_squared_error: 0.2686\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1055 - mean_squared_error: 0.2151\n",
      "Epoch 6: val_loss improved from 0.13176 to 0.11802, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.1055 - mean_squared_error: 0.2151 - val_loss: 0.1180 - val_mean_squared_error: 0.2386\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1015 - mean_squared_error: 0.2074\n",
      "Epoch 7: val_loss did not improve from 0.11802\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.1015 - mean_squared_error: 0.2074 - val_loss: 0.1239 - val_mean_squared_error: 0.2515\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1003 - mean_squared_error: 0.2052\n",
      "Epoch 8: val_loss did not improve from 0.11802\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.1003 - mean_squared_error: 0.2052 - val_loss: 0.1255 - val_mean_squared_error: 0.2551\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1018 - mean_squared_error: 0.2082\n",
      "Epoch 9: val_loss did not improve from 0.11802\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.1018 - mean_squared_error: 0.2082 - val_loss: 0.1255 - val_mean_squared_error: 0.2547\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1031 - mean_squared_error: 0.2107\n",
      "Epoch 10: val_loss did not improve from 0.11802\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.1031 - mean_squared_error: 0.2107 - val_loss: 0.1221 - val_mean_squared_error: 0.2476\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0979 - mean_squared_error: 0.1995\n",
      "Epoch 11: val_loss did not improve from 0.11802\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0979 - mean_squared_error: 0.1995 - val_loss: 0.1230 - val_mean_squared_error: 0.2502\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0972 - mean_squared_error: 0.1988\n",
      "Epoch 12: val_loss improved from 0.11802 to 0.11347, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0972 - mean_squared_error: 0.1988 - val_loss: 0.1135 - val_mean_squared_error: 0.2312\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0900 - mean_squared_error: 0.1838\n",
      "Epoch 13: val_loss did not improve from 0.11347\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0900 - mean_squared_error: 0.1838 - val_loss: 0.1203 - val_mean_squared_error: 0.2454\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0890 - mean_squared_error: 0.1824\n",
      "Epoch 14: val_loss did not improve from 0.11347\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0890 - mean_squared_error: 0.1824 - val_loss: 0.1181 - val_mean_squared_error: 0.2412\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0938 - mean_squared_error: 0.1922\n",
      "Epoch 15: val_loss did not improve from 0.11347\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0938 - mean_squared_error: 0.1922 - val_loss: 0.1212 - val_mean_squared_error: 0.2473\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0929 - mean_squared_error: 0.1899\n",
      "Epoch 16: val_loss did not improve from 0.11347\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0929 - mean_squared_error: 0.1899 - val_loss: 0.1276 - val_mean_squared_error: 0.2621\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0931 - mean_squared_error: 0.1904\n",
      "Epoch 17: val_loss did not improve from 0.11347\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0931 - mean_squared_error: 0.1904 - val_loss: 0.1300 - val_mean_squared_error: 0.2662\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0877 - mean_squared_error: 0.1792\n",
      "Epoch 18: val_loss did not improve from 0.11347\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0877 - mean_squared_error: 0.1792 - val_loss: 0.1148 - val_mean_squared_error: 0.2356\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0850 - mean_squared_error: 0.1742\n",
      "Epoch 19: val_loss did not improve from 0.11347\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0850 - mean_squared_error: 0.1742 - val_loss: 0.1235 - val_mean_squared_error: 0.2529\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1003 - mean_squared_error: 0.2038\n",
      "Epoch 20: val_loss did not improve from 0.11347\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.1003 - mean_squared_error: 0.2038 - val_loss: 0.1351 - val_mean_squared_error: 0.2761\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0957 - mean_squared_error: 0.1950\n",
      "Epoch 21: val_loss did not improve from 0.11347\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0957 - mean_squared_error: 0.1950 - val_loss: 0.1208 - val_mean_squared_error: 0.2451\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0934 - mean_squared_error: 0.1899\n",
      "Epoch 22: val_loss did not improve from 0.11347\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0934 - mean_squared_error: 0.1899 - val_loss: 0.1179 - val_mean_squared_error: 0.2391\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0982 - mean_squared_error: 0.2024\n",
      "Epoch 23: val_loss did not improve from 0.11347\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0982 - mean_squared_error: 0.2024 - val_loss: 0.1202 - val_mean_squared_error: 0.2449\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0890 - mean_squared_error: 0.1818\n",
      "Epoch 24: val_loss did not improve from 0.11347\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0890 - mean_squared_error: 0.1818 - val_loss: 0.1147 - val_mean_squared_error: 0.2334\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0832 - mean_squared_error: 0.1700\n",
      "Epoch 25: val_loss improved from 0.11347 to 0.11009, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0832 - mean_squared_error: 0.1700 - val_loss: 0.1101 - val_mean_squared_error: 0.2245\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0838 - mean_squared_error: 0.1719\n",
      "Epoch 26: val_loss did not improve from 0.11009\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0838 - mean_squared_error: 0.1719 - val_loss: 0.1123 - val_mean_squared_error: 0.2289\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0810 - mean_squared_error: 0.1656\n",
      "Epoch 27: val_loss did not improve from 0.11009\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0810 - mean_squared_error: 0.1656 - val_loss: 0.1136 - val_mean_squared_error: 0.2315\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0823 - mean_squared_error: 0.1682\n",
      "Epoch 28: val_loss did not improve from 0.11009\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0823 - mean_squared_error: 0.1682 - val_loss: 0.1139 - val_mean_squared_error: 0.2322\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0817 - mean_squared_error: 0.1672\n",
      "Epoch 29: val_loss improved from 0.11009 to 0.10677, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0817 - mean_squared_error: 0.1672 - val_loss: 0.1068 - val_mean_squared_error: 0.2182\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0779 - mean_squared_error: 0.1593\n",
      "Epoch 30: val_loss improved from 0.10677 to 0.10309, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0779 - mean_squared_error: 0.1593 - val_loss: 0.1031 - val_mean_squared_error: 0.2098\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0757 - mean_squared_error: 0.1545\n",
      "Epoch 31: val_loss improved from 0.10309 to 0.09932, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0757 - mean_squared_error: 0.1545 - val_loss: 0.0993 - val_mean_squared_error: 0.2011\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0738 - mean_squared_error: 0.1507\n",
      "Epoch 32: val_loss improved from 0.09932 to 0.09733, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0738 - mean_squared_error: 0.1507 - val_loss: 0.0973 - val_mean_squared_error: 0.1976\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0706 - mean_squared_error: 0.1440\n",
      "Epoch 33: val_loss improved from 0.09733 to 0.08995, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0706 - mean_squared_error: 0.1440 - val_loss: 0.0899 - val_mean_squared_error: 0.1828\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0724 - mean_squared_error: 0.1480\n",
      "Epoch 34: val_loss did not improve from 0.08995\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0724 - mean_squared_error: 0.1480 - val_loss: 0.1020 - val_mean_squared_error: 0.2079\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0704 - mean_squared_error: 0.1439\n",
      "Epoch 35: val_loss improved from 0.08995 to 0.08840, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0704 - mean_squared_error: 0.1439 - val_loss: 0.0884 - val_mean_squared_error: 0.1790\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0680 - mean_squared_error: 0.1387\n",
      "Epoch 36: val_loss did not improve from 0.08840\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0680 - mean_squared_error: 0.1387 - val_loss: 0.0940 - val_mean_squared_error: 0.1919\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0657 - mean_squared_error: 0.1342\n",
      "Epoch 37: val_loss did not improve from 0.08840\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0657 - mean_squared_error: 0.1342 - val_loss: 0.0902 - val_mean_squared_error: 0.1841\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0638 - mean_squared_error: 0.1302\n",
      "Epoch 38: val_loss did not improve from 0.08840\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0638 - mean_squared_error: 0.1302 - val_loss: 0.0887 - val_mean_squared_error: 0.1804\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0619 - mean_squared_error: 0.1261\n",
      "Epoch 39: val_loss did not improve from 0.08840\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0619 - mean_squared_error: 0.1261 - val_loss: 0.0901 - val_mean_squared_error: 0.1842\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0677 - mean_squared_error: 0.1379\n",
      "Epoch 40: val_loss improved from 0.08840 to 0.08046, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0677 - mean_squared_error: 0.1379 - val_loss: 0.0805 - val_mean_squared_error: 0.1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0620 - mean_squared_error: 0.1266\n",
      "Epoch 41: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0620 - mean_squared_error: 0.1266 - val_loss: 0.0837 - val_mean_squared_error: 0.1701\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0669 - mean_squared_error: 0.1363\n",
      "Epoch 42: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0669 - mean_squared_error: 0.1363 - val_loss: 0.0992 - val_mean_squared_error: 0.2023\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0886 - mean_squared_error: 0.1814\n",
      "Epoch 43: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0886 - mean_squared_error: 0.1814 - val_loss: 0.1013 - val_mean_squared_error: 0.2047\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0868 - mean_squared_error: 0.1780\n",
      "Epoch 44: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0868 - mean_squared_error: 0.1780 - val_loss: 0.1269 - val_mean_squared_error: 0.2596\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0774 - mean_squared_error: 0.1580\n",
      "Epoch 45: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0774 - mean_squared_error: 0.1580 - val_loss: 0.0966 - val_mean_squared_error: 0.1967\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0763 - mean_squared_error: 0.1558\n",
      "Epoch 46: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0763 - mean_squared_error: 0.1558 - val_loss: 0.1113 - val_mean_squared_error: 0.2279\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0729 - mean_squared_error: 0.1489\n",
      "Epoch 47: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0729 - mean_squared_error: 0.1489 - val_loss: 0.0997 - val_mean_squared_error: 0.2034\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0747 - mean_squared_error: 0.1518\n",
      "Epoch 48: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0747 - mean_squared_error: 0.1518 - val_loss: 0.0923 - val_mean_squared_error: 0.1876\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0736 - mean_squared_error: 0.1504\n",
      "Epoch 49: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0736 - mean_squared_error: 0.1504 - val_loss: 0.1037 - val_mean_squared_error: 0.2121\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0737 - mean_squared_error: 0.1502\n",
      "Epoch 50: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0737 - mean_squared_error: 0.1502 - val_loss: 0.0875 - val_mean_squared_error: 0.1778\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0645 - mean_squared_error: 0.1318\n",
      "Epoch 51: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0645 - mean_squared_error: 0.1318 - val_loss: 0.0966 - val_mean_squared_error: 0.1961\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0611 - mean_squared_error: 0.1245\n",
      "Epoch 52: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0611 - mean_squared_error: 0.1245 - val_loss: 0.0848 - val_mean_squared_error: 0.1715\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0577 - mean_squared_error: 0.1178\n",
      "Epoch 53: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0577 - mean_squared_error: 0.1178 - val_loss: 0.0822 - val_mean_squared_error: 0.1663\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0572 - mean_squared_error: 0.1167\n",
      "Epoch 54: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0572 - mean_squared_error: 0.1167 - val_loss: 0.0941 - val_mean_squared_error: 0.1918\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0604 - mean_squared_error: 0.1230\n",
      "Epoch 55: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0604 - mean_squared_error: 0.1230 - val_loss: 0.0887 - val_mean_squared_error: 0.1801\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0612 - mean_squared_error: 0.1249\n",
      "Epoch 56: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0612 - mean_squared_error: 0.1249 - val_loss: 0.0885 - val_mean_squared_error: 0.1796\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0578 - mean_squared_error: 0.1177\n",
      "Epoch 57: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0578 - mean_squared_error: 0.1177 - val_loss: 0.0894 - val_mean_squared_error: 0.1816\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0548 - mean_squared_error: 0.1119\n",
      "Epoch 58: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0548 - mean_squared_error: 0.1119 - val_loss: 0.0893 - val_mean_squared_error: 0.1821\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0532 - mean_squared_error: 0.1085\n",
      "Epoch 59: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0532 - mean_squared_error: 0.1085 - val_loss: 0.0814 - val_mean_squared_error: 0.1648\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0511 - mean_squared_error: 0.1041\n",
      "Epoch 60: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0511 - mean_squared_error: 0.1041 - val_loss: 0.0857 - val_mean_squared_error: 0.1740\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0549 - mean_squared_error: 0.1120\n",
      "Epoch 61: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0549 - mean_squared_error: 0.1120 - val_loss: 0.0879 - val_mean_squared_error: 0.1800\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0529 - mean_squared_error: 0.1079\n",
      "Epoch 62: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0529 - mean_squared_error: 0.1079 - val_loss: 0.0806 - val_mean_squared_error: 0.1629\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0500 - mean_squared_error: 0.1019\n",
      "Epoch 63: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0500 - mean_squared_error: 0.1019 - val_loss: 0.0844 - val_mean_squared_error: 0.1709\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0503 - mean_squared_error: 0.1026\n",
      "Epoch 64: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0503 - mean_squared_error: 0.1026 - val_loss: 0.0883 - val_mean_squared_error: 0.1799\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0510 - mean_squared_error: 0.1040\n",
      "Epoch 65: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0510 - mean_squared_error: 0.1040 - val_loss: 0.0825 - val_mean_squared_error: 0.1672\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0566 - mean_squared_error: 0.1156\n",
      "Epoch 66: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0566 - mean_squared_error: 0.1156 - val_loss: 0.0871 - val_mean_squared_error: 0.1772\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0550 - mean_squared_error: 0.1123\n",
      "Epoch 67: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0550 - mean_squared_error: 0.1123 - val_loss: 0.0839 - val_mean_squared_error: 0.1692\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.0576 - mean_squared_error: 0.1174\n",
      "Epoch 68: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0576 - mean_squared_error: 0.1174 - val_loss: 0.0890 - val_mean_squared_error: 0.1825\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0564 - mean_squared_error: 0.1149\n",
      "Epoch 69: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0564 - mean_squared_error: 0.1149 - val_loss: 0.0865 - val_mean_squared_error: 0.1750\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0522 - mean_squared_error: 0.1065\n",
      "Epoch 70: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0522 - mean_squared_error: 0.1065 - val_loss: 0.0860 - val_mean_squared_error: 0.1746\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0493 - mean_squared_error: 0.1005\n",
      "Epoch 71: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0493 - mean_squared_error: 0.1005 - val_loss: 0.0827 - val_mean_squared_error: 0.1672\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0497 - mean_squared_error: 0.1016\n",
      "Epoch 72: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0497 - mean_squared_error: 0.1016 - val_loss: 0.0832 - val_mean_squared_error: 0.1687\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0482 - mean_squared_error: 0.0984\n",
      "Epoch 73: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0482 - mean_squared_error: 0.0984 - val_loss: 0.0836 - val_mean_squared_error: 0.1691\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0474 - mean_squared_error: 0.0967\n",
      "Epoch 74: val_loss did not improve from 0.08046\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0474 - mean_squared_error: 0.0967 - val_loss: 0.0834 - val_mean_squared_error: 0.1693\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0494 - mean_squared_error: 0.1010\n",
      "Epoch 75: val_loss improved from 0.08046 to 0.07913, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0494 - mean_squared_error: 0.1010 - val_loss: 0.0791 - val_mean_squared_error: 0.1608\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.1052\n",
      "Epoch 76: val_loss did not improve from 0.07913\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0515 - mean_squared_error: 0.1052 - val_loss: 0.0914 - val_mean_squared_error: 0.1855\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0512 - mean_squared_error: 0.1045\n",
      "Epoch 77: val_loss improved from 0.07913 to 0.07674, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0512 - mean_squared_error: 0.1045 - val_loss: 0.0767 - val_mean_squared_error: 0.1549\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0543 - mean_squared_error: 0.1106\n",
      "Epoch 78: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0543 - mean_squared_error: 0.1106 - val_loss: 0.0902 - val_mean_squared_error: 0.1827\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0522 - mean_squared_error: 0.1062\n",
      "Epoch 79: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0522 - mean_squared_error: 0.1062 - val_loss: 0.0790 - val_mean_squared_error: 0.1600\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0529 - mean_squared_error: 0.1080\n",
      "Epoch 80: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0529 - mean_squared_error: 0.1080 - val_loss: 0.0816 - val_mean_squared_error: 0.1652\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0504 - mean_squared_error: 0.1027\n",
      "Epoch 81: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0504 - mean_squared_error: 0.1027 - val_loss: 0.0826 - val_mean_squared_error: 0.1662\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0768 - mean_squared_error: 0.1591\n",
      "Epoch 82: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0768 - mean_squared_error: 0.1591 - val_loss: 0.1179 - val_mean_squared_error: 0.2429\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0637 - mean_squared_error: 0.1302\n",
      "Epoch 83: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0637 - mean_squared_error: 0.1302 - val_loss: 0.0857 - val_mean_squared_error: 0.1748\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0609 - mean_squared_error: 0.1244\n",
      "Epoch 84: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0609 - mean_squared_error: 0.1244 - val_loss: 0.0997 - val_mean_squared_error: 0.2043\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0534 - mean_squared_error: 0.1090\n",
      "Epoch 85: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0534 - mean_squared_error: 0.1090 - val_loss: 0.0875 - val_mean_squared_error: 0.1770\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0548 - mean_squared_error: 0.1114\n",
      "Epoch 86: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0548 - mean_squared_error: 0.1114 - val_loss: 0.0855 - val_mean_squared_error: 0.1725\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0499 - mean_squared_error: 0.1020\n",
      "Epoch 87: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0499 - mean_squared_error: 0.1020 - val_loss: 0.0828 - val_mean_squared_error: 0.1674\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0469 - mean_squared_error: 0.0959\n",
      "Epoch 88: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0469 - mean_squared_error: 0.0959 - val_loss: 0.0811 - val_mean_squared_error: 0.1635\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0464 - mean_squared_error: 0.0949\n",
      "Epoch 89: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0464 - mean_squared_error: 0.0949 - val_loss: 0.0823 - val_mean_squared_error: 0.1669\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0452 - mean_squared_error: 0.0923\n",
      "Epoch 90: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0452 - mean_squared_error: 0.0923 - val_loss: 0.0794 - val_mean_squared_error: 0.1601\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0441 - mean_squared_error: 0.0902\n",
      "Epoch 91: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0441 - mean_squared_error: 0.0902 - val_loss: 0.0779 - val_mean_squared_error: 0.1570\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0451 - mean_squared_error: 0.0921\n",
      "Epoch 92: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0451 - mean_squared_error: 0.0921 - val_loss: 0.0781 - val_mean_squared_error: 0.1573\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0447 - mean_squared_error: 0.0916\n",
      "Epoch 93: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0447 - mean_squared_error: 0.0916 - val_loss: 0.0798 - val_mean_squared_error: 0.1606\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0442 - mean_squared_error: 0.0905\n",
      "Epoch 94: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0442 - mean_squared_error: 0.0905 - val_loss: 0.0770 - val_mean_squared_error: 0.1553\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0438 - mean_squared_error: 0.0895\n",
      "Epoch 95: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0438 - mean_squared_error: 0.0895 - val_loss: 0.0800 - val_mean_squared_error: 0.1610\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0421 - mean_squared_error: 0.0861\n",
      "Epoch 96: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0421 - mean_squared_error: 0.0861 - val_loss: 0.0794 - val_mean_squared_error: 0.1604\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0424 - mean_squared_error: 0.0867\n",
      "Epoch 97: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0424 - mean_squared_error: 0.0867 - val_loss: 0.0863 - val_mean_squared_error: 0.1738\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0508 - mean_squared_error: 0.1035\n",
      "Epoch 98: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0508 - mean_squared_error: 0.1035 - val_loss: 0.0879 - val_mean_squared_error: 0.1779\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0446 - mean_squared_error: 0.0913\n",
      "Epoch 99: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0446 - mean_squared_error: 0.0913 - val_loss: 0.0800 - val_mean_squared_error: 0.1619\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0447 - mean_squared_error: 0.0914\n",
      "Epoch 100: val_loss did not improve from 0.07674\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0447 - mean_squared_error: 0.0914 - val_loss: 0.0884 - val_mean_squared_error: 0.1792\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0429 - mean_squared_error: 0.0877\n",
      "Epoch 101: val_loss improved from 0.07674 to 0.07672, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0429 - mean_squared_error: 0.0877 - val_loss: 0.0767 - val_mean_squared_error: 0.1544\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0464 - mean_squared_error: 0.0949\n",
      "Epoch 102: val_loss did not improve from 0.07672\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0464 - mean_squared_error: 0.0949 - val_loss: 0.0886 - val_mean_squared_error: 0.1808\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0430 - mean_squared_error: 0.0878\n",
      "Epoch 103: val_loss did not improve from 0.07672\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0430 - mean_squared_error: 0.0878 - val_loss: 0.0846 - val_mean_squared_error: 0.1710\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0443 - mean_squared_error: 0.0906\n",
      "Epoch 104: val_loss did not improve from 0.07672\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0443 - mean_squared_error: 0.0906 - val_loss: 0.0815 - val_mean_squared_error: 0.1647\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0425 - mean_squared_error: 0.0869\n",
      "Epoch 105: val_loss did not improve from 0.07672\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0425 - mean_squared_error: 0.0869 - val_loss: 0.0802 - val_mean_squared_error: 0.1620\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0428 - mean_squared_error: 0.0875\n",
      "Epoch 106: val_loss did not improve from 0.07672\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0428 - mean_squared_error: 0.0875 - val_loss: 0.0907 - val_mean_squared_error: 0.1844\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0407 - mean_squared_error: 0.0831\n",
      "Epoch 107: val_loss did not improve from 0.07672\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0407 - mean_squared_error: 0.0831 - val_loss: 0.0794 - val_mean_squared_error: 0.1606\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0402 - mean_squared_error: 0.0823\n",
      "Epoch 108: val_loss did not improve from 0.07672\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0402 - mean_squared_error: 0.0823 - val_loss: 0.0856 - val_mean_squared_error: 0.1730\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0411 - mean_squared_error: 0.0839\n",
      "Epoch 109: val_loss improved from 0.07672 to 0.07491, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0411 - mean_squared_error: 0.0839 - val_loss: 0.0749 - val_mean_squared_error: 0.1509\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0419 - mean_squared_error: 0.0857\n",
      "Epoch 110: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0419 - mean_squared_error: 0.0857 - val_loss: 0.0857 - val_mean_squared_error: 0.1736\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0813\n",
      "Epoch 111: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0398 - mean_squared_error: 0.0813 - val_loss: 0.0825 - val_mean_squared_error: 0.1677\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0829\n",
      "Epoch 112: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0405 - mean_squared_error: 0.0829 - val_loss: 0.0833 - val_mean_squared_error: 0.1691\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0458 - mean_squared_error: 0.0934\n",
      "Epoch 113: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0458 - mean_squared_error: 0.0934 - val_loss: 0.0863 - val_mean_squared_error: 0.1751\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0419 - mean_squared_error: 0.0857\n",
      "Epoch 114: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0419 - mean_squared_error: 0.0857 - val_loss: 0.0839 - val_mean_squared_error: 0.1701\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0409 - mean_squared_error: 0.0836\n",
      "Epoch 115: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0409 - mean_squared_error: 0.0836 - val_loss: 0.0839 - val_mean_squared_error: 0.1708\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0419 - mean_squared_error: 0.0855\n",
      "Epoch 116: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0419 - mean_squared_error: 0.0855 - val_loss: 0.0942 - val_mean_squared_error: 0.1916\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0799\n",
      "Epoch 117: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0391 - mean_squared_error: 0.0799 - val_loss: 0.0827 - val_mean_squared_error: 0.1682\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0414 - mean_squared_error: 0.0846\n",
      "Epoch 118: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0414 - mean_squared_error: 0.0846 - val_loss: 0.0891 - val_mean_squared_error: 0.1813\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0402 - mean_squared_error: 0.0822\n",
      "Epoch 119: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0402 - mean_squared_error: 0.0822 - val_loss: 0.0960 - val_mean_squared_error: 0.1970\n",
      "Epoch 120/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.0418 - mean_squared_error: 0.0850\n",
      "Epoch 120: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0418 - mean_squared_error: 0.0850 - val_loss: 0.0817 - val_mean_squared_error: 0.1655\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0792\n",
      "Epoch 121: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0388 - mean_squared_error: 0.0792 - val_loss: 0.0928 - val_mean_squared_error: 0.1882\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0469 - mean_squared_error: 0.0956\n",
      "Epoch 122: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0469 - mean_squared_error: 0.0956 - val_loss: 0.0939 - val_mean_squared_error: 0.1918\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0417 - mean_squared_error: 0.0853\n",
      "Epoch 123: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0417 - mean_squared_error: 0.0853 - val_loss: 0.0793 - val_mean_squared_error: 0.1602\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0429 - mean_squared_error: 0.0874\n",
      "Epoch 124: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0429 - mean_squared_error: 0.0874 - val_loss: 0.0951 - val_mean_squared_error: 0.1939\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0451 - mean_squared_error: 0.0920\n",
      "Epoch 125: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0451 - mean_squared_error: 0.0920 - val_loss: 0.0794 - val_mean_squared_error: 0.1603\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0402 - mean_squared_error: 0.0824\n",
      "Epoch 126: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0402 - mean_squared_error: 0.0824 - val_loss: 0.0833 - val_mean_squared_error: 0.1685\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0374 - mean_squared_error: 0.0764\n",
      "Epoch 127: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0374 - mean_squared_error: 0.0764 - val_loss: 0.0948 - val_mean_squared_error: 0.1940\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0803\n",
      "Epoch 128: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0393 - mean_squared_error: 0.0803 - val_loss: 0.0844 - val_mean_squared_error: 0.1706\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0470 - mean_squared_error: 0.0959\n",
      "Epoch 129: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0470 - mean_squared_error: 0.0959 - val_loss: 0.0831 - val_mean_squared_error: 0.1686\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0418 - mean_squared_error: 0.0853\n",
      "Epoch 130: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0418 - mean_squared_error: 0.0853 - val_loss: 0.0842 - val_mean_squared_error: 0.1705\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0375 - mean_squared_error: 0.0766\n",
      "Epoch 131: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0375 - mean_squared_error: 0.0766 - val_loss: 0.0861 - val_mean_squared_error: 0.1748\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0779\n",
      "Epoch 132: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0381 - mean_squared_error: 0.0779 - val_loss: 0.0833 - val_mean_squared_error: 0.1685\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0780\n",
      "Epoch 133: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0381 - mean_squared_error: 0.0780 - val_loss: 0.0878 - val_mean_squared_error: 0.1794\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0362 - mean_squared_error: 0.0741\n",
      "Epoch 134: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0362 - mean_squared_error: 0.0741 - val_loss: 0.0911 - val_mean_squared_error: 0.1858\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0786\n",
      "Epoch 135: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0384 - mean_squared_error: 0.0786 - val_loss: 0.0795 - val_mean_squared_error: 0.1602\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0787\n",
      "Epoch 136: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0384 - mean_squared_error: 0.0787 - val_loss: 0.0926 - val_mean_squared_error: 0.1903\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0377 - mean_squared_error: 0.0770\n",
      "Epoch 137: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0377 - mean_squared_error: 0.0770 - val_loss: 0.0892 - val_mean_squared_error: 0.1808\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0367 - mean_squared_error: 0.0751\n",
      "Epoch 138: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0367 - mean_squared_error: 0.0751 - val_loss: 0.0830 - val_mean_squared_error: 0.1680\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0359 - mean_squared_error: 0.0734\n",
      "Epoch 139: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0359 - mean_squared_error: 0.0734 - val_loss: 0.0818 - val_mean_squared_error: 0.1653\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0341 - mean_squared_error: 0.0700\n",
      "Epoch 140: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0341 - mean_squared_error: 0.0700 - val_loss: 0.0867 - val_mean_squared_error: 0.1761\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0338 - mean_squared_error: 0.0693\n",
      "Epoch 141: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0338 - mean_squared_error: 0.0693 - val_loss: 0.0897 - val_mean_squared_error: 0.1823\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0748\n",
      "Epoch 142: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0366 - mean_squared_error: 0.0748 - val_loss: 0.0903 - val_mean_squared_error: 0.1834\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0412 - mean_squared_error: 0.0843\n",
      "Epoch 143: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0412 - mean_squared_error: 0.0843 - val_loss: 0.0822 - val_mean_squared_error: 0.1667\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0368 - mean_squared_error: 0.0754\n",
      "Epoch 144: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0368 - mean_squared_error: 0.0754 - val_loss: 0.0832 - val_mean_squared_error: 0.1684\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0364 - mean_squared_error: 0.0744\n",
      "Epoch 145: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0364 - mean_squared_error: 0.0744 - val_loss: 0.0893 - val_mean_squared_error: 0.1824\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0352 - mean_squared_error: 0.0723\n",
      "Epoch 146: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0352 - mean_squared_error: 0.0723 - val_loss: 0.0831 - val_mean_squared_error: 0.1683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0365 - mean_squared_error: 0.0749\n",
      "Epoch 147: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0365 - mean_squared_error: 0.0749 - val_loss: 0.0836 - val_mean_squared_error: 0.1695\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0335 - mean_squared_error: 0.0689\n",
      "Epoch 148: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0335 - mean_squared_error: 0.0689 - val_loss: 0.0860 - val_mean_squared_error: 0.1739\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0324 - mean_squared_error: 0.0666\n",
      "Epoch 149: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0324 - mean_squared_error: 0.0666 - val_loss: 0.0883 - val_mean_squared_error: 0.1798\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0319 - mean_squared_error: 0.0655\n",
      "Epoch 150: val_loss did not improve from 0.07491\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.0319 - mean_squared_error: 0.0655 - val_loss: 0.0837 - val_mean_squared_error: 0.1695\n",
      "5/5 [==============================] - 11s 223ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  240\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3970 - mean_squared_error: 0.8905\n",
      "Epoch 1: val_loss improved from inf to 0.27412, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 81s 3s/step - loss: 0.3970 - mean_squared_error: 0.8905 - val_loss: 0.2741 - val_mean_squared_error: 0.5918\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2339 - mean_squared_error: 0.5025\n",
      "Epoch 2: val_loss improved from 0.27412 to 0.16614, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2339 - mean_squared_error: 0.5025 - val_loss: 0.1661 - val_mean_squared_error: 0.3437\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1388 - mean_squared_error: 0.2861\n",
      "Epoch 3: val_loss improved from 0.16614 to 0.13904, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1388 - mean_squared_error: 0.2861 - val_loss: 0.1390 - val_mean_squared_error: 0.2849\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1142 - mean_squared_error: 0.2330\n",
      "Epoch 4: val_loss improved from 0.13904 to 0.13069, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1142 - mean_squared_error: 0.2330 - val_loss: 0.1307 - val_mean_squared_error: 0.2667\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1101 - mean_squared_error: 0.2261\n",
      "Epoch 5: val_loss did not improve from 0.13069\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1101 - mean_squared_error: 0.2261 - val_loss: 0.1316 - val_mean_squared_error: 0.2671\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1112 - mean_squared_error: 0.2286\n",
      "Epoch 6: val_loss improved from 0.13069 to 0.13061, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1112 - mean_squared_error: 0.2286 - val_loss: 0.1306 - val_mean_squared_error: 0.2664\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1001 - mean_squared_error: 0.2045\n",
      "Epoch 7: val_loss improved from 0.13061 to 0.12201, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1001 - mean_squared_error: 0.2045 - val_loss: 0.1220 - val_mean_squared_error: 0.2490\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1015 - mean_squared_error: 0.2083\n",
      "Epoch 8: val_loss did not improve from 0.12201\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1015 - mean_squared_error: 0.2083 - val_loss: 0.1276 - val_mean_squared_error: 0.2615\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0992 - mean_squared_error: 0.2023\n",
      "Epoch 9: val_loss did not improve from 0.12201\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0992 - mean_squared_error: 0.2023 - val_loss: 0.1225 - val_mean_squared_error: 0.2497\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1007 - mean_squared_error: 0.2071\n",
      "Epoch 10: val_loss did not improve from 0.12201\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1007 - mean_squared_error: 0.2071 - val_loss: 0.1309 - val_mean_squared_error: 0.2678\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0994 - mean_squared_error: 0.2020\n",
      "Epoch 11: val_loss did not improve from 0.12201\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0994 - mean_squared_error: 0.2020 - val_loss: 0.1284 - val_mean_squared_error: 0.2615\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0925 - mean_squared_error: 0.1893\n",
      "Epoch 12: val_loss improved from 0.12201 to 0.11451, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0925 - mean_squared_error: 0.1893 - val_loss: 0.1145 - val_mean_squared_error: 0.2329\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0885 - mean_squared_error: 0.1809\n",
      "Epoch 13: val_loss improved from 0.11451 to 0.11227, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0885 - mean_squared_error: 0.1809 - val_loss: 0.1123 - val_mean_squared_error: 0.2283\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0874 - mean_squared_error: 0.1794\n",
      "Epoch 14: val_loss improved from 0.11227 to 0.11137, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0874 - mean_squared_error: 0.1794 - val_loss: 0.1114 - val_mean_squared_error: 0.2272\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0871 - mean_squared_error: 0.1795\n",
      "Epoch 15: val_loss did not improve from 0.11137\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0871 - mean_squared_error: 0.1795 - val_loss: 0.1165 - val_mean_squared_error: 0.2389\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0858 - mean_squared_error: 0.1757\n",
      "Epoch 16: val_loss did not improve from 0.11137\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0858 - mean_squared_error: 0.1757 - val_loss: 0.1114 - val_mean_squared_error: 0.2265\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0859 - mean_squared_error: 0.1758\n",
      "Epoch 17: val_loss did not improve from 0.11137\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0859 - mean_squared_error: 0.1758 - val_loss: 0.1126 - val_mean_squared_error: 0.2294\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0866 - mean_squared_error: 0.1766\n",
      "Epoch 18: val_loss did not improve from 0.11137\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0866 - mean_squared_error: 0.1766 - val_loss: 0.1191 - val_mean_squared_error: 0.2434\n",
      "Epoch 19/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.0854 - mean_squared_error: 0.1740\n",
      "Epoch 19: val_loss did not improve from 0.11137\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0854 - mean_squared_error: 0.1740 - val_loss: 0.1171 - val_mean_squared_error: 0.2385\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0819 - mean_squared_error: 0.1673\n",
      "Epoch 20: val_loss did not improve from 0.11137\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0819 - mean_squared_error: 0.1673 - val_loss: 0.1173 - val_mean_squared_error: 0.2392\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1001 - mean_squared_error: 0.2058\n",
      "Epoch 21: val_loss did not improve from 0.11137\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1001 - mean_squared_error: 0.2058 - val_loss: 0.1358 - val_mean_squared_error: 0.2790\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0928 - mean_squared_error: 0.1892\n",
      "Epoch 22: val_loss improved from 0.11137 to 0.11051, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0928 - mean_squared_error: 0.1892 - val_loss: 0.1105 - val_mean_squared_error: 0.2247\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0953 - mean_squared_error: 0.1962\n",
      "Epoch 23: val_loss did not improve from 0.11051\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0953 - mean_squared_error: 0.1962 - val_loss: 0.1242 - val_mean_squared_error: 0.2541\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0854 - mean_squared_error: 0.1750\n",
      "Epoch 24: val_loss improved from 0.11051 to 0.10713, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0854 - mean_squared_error: 0.1750 - val_loss: 0.1071 - val_mean_squared_error: 0.2187\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0816 - mean_squared_error: 0.1672\n",
      "Epoch 25: val_loss did not improve from 0.10713\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0816 - mean_squared_error: 0.1672 - val_loss: 0.1107 - val_mean_squared_error: 0.2251\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0844 - mean_squared_error: 0.1730\n",
      "Epoch 26: val_loss did not improve from 0.10713\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0844 - mean_squared_error: 0.1730 - val_loss: 0.1153 - val_mean_squared_error: 0.2358\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0881 - mean_squared_error: 0.1810\n",
      "Epoch 27: val_loss improved from 0.10713 to 0.10157, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0881 - mean_squared_error: 0.1810 - val_loss: 0.1016 - val_mean_squared_error: 0.2064\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0791 - mean_squared_error: 0.1622\n",
      "Epoch 28: val_loss did not improve from 0.10157\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0791 - mean_squared_error: 0.1622 - val_loss: 0.1071 - val_mean_squared_error: 0.2175\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0778 - mean_squared_error: 0.1593\n",
      "Epoch 29: val_loss did not improve from 0.10157\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0778 - mean_squared_error: 0.1593 - val_loss: 0.1016 - val_mean_squared_error: 0.2063\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0856 - mean_squared_error: 0.1754\n",
      "Epoch 30: val_loss did not improve from 0.10157\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0856 - mean_squared_error: 0.1754 - val_loss: 0.1127 - val_mean_squared_error: 0.2292\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0843 - mean_squared_error: 0.1719\n",
      "Epoch 31: val_loss did not improve from 0.10157\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0843 - mean_squared_error: 0.1719 - val_loss: 0.1085 - val_mean_squared_error: 0.2202\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0773 - mean_squared_error: 0.1585\n",
      "Epoch 32: val_loss did not improve from 0.10157\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0773 - mean_squared_error: 0.1585 - val_loss: 0.1099 - val_mean_squared_error: 0.2231\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0800 - mean_squared_error: 0.1633\n",
      "Epoch 33: val_loss did not improve from 0.10157\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0800 - mean_squared_error: 0.1633 - val_loss: 0.1146 - val_mean_squared_error: 0.2329\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0764 - mean_squared_error: 0.1556\n",
      "Epoch 34: val_loss did not improve from 0.10157\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0764 - mean_squared_error: 0.1556 - val_loss: 0.1129 - val_mean_squared_error: 0.2312\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0828 - mean_squared_error: 0.1687\n",
      "Epoch 35: val_loss did not improve from 0.10157\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0828 - mean_squared_error: 0.1687 - val_loss: 0.1157 - val_mean_squared_error: 0.2355\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0866 - mean_squared_error: 0.1778\n",
      "Epoch 36: val_loss did not improve from 0.10157\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0866 - mean_squared_error: 0.1778 - val_loss: 0.1069 - val_mean_squared_error: 0.2169\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0786 - mean_squared_error: 0.1604\n",
      "Epoch 37: val_loss improved from 0.10157 to 0.09690, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0786 - mean_squared_error: 0.1604 - val_loss: 0.0969 - val_mean_squared_error: 0.1965\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0764 - mean_squared_error: 0.1564\n",
      "Epoch 38: val_loss did not improve from 0.09690\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0764 - mean_squared_error: 0.1564 - val_loss: 0.1034 - val_mean_squared_error: 0.2100\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0735 - mean_squared_error: 0.1497\n",
      "Epoch 39: val_loss improved from 0.09690 to 0.09679, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0735 - mean_squared_error: 0.1497 - val_loss: 0.0968 - val_mean_squared_error: 0.1969\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0720 - mean_squared_error: 0.1472\n",
      "Epoch 40: val_loss improved from 0.09679 to 0.09519, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0720 - mean_squared_error: 0.1472 - val_loss: 0.0952 - val_mean_squared_error: 0.1936\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0709 - mean_squared_error: 0.1449\n",
      "Epoch 41: val_loss did not improve from 0.09519\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0709 - mean_squared_error: 0.1449 - val_loss: 0.1138 - val_mean_squared_error: 0.2320\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0685 - mean_squared_error: 0.1396\n",
      "Epoch 42: val_loss improved from 0.09519 to 0.08853, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0685 - mean_squared_error: 0.1396 - val_loss: 0.0885 - val_mean_squared_error: 0.1797\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0655 - mean_squared_error: 0.1339\n",
      "Epoch 43: val_loss did not improve from 0.08853\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0655 - mean_squared_error: 0.1339 - val_loss: 0.1047 - val_mean_squared_error: 0.2124\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0832 - mean_squared_error: 0.1706\n",
      "Epoch 44: val_loss did not improve from 0.08853\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0832 - mean_squared_error: 0.1706 - val_loss: 0.0946 - val_mean_squared_error: 0.1914\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0770 - mean_squared_error: 0.1574\n",
      "Epoch 45: val_loss did not improve from 0.08853\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0770 - mean_squared_error: 0.1574 - val_loss: 0.0935 - val_mean_squared_error: 0.1896\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0676 - mean_squared_error: 0.1378\n",
      "Epoch 46: val_loss improved from 0.08853 to 0.08838, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0676 - mean_squared_error: 0.1378 - val_loss: 0.0884 - val_mean_squared_error: 0.1796\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0753 - mean_squared_error: 0.1551\n",
      "Epoch 47: val_loss did not improve from 0.08838\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0753 - mean_squared_error: 0.1551 - val_loss: 0.0969 - val_mean_squared_error: 0.1964\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0753 - mean_squared_error: 0.1547\n",
      "Epoch 48: val_loss did not improve from 0.08838\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0753 - mean_squared_error: 0.1547 - val_loss: 0.1061 - val_mean_squared_error: 0.2163\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0696 - mean_squared_error: 0.1424\n",
      "Epoch 49: val_loss did not improve from 0.08838\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0696 - mean_squared_error: 0.1424 - val_loss: 0.0928 - val_mean_squared_error: 0.1884\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0662 - mean_squared_error: 0.1353\n",
      "Epoch 50: val_loss did not improve from 0.08838\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0662 - mean_squared_error: 0.1353 - val_loss: 0.0940 - val_mean_squared_error: 0.1901\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0647 - mean_squared_error: 0.1321\n",
      "Epoch 51: val_loss did not improve from 0.08838\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0647 - mean_squared_error: 0.1321 - val_loss: 0.0886 - val_mean_squared_error: 0.1794\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0667 - mean_squared_error: 0.1362\n",
      "Epoch 52: val_loss did not improve from 0.08838\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0667 - mean_squared_error: 0.1362 - val_loss: 0.0897 - val_mean_squared_error: 0.1819\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0636 - mean_squared_error: 0.1298\n",
      "Epoch 53: val_loss improved from 0.08838 to 0.08404, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0636 - mean_squared_error: 0.1298 - val_loss: 0.0840 - val_mean_squared_error: 0.1705\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0601 - mean_squared_error: 0.1226\n",
      "Epoch 54: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0601 - mean_squared_error: 0.1226 - val_loss: 0.0890 - val_mean_squared_error: 0.1802\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0605 - mean_squared_error: 0.1233\n",
      "Epoch 55: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0605 - mean_squared_error: 0.1233 - val_loss: 0.0948 - val_mean_squared_error: 0.1926\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0710 - mean_squared_error: 0.1459\n",
      "Epoch 56: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0710 - mean_squared_error: 0.1459 - val_loss: 0.1080 - val_mean_squared_error: 0.2211\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0783 - mean_squared_error: 0.1596\n",
      "Epoch 57: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0783 - mean_squared_error: 0.1596 - val_loss: 0.1027 - val_mean_squared_error: 0.2097\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0732 - mean_squared_error: 0.1500\n",
      "Epoch 58: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0732 - mean_squared_error: 0.1500 - val_loss: 0.1134 - val_mean_squared_error: 0.2315\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0942 - mean_squared_error: 0.1942\n",
      "Epoch 59: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0942 - mean_squared_error: 0.1942 - val_loss: 0.1229 - val_mean_squared_error: 0.2508\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0810 - mean_squared_error: 0.1660\n",
      "Epoch 60: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0810 - mean_squared_error: 0.1660 - val_loss: 0.1020 - val_mean_squared_error: 0.2073\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0753 - mean_squared_error: 0.1537\n",
      "Epoch 61: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0753 - mean_squared_error: 0.1537 - val_loss: 0.1045 - val_mean_squared_error: 0.2120\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0744 - mean_squared_error: 0.1524\n",
      "Epoch 62: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0744 - mean_squared_error: 0.1524 - val_loss: 0.1106 - val_mean_squared_error: 0.2244\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0715 - mean_squared_error: 0.1460\n",
      "Epoch 63: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0715 - mean_squared_error: 0.1460 - val_loss: 0.0962 - val_mean_squared_error: 0.1950\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0745 - mean_squared_error: 0.1525\n",
      "Epoch 64: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0745 - mean_squared_error: 0.1525 - val_loss: 0.0973 - val_mean_squared_error: 0.1973\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0743 - mean_squared_error: 0.1512\n",
      "Epoch 65: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0743 - mean_squared_error: 0.1512 - val_loss: 0.0979 - val_mean_squared_error: 0.1978\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0697 - mean_squared_error: 0.1424\n",
      "Epoch 66: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0697 - mean_squared_error: 0.1424 - val_loss: 0.1047 - val_mean_squared_error: 0.2138\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0679 - mean_squared_error: 0.1390\n",
      "Epoch 67: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0679 - mean_squared_error: 0.1390 - val_loss: 0.0973 - val_mean_squared_error: 0.1967\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0786 - mean_squared_error: 0.1613\n",
      "Epoch 68: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0786 - mean_squared_error: 0.1613 - val_loss: 0.1174 - val_mean_squared_error: 0.2430\n",
      "Epoch 69/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.0694 - mean_squared_error: 0.1414\n",
      "Epoch 69: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0694 - mean_squared_error: 0.1414 - val_loss: 0.0929 - val_mean_squared_error: 0.1878\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0626 - mean_squared_error: 0.1280\n",
      "Epoch 70: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0626 - mean_squared_error: 0.1280 - val_loss: 0.0946 - val_mean_squared_error: 0.1916\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0591 - mean_squared_error: 0.1208\n",
      "Epoch 71: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0591 - mean_squared_error: 0.1208 - val_loss: 0.0846 - val_mean_squared_error: 0.1709\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0613 - mean_squared_error: 0.1254\n",
      "Epoch 72: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0613 - mean_squared_error: 0.1254 - val_loss: 0.0938 - val_mean_squared_error: 0.1903\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0579 - mean_squared_error: 0.1180\n",
      "Epoch 73: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0579 - mean_squared_error: 0.1180 - val_loss: 0.0862 - val_mean_squared_error: 0.1742\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0569 - mean_squared_error: 0.1163\n",
      "Epoch 74: val_loss did not improve from 0.08404\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0569 - mean_squared_error: 0.1163 - val_loss: 0.0882 - val_mean_squared_error: 0.1785\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0545 - mean_squared_error: 0.1113\n",
      "Epoch 75: val_loss improved from 0.08404 to 0.07902, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0545 - mean_squared_error: 0.1113 - val_loss: 0.0790 - val_mean_squared_error: 0.1594\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0619 - mean_squared_error: 0.1265\n",
      "Epoch 76: val_loss did not improve from 0.07902\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0619 - mean_squared_error: 0.1265 - val_loss: 0.0915 - val_mean_squared_error: 0.1870\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0593 - mean_squared_error: 0.1210\n",
      "Epoch 77: val_loss did not improve from 0.07902\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0593 - mean_squared_error: 0.1210 - val_loss: 0.0839 - val_mean_squared_error: 0.1695\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0542 - mean_squared_error: 0.1107\n",
      "Epoch 78: val_loss did not improve from 0.07902\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0542 - mean_squared_error: 0.1107 - val_loss: 0.0870 - val_mean_squared_error: 0.1759\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0548 - mean_squared_error: 0.1122\n",
      "Epoch 79: val_loss did not improve from 0.07902\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0548 - mean_squared_error: 0.1122 - val_loss: 0.0842 - val_mean_squared_error: 0.1704\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0542 - mean_squared_error: 0.1108\n",
      "Epoch 80: val_loss did not improve from 0.07902\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0542 - mean_squared_error: 0.1108 - val_loss: 0.0861 - val_mean_squared_error: 0.1742\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0578 - mean_squared_error: 0.1176\n",
      "Epoch 81: val_loss improved from 0.07902 to 0.07890, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0578 - mean_squared_error: 0.1176 - val_loss: 0.0789 - val_mean_squared_error: 0.1590\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0560 - mean_squared_error: 0.1144\n",
      "Epoch 82: val_loss did not improve from 0.07890\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0560 - mean_squared_error: 0.1144 - val_loss: 0.0887 - val_mean_squared_error: 0.1802\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0524 - mean_squared_error: 0.1070\n",
      "Epoch 83: val_loss did not improve from 0.07890\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0524 - mean_squared_error: 0.1070 - val_loss: 0.0826 - val_mean_squared_error: 0.1660\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0667 - mean_squared_error: 0.1367\n",
      "Epoch 84: val_loss did not improve from 0.07890\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0667 - mean_squared_error: 0.1367 - val_loss: 0.0976 - val_mean_squared_error: 0.1975\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0637 - mean_squared_error: 0.1295\n",
      "Epoch 85: val_loss did not improve from 0.07890\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0637 - mean_squared_error: 0.1295 - val_loss: 0.0935 - val_mean_squared_error: 0.1898\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0610 - mean_squared_error: 0.1241\n",
      "Epoch 86: val_loss did not improve from 0.07890\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0610 - mean_squared_error: 0.1241 - val_loss: 0.0911 - val_mean_squared_error: 0.1856\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0572 - mean_squared_error: 0.1166\n",
      "Epoch 87: val_loss did not improve from 0.07890\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0572 - mean_squared_error: 0.1166 - val_loss: 0.0839 - val_mean_squared_error: 0.1695\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0636 - mean_squared_error: 0.1300\n",
      "Epoch 88: val_loss did not improve from 0.07890\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0636 - mean_squared_error: 0.1300 - val_loss: 0.0956 - val_mean_squared_error: 0.1939\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0561 - mean_squared_error: 0.1142\n",
      "Epoch 89: val_loss improved from 0.07890 to 0.07707, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0561 - mean_squared_error: 0.1142 - val_loss: 0.0771 - val_mean_squared_error: 0.1552\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0644 - mean_squared_error: 0.1320\n",
      "Epoch 90: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0644 - mean_squared_error: 0.1320 - val_loss: 0.0990 - val_mean_squared_error: 0.2011\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0697 - mean_squared_error: 0.1417\n",
      "Epoch 91: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0697 - mean_squared_error: 0.1417 - val_loss: 0.0863 - val_mean_squared_error: 0.1744\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0579 - mean_squared_error: 0.1182\n",
      "Epoch 92: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0579 - mean_squared_error: 0.1182 - val_loss: 0.0848 - val_mean_squared_error: 0.1712\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0549 - mean_squared_error: 0.1118\n",
      "Epoch 93: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0549 - mean_squared_error: 0.1118 - val_loss: 0.0809 - val_mean_squared_error: 0.1631\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0553 - mean_squared_error: 0.1125\n",
      "Epoch 94: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0553 - mean_squared_error: 0.1125 - val_loss: 0.0838 - val_mean_squared_error: 0.1690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0568 - mean_squared_error: 0.1158\n",
      "Epoch 95: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0568 - mean_squared_error: 0.1158 - val_loss: 0.0820 - val_mean_squared_error: 0.1658\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0559 - mean_squared_error: 0.1139\n",
      "Epoch 96: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0559 - mean_squared_error: 0.1139 - val_loss: 0.0802 - val_mean_squared_error: 0.1616\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0601 - mean_squared_error: 0.1224\n",
      "Epoch 97: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0601 - mean_squared_error: 0.1224 - val_loss: 0.0946 - val_mean_squared_error: 0.1911\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0566 - mean_squared_error: 0.1152\n",
      "Epoch 98: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0566 - mean_squared_error: 0.1152 - val_loss: 0.0801 - val_mean_squared_error: 0.1614\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0568 - mean_squared_error: 0.1157\n",
      "Epoch 99: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0568 - mean_squared_error: 0.1157 - val_loss: 0.0956 - val_mean_squared_error: 0.1928\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0610 - mean_squared_error: 0.1240\n",
      "Epoch 100: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0610 - mean_squared_error: 0.1240 - val_loss: 0.0889 - val_mean_squared_error: 0.1793\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0557 - mean_squared_error: 0.1140\n",
      "Epoch 101: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0557 - mean_squared_error: 0.1140 - val_loss: 0.0911 - val_mean_squared_error: 0.1849\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0525 - mean_squared_error: 0.1068\n",
      "Epoch 102: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0525 - mean_squared_error: 0.1068 - val_loss: 0.0783 - val_mean_squared_error: 0.1575\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0519 - mean_squared_error: 0.1060\n",
      "Epoch 103: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0519 - mean_squared_error: 0.1060 - val_loss: 0.0837 - val_mean_squared_error: 0.1685\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0504 - mean_squared_error: 0.1028\n",
      "Epoch 104: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0504 - mean_squared_error: 0.1028 - val_loss: 0.0787 - val_mean_squared_error: 0.1584\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0474 - mean_squared_error: 0.0968\n",
      "Epoch 105: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0474 - mean_squared_error: 0.0968 - val_loss: 0.0805 - val_mean_squared_error: 0.1625\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0654 - mean_squared_error: 0.1352\n",
      "Epoch 106: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0654 - mean_squared_error: 0.1352 - val_loss: 0.0925 - val_mean_squared_error: 0.1879\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0537 - mean_squared_error: 0.1095\n",
      "Epoch 107: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0537 - mean_squared_error: 0.1095 - val_loss: 0.0844 - val_mean_squared_error: 0.1711\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0506 - mean_squared_error: 0.1032\n",
      "Epoch 108: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0506 - mean_squared_error: 0.1032 - val_loss: 0.0821 - val_mean_squared_error: 0.1658\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0470 - mean_squared_error: 0.0961\n",
      "Epoch 109: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0470 - mean_squared_error: 0.0961 - val_loss: 0.0834 - val_mean_squared_error: 0.1683\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0464 - mean_squared_error: 0.0948\n",
      "Epoch 110: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0464 - mean_squared_error: 0.0948 - val_loss: 0.0824 - val_mean_squared_error: 0.1660\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0499 - mean_squared_error: 0.1017\n",
      "Epoch 111: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0499 - mean_squared_error: 0.1017 - val_loss: 0.0868 - val_mean_squared_error: 0.1748\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0468 - mean_squared_error: 0.0957\n",
      "Epoch 112: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0468 - mean_squared_error: 0.0957 - val_loss: 0.0869 - val_mean_squared_error: 0.1756\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0513 - mean_squared_error: 0.1047\n",
      "Epoch 113: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0513 - mean_squared_error: 0.1047 - val_loss: 0.0812 - val_mean_squared_error: 0.1639\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0488 - mean_squared_error: 0.0998\n",
      "Epoch 114: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0488 - mean_squared_error: 0.0998 - val_loss: 0.0783 - val_mean_squared_error: 0.1575\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0495 - mean_squared_error: 0.1011\n",
      "Epoch 115: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0495 - mean_squared_error: 0.1011 - val_loss: 0.0782 - val_mean_squared_error: 0.1581\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0504 - mean_squared_error: 0.1027\n",
      "Epoch 116: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0504 - mean_squared_error: 0.1027 - val_loss: 0.0891 - val_mean_squared_error: 0.1797\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0944\n",
      "Epoch 117: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0462 - mean_squared_error: 0.0944 - val_loss: 0.0793 - val_mean_squared_error: 0.1595\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0464 - mean_squared_error: 0.0948\n",
      "Epoch 118: val_loss did not improve from 0.07707\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0464 - mean_squared_error: 0.0948 - val_loss: 0.0810 - val_mean_squared_error: 0.1630\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0437 - mean_squared_error: 0.0894\n",
      "Epoch 119: val_loss improved from 0.07707 to 0.07407, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0437 - mean_squared_error: 0.0894 - val_loss: 0.0741 - val_mean_squared_error: 0.1489\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0638 - mean_squared_error: 0.1318\n",
      "Epoch 120: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0638 - mean_squared_error: 0.1318 - val_loss: 0.0950 - val_mean_squared_error: 0.1925\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0813 - mean_squared_error: 0.1684\n",
      "Epoch 121: val_loss did not improve from 0.07407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 20s 2s/step - loss: 0.0813 - mean_squared_error: 0.1684 - val_loss: 0.1141 - val_mean_squared_error: 0.2334\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0747 - mean_squared_error: 0.1532\n",
      "Epoch 122: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0747 - mean_squared_error: 0.1532 - val_loss: 0.1079 - val_mean_squared_error: 0.2190\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0676 - mean_squared_error: 0.1384\n",
      "Epoch 123: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0676 - mean_squared_error: 0.1384 - val_loss: 0.0958 - val_mean_squared_error: 0.1938\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0764 - mean_squared_error: 0.1569\n",
      "Epoch 124: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0764 - mean_squared_error: 0.1569 - val_loss: 0.1008 - val_mean_squared_error: 0.2046\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0856 - mean_squared_error: 0.1762\n",
      "Epoch 125: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0856 - mean_squared_error: 0.1762 - val_loss: 0.1089 - val_mean_squared_error: 0.2219\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0673 - mean_squared_error: 0.1379\n",
      "Epoch 126: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0673 - mean_squared_error: 0.1379 - val_loss: 0.0980 - val_mean_squared_error: 0.1984\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0604 - mean_squared_error: 0.1236\n",
      "Epoch 127: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0604 - mean_squared_error: 0.1236 - val_loss: 0.0966 - val_mean_squared_error: 0.1958\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0689 - mean_squared_error: 0.1406\n",
      "Epoch 128: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0689 - mean_squared_error: 0.1406 - val_loss: 0.0945 - val_mean_squared_error: 0.1911\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0671 - mean_squared_error: 0.1376\n",
      "Epoch 129: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0671 - mean_squared_error: 0.1376 - val_loss: 0.0881 - val_mean_squared_error: 0.1787\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0605 - mean_squared_error: 0.1240\n",
      "Epoch 130: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0605 - mean_squared_error: 0.1240 - val_loss: 0.0905 - val_mean_squared_error: 0.1836\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0558 - mean_squared_error: 0.1140\n",
      "Epoch 131: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0558 - mean_squared_error: 0.1140 - val_loss: 0.0846 - val_mean_squared_error: 0.1709\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0530 - mean_squared_error: 0.1084\n",
      "Epoch 132: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0530 - mean_squared_error: 0.1084 - val_loss: 0.0816 - val_mean_squared_error: 0.1649\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0610 - mean_squared_error: 0.1252\n",
      "Epoch 133: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0610 - mean_squared_error: 0.1252 - val_loss: 0.0815 - val_mean_squared_error: 0.1649\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0542 - mean_squared_error: 0.1109\n",
      "Epoch 134: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0542 - mean_squared_error: 0.1109 - val_loss: 0.0965 - val_mean_squared_error: 0.1951\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.1052\n",
      "Epoch 135: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0515 - mean_squared_error: 0.1052 - val_loss: 0.0851 - val_mean_squared_error: 0.1718\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0485 - mean_squared_error: 0.0991\n",
      "Epoch 136: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0485 - mean_squared_error: 0.0991 - val_loss: 0.0818 - val_mean_squared_error: 0.1652\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0472 - mean_squared_error: 0.0965\n",
      "Epoch 137: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0472 - mean_squared_error: 0.0965 - val_loss: 0.0795 - val_mean_squared_error: 0.1605\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0464 - mean_squared_error: 0.0947\n",
      "Epoch 138: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0464 - mean_squared_error: 0.0947 - val_loss: 0.0806 - val_mean_squared_error: 0.1626\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0498 - mean_squared_error: 0.1019\n",
      "Epoch 139: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0498 - mean_squared_error: 0.1019 - val_loss: 0.0858 - val_mean_squared_error: 0.1735\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0476 - mean_squared_error: 0.0972\n",
      "Epoch 140: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0476 - mean_squared_error: 0.0972 - val_loss: 0.0854 - val_mean_squared_error: 0.1721\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0464 - mean_squared_error: 0.0947\n",
      "Epoch 141: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0464 - mean_squared_error: 0.0947 - val_loss: 0.0850 - val_mean_squared_error: 0.1716\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0467 - mean_squared_error: 0.0953\n",
      "Epoch 142: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0467 - mean_squared_error: 0.0953 - val_loss: 0.0872 - val_mean_squared_error: 0.1761\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0528 - mean_squared_error: 0.1078\n",
      "Epoch 143: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0528 - mean_squared_error: 0.1078 - val_loss: 0.0986 - val_mean_squared_error: 0.1996\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0469 - mean_squared_error: 0.0961\n",
      "Epoch 144: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0469 - mean_squared_error: 0.0961 - val_loss: 0.0823 - val_mean_squared_error: 0.1662\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0444 - mean_squared_error: 0.0909\n",
      "Epoch 145: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0444 - mean_squared_error: 0.0909 - val_loss: 0.0820 - val_mean_squared_error: 0.1652\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0431 - mean_squared_error: 0.0882\n",
      "Epoch 146: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0431 - mean_squared_error: 0.0882 - val_loss: 0.0811 - val_mean_squared_error: 0.1636\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0422 - mean_squared_error: 0.0865\n",
      "Epoch 147: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0422 - mean_squared_error: 0.0865 - val_loss: 0.0812 - val_mean_squared_error: 0.1636\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0412 - mean_squared_error: 0.0844\n",
      "Epoch 148: val_loss did not improve from 0.07407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 20s 2s/step - loss: 0.0412 - mean_squared_error: 0.0844 - val_loss: 0.0817 - val_mean_squared_error: 0.1646\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0408 - mean_squared_error: 0.0835\n",
      "Epoch 149: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0408 - mean_squared_error: 0.0835 - val_loss: 0.0772 - val_mean_squared_error: 0.1556\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.1049\n",
      "Epoch 150: val_loss did not improve from 0.07407\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0515 - mean_squared_error: 0.1049 - val_loss: 0.0949 - val_mean_squared_error: 0.1938\n",
      "5/5 [==============================] - 15s 230ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  264\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3952 - mean_squared_error: 0.8897\n",
      "Epoch 1: val_loss improved from inf to 0.28742, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 69s 4s/step - loss: 0.3952 - mean_squared_error: 0.8897 - val_loss: 0.2874 - val_mean_squared_error: 0.6259\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2196 - mean_squared_error: 0.4683\n",
      "Epoch 2: val_loss improved from 0.28742 to 0.15550, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.2196 - mean_squared_error: 0.4683 - val_loss: 0.1555 - val_mean_squared_error: 0.3215\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1211 - mean_squared_error: 0.2490\n",
      "Epoch 3: val_loss improved from 0.15550 to 0.12924, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.1211 - mean_squared_error: 0.2490 - val_loss: 0.1292 - val_mean_squared_error: 0.2637\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.2173\n",
      "Epoch 4: val_loss improved from 0.12924 to 0.12718, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.1063 - mean_squared_error: 0.2173 - val_loss: 0.1272 - val_mean_squared_error: 0.2584\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0987 - mean_squared_error: 0.2017\n",
      "Epoch 5: val_loss did not improve from 0.12718\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0987 - mean_squared_error: 0.2017 - val_loss: 0.1305 - val_mean_squared_error: 0.2665\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0944 - mean_squared_error: 0.1926\n",
      "Epoch 6: val_loss improved from 0.12718 to 0.12546, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0944 - mean_squared_error: 0.1926 - val_loss: 0.1255 - val_mean_squared_error: 0.2558\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0912 - mean_squared_error: 0.1862\n",
      "Epoch 7: val_loss improved from 0.12546 to 0.12351, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0912 - mean_squared_error: 0.1862 - val_loss: 0.1235 - val_mean_squared_error: 0.2522\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0888 - mean_squared_error: 0.1817\n",
      "Epoch 8: val_loss improved from 0.12351 to 0.11878, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0888 - mean_squared_error: 0.1817 - val_loss: 0.1188 - val_mean_squared_error: 0.2430\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0857 - mean_squared_error: 0.1753\n",
      "Epoch 9: val_loss improved from 0.11878 to 0.11773, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0857 - mean_squared_error: 0.1753 - val_loss: 0.1177 - val_mean_squared_error: 0.2416\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0824 - mean_squared_error: 0.1686\n",
      "Epoch 10: val_loss did not improve from 0.11773\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0824 - mean_squared_error: 0.1686 - val_loss: 0.1221 - val_mean_squared_error: 0.2508\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0802 - mean_squared_error: 0.1639\n",
      "Epoch 11: val_loss improved from 0.11773 to 0.11581, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0802 - mean_squared_error: 0.1639 - val_loss: 0.1158 - val_mean_squared_error: 0.2371\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0787 - mean_squared_error: 0.1608\n",
      "Epoch 12: val_loss improved from 0.11581 to 0.11536, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0787 - mean_squared_error: 0.1608 - val_loss: 0.1154 - val_mean_squared_error: 0.2367\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0757 - mean_squared_error: 0.1547\n",
      "Epoch 13: val_loss improved from 0.11536 to 0.11477, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0757 - mean_squared_error: 0.1547 - val_loss: 0.1148 - val_mean_squared_error: 0.2365\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0755 - mean_squared_error: 0.1542\n",
      "Epoch 14: val_loss improved from 0.11477 to 0.11050, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0755 - mean_squared_error: 0.1542 - val_loss: 0.1105 - val_mean_squared_error: 0.2275\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0734 - mean_squared_error: 0.1500\n",
      "Epoch 15: val_loss did not improve from 0.11050\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0734 - mean_squared_error: 0.1500 - val_loss: 0.1149 - val_mean_squared_error: 0.2353\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0719 - mean_squared_error: 0.1466\n",
      "Epoch 16: val_loss improved from 0.11050 to 0.10582, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0719 - mean_squared_error: 0.1466 - val_loss: 0.1058 - val_mean_squared_error: 0.2168\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0701 - mean_squared_error: 0.1430\n",
      "Epoch 17: val_loss improved from 0.10582 to 0.10320, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0701 - mean_squared_error: 0.1430 - val_loss: 0.1032 - val_mean_squared_error: 0.2116\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0684 - mean_squared_error: 0.1395\n",
      "Epoch 18: val_loss improved from 0.10320 to 0.10174, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 21s 2s/step - loss: 0.0684 - mean_squared_error: 0.1395 - val_loss: 0.1017 - val_mean_squared_error: 0.2083\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0662 - mean_squared_error: 0.1347\n",
      "Epoch 19: val_loss improved from 0.10174 to 0.09360, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0662 - mean_squared_error: 0.1347 - val_loss: 0.0936 - val_mean_squared_error: 0.1912\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0665 - mean_squared_error: 0.1352\n",
      "Epoch 20: val_loss improved from 0.09360 to 0.08936, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0665 - mean_squared_error: 0.1352 - val_loss: 0.0894 - val_mean_squared_error: 0.1819\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0610 - mean_squared_error: 0.1244\n",
      "Epoch 21: val_loss did not improve from 0.08936\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0610 - mean_squared_error: 0.1244 - val_loss: 0.0928 - val_mean_squared_error: 0.1888\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0585 - mean_squared_error: 0.1192\n",
      "Epoch 22: val_loss did not improve from 0.08936\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0585 - mean_squared_error: 0.1192 - val_loss: 0.0900 - val_mean_squared_error: 0.1827\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0569 - mean_squared_error: 0.1160\n",
      "Epoch 23: val_loss improved from 0.08936 to 0.08745, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0569 - mean_squared_error: 0.1160 - val_loss: 0.0875 - val_mean_squared_error: 0.1771\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0559 - mean_squared_error: 0.1137\n",
      "Epoch 24: val_loss did not improve from 0.08745\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0559 - mean_squared_error: 0.1137 - val_loss: 0.0884 - val_mean_squared_error: 0.1788\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0553 - mean_squared_error: 0.1128\n",
      "Epoch 25: val_loss did not improve from 0.08745\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0553 - mean_squared_error: 0.1128 - val_loss: 0.0978 - val_mean_squared_error: 0.2004\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0571 - mean_squared_error: 0.1166\n",
      "Epoch 26: val_loss did not improve from 0.08745\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0571 - mean_squared_error: 0.1166 - val_loss: 0.0981 - val_mean_squared_error: 0.1996\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0534 - mean_squared_error: 0.1087\n",
      "Epoch 27: val_loss did not improve from 0.08745\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0534 - mean_squared_error: 0.1087 - val_loss: 0.0928 - val_mean_squared_error: 0.1886\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0522 - mean_squared_error: 0.1063\n",
      "Epoch 28: val_loss improved from 0.08745 to 0.08269, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0522 - mean_squared_error: 0.1063 - val_loss: 0.0827 - val_mean_squared_error: 0.1673\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0517 - mean_squared_error: 0.1053\n",
      "Epoch 29: val_loss did not improve from 0.08269\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0517 - mean_squared_error: 0.1053 - val_loss: 0.0828 - val_mean_squared_error: 0.1681\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0508 - mean_squared_error: 0.1034\n",
      "Epoch 30: val_loss did not improve from 0.08269\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0508 - mean_squared_error: 0.1034 - val_loss: 0.0887 - val_mean_squared_error: 0.1798\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0501 - mean_squared_error: 0.1022\n",
      "Epoch 31: val_loss did not improve from 0.08269\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0501 - mean_squared_error: 0.1022 - val_loss: 0.0868 - val_mean_squared_error: 0.1758\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0493 - mean_squared_error: 0.1005\n",
      "Epoch 32: val_loss did not improve from 0.08269\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0493 - mean_squared_error: 0.1005 - val_loss: 0.0840 - val_mean_squared_error: 0.1699\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0483 - mean_squared_error: 0.0985\n",
      "Epoch 33: val_loss did not improve from 0.08269\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0483 - mean_squared_error: 0.0985 - val_loss: 0.0882 - val_mean_squared_error: 0.1789\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0476 - mean_squared_error: 0.0970\n",
      "Epoch 34: val_loss did not improve from 0.08269\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0476 - mean_squared_error: 0.0970 - val_loss: 0.0866 - val_mean_squared_error: 0.1753\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0479 - mean_squared_error: 0.0978\n",
      "Epoch 35: val_loss did not improve from 0.08269\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0479 - mean_squared_error: 0.0978 - val_loss: 0.0915 - val_mean_squared_error: 0.1858\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0464 - mean_squared_error: 0.0945\n",
      "Epoch 36: val_loss improved from 0.08269 to 0.08092, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0464 - mean_squared_error: 0.0945 - val_loss: 0.0809 - val_mean_squared_error: 0.1636\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0471 - mean_squared_error: 0.0959\n",
      "Epoch 37: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0471 - mean_squared_error: 0.0959 - val_loss: 0.0896 - val_mean_squared_error: 0.1814\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0458 - mean_squared_error: 0.0935\n",
      "Epoch 38: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0458 - mean_squared_error: 0.0935 - val_loss: 0.0914 - val_mean_squared_error: 0.1862\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.0918\n",
      "Epoch 39: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0450 - mean_squared_error: 0.0918 - val_loss: 0.0917 - val_mean_squared_error: 0.1859\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0440 - mean_squared_error: 0.0899\n",
      "Epoch 40: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0440 - mean_squared_error: 0.0899 - val_loss: 0.0865 - val_mean_squared_error: 0.1754\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0449 - mean_squared_error: 0.0915\n",
      "Epoch 41: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0449 - mean_squared_error: 0.0915 - val_loss: 0.0976 - val_mean_squared_error: 0.1985\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0449 - mean_squared_error: 0.0916\n",
      "Epoch 42: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0449 - mean_squared_error: 0.0916 - val_loss: 0.0881 - val_mean_squared_error: 0.1786\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0445 - mean_squared_error: 0.0907\n",
      "Epoch 43: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0445 - mean_squared_error: 0.0907 - val_loss: 0.0876 - val_mean_squared_error: 0.1779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0435 - mean_squared_error: 0.0888\n",
      "Epoch 44: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0435 - mean_squared_error: 0.0888 - val_loss: 0.0840 - val_mean_squared_error: 0.1699\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0416 - mean_squared_error: 0.0849\n",
      "Epoch 45: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0416 - mean_squared_error: 0.0849 - val_loss: 0.0849 - val_mean_squared_error: 0.1719\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0415 - mean_squared_error: 0.0847\n",
      "Epoch 46: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0415 - mean_squared_error: 0.0847 - val_loss: 0.0974 - val_mean_squared_error: 0.1975\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0410 - mean_squared_error: 0.0838\n",
      "Epoch 47: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0410 - mean_squared_error: 0.0838 - val_loss: 0.0855 - val_mean_squared_error: 0.1732\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0401 - mean_squared_error: 0.0819\n",
      "Epoch 48: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0401 - mean_squared_error: 0.0819 - val_loss: 0.0867 - val_mean_squared_error: 0.1755\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0800\n",
      "Epoch 49: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0391 - mean_squared_error: 0.0800 - val_loss: 0.0923 - val_mean_squared_error: 0.1872\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0387 - mean_squared_error: 0.0791\n",
      "Epoch 50: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0387 - mean_squared_error: 0.0791 - val_loss: 0.0855 - val_mean_squared_error: 0.1727\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0383 - mean_squared_error: 0.0784\n",
      "Epoch 51: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0383 - mean_squared_error: 0.0784 - val_loss: 0.0907 - val_mean_squared_error: 0.1840\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0799\n",
      "Epoch 52: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0391 - mean_squared_error: 0.0799 - val_loss: 0.0875 - val_mean_squared_error: 0.1773\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.0789\n",
      "Epoch 53: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0386 - mean_squared_error: 0.0789 - val_loss: 0.0957 - val_mean_squared_error: 0.1944\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0786\n",
      "Epoch 54: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0384 - mean_squared_error: 0.0786 - val_loss: 0.0916 - val_mean_squared_error: 0.1857\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0373 - mean_squared_error: 0.0764\n",
      "Epoch 55: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0373 - mean_squared_error: 0.0764 - val_loss: 0.0902 - val_mean_squared_error: 0.1827\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0358 - mean_squared_error: 0.0733\n",
      "Epoch 56: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0358 - mean_squared_error: 0.0733 - val_loss: 0.0906 - val_mean_squared_error: 0.1830\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0363 - mean_squared_error: 0.0743\n",
      "Epoch 57: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0363 - mean_squared_error: 0.0743 - val_loss: 0.0858 - val_mean_squared_error: 0.1737\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0368 - mean_squared_error: 0.0753\n",
      "Epoch 58: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0368 - mean_squared_error: 0.0753 - val_loss: 0.0857 - val_mean_squared_error: 0.1731\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0363 - mean_squared_error: 0.0743\n",
      "Epoch 59: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0363 - mean_squared_error: 0.0743 - val_loss: 0.0888 - val_mean_squared_error: 0.1802\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0348 - mean_squared_error: 0.0713\n",
      "Epoch 60: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0348 - mean_squared_error: 0.0713 - val_loss: 0.0924 - val_mean_squared_error: 0.1873\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0336 - mean_squared_error: 0.0689\n",
      "Epoch 61: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0336 - mean_squared_error: 0.0689 - val_loss: 0.0845 - val_mean_squared_error: 0.1715\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0331 - mean_squared_error: 0.0679\n",
      "Epoch 62: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0331 - mean_squared_error: 0.0679 - val_loss: 0.0919 - val_mean_squared_error: 0.1862\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0662\n",
      "Epoch 63: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0323 - mean_squared_error: 0.0662 - val_loss: 0.0950 - val_mean_squared_error: 0.1937\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0326 - mean_squared_error: 0.0670\n",
      "Epoch 64: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0326 - mean_squared_error: 0.0670 - val_loss: 0.0907 - val_mean_squared_error: 0.1845\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0333 - mean_squared_error: 0.0685\n",
      "Epoch 65: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0333 - mean_squared_error: 0.0685 - val_loss: 0.0958 - val_mean_squared_error: 0.1953\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0326 - mean_squared_error: 0.0667\n",
      "Epoch 66: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0326 - mean_squared_error: 0.0667 - val_loss: 0.0961 - val_mean_squared_error: 0.1957\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0307 - mean_squared_error: 0.0631\n",
      "Epoch 67: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0307 - mean_squared_error: 0.0631 - val_loss: 0.0953 - val_mean_squared_error: 0.1941\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0297 - mean_squared_error: 0.0610\n",
      "Epoch 68: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0297 - mean_squared_error: 0.0610 - val_loss: 0.0884 - val_mean_squared_error: 0.1797\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0294 - mean_squared_error: 0.0604\n",
      "Epoch 69: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0294 - mean_squared_error: 0.0604 - val_loss: 0.0939 - val_mean_squared_error: 0.1902\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0291 - mean_squared_error: 0.0599\n",
      "Epoch 70: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0291 - mean_squared_error: 0.0599 - val_loss: 0.0974 - val_mean_squared_error: 0.1974\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0300 - mean_squared_error: 0.0617\n",
      "Epoch 71: val_loss did not improve from 0.08092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 21s 2s/step - loss: 0.0300 - mean_squared_error: 0.0617 - val_loss: 0.1020 - val_mean_squared_error: 0.2081\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0303 - mean_squared_error: 0.0621\n",
      "Epoch 72: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0303 - mean_squared_error: 0.0621 - val_loss: 0.1049 - val_mean_squared_error: 0.2160\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0294 - mean_squared_error: 0.0604\n",
      "Epoch 73: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0294 - mean_squared_error: 0.0604 - val_loss: 0.0896 - val_mean_squared_error: 0.1827\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0296 - mean_squared_error: 0.0608\n",
      "Epoch 74: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0296 - mean_squared_error: 0.0608 - val_loss: 0.0894 - val_mean_squared_error: 0.1815\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0276 - mean_squared_error: 0.0570\n",
      "Epoch 75: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0276 - mean_squared_error: 0.0570 - val_loss: 0.0957 - val_mean_squared_error: 0.1945\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0272 - mean_squared_error: 0.0560\n",
      "Epoch 76: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0272 - mean_squared_error: 0.0560 - val_loss: 0.0991 - val_mean_squared_error: 0.2015\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0558\n",
      "Epoch 77: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0271 - mean_squared_error: 0.0558 - val_loss: 0.0939 - val_mean_squared_error: 0.1916\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0266 - mean_squared_error: 0.0549\n",
      "Epoch 78: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0266 - mean_squared_error: 0.0549 - val_loss: 0.0962 - val_mean_squared_error: 0.1957\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0261 - mean_squared_error: 0.0538\n",
      "Epoch 79: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0261 - mean_squared_error: 0.0538 - val_loss: 0.1029 - val_mean_squared_error: 0.2103\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0252 - mean_squared_error: 0.0520\n",
      "Epoch 80: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0252 - mean_squared_error: 0.0520 - val_loss: 0.1002 - val_mean_squared_error: 0.2054\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0503\n",
      "Epoch 81: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0243 - mean_squared_error: 0.0503 - val_loss: 0.0990 - val_mean_squared_error: 0.2018\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0235 - mean_squared_error: 0.0487\n",
      "Epoch 82: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0235 - mean_squared_error: 0.0487 - val_loss: 0.0963 - val_mean_squared_error: 0.1956\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0240 - mean_squared_error: 0.0495\n",
      "Epoch 83: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0240 - mean_squared_error: 0.0495 - val_loss: 0.1000 - val_mean_squared_error: 0.2037\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0242 - mean_squared_error: 0.0499\n",
      "Epoch 84: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0242 - mean_squared_error: 0.0499 - val_loss: 0.1079 - val_mean_squared_error: 0.2214\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0238 - mean_squared_error: 0.0492\n",
      "Epoch 85: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0238 - mean_squared_error: 0.0492 - val_loss: 0.0992 - val_mean_squared_error: 0.2028\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0236 - mean_squared_error: 0.0490\n",
      "Epoch 86: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0236 - mean_squared_error: 0.0490 - val_loss: 0.0994 - val_mean_squared_error: 0.2027\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0238 - mean_squared_error: 0.0492\n",
      "Epoch 87: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0238 - mean_squared_error: 0.0492 - val_loss: 0.1053 - val_mean_squared_error: 0.2149\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0236 - mean_squared_error: 0.0487\n",
      "Epoch 88: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0236 - mean_squared_error: 0.0487 - val_loss: 0.1059 - val_mean_squared_error: 0.2163\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0230 - mean_squared_error: 0.0476\n",
      "Epoch 89: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0230 - mean_squared_error: 0.0476 - val_loss: 0.0987 - val_mean_squared_error: 0.2019\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0220 - mean_squared_error: 0.0455\n",
      "Epoch 90: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0220 - mean_squared_error: 0.0455 - val_loss: 0.1010 - val_mean_squared_error: 0.2057\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0212 - mean_squared_error: 0.0441\n",
      "Epoch 91: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0212 - mean_squared_error: 0.0441 - val_loss: 0.1020 - val_mean_squared_error: 0.2087\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0208 - mean_squared_error: 0.0433\n",
      "Epoch 92: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0208 - mean_squared_error: 0.0433 - val_loss: 0.1044 - val_mean_squared_error: 0.2130\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0210 - mean_squared_error: 0.0437\n",
      "Epoch 93: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0210 - mean_squared_error: 0.0437 - val_loss: 0.1049 - val_mean_squared_error: 0.2144\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0206 - mean_squared_error: 0.0429\n",
      "Epoch 94: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0206 - mean_squared_error: 0.0429 - val_loss: 0.1079 - val_mean_squared_error: 0.2211\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0200 - mean_squared_error: 0.0416\n",
      "Epoch 95: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0200 - mean_squared_error: 0.0416 - val_loss: 0.1132 - val_mean_squared_error: 0.2340\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0199 - mean_squared_error: 0.0414\n",
      "Epoch 96: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0199 - mean_squared_error: 0.0414 - val_loss: 0.1003 - val_mean_squared_error: 0.2042\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0195 - mean_squared_error: 0.0407\n",
      "Epoch 97: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0195 - mean_squared_error: 0.0407 - val_loss: 0.1060 - val_mean_squared_error: 0.2167\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0394\n",
      "Epoch 98: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0189 - mean_squared_error: 0.0394 - val_loss: 0.1008 - val_mean_squared_error: 0.2060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0395\n",
      "Epoch 99: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0189 - mean_squared_error: 0.0395 - val_loss: 0.1024 - val_mean_squared_error: 0.2097\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0394\n",
      "Epoch 100: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0189 - mean_squared_error: 0.0394 - val_loss: 0.1054 - val_mean_squared_error: 0.2167\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0184 - mean_squared_error: 0.0385\n",
      "Epoch 101: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0184 - mean_squared_error: 0.0385 - val_loss: 0.1044 - val_mean_squared_error: 0.2136\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0379\n",
      "Epoch 102: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0181 - mean_squared_error: 0.0379 - val_loss: 0.1077 - val_mean_squared_error: 0.2211\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0187 - mean_squared_error: 0.0391\n",
      "Epoch 103: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0187 - mean_squared_error: 0.0391 - val_loss: 0.1091 - val_mean_squared_error: 0.2254\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0378\n",
      "Epoch 104: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0181 - mean_squared_error: 0.0378 - val_loss: 0.1074 - val_mean_squared_error: 0.2196\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0366\n",
      "Epoch 105: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0175 - mean_squared_error: 0.0366 - val_loss: 0.1065 - val_mean_squared_error: 0.2186\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0360\n",
      "Epoch 106: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0172 - mean_squared_error: 0.0360 - val_loss: 0.1091 - val_mean_squared_error: 0.2239\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0170 - mean_squared_error: 0.0357\n",
      "Epoch 107: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0170 - mean_squared_error: 0.0357 - val_loss: 0.1044 - val_mean_squared_error: 0.2136\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0170 - mean_squared_error: 0.0357\n",
      "Epoch 108: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0170 - mean_squared_error: 0.0357 - val_loss: 0.1123 - val_mean_squared_error: 0.2324\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0171 - mean_squared_error: 0.0357\n",
      "Epoch 109: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0171 - mean_squared_error: 0.0357 - val_loss: 0.1109 - val_mean_squared_error: 0.2280\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0353\n",
      "Epoch 110: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0168 - mean_squared_error: 0.0353 - val_loss: 0.1051 - val_mean_squared_error: 0.2145\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0345\n",
      "Epoch 111: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0164 - mean_squared_error: 0.0345 - val_loss: 0.1121 - val_mean_squared_error: 0.2308\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0339\n",
      "Epoch 112: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0161 - mean_squared_error: 0.0339 - val_loss: 0.1085 - val_mean_squared_error: 0.2224\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0158 - mean_squared_error: 0.0333\n",
      "Epoch 113: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0158 - mean_squared_error: 0.0333 - val_loss: 0.1074 - val_mean_squared_error: 0.2198\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0319\n",
      "Epoch 114: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0151 - mean_squared_error: 0.0319 - val_loss: 0.1061 - val_mean_squared_error: 0.2177\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0312\n",
      "Epoch 115: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0148 - mean_squared_error: 0.0312 - val_loss: 0.1073 - val_mean_squared_error: 0.2188\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0312\n",
      "Epoch 116: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0148 - mean_squared_error: 0.0312 - val_loss: 0.1127 - val_mean_squared_error: 0.2316\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0312\n",
      "Epoch 117: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0148 - mean_squared_error: 0.0312 - val_loss: 0.1155 - val_mean_squared_error: 0.2385\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0307\n",
      "Epoch 118: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0145 - mean_squared_error: 0.0307 - val_loss: 0.1091 - val_mean_squared_error: 0.2234\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0307\n",
      "Epoch 119: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.0146 - mean_squared_error: 0.0307 - val_loss: 0.1107 - val_mean_squared_error: 0.2266\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0306\n",
      "Epoch 120: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0145 - mean_squared_error: 0.0306 - val_loss: 0.1145 - val_mean_squared_error: 0.2356\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0299\n",
      "Epoch 121: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0141 - mean_squared_error: 0.0299 - val_loss: 0.1126 - val_mean_squared_error: 0.2315\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0289\n",
      "Epoch 122: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0136 - mean_squared_error: 0.0289 - val_loss: 0.1106 - val_mean_squared_error: 0.2264\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0289\n",
      "Epoch 123: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0137 - mean_squared_error: 0.0289 - val_loss: 0.1128 - val_mean_squared_error: 0.2327\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0291\n",
      "Epoch 124: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0137 - mean_squared_error: 0.0291 - val_loss: 0.1113 - val_mean_squared_error: 0.2275\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0291\n",
      "Epoch 125: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0138 - mean_squared_error: 0.0291 - val_loss: 0.1124 - val_mean_squared_error: 0.2311\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0300\n",
      "Epoch 126: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0142 - mean_squared_error: 0.0300 - val_loss: 0.1145 - val_mean_squared_error: 0.2372\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0288\n",
      "Epoch 127: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0136 - mean_squared_error: 0.0288 - val_loss: 0.1140 - val_mean_squared_error: 0.2340\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0273\n",
      "Epoch 128: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0129 - mean_squared_error: 0.0273 - val_loss: 0.1163 - val_mean_squared_error: 0.2390\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0272\n",
      "Epoch 129: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0128 - mean_squared_error: 0.0272 - val_loss: 0.1134 - val_mean_squared_error: 0.2326\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0267\n",
      "Epoch 130: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0125 - mean_squared_error: 0.0267 - val_loss: 0.1160 - val_mean_squared_error: 0.2395\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0262\n",
      "Epoch 131: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0123 - mean_squared_error: 0.0262 - val_loss: 0.1118 - val_mean_squared_error: 0.2304\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0265\n",
      "Epoch 132: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0124 - mean_squared_error: 0.0265 - val_loss: 0.1178 - val_mean_squared_error: 0.2439\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0261\n",
      "Epoch 133: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0123 - mean_squared_error: 0.0261 - val_loss: 0.1128 - val_mean_squared_error: 0.2315\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0259\n",
      "Epoch 134: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0122 - mean_squared_error: 0.0259 - val_loss: 0.1182 - val_mean_squared_error: 0.2441\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0258\n",
      "Epoch 135: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0121 - mean_squared_error: 0.0258 - val_loss: 0.1177 - val_mean_squared_error: 0.2429\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0253\n",
      "Epoch 136: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0118 - mean_squared_error: 0.0253 - val_loss: 0.1140 - val_mean_squared_error: 0.2354\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0252\n",
      "Epoch 137: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0118 - mean_squared_error: 0.0252 - val_loss: 0.1217 - val_mean_squared_error: 0.2523\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0255\n",
      "Epoch 138: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0119 - mean_squared_error: 0.0255 - val_loss: 0.1130 - val_mean_squared_error: 0.2313\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0249\n",
      "Epoch 139: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0117 - mean_squared_error: 0.0249 - val_loss: 0.1143 - val_mean_squared_error: 0.2363\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0248\n",
      "Epoch 140: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0116 - mean_squared_error: 0.0248 - val_loss: 0.1145 - val_mean_squared_error: 0.2360\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0244\n",
      "Epoch 141: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0114 - mean_squared_error: 0.0244 - val_loss: 0.1157 - val_mean_squared_error: 0.2380\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0241\n",
      "Epoch 142: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0112 - mean_squared_error: 0.0241 - val_loss: 0.1132 - val_mean_squared_error: 0.2331\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0242\n",
      "Epoch 143: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0112 - mean_squared_error: 0.0242 - val_loss: 0.1150 - val_mean_squared_error: 0.2371\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0232\n",
      "Epoch 144: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0108 - mean_squared_error: 0.0232 - val_loss: 0.1190 - val_mean_squared_error: 0.2447\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0231\n",
      "Epoch 145: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0107 - mean_squared_error: 0.0231 - val_loss: 0.1213 - val_mean_squared_error: 0.2507\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0228\n",
      "Epoch 146: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0106 - mean_squared_error: 0.0228 - val_loss: 0.1153 - val_mean_squared_error: 0.2370\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0222\n",
      "Epoch 147: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0103 - mean_squared_error: 0.0222 - val_loss: 0.1202 - val_mean_squared_error: 0.2482\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0223\n",
      "Epoch 148: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0103 - mean_squared_error: 0.0223 - val_loss: 0.1171 - val_mean_squared_error: 0.2415\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0223\n",
      "Epoch 149: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0103 - mean_squared_error: 0.0223 - val_loss: 0.1220 - val_mean_squared_error: 0.2526\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0221\n",
      "Epoch 150: val_loss did not improve from 0.08092\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.0102 - mean_squared_error: 0.0221 - val_loss: 0.1159 - val_mean_squared_error: 0.2385\n",
      "5/5 [==============================] - 11s 227ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  288\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3956 - mean_squared_error: 0.8876\n",
      "Epoch 1: val_loss improved from inf to 0.30562, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 87s 4s/step - loss: 0.3956 - mean_squared_error: 0.8876 - val_loss: 0.3056 - val_mean_squared_error: 0.6541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2462 - mean_squared_error: 0.5251\n",
      "Epoch 2: val_loss improved from 0.30562 to 0.18497, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.2462 - mean_squared_error: 0.5251 - val_loss: 0.1850 - val_mean_squared_error: 0.3833\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1368 - mean_squared_error: 0.2814\n",
      "Epoch 3: val_loss improved from 0.18497 to 0.14058, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.1368 - mean_squared_error: 0.2814 - val_loss: 0.1406 - val_mean_squared_error: 0.2870\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1090 - mean_squared_error: 0.2223\n",
      "Epoch 4: val_loss improved from 0.14058 to 0.12891, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.1090 - mean_squared_error: 0.2223 - val_loss: 0.1289 - val_mean_squared_error: 0.2623\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1006 - mean_squared_error: 0.2050\n",
      "Epoch 5: val_loss improved from 0.12891 to 0.12429, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.1006 - mean_squared_error: 0.2050 - val_loss: 0.1243 - val_mean_squared_error: 0.2534\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0967 - mean_squared_error: 0.1974\n",
      "Epoch 6: val_loss improved from 0.12429 to 0.12083, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0967 - mean_squared_error: 0.1974 - val_loss: 0.1208 - val_mean_squared_error: 0.2460\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0955 - mean_squared_error: 0.1955\n",
      "Epoch 7: val_loss did not improve from 0.12083\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0955 - mean_squared_error: 0.1955 - val_loss: 0.1219 - val_mean_squared_error: 0.2486\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0928 - mean_squared_error: 0.1891\n",
      "Epoch 8: val_loss improved from 0.12083 to 0.11608, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0928 - mean_squared_error: 0.1891 - val_loss: 0.1161 - val_mean_squared_error: 0.2361\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0894 - mean_squared_error: 0.1824\n",
      "Epoch 9: val_loss did not improve from 0.11608\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0894 - mean_squared_error: 0.1824 - val_loss: 0.1228 - val_mean_squared_error: 0.2511\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0863 - mean_squared_error: 0.1768\n",
      "Epoch 10: val_loss improved from 0.11608 to 0.11432, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0863 - mean_squared_error: 0.1768 - val_loss: 0.1143 - val_mean_squared_error: 0.2338\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0838 - mean_squared_error: 0.1718\n",
      "Epoch 11: val_loss did not improve from 0.11432\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0838 - mean_squared_error: 0.1718 - val_loss: 0.1159 - val_mean_squared_error: 0.2377\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0824 - mean_squared_error: 0.1689\n",
      "Epoch 12: val_loss improved from 0.11432 to 0.11098, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0824 - mean_squared_error: 0.1689 - val_loss: 0.1110 - val_mean_squared_error: 0.2268\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0800 - mean_squared_error: 0.1634\n",
      "Epoch 13: val_loss improved from 0.11098 to 0.10925, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0800 - mean_squared_error: 0.1634 - val_loss: 0.1092 - val_mean_squared_error: 0.2241\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0791 - mean_squared_error: 0.1621\n",
      "Epoch 14: val_loss did not improve from 0.10925\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0791 - mean_squared_error: 0.1621 - val_loss: 0.1107 - val_mean_squared_error: 0.2264\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0771 - mean_squared_error: 0.1575\n",
      "Epoch 15: val_loss improved from 0.10925 to 0.10789, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0771 - mean_squared_error: 0.1575 - val_loss: 0.1079 - val_mean_squared_error: 0.2209\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0767 - mean_squared_error: 0.1568\n",
      "Epoch 16: val_loss improved from 0.10789 to 0.10572, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0767 - mean_squared_error: 0.1568 - val_loss: 0.1057 - val_mean_squared_error: 0.2156\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0747 - mean_squared_error: 0.1527\n",
      "Epoch 17: val_loss improved from 0.10572 to 0.10472, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0747 - mean_squared_error: 0.1527 - val_loss: 0.1047 - val_mean_squared_error: 0.2140\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0734 - mean_squared_error: 0.1501\n",
      "Epoch 18: val_loss improved from 0.10472 to 0.09989, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0734 - mean_squared_error: 0.1501 - val_loss: 0.0999 - val_mean_squared_error: 0.2036\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0715 - mean_squared_error: 0.1459\n",
      "Epoch 19: val_loss improved from 0.09989 to 0.09723, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0715 - mean_squared_error: 0.1459 - val_loss: 0.0972 - val_mean_squared_error: 0.1984\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0696 - mean_squared_error: 0.1419\n",
      "Epoch 20: val_loss improved from 0.09723 to 0.09510, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0696 - mean_squared_error: 0.1419 - val_loss: 0.0951 - val_mean_squared_error: 0.1946\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0667 - mean_squared_error: 0.1360\n",
      "Epoch 21: val_loss did not improve from 0.09510\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0667 - mean_squared_error: 0.1360 - val_loss: 0.1050 - val_mean_squared_error: 0.2146\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0656 - mean_squared_error: 0.1335\n",
      "Epoch 22: val_loss improved from 0.09510 to 0.08791, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0656 - mean_squared_error: 0.1335 - val_loss: 0.0879 - val_mean_squared_error: 0.1790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0617 - mean_squared_error: 0.1257\n",
      "Epoch 23: val_loss improved from 0.08791 to 0.08212, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0617 - mean_squared_error: 0.1257 - val_loss: 0.0821 - val_mean_squared_error: 0.1671\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0597 - mean_squared_error: 0.1217\n",
      "Epoch 24: val_loss did not improve from 0.08212\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0597 - mean_squared_error: 0.1217 - val_loss: 0.0942 - val_mean_squared_error: 0.1924\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0576 - mean_squared_error: 0.1174\n",
      "Epoch 25: val_loss did not improve from 0.08212\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0576 - mean_squared_error: 0.1174 - val_loss: 0.0948 - val_mean_squared_error: 0.1927\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0575 - mean_squared_error: 0.1171\n",
      "Epoch 26: val_loss did not improve from 0.08212\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0575 - mean_squared_error: 0.1171 - val_loss: 0.0909 - val_mean_squared_error: 0.1857\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0581 - mean_squared_error: 0.1184\n",
      "Epoch 27: val_loss did not improve from 0.08212\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0581 - mean_squared_error: 0.1184 - val_loss: 0.0868 - val_mean_squared_error: 0.1765\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0576 - mean_squared_error: 0.1175\n",
      "Epoch 28: val_loss did not improve from 0.08212\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0576 - mean_squared_error: 0.1175 - val_loss: 0.1005 - val_mean_squared_error: 0.2061\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0565 - mean_squared_error: 0.1151\n",
      "Epoch 29: val_loss did not improve from 0.08212\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0565 - mean_squared_error: 0.1151 - val_loss: 0.0892 - val_mean_squared_error: 0.1813\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0548 - mean_squared_error: 0.1116\n",
      "Epoch 30: val_loss improved from 0.08212 to 0.08200, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0548 - mean_squared_error: 0.1116 - val_loss: 0.0820 - val_mean_squared_error: 0.1664\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0538 - mean_squared_error: 0.1096\n",
      "Epoch 31: val_loss did not improve from 0.08200\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0538 - mean_squared_error: 0.1096 - val_loss: 0.0954 - val_mean_squared_error: 0.1935\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0553 - mean_squared_error: 0.1125\n",
      "Epoch 32: val_loss did not improve from 0.08200\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0553 - mean_squared_error: 0.1125 - val_loss: 0.0920 - val_mean_squared_error: 0.1874\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0532 - mean_squared_error: 0.1085\n",
      "Epoch 33: val_loss did not improve from 0.08200\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0532 - mean_squared_error: 0.1085 - val_loss: 0.0913 - val_mean_squared_error: 0.1854\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0517 - mean_squared_error: 0.1055\n",
      "Epoch 34: val_loss did not improve from 0.08200\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0517 - mean_squared_error: 0.1055 - val_loss: 0.0911 - val_mean_squared_error: 0.1851\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0502 - mean_squared_error: 0.1023\n",
      "Epoch 35: val_loss did not improve from 0.08200\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0502 - mean_squared_error: 0.1023 - val_loss: 0.0852 - val_mean_squared_error: 0.1724\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0484 - mean_squared_error: 0.0986\n",
      "Epoch 36: val_loss did not improve from 0.08200\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0484 - mean_squared_error: 0.0986 - val_loss: 0.0823 - val_mean_squared_error: 0.1669\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0480 - mean_squared_error: 0.0979\n",
      "Epoch 37: val_loss improved from 0.08200 to 0.07991, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0480 - mean_squared_error: 0.0979 - val_loss: 0.0799 - val_mean_squared_error: 0.1620\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0466 - mean_squared_error: 0.0951\n",
      "Epoch 38: val_loss did not improve from 0.07991\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0466 - mean_squared_error: 0.0951 - val_loss: 0.0858 - val_mean_squared_error: 0.1743\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0468 - mean_squared_error: 0.0955\n",
      "Epoch 39: val_loss did not improve from 0.07991\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0468 - mean_squared_error: 0.0955 - val_loss: 0.0841 - val_mean_squared_error: 0.1706\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0467 - mean_squared_error: 0.0953\n",
      "Epoch 40: val_loss did not improve from 0.07991\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0467 - mean_squared_error: 0.0953 - val_loss: 0.0836 - val_mean_squared_error: 0.1698\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0459 - mean_squared_error: 0.0937\n",
      "Epoch 41: val_loss did not improve from 0.07991\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0459 - mean_squared_error: 0.0937 - val_loss: 0.0804 - val_mean_squared_error: 0.1626\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0446 - mean_squared_error: 0.0910\n",
      "Epoch 42: val_loss did not improve from 0.07991\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0446 - mean_squared_error: 0.0910 - val_loss: 0.0819 - val_mean_squared_error: 0.1655\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0438 - mean_squared_error: 0.0894\n",
      "Epoch 43: val_loss did not improve from 0.07991\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0438 - mean_squared_error: 0.0894 - val_loss: 0.0817 - val_mean_squared_error: 0.1652\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0453 - mean_squared_error: 0.0925\n",
      "Epoch 44: val_loss did not improve from 0.07991\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0453 - mean_squared_error: 0.0925 - val_loss: 0.0853 - val_mean_squared_error: 0.1725\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0433 - mean_squared_error: 0.0884\n",
      "Epoch 45: val_loss did not improve from 0.07991\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0433 - mean_squared_error: 0.0884 - val_loss: 0.0828 - val_mean_squared_error: 0.1673\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0430 - mean_squared_error: 0.0877\n",
      "Epoch 46: val_loss did not improve from 0.07991\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0430 - mean_squared_error: 0.0877 - val_loss: 0.0894 - val_mean_squared_error: 0.1813\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0423 - mean_squared_error: 0.0864\n",
      "Epoch 47: val_loss did not improve from 0.07991\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0423 - mean_squared_error: 0.0864 - val_loss: 0.0834 - val_mean_squared_error: 0.1686\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0410 - mean_squared_error: 0.0838\n",
      "Epoch 48: val_loss did not improve from 0.07991\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0410 - mean_squared_error: 0.0838 - val_loss: 0.0837 - val_mean_squared_error: 0.1691\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0404 - mean_squared_error: 0.0826\n",
      "Epoch 49: val_loss did not improve from 0.07991\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0404 - mean_squared_error: 0.0826 - val_loss: 0.0843 - val_mean_squared_error: 0.1703\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0406 - mean_squared_error: 0.0830\n",
      "Epoch 50: val_loss did not improve from 0.07991\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0406 - mean_squared_error: 0.0830 - val_loss: 0.0802 - val_mean_squared_error: 0.1622\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0412 - mean_squared_error: 0.0843\n",
      "Epoch 51: val_loss improved from 0.07991 to 0.07701, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0412 - mean_squared_error: 0.0843 - val_loss: 0.0770 - val_mean_squared_error: 0.1551\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0406 - mean_squared_error: 0.0831\n",
      "Epoch 52: val_loss did not improve from 0.07701\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0406 - mean_squared_error: 0.0831 - val_loss: 0.0849 - val_mean_squared_error: 0.1715\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.0798\n",
      "Epoch 53: val_loss did not improve from 0.07701\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0390 - mean_squared_error: 0.0798 - val_loss: 0.0780 - val_mean_squared_error: 0.1573\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0779\n",
      "Epoch 54: val_loss improved from 0.07701 to 0.07474, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0381 - mean_squared_error: 0.0779 - val_loss: 0.0747 - val_mean_squared_error: 0.1505\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0369 - mean_squared_error: 0.0756\n",
      "Epoch 55: val_loss did not improve from 0.07474\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0369 - mean_squared_error: 0.0756 - val_loss: 0.0758 - val_mean_squared_error: 0.1524\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0749\n",
      "Epoch 56: val_loss did not improve from 0.07474\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0366 - mean_squared_error: 0.0749 - val_loss: 0.0787 - val_mean_squared_error: 0.1587\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0368 - mean_squared_error: 0.0754\n",
      "Epoch 57: val_loss did not improve from 0.07474\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0368 - mean_squared_error: 0.0754 - val_loss: 0.0800 - val_mean_squared_error: 0.1611\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.0725\n",
      "Epoch 58: val_loss did not improve from 0.07474\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0354 - mean_squared_error: 0.0725 - val_loss: 0.0818 - val_mean_squared_error: 0.1648\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0348 - mean_squared_error: 0.0715\n",
      "Epoch 59: val_loss did not improve from 0.07474\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0348 - mean_squared_error: 0.0715 - val_loss: 0.0861 - val_mean_squared_error: 0.1733\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0345 - mean_squared_error: 0.0707\n",
      "Epoch 60: val_loss did not improve from 0.07474\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0345 - mean_squared_error: 0.0707 - val_loss: 0.0830 - val_mean_squared_error: 0.1673\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0339 - mean_squared_error: 0.0696\n",
      "Epoch 61: val_loss did not improve from 0.07474\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0339 - mean_squared_error: 0.0696 - val_loss: 0.0812 - val_mean_squared_error: 0.1631\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0332 - mean_squared_error: 0.0681\n",
      "Epoch 62: val_loss did not improve from 0.07474\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0332 - mean_squared_error: 0.0681 - val_loss: 0.0836 - val_mean_squared_error: 0.1681\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0332 - mean_squared_error: 0.0681\n",
      "Epoch 63: val_loss did not improve from 0.07474\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0332 - mean_squared_error: 0.0681 - val_loss: 0.0883 - val_mean_squared_error: 0.1783\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0329 - mean_squared_error: 0.0675\n",
      "Epoch 64: val_loss did not improve from 0.07474\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0329 - mean_squared_error: 0.0675 - val_loss: 0.0809 - val_mean_squared_error: 0.1629\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0317 - mean_squared_error: 0.0651\n",
      "Epoch 65: val_loss improved from 0.07474 to 0.07390, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0317 - mean_squared_error: 0.0651 - val_loss: 0.0739 - val_mean_squared_error: 0.1485\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0317 - mean_squared_error: 0.0651\n",
      "Epoch 66: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0317 - mean_squared_error: 0.0651 - val_loss: 0.0799 - val_mean_squared_error: 0.1607\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0315 - mean_squared_error: 0.0647\n",
      "Epoch 67: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0315 - mean_squared_error: 0.0647 - val_loss: 0.0890 - val_mean_squared_error: 0.1797\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0306 - mean_squared_error: 0.0629\n",
      "Epoch 68: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0306 - mean_squared_error: 0.0629 - val_loss: 0.0857 - val_mean_squared_error: 0.1724\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0302 - mean_squared_error: 0.0620\n",
      "Epoch 69: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0302 - mean_squared_error: 0.0620 - val_loss: 0.0815 - val_mean_squared_error: 0.1640\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0302 - mean_squared_error: 0.0621\n",
      "Epoch 70: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0302 - mean_squared_error: 0.0621 - val_loss: 0.0820 - val_mean_squared_error: 0.1649\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0287 - mean_squared_error: 0.0591\n",
      "Epoch 71: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0287 - mean_squared_error: 0.0591 - val_loss: 0.0854 - val_mean_squared_error: 0.1723\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0282 - mean_squared_error: 0.0581\n",
      "Epoch 72: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0282 - mean_squared_error: 0.0581 - val_loss: 0.0849 - val_mean_squared_error: 0.1712\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0280 - mean_squared_error: 0.0577\n",
      "Epoch 73: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0280 - mean_squared_error: 0.0577 - val_loss: 0.0850 - val_mean_squared_error: 0.1711\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0559\n",
      "Epoch 74: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0271 - mean_squared_error: 0.0559 - val_loss: 0.0900 - val_mean_squared_error: 0.1813\n",
      "Epoch 75/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - ETA: 0s - loss: 0.0273 - mean_squared_error: 0.0562\n",
      "Epoch 75: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0273 - mean_squared_error: 0.0562 - val_loss: 0.0843 - val_mean_squared_error: 0.1700\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0266 - mean_squared_error: 0.0548\n",
      "Epoch 76: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0266 - mean_squared_error: 0.0548 - val_loss: 0.0814 - val_mean_squared_error: 0.1640\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0268 - mean_squared_error: 0.0551\n",
      "Epoch 77: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0268 - mean_squared_error: 0.0551 - val_loss: 0.0877 - val_mean_squared_error: 0.1772\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0263 - mean_squared_error: 0.0543\n",
      "Epoch 78: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0263 - mean_squared_error: 0.0543 - val_loss: 0.0908 - val_mean_squared_error: 0.1832\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0264 - mean_squared_error: 0.0545\n",
      "Epoch 79: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0264 - mean_squared_error: 0.0545 - val_loss: 0.0872 - val_mean_squared_error: 0.1760\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0258 - mean_squared_error: 0.0533\n",
      "Epoch 80: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0258 - mean_squared_error: 0.0533 - val_loss: 0.0850 - val_mean_squared_error: 0.1714\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0245 - mean_squared_error: 0.0506\n",
      "Epoch 81: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0245 - mean_squared_error: 0.0506 - val_loss: 0.0909 - val_mean_squared_error: 0.1832\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0504\n",
      "Epoch 82: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0243 - mean_squared_error: 0.0504 - val_loss: 0.0987 - val_mean_squared_error: 0.1992\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0245 - mean_squared_error: 0.0506\n",
      "Epoch 83: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0245 - mean_squared_error: 0.0506 - val_loss: 0.0894 - val_mean_squared_error: 0.1804\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0242 - mean_squared_error: 0.0500\n",
      "Epoch 84: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0242 - mean_squared_error: 0.0500 - val_loss: 0.0854 - val_mean_squared_error: 0.1724\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0235 - mean_squared_error: 0.0486\n",
      "Epoch 85: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0235 - mean_squared_error: 0.0486 - val_loss: 0.0915 - val_mean_squared_error: 0.1843\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0235 - mean_squared_error: 0.0486\n",
      "Epoch 86: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0235 - mean_squared_error: 0.0486 - val_loss: 0.0977 - val_mean_squared_error: 0.1971\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0231 - mean_squared_error: 0.0478\n",
      "Epoch 87: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0231 - mean_squared_error: 0.0478 - val_loss: 0.0948 - val_mean_squared_error: 0.1918\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0465\n",
      "Epoch 88: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0224 - mean_squared_error: 0.0465 - val_loss: 0.0928 - val_mean_squared_error: 0.1874\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0222 - mean_squared_error: 0.0460\n",
      "Epoch 89: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0222 - mean_squared_error: 0.0460 - val_loss: 0.0872 - val_mean_squared_error: 0.1759\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0232 - mean_squared_error: 0.0478\n",
      "Epoch 90: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0232 - mean_squared_error: 0.0478 - val_loss: 0.1024 - val_mean_squared_error: 0.2083\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0238 - mean_squared_error: 0.0493\n",
      "Epoch 91: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0238 - mean_squared_error: 0.0493 - val_loss: 0.1012 - val_mean_squared_error: 0.2047\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0223 - mean_squared_error: 0.0463\n",
      "Epoch 92: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0223 - mean_squared_error: 0.0463 - val_loss: 0.0894 - val_mean_squared_error: 0.1806\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0214 - mean_squared_error: 0.0444\n",
      "Epoch 93: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0214 - mean_squared_error: 0.0444 - val_loss: 0.0880 - val_mean_squared_error: 0.1781\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0209 - mean_squared_error: 0.0434\n",
      "Epoch 94: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0209 - mean_squared_error: 0.0434 - val_loss: 0.0989 - val_mean_squared_error: 0.2005\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0208 - mean_squared_error: 0.0433\n",
      "Epoch 95: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0208 - mean_squared_error: 0.0433 - val_loss: 0.0972 - val_mean_squared_error: 0.1968\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0194 - mean_squared_error: 0.0404\n",
      "Epoch 96: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0194 - mean_squared_error: 0.0404 - val_loss: 0.0954 - val_mean_squared_error: 0.1932\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0187 - mean_squared_error: 0.0390\n",
      "Epoch 97: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0187 - mean_squared_error: 0.0390 - val_loss: 0.0981 - val_mean_squared_error: 0.1988\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0403\n",
      "Epoch 98: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0193 - mean_squared_error: 0.0403 - val_loss: 0.0949 - val_mean_squared_error: 0.1921\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0187 - mean_squared_error: 0.0391\n",
      "Epoch 99: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0187 - mean_squared_error: 0.0391 - val_loss: 0.0963 - val_mean_squared_error: 0.1949\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0183 - mean_squared_error: 0.0381\n",
      "Epoch 100: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0183 - mean_squared_error: 0.0381 - val_loss: 0.0968 - val_mean_squared_error: 0.1961\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0184 - mean_squared_error: 0.0386\n",
      "Epoch 101: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0184 - mean_squared_error: 0.0386 - val_loss: 0.1046 - val_mean_squared_error: 0.2125\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0179 - mean_squared_error: 0.0375\n",
      "Epoch 102: val_loss did not improve from 0.07390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 23s 3s/step - loss: 0.0179 - mean_squared_error: 0.0375 - val_loss: 0.1008 - val_mean_squared_error: 0.2041\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0364\n",
      "Epoch 103: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0174 - mean_squared_error: 0.0364 - val_loss: 0.0959 - val_mean_squared_error: 0.1941\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0171 - mean_squared_error: 0.0357\n",
      "Epoch 104: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0171 - mean_squared_error: 0.0357 - val_loss: 0.1050 - val_mean_squared_error: 0.2133\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0353\n",
      "Epoch 105: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0168 - mean_squared_error: 0.0353 - val_loss: 0.1009 - val_mean_squared_error: 0.2046\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0345\n",
      "Epoch 106: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0164 - mean_squared_error: 0.0345 - val_loss: 0.1003 - val_mean_squared_error: 0.2037\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0347\n",
      "Epoch 107: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0165 - mean_squared_error: 0.0347 - val_loss: 0.1033 - val_mean_squared_error: 0.2101\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0351\n",
      "Epoch 108: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0167 - mean_squared_error: 0.0351 - val_loss: 0.0954 - val_mean_squared_error: 0.1931\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0355\n",
      "Epoch 109: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0169 - mean_squared_error: 0.0355 - val_loss: 0.1099 - val_mean_squared_error: 0.2236\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0173 - mean_squared_error: 0.0362\n",
      "Epoch 110: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0173 - mean_squared_error: 0.0362 - val_loss: 0.0976 - val_mean_squared_error: 0.1974\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0355\n",
      "Epoch 111: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0169 - mean_squared_error: 0.0355 - val_loss: 0.1033 - val_mean_squared_error: 0.2099\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0344\n",
      "Epoch 112: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0164 - mean_squared_error: 0.0344 - val_loss: 0.1012 - val_mean_squared_error: 0.2054\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0325\n",
      "Epoch 113: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0154 - mean_squared_error: 0.0325 - val_loss: 0.1006 - val_mean_squared_error: 0.2043\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0158 - mean_squared_error: 0.0333\n",
      "Epoch 114: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0158 - mean_squared_error: 0.0333 - val_loss: 0.1030 - val_mean_squared_error: 0.2095\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0158 - mean_squared_error: 0.0331\n",
      "Epoch 115: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0158 - mean_squared_error: 0.0331 - val_loss: 0.0991 - val_mean_squared_error: 0.2011\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0320\n",
      "Epoch 116: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0152 - mean_squared_error: 0.0320 - val_loss: 0.1041 - val_mean_squared_error: 0.2114\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0311\n",
      "Epoch 117: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0147 - mean_squared_error: 0.0311 - val_loss: 0.1094 - val_mean_squared_error: 0.2229\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0304\n",
      "Epoch 118: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0144 - mean_squared_error: 0.0304 - val_loss: 0.1060 - val_mean_squared_error: 0.2156\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0302\n",
      "Epoch 119: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0143 - mean_squared_error: 0.0302 - val_loss: 0.1060 - val_mean_squared_error: 0.2154\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0303\n",
      "Epoch 120: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0143 - mean_squared_error: 0.0303 - val_loss: 0.1047 - val_mean_squared_error: 0.2128\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0293\n",
      "Epoch 121: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0138 - mean_squared_error: 0.0293 - val_loss: 0.1041 - val_mean_squared_error: 0.2116\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0284\n",
      "Epoch 122: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0134 - mean_squared_error: 0.0284 - val_loss: 0.1035 - val_mean_squared_error: 0.2104\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0281\n",
      "Epoch 123: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0132 - mean_squared_error: 0.0281 - val_loss: 0.1050 - val_mean_squared_error: 0.2139\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0282\n",
      "Epoch 124: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0133 - mean_squared_error: 0.0282 - val_loss: 0.1085 - val_mean_squared_error: 0.2212\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0283\n",
      "Epoch 125: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0134 - mean_squared_error: 0.0283 - val_loss: 0.1084 - val_mean_squared_error: 0.2205\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0275\n",
      "Epoch 126: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0129 - mean_squared_error: 0.0275 - val_loss: 0.1086 - val_mean_squared_error: 0.2212\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0270\n",
      "Epoch 127: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0127 - mean_squared_error: 0.0270 - val_loss: 0.1091 - val_mean_squared_error: 0.2221\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0264\n",
      "Epoch 128: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0124 - mean_squared_error: 0.0264 - val_loss: 0.1096 - val_mean_squared_error: 0.2231\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0265\n",
      "Epoch 129: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0124 - mean_squared_error: 0.0265 - val_loss: 0.1070 - val_mean_squared_error: 0.2178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0266\n",
      "Epoch 130: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0125 - mean_squared_error: 0.0266 - val_loss: 0.1057 - val_mean_squared_error: 0.2152\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0259\n",
      "Epoch 131: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0121 - mean_squared_error: 0.0259 - val_loss: 0.1101 - val_mean_squared_error: 0.2244\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0256\n",
      "Epoch 132: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0120 - mean_squared_error: 0.0256 - val_loss: 0.1078 - val_mean_squared_error: 0.2196\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0255\n",
      "Epoch 133: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0119 - mean_squared_error: 0.0255 - val_loss: 0.1052 - val_mean_squared_error: 0.2142\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0250\n",
      "Epoch 134: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0117 - mean_squared_error: 0.0250 - val_loss: 0.1122 - val_mean_squared_error: 0.2289\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0251\n",
      "Epoch 135: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0117 - mean_squared_error: 0.0251 - val_loss: 0.1058 - val_mean_squared_error: 0.2153\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0257\n",
      "Epoch 136: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0120 - mean_squared_error: 0.0257 - val_loss: 0.1144 - val_mean_squared_error: 0.2338\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0252\n",
      "Epoch 137: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0118 - mean_squared_error: 0.0252 - val_loss: 0.1051 - val_mean_squared_error: 0.2139\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0244\n",
      "Epoch 138: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0114 - mean_squared_error: 0.0244 - val_loss: 0.1092 - val_mean_squared_error: 0.2228\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0249\n",
      "Epoch 139: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0116 - mean_squared_error: 0.0249 - val_loss: 0.1089 - val_mean_squared_error: 0.2217\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0245\n",
      "Epoch 140: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0114 - mean_squared_error: 0.0245 - val_loss: 0.1093 - val_mean_squared_error: 0.2228\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0242\n",
      "Epoch 141: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0113 - mean_squared_error: 0.0242 - val_loss: 0.1136 - val_mean_squared_error: 0.2321\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0237\n",
      "Epoch 142: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0110 - mean_squared_error: 0.0237 - val_loss: 0.1071 - val_mean_squared_error: 0.2182\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0236\n",
      "Epoch 143: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0109 - mean_squared_error: 0.0236 - val_loss: 0.1101 - val_mean_squared_error: 0.2250\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0236\n",
      "Epoch 144: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0110 - mean_squared_error: 0.0236 - val_loss: 0.1173 - val_mean_squared_error: 0.2398\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0233\n",
      "Epoch 145: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0108 - mean_squared_error: 0.0233 - val_loss: 0.1053 - val_mean_squared_error: 0.2143\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0229\n",
      "Epoch 146: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0106 - mean_squared_error: 0.0229 - val_loss: 0.1107 - val_mean_squared_error: 0.2261\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0219\n",
      "Epoch 147: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0101 - mean_squared_error: 0.0219 - val_loss: 0.1081 - val_mean_squared_error: 0.2200\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0217\n",
      "Epoch 148: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0100 - mean_squared_error: 0.0217 - val_loss: 0.1107 - val_mean_squared_error: 0.2261\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0218\n",
      "Epoch 149: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0101 - mean_squared_error: 0.0218 - val_loss: 0.1092 - val_mean_squared_error: 0.2229\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0216\n",
      "Epoch 150: val_loss did not improve from 0.07390\n",
      "9/9 [==============================] - 23s 3s/step - loss: 0.0100 - mean_squared_error: 0.0216 - val_loss: 0.1112 - val_mean_squared_error: 0.2268\n",
      "5/5 [==============================] - 14s 246ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  312\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3937 - mean_squared_error: 0.8925\n",
      "Epoch 1: val_loss improved from inf to 0.27995, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 90s 4s/step - loss: 0.3937 - mean_squared_error: 0.8925 - val_loss: 0.2800 - val_mean_squared_error: 0.6299\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2531 - mean_squared_error: 0.5582\n",
      "Epoch 2: val_loss improved from 0.27995 to 0.17908, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.2531 - mean_squared_error: 0.5582 - val_loss: 0.1791 - val_mean_squared_error: 0.3800\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1602 - mean_squared_error: 0.3343\n",
      "Epoch 3: val_loss improved from 0.17908 to 0.13929, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.1602 - mean_squared_error: 0.3343 - val_loss: 0.1393 - val_mean_squared_error: 0.2857\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1140 - mean_squared_error: 0.2331\n",
      "Epoch 4: val_loss improved from 0.13929 to 0.12905, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 32s 4s/step - loss: 0.1140 - mean_squared_error: 0.2331 - val_loss: 0.1291 - val_mean_squared_error: 0.2623\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1019 - mean_squared_error: 0.2077\n",
      "Epoch 5: val_loss improved from 0.12905 to 0.12378, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.1019 - mean_squared_error: 0.2077 - val_loss: 0.1238 - val_mean_squared_error: 0.2515\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0963 - mean_squared_error: 0.1966\n",
      "Epoch 6: val_loss improved from 0.12378 to 0.12242, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0963 - mean_squared_error: 0.1966 - val_loss: 0.1224 - val_mean_squared_error: 0.2495\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0921 - mean_squared_error: 0.1877\n",
      "Epoch 7: val_loss improved from 0.12242 to 0.12090, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0921 - mean_squared_error: 0.1877 - val_loss: 0.1209 - val_mean_squared_error: 0.2466\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0881 - mean_squared_error: 0.1797\n",
      "Epoch 8: val_loss improved from 0.12090 to 0.11717, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0881 - mean_squared_error: 0.1797 - val_loss: 0.1172 - val_mean_squared_error: 0.2389\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0849 - mean_squared_error: 0.1734\n",
      "Epoch 9: val_loss did not improve from 0.11717\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0849 - mean_squared_error: 0.1734 - val_loss: 0.1186 - val_mean_squared_error: 0.2429\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0824 - mean_squared_error: 0.1685\n",
      "Epoch 10: val_loss improved from 0.11717 to 0.11347, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0824 - mean_squared_error: 0.1685 - val_loss: 0.1135 - val_mean_squared_error: 0.2320\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0792 - mean_squared_error: 0.1618\n",
      "Epoch 11: val_loss improved from 0.11347 to 0.11315, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0792 - mean_squared_error: 0.1618 - val_loss: 0.1131 - val_mean_squared_error: 0.2304\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0770 - mean_squared_error: 0.1573\n",
      "Epoch 12: val_loss improved from 0.11315 to 0.10690, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0770 - mean_squared_error: 0.1573 - val_loss: 0.1069 - val_mean_squared_error: 0.2174\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0752 - mean_squared_error: 0.1540\n",
      "Epoch 13: val_loss did not improve from 0.10690\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0752 - mean_squared_error: 0.1540 - val_loss: 0.1074 - val_mean_squared_error: 0.2188\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0728 - mean_squared_error: 0.1483\n",
      "Epoch 14: val_loss improved from 0.10690 to 0.10530, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0728 - mean_squared_error: 0.1483 - val_loss: 0.1053 - val_mean_squared_error: 0.2130\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0714 - mean_squared_error: 0.1458\n",
      "Epoch 15: val_loss improved from 0.10530 to 0.10160, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0714 - mean_squared_error: 0.1458 - val_loss: 0.1016 - val_mean_squared_error: 0.2065\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0684 - mean_squared_error: 0.1396\n",
      "Epoch 16: val_loss improved from 0.10160 to 0.09385, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0684 - mean_squared_error: 0.1396 - val_loss: 0.0939 - val_mean_squared_error: 0.1910\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0652 - mean_squared_error: 0.1327\n",
      "Epoch 17: val_loss improved from 0.09385 to 0.09211, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0652 - mean_squared_error: 0.1327 - val_loss: 0.0921 - val_mean_squared_error: 0.1877\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0635 - mean_squared_error: 0.1297\n",
      "Epoch 18: val_loss did not improve from 0.09211\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0635 - mean_squared_error: 0.1297 - val_loss: 0.0997 - val_mean_squared_error: 0.2046\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0616 - mean_squared_error: 0.1256\n",
      "Epoch 19: val_loss improved from 0.09211 to 0.08611, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0616 - mean_squared_error: 0.1256 - val_loss: 0.0861 - val_mean_squared_error: 0.1744\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0575 - mean_squared_error: 0.1171\n",
      "Epoch 20: val_loss improved from 0.08611 to 0.08278, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0575 - mean_squared_error: 0.1171 - val_loss: 0.0828 - val_mean_squared_error: 0.1668\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0557 - mean_squared_error: 0.1134\n",
      "Epoch 21: val_loss did not improve from 0.08278\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0557 - mean_squared_error: 0.1134 - val_loss: 0.1127 - val_mean_squared_error: 0.2308\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0582 - mean_squared_error: 0.1186\n",
      "Epoch 22: val_loss improved from 0.08278 to 0.08213, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0582 - mean_squared_error: 0.1186 - val_loss: 0.0821 - val_mean_squared_error: 0.1660\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0539 - mean_squared_error: 0.1098\n",
      "Epoch 23: val_loss did not improve from 0.08213\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0539 - mean_squared_error: 0.1098 - val_loss: 0.0944 - val_mean_squared_error: 0.1910\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0554 - mean_squared_error: 0.1129\n",
      "Epoch 24: val_loss did not improve from 0.08213\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0554 - mean_squared_error: 0.1129 - val_loss: 0.0850 - val_mean_squared_error: 0.1716\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0547 - mean_squared_error: 0.1115\n",
      "Epoch 25: val_loss did not improve from 0.08213\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0547 - mean_squared_error: 0.1115 - val_loss: 0.0857 - val_mean_squared_error: 0.1729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.1049\n",
      "Epoch 26: val_loss improved from 0.08213 to 0.08205, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0515 - mean_squared_error: 0.1049 - val_loss: 0.0821 - val_mean_squared_error: 0.1660\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0509 - mean_squared_error: 0.1039\n",
      "Epoch 27: val_loss did not improve from 0.08205\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0509 - mean_squared_error: 0.1039 - val_loss: 0.0928 - val_mean_squared_error: 0.1881\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0512 - mean_squared_error: 0.1043\n",
      "Epoch 28: val_loss did not improve from 0.08205\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0512 - mean_squared_error: 0.1043 - val_loss: 0.0855 - val_mean_squared_error: 0.1727\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0491 - mean_squared_error: 0.1000\n",
      "Epoch 29: val_loss improved from 0.08205 to 0.08094, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0491 - mean_squared_error: 0.1000 - val_loss: 0.0809 - val_mean_squared_error: 0.1635\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0495 - mean_squared_error: 0.1009\n",
      "Epoch 30: val_loss did not improve from 0.08094\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0495 - mean_squared_error: 0.1009 - val_loss: 0.0886 - val_mean_squared_error: 0.1789\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0498 - mean_squared_error: 0.1015\n",
      "Epoch 31: val_loss did not improve from 0.08094\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0498 - mean_squared_error: 0.1015 - val_loss: 0.0875 - val_mean_squared_error: 0.1767\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0476 - mean_squared_error: 0.0971\n",
      "Epoch 32: val_loss did not improve from 0.08094\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0476 - mean_squared_error: 0.0971 - val_loss: 0.0853 - val_mean_squared_error: 0.1721\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0466 - mean_squared_error: 0.0949\n",
      "Epoch 33: val_loss did not improve from 0.08094\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0466 - mean_squared_error: 0.0949 - val_loss: 0.0825 - val_mean_squared_error: 0.1665\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0469 - mean_squared_error: 0.0956\n",
      "Epoch 34: val_loss did not improve from 0.08094\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0469 - mean_squared_error: 0.0956 - val_loss: 0.0883 - val_mean_squared_error: 0.1782\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0457 - mean_squared_error: 0.0932\n",
      "Epoch 35: val_loss did not improve from 0.08094\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0457 - mean_squared_error: 0.0932 - val_loss: 0.0879 - val_mean_squared_error: 0.1775\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0460 - mean_squared_error: 0.0937\n",
      "Epoch 36: val_loss did not improve from 0.08094\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0460 - mean_squared_error: 0.0937 - val_loss: 0.0948 - val_mean_squared_error: 0.1931\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0474 - mean_squared_error: 0.0966\n",
      "Epoch 37: val_loss did not improve from 0.08094\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0474 - mean_squared_error: 0.0966 - val_loss: 0.0869 - val_mean_squared_error: 0.1756\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0441 - mean_squared_error: 0.0899\n",
      "Epoch 38: val_loss did not improve from 0.08094\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0441 - mean_squared_error: 0.0899 - val_loss: 0.0849 - val_mean_squared_error: 0.1709\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0445 - mean_squared_error: 0.0907\n",
      "Epoch 39: val_loss improved from 0.08094 to 0.07941, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0445 - mean_squared_error: 0.0907 - val_loss: 0.0794 - val_mean_squared_error: 0.1598\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0427 - mean_squared_error: 0.0872\n",
      "Epoch 40: val_loss did not improve from 0.07941\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0427 - mean_squared_error: 0.0872 - val_loss: 0.0802 - val_mean_squared_error: 0.1616\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0417 - mean_squared_error: 0.0851\n",
      "Epoch 41: val_loss did not improve from 0.07941\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0417 - mean_squared_error: 0.0851 - val_loss: 0.0824 - val_mean_squared_error: 0.1661\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0414 - mean_squared_error: 0.0845\n",
      "Epoch 42: val_loss did not improve from 0.07941\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0414 - mean_squared_error: 0.0845 - val_loss: 0.0827 - val_mean_squared_error: 0.1666\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0404 - mean_squared_error: 0.0825\n",
      "Epoch 43: val_loss improved from 0.07941 to 0.07782, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0404 - mean_squared_error: 0.0825 - val_loss: 0.0778 - val_mean_squared_error: 0.1568\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0416 - mean_squared_error: 0.0848\n",
      "Epoch 44: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0416 - mean_squared_error: 0.0848 - val_loss: 0.0821 - val_mean_squared_error: 0.1656\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0406 - mean_squared_error: 0.0828\n",
      "Epoch 45: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0406 - mean_squared_error: 0.0828 - val_loss: 0.0851 - val_mean_squared_error: 0.1717\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0395 - mean_squared_error: 0.0808\n",
      "Epoch 46: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0395 - mean_squared_error: 0.0808 - val_loss: 0.0816 - val_mean_squared_error: 0.1644\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0396 - mean_squared_error: 0.0808\n",
      "Epoch 47: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0396 - mean_squared_error: 0.0808 - val_loss: 0.0848 - val_mean_squared_error: 0.1711\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.0789\n",
      "Epoch 48: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0386 - mean_squared_error: 0.0789 - val_loss: 0.0833 - val_mean_squared_error: 0.1680\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0784\n",
      "Epoch 49: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0384 - mean_squared_error: 0.0784 - val_loss: 0.0910 - val_mean_squared_error: 0.1837\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0375 - mean_squared_error: 0.0767\n",
      "Epoch 50: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0375 - mean_squared_error: 0.0767 - val_loss: 0.0850 - val_mean_squared_error: 0.1715\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0749\n",
      "Epoch 51: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0366 - mean_squared_error: 0.0749 - val_loss: 0.0842 - val_mean_squared_error: 0.1697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0370 - mean_squared_error: 0.0756\n",
      "Epoch 52: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0370 - mean_squared_error: 0.0756 - val_loss: 0.0838 - val_mean_squared_error: 0.1690\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0376 - mean_squared_error: 0.0768\n",
      "Epoch 53: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0376 - mean_squared_error: 0.0768 - val_loss: 0.0843 - val_mean_squared_error: 0.1697\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0748\n",
      "Epoch 54: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0366 - mean_squared_error: 0.0748 - val_loss: 0.0865 - val_mean_squared_error: 0.1743\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.0724\n",
      "Epoch 55: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0354 - mean_squared_error: 0.0724 - val_loss: 0.0796 - val_mean_squared_error: 0.1604\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0355 - mean_squared_error: 0.0726\n",
      "Epoch 56: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0355 - mean_squared_error: 0.0726 - val_loss: 0.0874 - val_mean_squared_error: 0.1765\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0360 - mean_squared_error: 0.0737\n",
      "Epoch 57: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0360 - mean_squared_error: 0.0737 - val_loss: 0.0866 - val_mean_squared_error: 0.1748\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0339 - mean_squared_error: 0.0695\n",
      "Epoch 58: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0339 - mean_squared_error: 0.0695 - val_loss: 0.0812 - val_mean_squared_error: 0.1636\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0332 - mean_squared_error: 0.0681\n",
      "Epoch 59: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0332 - mean_squared_error: 0.0681 - val_loss: 0.0815 - val_mean_squared_error: 0.1641\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0332 - mean_squared_error: 0.0681\n",
      "Epoch 60: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0332 - mean_squared_error: 0.0681 - val_loss: 0.0873 - val_mean_squared_error: 0.1762\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0335 - mean_squared_error: 0.0687\n",
      "Epoch 61: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0335 - mean_squared_error: 0.0687 - val_loss: 0.1008 - val_mean_squared_error: 0.2039\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0337 - mean_squared_error: 0.0692\n",
      "Epoch 62: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0337 - mean_squared_error: 0.0692 - val_loss: 0.0800 - val_mean_squared_error: 0.1609\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0662\n",
      "Epoch 63: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0323 - mean_squared_error: 0.0662 - val_loss: 0.0849 - val_mean_squared_error: 0.1711\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0664\n",
      "Epoch 64: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0323 - mean_squared_error: 0.0664 - val_loss: 0.0956 - val_mean_squared_error: 0.1932\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0315 - mean_squared_error: 0.0645\n",
      "Epoch 65: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0315 - mean_squared_error: 0.0645 - val_loss: 0.0880 - val_mean_squared_error: 0.1776\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0663\n",
      "Epoch 66: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0323 - mean_squared_error: 0.0663 - val_loss: 0.0810 - val_mean_squared_error: 0.1633\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0322 - mean_squared_error: 0.0658\n",
      "Epoch 67: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0322 - mean_squared_error: 0.0658 - val_loss: 0.0873 - val_mean_squared_error: 0.1762\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0320 - mean_squared_error: 0.0656\n",
      "Epoch 68: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0320 - mean_squared_error: 0.0656 - val_loss: 0.0909 - val_mean_squared_error: 0.1835\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0311 - mean_squared_error: 0.0638\n",
      "Epoch 69: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0311 - mean_squared_error: 0.0638 - val_loss: 0.0838 - val_mean_squared_error: 0.1688\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0300 - mean_squared_error: 0.0616\n",
      "Epoch 70: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0300 - mean_squared_error: 0.0616 - val_loss: 0.0862 - val_mean_squared_error: 0.1736\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0291 - mean_squared_error: 0.0599\n",
      "Epoch 71: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0291 - mean_squared_error: 0.0599 - val_loss: 0.0897 - val_mean_squared_error: 0.1808\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0293 - mean_squared_error: 0.0602\n",
      "Epoch 72: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0293 - mean_squared_error: 0.0602 - val_loss: 0.0881 - val_mean_squared_error: 0.1775\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0284 - mean_squared_error: 0.0585\n",
      "Epoch 73: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0284 - mean_squared_error: 0.0585 - val_loss: 0.0932 - val_mean_squared_error: 0.1879\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0287 - mean_squared_error: 0.0590\n",
      "Epoch 74: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0287 - mean_squared_error: 0.0590 - val_loss: 0.0888 - val_mean_squared_error: 0.1790\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0280 - mean_squared_error: 0.0576\n",
      "Epoch 75: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0280 - mean_squared_error: 0.0576 - val_loss: 0.0926 - val_mean_squared_error: 0.1867\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0279 - mean_squared_error: 0.0574\n",
      "Epoch 76: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0279 - mean_squared_error: 0.0574 - val_loss: 0.0896 - val_mean_squared_error: 0.1805\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0269 - mean_squared_error: 0.0553\n",
      "Epoch 77: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0269 - mean_squared_error: 0.0553 - val_loss: 0.0930 - val_mean_squared_error: 0.1872\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0283 - mean_squared_error: 0.0581\n",
      "Epoch 78: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0283 - mean_squared_error: 0.0581 - val_loss: 0.0938 - val_mean_squared_error: 0.1892\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0277 - mean_squared_error: 0.0570\n",
      "Epoch 79: val_loss did not improve from 0.07782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 31s 3s/step - loss: 0.0277 - mean_squared_error: 0.0570 - val_loss: 0.0863 - val_mean_squared_error: 0.1738\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0267 - mean_squared_error: 0.0550\n",
      "Epoch 80: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0267 - mean_squared_error: 0.0550 - val_loss: 0.0836 - val_mean_squared_error: 0.1682\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0258 - mean_squared_error: 0.0532\n",
      "Epoch 81: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0258 - mean_squared_error: 0.0532 - val_loss: 0.0919 - val_mean_squared_error: 0.1853\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0253 - mean_squared_error: 0.0522\n",
      "Epoch 82: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0253 - mean_squared_error: 0.0522 - val_loss: 0.0924 - val_mean_squared_error: 0.1863\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0502\n",
      "Epoch 83: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0243 - mean_squared_error: 0.0502 - val_loss: 0.0953 - val_mean_squared_error: 0.1922\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0246 - mean_squared_error: 0.0508\n",
      "Epoch 84: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0246 - mean_squared_error: 0.0508 - val_loss: 0.0852 - val_mean_squared_error: 0.1716\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0237 - mean_squared_error: 0.0491\n",
      "Epoch 85: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0237 - mean_squared_error: 0.0491 - val_loss: 0.0934 - val_mean_squared_error: 0.1882\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0238 - mean_squared_error: 0.0492\n",
      "Epoch 86: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0238 - mean_squared_error: 0.0492 - val_loss: 0.0931 - val_mean_squared_error: 0.1877\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0232 - mean_squared_error: 0.0480\n",
      "Epoch 87: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0232 - mean_squared_error: 0.0480 - val_loss: 0.0878 - val_mean_squared_error: 0.1767\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0230 - mean_squared_error: 0.0477\n",
      "Epoch 88: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0230 - mean_squared_error: 0.0477 - val_loss: 0.0896 - val_mean_squared_error: 0.1805\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0225 - mean_squared_error: 0.0466\n",
      "Epoch 89: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0225 - mean_squared_error: 0.0466 - val_loss: 0.0964 - val_mean_squared_error: 0.1944\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0222 - mean_squared_error: 0.0461\n",
      "Epoch 90: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0222 - mean_squared_error: 0.0461 - val_loss: 0.0920 - val_mean_squared_error: 0.1854\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0216 - mean_squared_error: 0.0448\n",
      "Epoch 91: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0216 - mean_squared_error: 0.0448 - val_loss: 0.0972 - val_mean_squared_error: 0.1958\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0218 - mean_squared_error: 0.0452\n",
      "Epoch 92: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0218 - mean_squared_error: 0.0452 - val_loss: 0.0973 - val_mean_squared_error: 0.1962\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0218 - mean_squared_error: 0.0452\n",
      "Epoch 93: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0218 - mean_squared_error: 0.0452 - val_loss: 0.0950 - val_mean_squared_error: 0.1915\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0212 - mean_squared_error: 0.0441\n",
      "Epoch 94: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0212 - mean_squared_error: 0.0441 - val_loss: 0.0884 - val_mean_squared_error: 0.1779\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0211 - mean_squared_error: 0.0438\n",
      "Epoch 95: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0211 - mean_squared_error: 0.0438 - val_loss: 0.0952 - val_mean_squared_error: 0.1920\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0212 - mean_squared_error: 0.0441\n",
      "Epoch 96: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0212 - mean_squared_error: 0.0441 - val_loss: 0.0987 - val_mean_squared_error: 0.1992\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0204 - mean_squared_error: 0.0424\n",
      "Epoch 97: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0204 - mean_squared_error: 0.0424 - val_loss: 0.0953 - val_mean_squared_error: 0.1922\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0196 - mean_squared_error: 0.0409\n",
      "Epoch 98: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0196 - mean_squared_error: 0.0409 - val_loss: 0.0911 - val_mean_squared_error: 0.1836\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0194 - mean_squared_error: 0.0403\n",
      "Epoch 99: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0194 - mean_squared_error: 0.0403 - val_loss: 0.0916 - val_mean_squared_error: 0.1846\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.0399\n",
      "Epoch 100: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0192 - mean_squared_error: 0.0399 - val_loss: 0.0949 - val_mean_squared_error: 0.1913\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0190 - mean_squared_error: 0.0397\n",
      "Epoch 101: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0190 - mean_squared_error: 0.0397 - val_loss: 0.0943 - val_mean_squared_error: 0.1900\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0190 - mean_squared_error: 0.0396\n",
      "Epoch 102: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0190 - mean_squared_error: 0.0396 - val_loss: 0.0944 - val_mean_squared_error: 0.1904\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0184 - mean_squared_error: 0.0384\n",
      "Epoch 103: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0184 - mean_squared_error: 0.0384 - val_loss: 0.0980 - val_mean_squared_error: 0.1977\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0378\n",
      "Epoch 104: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0181 - mean_squared_error: 0.0378 - val_loss: 0.0951 - val_mean_squared_error: 0.1918\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0179 - mean_squared_error: 0.0374\n",
      "Epoch 105: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0179 - mean_squared_error: 0.0374 - val_loss: 0.0952 - val_mean_squared_error: 0.1919\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0367\n",
      "Epoch 106: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0175 - mean_squared_error: 0.0367 - val_loss: 0.0973 - val_mean_squared_error: 0.1961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0360\n",
      "Epoch 107: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0172 - mean_squared_error: 0.0360 - val_loss: 0.0941 - val_mean_squared_error: 0.1897\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0354\n",
      "Epoch 108: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0168 - mean_squared_error: 0.0354 - val_loss: 0.0974 - val_mean_squared_error: 0.1966\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0352\n",
      "Epoch 109: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0168 - mean_squared_error: 0.0352 - val_loss: 0.0947 - val_mean_squared_error: 0.1909\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0346\n",
      "Epoch 110: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0165 - mean_squared_error: 0.0346 - val_loss: 0.1005 - val_mean_squared_error: 0.2029\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0346\n",
      "Epoch 111: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0165 - mean_squared_error: 0.0346 - val_loss: 0.0937 - val_mean_squared_error: 0.1888\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0343\n",
      "Epoch 112: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0163 - mean_squared_error: 0.0343 - val_loss: 0.0976 - val_mean_squared_error: 0.1970\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0158 - mean_squared_error: 0.0333\n",
      "Epoch 113: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0158 - mean_squared_error: 0.0333 - val_loss: 0.0982 - val_mean_squared_error: 0.1979\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0335\n",
      "Epoch 114: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0159 - mean_squared_error: 0.0335 - val_loss: 0.1004 - val_mean_squared_error: 0.2028\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0342\n",
      "Epoch 115: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0163 - mean_squared_error: 0.0342 - val_loss: 0.0979 - val_mean_squared_error: 0.1975\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0331\n",
      "Epoch 116: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0157 - mean_squared_error: 0.0331 - val_loss: 0.0995 - val_mean_squared_error: 0.2009\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0331\n",
      "Epoch 117: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0157 - mean_squared_error: 0.0331 - val_loss: 0.0970 - val_mean_squared_error: 0.1957\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.0317\n",
      "Epoch 118: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0150 - mean_squared_error: 0.0317 - val_loss: 0.0963 - val_mean_squared_error: 0.1943\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0319\n",
      "Epoch 119: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0151 - mean_squared_error: 0.0319 - val_loss: 0.0971 - val_mean_squared_error: 0.1958\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0309\n",
      "Epoch 120: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0146 - mean_squared_error: 0.0309 - val_loss: 0.0972 - val_mean_squared_error: 0.1962\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0314\n",
      "Epoch 121: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0149 - mean_squared_error: 0.0314 - val_loss: 0.1000 - val_mean_squared_error: 0.2021\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0310\n",
      "Epoch 122: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0146 - mean_squared_error: 0.0310 - val_loss: 0.0969 - val_mean_squared_error: 0.1954\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0306\n",
      "Epoch 123: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0145 - mean_squared_error: 0.0306 - val_loss: 0.0967 - val_mean_squared_error: 0.1950\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0309\n",
      "Epoch 124: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0146 - mean_squared_error: 0.0309 - val_loss: 0.0974 - val_mean_squared_error: 0.1964\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0307\n",
      "Epoch 125: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0145 - mean_squared_error: 0.0307 - val_loss: 0.1001 - val_mean_squared_error: 0.2021\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0309\n",
      "Epoch 126: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0146 - mean_squared_error: 0.0309 - val_loss: 0.0982 - val_mean_squared_error: 0.1981\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0296\n",
      "Epoch 127: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0140 - mean_squared_error: 0.0296 - val_loss: 0.0993 - val_mean_squared_error: 0.2006\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0295\n",
      "Epoch 128: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0139 - mean_squared_error: 0.0295 - val_loss: 0.1006 - val_mean_squared_error: 0.2035\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0293\n",
      "Epoch 129: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0138 - mean_squared_error: 0.0293 - val_loss: 0.1006 - val_mean_squared_error: 0.2027\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0296\n",
      "Epoch 130: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0139 - mean_squared_error: 0.0296 - val_loss: 0.0999 - val_mean_squared_error: 0.2021\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0296\n",
      "Epoch 131: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0139 - mean_squared_error: 0.0296 - val_loss: 0.1023 - val_mean_squared_error: 0.2071\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0288\n",
      "Epoch 132: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0136 - mean_squared_error: 0.0288 - val_loss: 0.1028 - val_mean_squared_error: 0.2078\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0283\n",
      "Epoch 133: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0133 - mean_squared_error: 0.0283 - val_loss: 0.0995 - val_mean_squared_error: 0.2008\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0276\n",
      "Epoch 134: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0129 - mean_squared_error: 0.0276 - val_loss: 0.1008 - val_mean_squared_error: 0.2034\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0268\n",
      "Epoch 135: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 29s 3s/step - loss: 0.0125 - mean_squared_error: 0.0268 - val_loss: 0.1016 - val_mean_squared_error: 0.2056\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0267\n",
      "Epoch 136: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0125 - mean_squared_error: 0.0267 - val_loss: 0.1023 - val_mean_squared_error: 0.2070\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0266\n",
      "Epoch 137: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0124 - mean_squared_error: 0.0266 - val_loss: 0.1022 - val_mean_squared_error: 0.2065\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0266\n",
      "Epoch 138: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0124 - mean_squared_error: 0.0266 - val_loss: 0.1003 - val_mean_squared_error: 0.2027\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0259\n",
      "Epoch 139: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0121 - mean_squared_error: 0.0259 - val_loss: 0.1014 - val_mean_squared_error: 0.2050\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0254\n",
      "Epoch 140: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0119 - mean_squared_error: 0.0254 - val_loss: 0.0999 - val_mean_squared_error: 0.2020\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0256\n",
      "Epoch 141: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0119 - mean_squared_error: 0.0256 - val_loss: 0.1061 - val_mean_squared_error: 0.2147\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0259\n",
      "Epoch 142: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0121 - mean_squared_error: 0.0259 - val_loss: 0.1026 - val_mean_squared_error: 0.2075\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0251\n",
      "Epoch 143: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0117 - mean_squared_error: 0.0251 - val_loss: 0.1045 - val_mean_squared_error: 0.2116\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0115 - mean_squared_error: 0.0247\n",
      "Epoch 144: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0115 - mean_squared_error: 0.0247 - val_loss: 0.1029 - val_mean_squared_error: 0.2083\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0244\n",
      "Epoch 145: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0113 - mean_squared_error: 0.0244 - val_loss: 0.1004 - val_mean_squared_error: 0.2032\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0240\n",
      "Epoch 146: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0111 - mean_squared_error: 0.0240 - val_loss: 0.1026 - val_mean_squared_error: 0.2077\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0240\n",
      "Epoch 147: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0111 - mean_squared_error: 0.0240 - val_loss: 0.1035 - val_mean_squared_error: 0.2095\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0241\n",
      "Epoch 148: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0112 - mean_squared_error: 0.0241 - val_loss: 0.1070 - val_mean_squared_error: 0.2168\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0236\n",
      "Epoch 149: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0109 - mean_squared_error: 0.0236 - val_loss: 0.1017 - val_mean_squared_error: 0.2057\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0232\n",
      "Epoch 150: val_loss did not improve from 0.07782\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.0107 - mean_squared_error: 0.0232 - val_loss: 0.1045 - val_mean_squared_error: 0.2114\n",
      "5/5 [==============================] - 11s 352ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  336\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3815 - mean_squared_error: 0.8606\n",
      "Epoch 1: val_loss improved from inf to 0.28073, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 91s 5s/step - loss: 0.3815 - mean_squared_error: 0.8606 - val_loss: 0.2807 - val_mean_squared_error: 0.6120\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2143 - mean_squared_error: 0.4517\n",
      "Epoch 2: val_loss improved from 0.28073 to 0.15056, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.2143 - mean_squared_error: 0.4517 - val_loss: 0.1506 - val_mean_squared_error: 0.3082\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1198 - mean_squared_error: 0.2448\n",
      "Epoch 3: val_loss improved from 0.15056 to 0.13393, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.1198 - mean_squared_error: 0.2448 - val_loss: 0.1339 - val_mean_squared_error: 0.2734\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.2122\n",
      "Epoch 4: val_loss improved from 0.13393 to 0.12410, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.1040 - mean_squared_error: 0.2122 - val_loss: 0.1241 - val_mean_squared_error: 0.2536\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0959 - mean_squared_error: 0.1956\n",
      "Epoch 5: val_loss improved from 0.12410 to 0.11888, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0959 - mean_squared_error: 0.1956 - val_loss: 0.1189 - val_mean_squared_error: 0.2424\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0921 - mean_squared_error: 0.1886\n",
      "Epoch 6: val_loss did not improve from 0.11888\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0921 - mean_squared_error: 0.1886 - val_loss: 0.1193 - val_mean_squared_error: 0.2439\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0881 - mean_squared_error: 0.1803\n",
      "Epoch 7: val_loss did not improve from 0.11888\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0881 - mean_squared_error: 0.1803 - val_loss: 0.1217 - val_mean_squared_error: 0.2487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0865 - mean_squared_error: 0.1766\n",
      "Epoch 8: val_loss improved from 0.11888 to 0.11778, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0865 - mean_squared_error: 0.1766 - val_loss: 0.1178 - val_mean_squared_error: 0.2412\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0840 - mean_squared_error: 0.1722\n",
      "Epoch 9: val_loss improved from 0.11778 to 0.11539, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0840 - mean_squared_error: 0.1722 - val_loss: 0.1154 - val_mean_squared_error: 0.2355\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0831 - mean_squared_error: 0.1700\n",
      "Epoch 10: val_loss did not improve from 0.11539\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0831 - mean_squared_error: 0.1700 - val_loss: 0.1210 - val_mean_squared_error: 0.2480\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0818 - mean_squared_error: 0.1676\n",
      "Epoch 11: val_loss improved from 0.11539 to 0.11506, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0818 - mean_squared_error: 0.1676 - val_loss: 0.1151 - val_mean_squared_error: 0.2353\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0816 - mean_squared_error: 0.1669\n",
      "Epoch 12: val_loss did not improve from 0.11506\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0816 - mean_squared_error: 0.1669 - val_loss: 0.1183 - val_mean_squared_error: 0.2420\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0794 - mean_squared_error: 0.1624\n",
      "Epoch 13: val_loss improved from 0.11506 to 0.11084, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0794 - mean_squared_error: 0.1624 - val_loss: 0.1108 - val_mean_squared_error: 0.2267\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0781 - mean_squared_error: 0.1597\n",
      "Epoch 14: val_loss improved from 0.11084 to 0.10775, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0781 - mean_squared_error: 0.1597 - val_loss: 0.1078 - val_mean_squared_error: 0.2192\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0759 - mean_squared_error: 0.1553\n",
      "Epoch 15: val_loss did not improve from 0.10775\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0759 - mean_squared_error: 0.1553 - val_loss: 0.1108 - val_mean_squared_error: 0.2258\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0741 - mean_squared_error: 0.1516\n",
      "Epoch 16: val_loss did not improve from 0.10775\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0741 - mean_squared_error: 0.1516 - val_loss: 0.1246 - val_mean_squared_error: 0.2549\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0739 - mean_squared_error: 0.1510\n",
      "Epoch 17: val_loss did not improve from 0.10775\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0739 - mean_squared_error: 0.1510 - val_loss: 0.1154 - val_mean_squared_error: 0.2353\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0720 - mean_squared_error: 0.1467\n",
      "Epoch 18: val_loss did not improve from 0.10775\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0720 - mean_squared_error: 0.1467 - val_loss: 0.1106 - val_mean_squared_error: 0.2255\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0719 - mean_squared_error: 0.1467\n",
      "Epoch 19: val_loss did not improve from 0.10775\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0719 - mean_squared_error: 0.1467 - val_loss: 0.1100 - val_mean_squared_error: 0.2231\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0727 - mean_squared_error: 0.1486\n",
      "Epoch 20: val_loss did not improve from 0.10775\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0727 - mean_squared_error: 0.1486 - val_loss: 0.1135 - val_mean_squared_error: 0.2308\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0706 - mean_squared_error: 0.1441\n",
      "Epoch 21: val_loss improved from 0.10775 to 0.09607, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0706 - mean_squared_error: 0.1441 - val_loss: 0.0961 - val_mean_squared_error: 0.1951\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0677 - mean_squared_error: 0.1378\n",
      "Epoch 22: val_loss improved from 0.09607 to 0.09246, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0677 - mean_squared_error: 0.1378 - val_loss: 0.0925 - val_mean_squared_error: 0.1875\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0628 - mean_squared_error: 0.1282\n",
      "Epoch 23: val_loss improved from 0.09246 to 0.09113, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0628 - mean_squared_error: 0.1282 - val_loss: 0.0911 - val_mean_squared_error: 0.1846\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0602 - mean_squared_error: 0.1228\n",
      "Epoch 24: val_loss improved from 0.09113 to 0.08887, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0602 - mean_squared_error: 0.1228 - val_loss: 0.0889 - val_mean_squared_error: 0.1804\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0598 - mean_squared_error: 0.1218\n",
      "Epoch 25: val_loss improved from 0.08887 to 0.08417, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0598 - mean_squared_error: 0.1218 - val_loss: 0.0842 - val_mean_squared_error: 0.1704\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0605 - mean_squared_error: 0.1233\n",
      "Epoch 26: val_loss did not improve from 0.08417\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0605 - mean_squared_error: 0.1233 - val_loss: 0.0911 - val_mean_squared_error: 0.1846\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0553 - mean_squared_error: 0.1126\n",
      "Epoch 27: val_loss did not improve from 0.08417\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0553 - mean_squared_error: 0.1126 - val_loss: 0.0883 - val_mean_squared_error: 0.1795\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0541 - mean_squared_error: 0.1102\n",
      "Epoch 28: val_loss did not improve from 0.08417\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0541 - mean_squared_error: 0.1102 - val_loss: 0.0847 - val_mean_squared_error: 0.1717\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0532 - mean_squared_error: 0.1085\n",
      "Epoch 29: val_loss did not improve from 0.08417\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0532 - mean_squared_error: 0.1085 - val_loss: 0.0854 - val_mean_squared_error: 0.1725\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0544 - mean_squared_error: 0.1108\n",
      "Epoch 30: val_loss did not improve from 0.08417\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0544 - mean_squared_error: 0.1108 - val_loss: 0.0950 - val_mean_squared_error: 0.1927\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0529 - mean_squared_error: 0.1078\n",
      "Epoch 31: val_loss did not improve from 0.08417\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0529 - mean_squared_error: 0.1078 - val_loss: 0.0884 - val_mean_squared_error: 0.1787\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0513 - mean_squared_error: 0.1045\n",
      "Epoch 32: val_loss did not improve from 0.08417\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0513 - mean_squared_error: 0.1045 - val_loss: 0.0967 - val_mean_squared_error: 0.1968\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0496 - mean_squared_error: 0.1010\n",
      "Epoch 33: val_loss improved from 0.08417 to 0.08326, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0496 - mean_squared_error: 0.1010 - val_loss: 0.0833 - val_mean_squared_error: 0.1681\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0483 - mean_squared_error: 0.0985\n",
      "Epoch 34: val_loss did not improve from 0.08326\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0483 - mean_squared_error: 0.0985 - val_loss: 0.0836 - val_mean_squared_error: 0.1689\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0477 - mean_squared_error: 0.0974\n",
      "Epoch 35: val_loss did not improve from 0.08326\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0477 - mean_squared_error: 0.0974 - val_loss: 0.0848 - val_mean_squared_error: 0.1712\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0470 - mean_squared_error: 0.0959\n",
      "Epoch 36: val_loss did not improve from 0.08326\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0470 - mean_squared_error: 0.0959 - val_loss: 0.0849 - val_mean_squared_error: 0.1714\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0459 - mean_squared_error: 0.0936\n",
      "Epoch 37: val_loss did not improve from 0.08326\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0459 - mean_squared_error: 0.0936 - val_loss: 0.1010 - val_mean_squared_error: 0.2064\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.0918\n",
      "Epoch 38: val_loss did not improve from 0.08326\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0450 - mean_squared_error: 0.0918 - val_loss: 0.0910 - val_mean_squared_error: 0.1845\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0434 - mean_squared_error: 0.0886\n",
      "Epoch 39: val_loss did not improve from 0.08326\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0434 - mean_squared_error: 0.0886 - val_loss: 0.0901 - val_mean_squared_error: 0.1824\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0428 - mean_squared_error: 0.0873\n",
      "Epoch 40: val_loss did not improve from 0.08326\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0428 - mean_squared_error: 0.0873 - val_loss: 0.0843 - val_mean_squared_error: 0.1701\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0422 - mean_squared_error: 0.0864\n",
      "Epoch 41: val_loss improved from 0.08326 to 0.08132, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0422 - mean_squared_error: 0.0864 - val_loss: 0.0813 - val_mean_squared_error: 0.1640\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0416 - mean_squared_error: 0.0851\n",
      "Epoch 42: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0416 - mean_squared_error: 0.0851 - val_loss: 0.0904 - val_mean_squared_error: 0.1831\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0415 - mean_squared_error: 0.0848\n",
      "Epoch 43: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0415 - mean_squared_error: 0.0848 - val_loss: 0.0832 - val_mean_squared_error: 0.1683\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0828\n",
      "Epoch 44: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0405 - mean_squared_error: 0.0828 - val_loss: 0.0919 - val_mean_squared_error: 0.1863\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0396 - mean_squared_error: 0.0809\n",
      "Epoch 45: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0396 - mean_squared_error: 0.0809 - val_loss: 0.0828 - val_mean_squared_error: 0.1672\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0400 - mean_squared_error: 0.0819\n",
      "Epoch 46: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0400 - mean_squared_error: 0.0819 - val_loss: 0.0870 - val_mean_squared_error: 0.1756\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0399 - mean_squared_error: 0.0816\n",
      "Epoch 47: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0399 - mean_squared_error: 0.0816 - val_loss: 0.0840 - val_mean_squared_error: 0.1697\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0796\n",
      "Epoch 48: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0389 - mean_squared_error: 0.0796 - val_loss: 0.0926 - val_mean_squared_error: 0.1875\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0387 - mean_squared_error: 0.0793\n",
      "Epoch 49: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0387 - mean_squared_error: 0.0793 - val_loss: 0.0895 - val_mean_squared_error: 0.1804\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0375 - mean_squared_error: 0.0768\n",
      "Epoch 50: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0375 - mean_squared_error: 0.0768 - val_loss: 0.0926 - val_mean_squared_error: 0.1870\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0374 - mean_squared_error: 0.0766\n",
      "Epoch 51: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0374 - mean_squared_error: 0.0766 - val_loss: 0.0859 - val_mean_squared_error: 0.1730\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0358 - mean_squared_error: 0.0734\n",
      "Epoch 52: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0358 - mean_squared_error: 0.0734 - val_loss: 0.0848 - val_mean_squared_error: 0.1708\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0359 - mean_squared_error: 0.0736\n",
      "Epoch 53: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0359 - mean_squared_error: 0.0736 - val_loss: 0.0853 - val_mean_squared_error: 0.1722\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0350 - mean_squared_error: 0.0718\n",
      "Epoch 54: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0350 - mean_squared_error: 0.0718 - val_loss: 0.0870 - val_mean_squared_error: 0.1750\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0344 - mean_squared_error: 0.0706\n",
      "Epoch 55: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0344 - mean_squared_error: 0.0706 - val_loss: 0.0882 - val_mean_squared_error: 0.1777\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0337 - mean_squared_error: 0.0693\n",
      "Epoch 56: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0337 - mean_squared_error: 0.0693 - val_loss: 0.0973 - val_mean_squared_error: 0.1970\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0332 - mean_squared_error: 0.0681\n",
      "Epoch 57: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0332 - mean_squared_error: 0.0681 - val_loss: 0.0960 - val_mean_squared_error: 0.1938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0337 - mean_squared_error: 0.0691\n",
      "Epoch 58: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0337 - mean_squared_error: 0.0691 - val_loss: 0.0949 - val_mean_squared_error: 0.1914\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0328 - mean_squared_error: 0.0673\n",
      "Epoch 59: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0328 - mean_squared_error: 0.0673 - val_loss: 0.1018 - val_mean_squared_error: 0.2067\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0335 - mean_squared_error: 0.0687\n",
      "Epoch 60: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0335 - mean_squared_error: 0.0687 - val_loss: 0.0997 - val_mean_squared_error: 0.2021\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0332 - mean_squared_error: 0.0681\n",
      "Epoch 61: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0332 - mean_squared_error: 0.0681 - val_loss: 0.0917 - val_mean_squared_error: 0.1854\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0314 - mean_squared_error: 0.0644\n",
      "Epoch 62: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0314 - mean_squared_error: 0.0644 - val_loss: 0.0903 - val_mean_squared_error: 0.1825\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0312 - mean_squared_error: 0.0642\n",
      "Epoch 63: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0312 - mean_squared_error: 0.0642 - val_loss: 0.0866 - val_mean_squared_error: 0.1748\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0316 - mean_squared_error: 0.0651\n",
      "Epoch 64: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0316 - mean_squared_error: 0.0651 - val_loss: 0.0822 - val_mean_squared_error: 0.1658\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0318 - mean_squared_error: 0.0653\n",
      "Epoch 65: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0318 - mean_squared_error: 0.0653 - val_loss: 0.0886 - val_mean_squared_error: 0.1788\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0308 - mean_squared_error: 0.0633\n",
      "Epoch 66: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0308 - mean_squared_error: 0.0633 - val_loss: 0.1006 - val_mean_squared_error: 0.2030\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0304 - mean_squared_error: 0.0624\n",
      "Epoch 67: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0304 - mean_squared_error: 0.0624 - val_loss: 0.0899 - val_mean_squared_error: 0.1817\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0288 - mean_squared_error: 0.0592\n",
      "Epoch 68: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0288 - mean_squared_error: 0.0592 - val_loss: 0.0923 - val_mean_squared_error: 0.1864\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0281 - mean_squared_error: 0.0580\n",
      "Epoch 69: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0281 - mean_squared_error: 0.0580 - val_loss: 0.0913 - val_mean_squared_error: 0.1840\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0272 - mean_squared_error: 0.0560\n",
      "Epoch 70: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0272 - mean_squared_error: 0.0560 - val_loss: 0.0943 - val_mean_squared_error: 0.1904\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0275 - mean_squared_error: 0.0566\n",
      "Epoch 71: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0275 - mean_squared_error: 0.0566 - val_loss: 0.0989 - val_mean_squared_error: 0.2005\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0279 - mean_squared_error: 0.0575\n",
      "Epoch 72: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0279 - mean_squared_error: 0.0575 - val_loss: 0.0950 - val_mean_squared_error: 0.1921\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0274 - mean_squared_error: 0.0564\n",
      "Epoch 73: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0274 - mean_squared_error: 0.0564 - val_loss: 0.0928 - val_mean_squared_error: 0.1878\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0252 - mean_squared_error: 0.0522\n",
      "Epoch 74: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0252 - mean_squared_error: 0.0522 - val_loss: 0.0903 - val_mean_squared_error: 0.1827\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0255 - mean_squared_error: 0.0528\n",
      "Epoch 75: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0255 - mean_squared_error: 0.0528 - val_loss: 0.0961 - val_mean_squared_error: 0.1947\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0518\n",
      "Epoch 76: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0251 - mean_squared_error: 0.0518 - val_loss: 0.0926 - val_mean_squared_error: 0.1873\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0252 - mean_squared_error: 0.0521\n",
      "Epoch 77: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0252 - mean_squared_error: 0.0521 - val_loss: 0.0917 - val_mean_squared_error: 0.1852\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0260 - mean_squared_error: 0.0538\n",
      "Epoch 78: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0260 - mean_squared_error: 0.0538 - val_loss: 0.1032 - val_mean_squared_error: 0.2094\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0244 - mean_squared_error: 0.0504\n",
      "Epoch 79: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0244 - mean_squared_error: 0.0504 - val_loss: 0.0994 - val_mean_squared_error: 0.2010\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0233 - mean_squared_error: 0.0483\n",
      "Epoch 80: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0233 - mean_squared_error: 0.0483 - val_loss: 0.0984 - val_mean_squared_error: 0.1989\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0225 - mean_squared_error: 0.0467\n",
      "Epoch 81: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0225 - mean_squared_error: 0.0467 - val_loss: 0.0958 - val_mean_squared_error: 0.1939\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0464\n",
      "Epoch 82: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0224 - mean_squared_error: 0.0464 - val_loss: 0.1019 - val_mean_squared_error: 0.2070\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0219 - mean_squared_error: 0.0454\n",
      "Epoch 83: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0219 - mean_squared_error: 0.0454 - val_loss: 0.0979 - val_mean_squared_error: 0.1977\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0217 - mean_squared_error: 0.0452\n",
      "Epoch 84: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0217 - mean_squared_error: 0.0452 - val_loss: 0.0969 - val_mean_squared_error: 0.1965\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0212 - mean_squared_error: 0.0440\n",
      "Epoch 85: val_loss did not improve from 0.08132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 32s 4s/step - loss: 0.0212 - mean_squared_error: 0.0440 - val_loss: 0.0996 - val_mean_squared_error: 0.2017\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0210 - mean_squared_error: 0.0436\n",
      "Epoch 86: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0210 - mean_squared_error: 0.0436 - val_loss: 0.0953 - val_mean_squared_error: 0.1924\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0419\n",
      "Epoch 87: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0202 - mean_squared_error: 0.0419 - val_loss: 0.0927 - val_mean_squared_error: 0.1876\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0203 - mean_squared_error: 0.0422\n",
      "Epoch 88: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0203 - mean_squared_error: 0.0422 - val_loss: 0.1009 - val_mean_squared_error: 0.2044\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0421\n",
      "Epoch 89: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0202 - mean_squared_error: 0.0421 - val_loss: 0.1069 - val_mean_squared_error: 0.2166\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0201 - mean_squared_error: 0.0418\n",
      "Epoch 90: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0201 - mean_squared_error: 0.0418 - val_loss: 0.1014 - val_mean_squared_error: 0.2052\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0197 - mean_squared_error: 0.0410\n",
      "Epoch 91: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0197 - mean_squared_error: 0.0410 - val_loss: 0.1050 - val_mean_squared_error: 0.2129\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.0401\n",
      "Epoch 92: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0192 - mean_squared_error: 0.0401 - val_loss: 0.0988 - val_mean_squared_error: 0.1998\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0403\n",
      "Epoch 93: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0193 - mean_squared_error: 0.0403 - val_loss: 0.1049 - val_mean_squared_error: 0.2127\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0186 - mean_squared_error: 0.0387\n",
      "Epoch 94: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0186 - mean_squared_error: 0.0387 - val_loss: 0.0980 - val_mean_squared_error: 0.1987\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0387\n",
      "Epoch 95: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0185 - mean_squared_error: 0.0387 - val_loss: 0.1032 - val_mean_squared_error: 0.2088\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.0391\n",
      "Epoch 96: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0188 - mean_squared_error: 0.0391 - val_loss: 0.1020 - val_mean_squared_error: 0.2067\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.0392\n",
      "Epoch 97: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0188 - mean_squared_error: 0.0392 - val_loss: 0.1074 - val_mean_squared_error: 0.2174\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0387\n",
      "Epoch 98: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0185 - mean_squared_error: 0.0387 - val_loss: 0.0939 - val_mean_squared_error: 0.1900\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0183 - mean_squared_error: 0.0382\n",
      "Epoch 99: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0183 - mean_squared_error: 0.0382 - val_loss: 0.0988 - val_mean_squared_error: 0.2003\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0180 - mean_squared_error: 0.0376\n",
      "Epoch 100: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0180 - mean_squared_error: 0.0376 - val_loss: 0.1022 - val_mean_squared_error: 0.2067\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0365\n",
      "Epoch 101: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0175 - mean_squared_error: 0.0365 - val_loss: 0.0971 - val_mean_squared_error: 0.1964\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0346\n",
      "Epoch 102: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0165 - mean_squared_error: 0.0346 - val_loss: 0.1015 - val_mean_squared_error: 0.2056\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0346\n",
      "Epoch 103: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0164 - mean_squared_error: 0.0346 - val_loss: 0.1027 - val_mean_squared_error: 0.2079\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0341\n",
      "Epoch 104: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0163 - mean_squared_error: 0.0341 - val_loss: 0.1008 - val_mean_squared_error: 0.2038\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0331\n",
      "Epoch 105: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0157 - mean_squared_error: 0.0331 - val_loss: 0.1023 - val_mean_squared_error: 0.2074\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0333\n",
      "Epoch 106: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0159 - mean_squared_error: 0.0333 - val_loss: 0.0995 - val_mean_squared_error: 0.2024\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0342\n",
      "Epoch 107: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0163 - mean_squared_error: 0.0342 - val_loss: 0.1077 - val_mean_squared_error: 0.2179\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0331\n",
      "Epoch 108: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0157 - mean_squared_error: 0.0331 - val_loss: 0.1043 - val_mean_squared_error: 0.2117\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0156 - mean_squared_error: 0.0328\n",
      "Epoch 109: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0156 - mean_squared_error: 0.0328 - val_loss: 0.1042 - val_mean_squared_error: 0.2114\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0327\n",
      "Epoch 110: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0155 - mean_squared_error: 0.0327 - val_loss: 0.1049 - val_mean_squared_error: 0.2129\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0324\n",
      "Epoch 111: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0154 - mean_squared_error: 0.0324 - val_loss: 0.1060 - val_mean_squared_error: 0.2145\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0318\n",
      "Epoch 112: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0151 - mean_squared_error: 0.0318 - val_loss: 0.1025 - val_mean_squared_error: 0.2080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0320\n",
      "Epoch 113: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0152 - mean_squared_error: 0.0320 - val_loss: 0.1050 - val_mean_squared_error: 0.2126\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.0318\n",
      "Epoch 114: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0150 - mean_squared_error: 0.0318 - val_loss: 0.1029 - val_mean_squared_error: 0.2085\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0309\n",
      "Epoch 115: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0146 - mean_squared_error: 0.0309 - val_loss: 0.1030 - val_mean_squared_error: 0.2084\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0303\n",
      "Epoch 116: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0143 - mean_squared_error: 0.0303 - val_loss: 0.1030 - val_mean_squared_error: 0.2090\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0302\n",
      "Epoch 117: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0143 - mean_squared_error: 0.0302 - val_loss: 0.1044 - val_mean_squared_error: 0.2116\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0293\n",
      "Epoch 118: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0138 - mean_squared_error: 0.0293 - val_loss: 0.1028 - val_mean_squared_error: 0.2083\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0287\n",
      "Epoch 119: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0135 - mean_squared_error: 0.0287 - val_loss: 0.1059 - val_mean_squared_error: 0.2146\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0281\n",
      "Epoch 120: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0132 - mean_squared_error: 0.0281 - val_loss: 0.1063 - val_mean_squared_error: 0.2152\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0279\n",
      "Epoch 121: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0131 - mean_squared_error: 0.0279 - val_loss: 0.1080 - val_mean_squared_error: 0.2192\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0281\n",
      "Epoch 122: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0132 - mean_squared_error: 0.0281 - val_loss: 0.1003 - val_mean_squared_error: 0.2031\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0284\n",
      "Epoch 123: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0134 - mean_squared_error: 0.0284 - val_loss: 0.1087 - val_mean_squared_error: 0.2203\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0279\n",
      "Epoch 124: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0131 - mean_squared_error: 0.0279 - val_loss: 0.1065 - val_mean_squared_error: 0.2159\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0273\n",
      "Epoch 125: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0128 - mean_squared_error: 0.0273 - val_loss: 0.1070 - val_mean_squared_error: 0.2171\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0274\n",
      "Epoch 126: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0129 - mean_squared_error: 0.0274 - val_loss: 0.1029 - val_mean_squared_error: 0.2084\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0265\n",
      "Epoch 127: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0124 - mean_squared_error: 0.0265 - val_loss: 0.1049 - val_mean_squared_error: 0.2128\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0269\n",
      "Epoch 128: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0126 - mean_squared_error: 0.0269 - val_loss: 0.1040 - val_mean_squared_error: 0.2108\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0266\n",
      "Epoch 129: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0125 - mean_squared_error: 0.0266 - val_loss: 0.1094 - val_mean_squared_error: 0.2218\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0263\n",
      "Epoch 130: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0123 - mean_squared_error: 0.0263 - val_loss: 0.1049 - val_mean_squared_error: 0.2127\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0254\n",
      "Epoch 131: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0119 - mean_squared_error: 0.0254 - val_loss: 0.1059 - val_mean_squared_error: 0.2145\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0255\n",
      "Epoch 132: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0119 - mean_squared_error: 0.0255 - val_loss: 0.1033 - val_mean_squared_error: 0.2093\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0249\n",
      "Epoch 133: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0116 - mean_squared_error: 0.0249 - val_loss: 0.1070 - val_mean_squared_error: 0.2168\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0115 - mean_squared_error: 0.0247\n",
      "Epoch 134: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0115 - mean_squared_error: 0.0247 - val_loss: 0.1089 - val_mean_squared_error: 0.2213\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0115 - mean_squared_error: 0.0247\n",
      "Epoch 135: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0115 - mean_squared_error: 0.0247 - val_loss: 0.1045 - val_mean_squared_error: 0.2119\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0243\n",
      "Epoch 136: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0113 - mean_squared_error: 0.0243 - val_loss: 0.1081 - val_mean_squared_error: 0.2195\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0240\n",
      "Epoch 137: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0111 - mean_squared_error: 0.0240 - val_loss: 0.1101 - val_mean_squared_error: 0.2233\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0235\n",
      "Epoch 138: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0109 - mean_squared_error: 0.0235 - val_loss: 0.1069 - val_mean_squared_error: 0.2171\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0235\n",
      "Epoch 139: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0109 - mean_squared_error: 0.0235 - val_loss: 0.1101 - val_mean_squared_error: 0.2231\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0234\n",
      "Epoch 140: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0109 - mean_squared_error: 0.0234 - val_loss: 0.1070 - val_mean_squared_error: 0.2171\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0233\n",
      "Epoch 141: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0108 - mean_squared_error: 0.0233 - val_loss: 0.1114 - val_mean_squared_error: 0.2261\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0231\n",
      "Epoch 142: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0107 - mean_squared_error: 0.0231 - val_loss: 0.1086 - val_mean_squared_error: 0.2205\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0225\n",
      "Epoch 143: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0104 - mean_squared_error: 0.0225 - val_loss: 0.1079 - val_mean_squared_error: 0.2188\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0221\n",
      "Epoch 144: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0102 - mean_squared_error: 0.0221 - val_loss: 0.1072 - val_mean_squared_error: 0.2172\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0218\n",
      "Epoch 145: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0100 - mean_squared_error: 0.0218 - val_loss: 0.1098 - val_mean_squared_error: 0.2229\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0216\n",
      "Epoch 146: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0100 - mean_squared_error: 0.0216 - val_loss: 0.1073 - val_mean_squared_error: 0.2178\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0214\n",
      "Epoch 147: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.0098 - mean_squared_error: 0.0214 - val_loss: 0.1094 - val_mean_squared_error: 0.2220\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0211\n",
      "Epoch 148: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0097 - mean_squared_error: 0.0211 - val_loss: 0.1099 - val_mean_squared_error: 0.2231\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0211\n",
      "Epoch 149: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0097 - mean_squared_error: 0.0211 - val_loss: 0.1093 - val_mean_squared_error: 0.2220\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0207\n",
      "Epoch 150: val_loss did not improve from 0.08132\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0095 - mean_squared_error: 0.0207 - val_loss: 0.1085 - val_mean_squared_error: 0.2201\n",
      "5/5 [==============================] - 12s 336ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  360\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4030 - mean_squared_error: 0.9110\n",
      "Epoch 1: val_loss improved from inf to 0.31579, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 95s 5s/step - loss: 0.4030 - mean_squared_error: 0.9110 - val_loss: 0.3158 - val_mean_squared_error: 0.6822\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2413 - mean_squared_error: 0.5136\n",
      "Epoch 2: val_loss improved from 0.31579 to 0.18067, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.2413 - mean_squared_error: 0.5136 - val_loss: 0.1807 - val_mean_squared_error: 0.3742\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1281 - mean_squared_error: 0.2619\n",
      "Epoch 3: val_loss improved from 0.18067 to 0.12785, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.1281 - mean_squared_error: 0.2619 - val_loss: 0.1279 - val_mean_squared_error: 0.2599\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1062 - mean_squared_error: 0.2169\n",
      "Epoch 4: val_loss improved from 0.12785 to 0.12650, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.1062 - mean_squared_error: 0.2169 - val_loss: 0.1265 - val_mean_squared_error: 0.2579\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0990 - mean_squared_error: 0.2023\n",
      "Epoch 5: val_loss improved from 0.12650 to 0.12181, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0990 - mean_squared_error: 0.2023 - val_loss: 0.1218 - val_mean_squared_error: 0.2481\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0932 - mean_squared_error: 0.1898\n",
      "Epoch 6: val_loss improved from 0.12181 to 0.11829, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0932 - mean_squared_error: 0.1898 - val_loss: 0.1183 - val_mean_squared_error: 0.2409\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0903 - mean_squared_error: 0.1843\n",
      "Epoch 7: val_loss did not improve from 0.11829\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0903 - mean_squared_error: 0.1843 - val_loss: 0.1205 - val_mean_squared_error: 0.2457\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0869 - mean_squared_error: 0.1778\n",
      "Epoch 8: val_loss improved from 0.11829 to 0.11725, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0869 - mean_squared_error: 0.1778 - val_loss: 0.1172 - val_mean_squared_error: 0.2404\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0848 - mean_squared_error: 0.1730\n",
      "Epoch 9: val_loss improved from 0.11725 to 0.11603, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0848 - mean_squared_error: 0.1730 - val_loss: 0.1160 - val_mean_squared_error: 0.2368\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0823 - mean_squared_error: 0.1684\n",
      "Epoch 10: val_loss improved from 0.11603 to 0.11314, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0823 - mean_squared_error: 0.1684 - val_loss: 0.1131 - val_mean_squared_error: 0.2317\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0810 - mean_squared_error: 0.1657\n",
      "Epoch 11: val_loss did not improve from 0.11314\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0810 - mean_squared_error: 0.1657 - val_loss: 0.1167 - val_mean_squared_error: 0.2387\n",
      "Epoch 12/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - ETA: 0s - loss: 0.0793 - mean_squared_error: 0.1622\n",
      "Epoch 12: val_loss improved from 0.11314 to 0.11203, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0793 - mean_squared_error: 0.1622 - val_loss: 0.1120 - val_mean_squared_error: 0.2289\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0777 - mean_squared_error: 0.1587\n",
      "Epoch 13: val_loss did not improve from 0.11203\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0777 - mean_squared_error: 0.1587 - val_loss: 0.1131 - val_mean_squared_error: 0.2318\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0757 - mean_squared_error: 0.1550\n",
      "Epoch 14: val_loss improved from 0.11203 to 0.10681, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0757 - mean_squared_error: 0.1550 - val_loss: 0.1068 - val_mean_squared_error: 0.2179\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0730 - mean_squared_error: 0.1491\n",
      "Epoch 15: val_loss improved from 0.10681 to 0.10554, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0730 - mean_squared_error: 0.1491 - val_loss: 0.1055 - val_mean_squared_error: 0.2161\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0722 - mean_squared_error: 0.1478\n",
      "Epoch 16: val_loss improved from 0.10554 to 0.09621, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0722 - mean_squared_error: 0.1478 - val_loss: 0.0962 - val_mean_squared_error: 0.1961\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0684 - mean_squared_error: 0.1395\n",
      "Epoch 17: val_loss did not improve from 0.09621\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0684 - mean_squared_error: 0.1395 - val_loss: 0.1006 - val_mean_squared_error: 0.2045\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0641 - mean_squared_error: 0.1306\n",
      "Epoch 18: val_loss improved from 0.09621 to 0.09166, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0641 - mean_squared_error: 0.1306 - val_loss: 0.0917 - val_mean_squared_error: 0.1861\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0612 - mean_squared_error: 0.1249\n",
      "Epoch 19: val_loss improved from 0.09166 to 0.08743, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0612 - mean_squared_error: 0.1249 - val_loss: 0.0874 - val_mean_squared_error: 0.1768\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0612 - mean_squared_error: 0.1250\n",
      "Epoch 20: val_loss improved from 0.08743 to 0.08653, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0612 - mean_squared_error: 0.1250 - val_loss: 0.0865 - val_mean_squared_error: 0.1751\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0583 - mean_squared_error: 0.1188\n",
      "Epoch 21: val_loss did not improve from 0.08653\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0583 - mean_squared_error: 0.1188 - val_loss: 0.0886 - val_mean_squared_error: 0.1794\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0569 - mean_squared_error: 0.1159\n",
      "Epoch 22: val_loss did not improve from 0.08653\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0569 - mean_squared_error: 0.1159 - val_loss: 0.0869 - val_mean_squared_error: 0.1757\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0554 - mean_squared_error: 0.1127\n",
      "Epoch 23: val_loss improved from 0.08653 to 0.08125, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0554 - mean_squared_error: 0.1127 - val_loss: 0.0813 - val_mean_squared_error: 0.1640\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0539 - mean_squared_error: 0.1096\n",
      "Epoch 24: val_loss did not improve from 0.08125\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0539 - mean_squared_error: 0.1096 - val_loss: 0.0928 - val_mean_squared_error: 0.1893\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0538 - mean_squared_error: 0.1096\n",
      "Epoch 25: val_loss did not improve from 0.08125\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0538 - mean_squared_error: 0.1096 - val_loss: 0.0874 - val_mean_squared_error: 0.1775\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0513 - mean_squared_error: 0.1046\n",
      "Epoch 26: val_loss did not improve from 0.08125\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0513 - mean_squared_error: 0.1046 - val_loss: 0.0861 - val_mean_squared_error: 0.1740\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0510 - mean_squared_error: 0.1040\n",
      "Epoch 27: val_loss improved from 0.08125 to 0.08075, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0510 - mean_squared_error: 0.1040 - val_loss: 0.0808 - val_mean_squared_error: 0.1629\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0504 - mean_squared_error: 0.1026\n",
      "Epoch 28: val_loss did not improve from 0.08075\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0504 - mean_squared_error: 0.1026 - val_loss: 0.0842 - val_mean_squared_error: 0.1699\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0489 - mean_squared_error: 0.0997\n",
      "Epoch 29: val_loss did not improve from 0.08075\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0489 - mean_squared_error: 0.0997 - val_loss: 0.0852 - val_mean_squared_error: 0.1722\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0481 - mean_squared_error: 0.0980\n",
      "Epoch 30: val_loss did not improve from 0.08075\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0481 - mean_squared_error: 0.0980 - val_loss: 0.0814 - val_mean_squared_error: 0.1644\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0476 - mean_squared_error: 0.0969\n",
      "Epoch 31: val_loss did not improve from 0.08075\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0476 - mean_squared_error: 0.0969 - val_loss: 0.0834 - val_mean_squared_error: 0.1686\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0473 - mean_squared_error: 0.0964\n",
      "Epoch 32: val_loss improved from 0.08075 to 0.07960, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0473 - mean_squared_error: 0.0964 - val_loss: 0.0796 - val_mean_squared_error: 0.1607\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0469 - mean_squared_error: 0.0957\n",
      "Epoch 33: val_loss did not improve from 0.07960\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0469 - mean_squared_error: 0.0957 - val_loss: 0.0893 - val_mean_squared_error: 0.1805\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0459 - mean_squared_error: 0.0934\n",
      "Epoch 34: val_loss improved from 0.07960 to 0.07914, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0459 - mean_squared_error: 0.0934 - val_loss: 0.0791 - val_mean_squared_error: 0.1595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0443 - mean_squared_error: 0.0903\n",
      "Epoch 35: val_loss did not improve from 0.07914\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0443 - mean_squared_error: 0.0903 - val_loss: 0.0848 - val_mean_squared_error: 0.1710\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0460 - mean_squared_error: 0.0939\n",
      "Epoch 36: val_loss improved from 0.07914 to 0.07536, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0460 - mean_squared_error: 0.0939 - val_loss: 0.0754 - val_mean_squared_error: 0.1517\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.0917\n",
      "Epoch 37: val_loss did not improve from 0.07536\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0450 - mean_squared_error: 0.0917 - val_loss: 0.0836 - val_mean_squared_error: 0.1686\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0439 - mean_squared_error: 0.0896\n",
      "Epoch 38: val_loss did not improve from 0.07536\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0439 - mean_squared_error: 0.0896 - val_loss: 0.0754 - val_mean_squared_error: 0.1518\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0447 - mean_squared_error: 0.0912\n",
      "Epoch 39: val_loss did not improve from 0.07536\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0447 - mean_squared_error: 0.0912 - val_loss: 0.0845 - val_mean_squared_error: 0.1715\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0433 - mean_squared_error: 0.0882\n",
      "Epoch 40: val_loss did not improve from 0.07536\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0433 - mean_squared_error: 0.0882 - val_loss: 0.0927 - val_mean_squared_error: 0.1875\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0448 - mean_squared_error: 0.0914\n",
      "Epoch 41: val_loss did not improve from 0.07536\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0448 - mean_squared_error: 0.0914 - val_loss: 0.0878 - val_mean_squared_error: 0.1772\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0423 - mean_squared_error: 0.0863\n",
      "Epoch 42: val_loss did not improve from 0.07536\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0423 - mean_squared_error: 0.0863 - val_loss: 0.0795 - val_mean_squared_error: 0.1601\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0420 - mean_squared_error: 0.0856\n",
      "Epoch 43: val_loss did not improve from 0.07536\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0420 - mean_squared_error: 0.0856 - val_loss: 0.0800 - val_mean_squared_error: 0.1613\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0404 - mean_squared_error: 0.0824\n",
      "Epoch 44: val_loss did not improve from 0.07536\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0404 - mean_squared_error: 0.0824 - val_loss: 0.0772 - val_mean_squared_error: 0.1554\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0803\n",
      "Epoch 45: val_loss improved from 0.07536 to 0.07476, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0394 - mean_squared_error: 0.0803 - val_loss: 0.0748 - val_mean_squared_error: 0.1505\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0804\n",
      "Epoch 46: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0394 - mean_squared_error: 0.0804 - val_loss: 0.0769 - val_mean_squared_error: 0.1547\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0387 - mean_squared_error: 0.0791\n",
      "Epoch 47: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0387 - mean_squared_error: 0.0791 - val_loss: 0.0761 - val_mean_squared_error: 0.1534\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0800\n",
      "Epoch 48: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0392 - mean_squared_error: 0.0800 - val_loss: 0.0777 - val_mean_squared_error: 0.1565\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0395 - mean_squared_error: 0.0806\n",
      "Epoch 49: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0395 - mean_squared_error: 0.0806 - val_loss: 0.0798 - val_mean_squared_error: 0.1608\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0792\n",
      "Epoch 50: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0388 - mean_squared_error: 0.0792 - val_loss: 0.0828 - val_mean_squared_error: 0.1672\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.0789\n",
      "Epoch 51: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0386 - mean_squared_error: 0.0789 - val_loss: 0.0844 - val_mean_squared_error: 0.1703\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0377 - mean_squared_error: 0.0771\n",
      "Epoch 52: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0377 - mean_squared_error: 0.0771 - val_loss: 0.0771 - val_mean_squared_error: 0.1551\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0367 - mean_squared_error: 0.0750\n",
      "Epoch 53: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0367 - mean_squared_error: 0.0750 - val_loss: 0.0794 - val_mean_squared_error: 0.1599\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0358 - mean_squared_error: 0.0732\n",
      "Epoch 54: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0358 - mean_squared_error: 0.0732 - val_loss: 0.0803 - val_mean_squared_error: 0.1621\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0356 - mean_squared_error: 0.0728\n",
      "Epoch 55: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0356 - mean_squared_error: 0.0728 - val_loss: 0.0839 - val_mean_squared_error: 0.1694\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0348 - mean_squared_error: 0.0712\n",
      "Epoch 56: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0348 - mean_squared_error: 0.0712 - val_loss: 0.0786 - val_mean_squared_error: 0.1584\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0345 - mean_squared_error: 0.0706\n",
      "Epoch 57: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0345 - mean_squared_error: 0.0706 - val_loss: 0.0785 - val_mean_squared_error: 0.1580\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0336 - mean_squared_error: 0.0689\n",
      "Epoch 58: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0336 - mean_squared_error: 0.0689 - val_loss: 0.0773 - val_mean_squared_error: 0.1556\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0338 - mean_squared_error: 0.0693\n",
      "Epoch 59: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0338 - mean_squared_error: 0.0693 - val_loss: 0.0848 - val_mean_squared_error: 0.1713\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0340 - mean_squared_error: 0.0697\n",
      "Epoch 60: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0340 - mean_squared_error: 0.0697 - val_loss: 0.0847 - val_mean_squared_error: 0.1709\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0337 - mean_squared_error: 0.0690\n",
      "Epoch 61: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0337 - mean_squared_error: 0.0690 - val_loss: 0.0832 - val_mean_squared_error: 0.1678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0325 - mean_squared_error: 0.0666\n",
      "Epoch 62: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0325 - mean_squared_error: 0.0666 - val_loss: 0.0773 - val_mean_squared_error: 0.1555\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0326 - mean_squared_error: 0.0668\n",
      "Epoch 63: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0326 - mean_squared_error: 0.0668 - val_loss: 0.0797 - val_mean_squared_error: 0.1606\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0328 - mean_squared_error: 0.0673\n",
      "Epoch 64: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0328 - mean_squared_error: 0.0673 - val_loss: 0.0823 - val_mean_squared_error: 0.1662\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0319 - mean_squared_error: 0.0654\n",
      "Epoch 65: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0319 - mean_squared_error: 0.0654 - val_loss: 0.0866 - val_mean_squared_error: 0.1749\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0303 - mean_squared_error: 0.0622\n",
      "Epoch 66: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0303 - mean_squared_error: 0.0622 - val_loss: 0.0780 - val_mean_squared_error: 0.1570\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0293 - mean_squared_error: 0.0603\n",
      "Epoch 67: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0293 - mean_squared_error: 0.0603 - val_loss: 0.0808 - val_mean_squared_error: 0.1628\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0601\n",
      "Epoch 68: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0292 - mean_squared_error: 0.0601 - val_loss: 0.0829 - val_mean_squared_error: 0.1672\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0288 - mean_squared_error: 0.0593\n",
      "Epoch 69: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0288 - mean_squared_error: 0.0593 - val_loss: 0.0812 - val_mean_squared_error: 0.1636\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0283 - mean_squared_error: 0.0582\n",
      "Epoch 70: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0283 - mean_squared_error: 0.0582 - val_loss: 0.0796 - val_mean_squared_error: 0.1606\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0273 - mean_squared_error: 0.0562\n",
      "Epoch 71: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0273 - mean_squared_error: 0.0562 - val_loss: 0.0803 - val_mean_squared_error: 0.1620\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0558\n",
      "Epoch 72: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0271 - mean_squared_error: 0.0558 - val_loss: 0.0795 - val_mean_squared_error: 0.1604\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0269 - mean_squared_error: 0.0554\n",
      "Epoch 73: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0269 - mean_squared_error: 0.0554 - val_loss: 0.0805 - val_mean_squared_error: 0.1627\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0269 - mean_squared_error: 0.0553\n",
      "Epoch 74: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0269 - mean_squared_error: 0.0553 - val_loss: 0.0814 - val_mean_squared_error: 0.1643\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0262 - mean_squared_error: 0.0539\n",
      "Epoch 75: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0262 - mean_squared_error: 0.0539 - val_loss: 0.0871 - val_mean_squared_error: 0.1759\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0263 - mean_squared_error: 0.0543\n",
      "Epoch 76: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0263 - mean_squared_error: 0.0543 - val_loss: 0.0877 - val_mean_squared_error: 0.1770\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0263 - mean_squared_error: 0.0542\n",
      "Epoch 77: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0263 - mean_squared_error: 0.0542 - val_loss: 0.0792 - val_mean_squared_error: 0.1596\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0250 - mean_squared_error: 0.0517\n",
      "Epoch 78: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0250 - mean_squared_error: 0.0517 - val_loss: 0.0862 - val_mean_squared_error: 0.1740\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0242 - mean_squared_error: 0.0500\n",
      "Epoch 79: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0242 - mean_squared_error: 0.0500 - val_loss: 0.0815 - val_mean_squared_error: 0.1642\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0241 - mean_squared_error: 0.0499\n",
      "Epoch 80: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0241 - mean_squared_error: 0.0499 - val_loss: 0.0896 - val_mean_squared_error: 0.1815\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0237 - mean_squared_error: 0.0490\n",
      "Epoch 81: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0237 - mean_squared_error: 0.0490 - val_loss: 0.0865 - val_mean_squared_error: 0.1748\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0234 - mean_squared_error: 0.0483\n",
      "Epoch 82: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0234 - mean_squared_error: 0.0483 - val_loss: 0.0860 - val_mean_squared_error: 0.1733\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0240 - mean_squared_error: 0.0496\n",
      "Epoch 83: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0240 - mean_squared_error: 0.0496 - val_loss: 0.0856 - val_mean_squared_error: 0.1728\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0228 - mean_squared_error: 0.0472\n",
      "Epoch 84: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0228 - mean_squared_error: 0.0472 - val_loss: 0.0876 - val_mean_squared_error: 0.1769\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0225 - mean_squared_error: 0.0466\n",
      "Epoch 85: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0225 - mean_squared_error: 0.0466 - val_loss: 0.0842 - val_mean_squared_error: 0.1699\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0220 - mean_squared_error: 0.0455\n",
      "Epoch 86: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0220 - mean_squared_error: 0.0455 - val_loss: 0.0907 - val_mean_squared_error: 0.1831\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0217 - mean_squared_error: 0.0449\n",
      "Epoch 87: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0217 - mean_squared_error: 0.0449 - val_loss: 0.0868 - val_mean_squared_error: 0.1752\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0209 - mean_squared_error: 0.0434\n",
      "Epoch 88: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0209 - mean_squared_error: 0.0434 - val_loss: 0.0919 - val_mean_squared_error: 0.1857\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0209 - mean_squared_error: 0.0433\n",
      "Epoch 89: val_loss did not improve from 0.07476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 32s 4s/step - loss: 0.0209 - mean_squared_error: 0.0433 - val_loss: 0.0925 - val_mean_squared_error: 0.1873\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0207 - mean_squared_error: 0.0430\n",
      "Epoch 90: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0207 - mean_squared_error: 0.0430 - val_loss: 0.0866 - val_mean_squared_error: 0.1751\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0420\n",
      "Epoch 91: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0202 - mean_squared_error: 0.0420 - val_loss: 0.0881 - val_mean_squared_error: 0.1780\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0204 - mean_squared_error: 0.0425\n",
      "Epoch 92: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0204 - mean_squared_error: 0.0425 - val_loss: 0.0960 - val_mean_squared_error: 0.1945\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0200 - mean_squared_error: 0.0416\n",
      "Epoch 93: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0200 - mean_squared_error: 0.0416 - val_loss: 0.0938 - val_mean_squared_error: 0.1899\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0199 - mean_squared_error: 0.0413\n",
      "Epoch 94: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0199 - mean_squared_error: 0.0413 - val_loss: 0.0869 - val_mean_squared_error: 0.1756\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0401\n",
      "Epoch 95: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0193 - mean_squared_error: 0.0401 - val_loss: 0.0890 - val_mean_squared_error: 0.1799\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0183 - mean_squared_error: 0.0381\n",
      "Epoch 96: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0183 - mean_squared_error: 0.0381 - val_loss: 0.0934 - val_mean_squared_error: 0.1889\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0177 - mean_squared_error: 0.0370\n",
      "Epoch 97: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0177 - mean_squared_error: 0.0370 - val_loss: 0.0935 - val_mean_squared_error: 0.1891\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0366\n",
      "Epoch 98: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0175 - mean_squared_error: 0.0366 - val_loss: 0.0977 - val_mean_squared_error: 0.1981\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0180 - mean_squared_error: 0.0376\n",
      "Epoch 99: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0180 - mean_squared_error: 0.0376 - val_loss: 0.0905 - val_mean_squared_error: 0.1830\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0378\n",
      "Epoch 100: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0181 - mean_squared_error: 0.0378 - val_loss: 0.1028 - val_mean_squared_error: 0.2086\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0365\n",
      "Epoch 101: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0175 - mean_squared_error: 0.0365 - val_loss: 0.0970 - val_mean_squared_error: 0.1965\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0379\n",
      "Epoch 102: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0181 - mean_squared_error: 0.0379 - val_loss: 0.0970 - val_mean_squared_error: 0.1967\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0180 - mean_squared_error: 0.0376\n",
      "Epoch 103: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0180 - mean_squared_error: 0.0376 - val_loss: 0.0985 - val_mean_squared_error: 0.1993\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0348\n",
      "Epoch 104: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0166 - mean_squared_error: 0.0348 - val_loss: 0.0961 - val_mean_squared_error: 0.1948\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0334\n",
      "Epoch 105: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0159 - mean_squared_error: 0.0334 - val_loss: 0.0952 - val_mean_squared_error: 0.1926\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0336\n",
      "Epoch 106: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0160 - mean_squared_error: 0.0336 - val_loss: 0.0989 - val_mean_squared_error: 0.2005\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0331\n",
      "Epoch 107: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0157 - mean_squared_error: 0.0331 - val_loss: 0.1047 - val_mean_squared_error: 0.2121\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0330\n",
      "Epoch 108: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0157 - mean_squared_error: 0.0330 - val_loss: 0.1010 - val_mean_squared_error: 0.2056\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0153 - mean_squared_error: 0.0322\n",
      "Epoch 109: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0153 - mean_squared_error: 0.0322 - val_loss: 0.0980 - val_mean_squared_error: 0.1984\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0319\n",
      "Epoch 110: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0152 - mean_squared_error: 0.0319 - val_loss: 0.0987 - val_mean_squared_error: 0.2000\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0310\n",
      "Epoch 111: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0147 - mean_squared_error: 0.0310 - val_loss: 0.1037 - val_mean_squared_error: 0.2108\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0304\n",
      "Epoch 112: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0144 - mean_squared_error: 0.0304 - val_loss: 0.1008 - val_mean_squared_error: 0.2048\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0300\n",
      "Epoch 113: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0142 - mean_squared_error: 0.0300 - val_loss: 0.1018 - val_mean_squared_error: 0.2066\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0295\n",
      "Epoch 114: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0139 - mean_squared_error: 0.0295 - val_loss: 0.1005 - val_mean_squared_error: 0.2037\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0293\n",
      "Epoch 115: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0138 - mean_squared_error: 0.0293 - val_loss: 0.0995 - val_mean_squared_error: 0.2019\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0292\n",
      "Epoch 116: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0138 - mean_squared_error: 0.0292 - val_loss: 0.1038 - val_mean_squared_error: 0.2108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0283\n",
      "Epoch 117: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0133 - mean_squared_error: 0.0283 - val_loss: 0.1053 - val_mean_squared_error: 0.2138\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0284\n",
      "Epoch 118: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0134 - mean_squared_error: 0.0284 - val_loss: 0.1006 - val_mean_squared_error: 0.2043\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0283\n",
      "Epoch 119: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0134 - mean_squared_error: 0.0283 - val_loss: 0.1049 - val_mean_squared_error: 0.2134\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0274\n",
      "Epoch 120: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0129 - mean_squared_error: 0.0274 - val_loss: 0.1009 - val_mean_squared_error: 0.2045\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0272\n",
      "Epoch 121: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0128 - mean_squared_error: 0.0272 - val_loss: 0.1018 - val_mean_squared_error: 0.2067\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0271\n",
      "Epoch 122: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0127 - mean_squared_error: 0.0271 - val_loss: 0.1053 - val_mean_squared_error: 0.2141\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0265\n",
      "Epoch 123: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0125 - mean_squared_error: 0.0265 - val_loss: 0.1044 - val_mean_squared_error: 0.2119\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0261\n",
      "Epoch 124: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0122 - mean_squared_error: 0.0261 - val_loss: 0.1080 - val_mean_squared_error: 0.2196\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0259\n",
      "Epoch 125: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0121 - mean_squared_error: 0.0259 - val_loss: 0.1040 - val_mean_squared_error: 0.2112\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0254\n",
      "Epoch 126: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0119 - mean_squared_error: 0.0254 - val_loss: 0.1068 - val_mean_squared_error: 0.2172\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0250\n",
      "Epoch 127: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0117 - mean_squared_error: 0.0250 - val_loss: 0.1063 - val_mean_squared_error: 0.2162\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0250\n",
      "Epoch 128: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0117 - mean_squared_error: 0.0250 - val_loss: 0.1061 - val_mean_squared_error: 0.2157\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0115 - mean_squared_error: 0.0246\n",
      "Epoch 129: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0115 - mean_squared_error: 0.0246 - val_loss: 0.1082 - val_mean_squared_error: 0.2201\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0249\n",
      "Epoch 130: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0116 - mean_squared_error: 0.0249 - val_loss: 0.1044 - val_mean_squared_error: 0.2123\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0245\n",
      "Epoch 131: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0114 - mean_squared_error: 0.0245 - val_loss: 0.1093 - val_mean_squared_error: 0.2223\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0249\n",
      "Epoch 132: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0116 - mean_squared_error: 0.0249 - val_loss: 0.1071 - val_mean_squared_error: 0.2177\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0245\n",
      "Epoch 133: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0114 - mean_squared_error: 0.0245 - val_loss: 0.1068 - val_mean_squared_error: 0.2174\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0242\n",
      "Epoch 134: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0113 - mean_squared_error: 0.0242 - val_loss: 0.1050 - val_mean_squared_error: 0.2132\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0236\n",
      "Epoch 135: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0110 - mean_squared_error: 0.0236 - val_loss: 0.1059 - val_mean_squared_error: 0.2149\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0231\n",
      "Epoch 136: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0107 - mean_squared_error: 0.0231 - val_loss: 0.1084 - val_mean_squared_error: 0.2209\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0229\n",
      "Epoch 137: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0106 - mean_squared_error: 0.0229 - val_loss: 0.1090 - val_mean_squared_error: 0.2218\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0226\n",
      "Epoch 138: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0105 - mean_squared_error: 0.0226 - val_loss: 0.1075 - val_mean_squared_error: 0.2191\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0222\n",
      "Epoch 139: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0103 - mean_squared_error: 0.0222 - val_loss: 0.1103 - val_mean_squared_error: 0.2249\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0223\n",
      "Epoch 140: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0103 - mean_squared_error: 0.0223 - val_loss: 0.1094 - val_mean_squared_error: 0.2224\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0224\n",
      "Epoch 141: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0104 - mean_squared_error: 0.0224 - val_loss: 0.1105 - val_mean_squared_error: 0.2252\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0224\n",
      "Epoch 142: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0103 - mean_squared_error: 0.0224 - val_loss: 0.1090 - val_mean_squared_error: 0.2217\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0225\n",
      "Epoch 143: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0104 - mean_squared_error: 0.0225 - val_loss: 0.1137 - val_mean_squared_error: 0.2323\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0218\n",
      "Epoch 144: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0101 - mean_squared_error: 0.0218 - val_loss: 0.1096 - val_mean_squared_error: 0.2234\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0214\n",
      "Epoch 145: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0098 - mean_squared_error: 0.0214 - val_loss: 0.1119 - val_mean_squared_error: 0.2281\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0214\n",
      "Epoch 146: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0099 - mean_squared_error: 0.0214 - val_loss: 0.1091 - val_mean_squared_error: 0.2221\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0218\n",
      "Epoch 147: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0100 - mean_squared_error: 0.0218 - val_loss: 0.1157 - val_mean_squared_error: 0.2360\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0214\n",
      "Epoch 148: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0099 - mean_squared_error: 0.0214 - val_loss: 0.1119 - val_mean_squared_error: 0.2285\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0217\n",
      "Epoch 149: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0100 - mean_squared_error: 0.0217 - val_loss: 0.1084 - val_mean_squared_error: 0.2205\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0210\n",
      "Epoch 150: val_loss did not improve from 0.07476\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0096 - mean_squared_error: 0.0210 - val_loss: 0.1130 - val_mean_squared_error: 0.2301\n",
      "5/5 [==============================] - 12s 355ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  384\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3862 - mean_squared_error: 0.8724\n",
      "Epoch 1: val_loss improved from inf to 0.27340, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 100s 5s/step - loss: 0.3862 - mean_squared_error: 0.8724 - val_loss: 0.2734 - val_mean_squared_error: 0.5973\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2189 - mean_squared_error: 0.4707\n",
      "Epoch 2: val_loss improved from 0.27340 to 0.16431, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.2189 - mean_squared_error: 0.4707 - val_loss: 0.1643 - val_mean_squared_error: 0.3403\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1359 - mean_squared_error: 0.2800\n",
      "Epoch 3: val_loss improved from 0.16431 to 0.13844, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.1359 - mean_squared_error: 0.2800 - val_loss: 0.1384 - val_mean_squared_error: 0.2822\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1110 - mean_squared_error: 0.2268\n",
      "Epoch 4: val_loss improved from 0.13844 to 0.12859, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.1110 - mean_squared_error: 0.2268 - val_loss: 0.1286 - val_mean_squared_error: 0.2619\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0999 - mean_squared_error: 0.2043\n",
      "Epoch 5: val_loss improved from 0.12859 to 0.12708, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0999 - mean_squared_error: 0.2043 - val_loss: 0.1271 - val_mean_squared_error: 0.2592\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0970 - mean_squared_error: 0.1980\n",
      "Epoch 6: val_loss improved from 0.12708 to 0.12090, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0970 - mean_squared_error: 0.1980 - val_loss: 0.1209 - val_mean_squared_error: 0.2457\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0933 - mean_squared_error: 0.1903\n",
      "Epoch 7: val_loss did not improve from 0.12090\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0933 - mean_squared_error: 0.1903 - val_loss: 0.1210 - val_mean_squared_error: 0.2462\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0906 - mean_squared_error: 0.1846\n",
      "Epoch 8: val_loss improved from 0.12090 to 0.11881, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0906 - mean_squared_error: 0.1846 - val_loss: 0.1188 - val_mean_squared_error: 0.2418\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0877 - mean_squared_error: 0.1791\n",
      "Epoch 9: val_loss did not improve from 0.11881\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0877 - mean_squared_error: 0.1791 - val_loss: 0.1244 - val_mean_squared_error: 0.2547\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0852 - mean_squared_error: 0.1742\n",
      "Epoch 10: val_loss did not improve from 0.11881\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0852 - mean_squared_error: 0.1742 - val_loss: 0.1242 - val_mean_squared_error: 0.2549\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0820 - mean_squared_error: 0.1676\n",
      "Epoch 11: val_loss improved from 0.11881 to 0.11539, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0820 - mean_squared_error: 0.1676 - val_loss: 0.1154 - val_mean_squared_error: 0.2362\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0794 - mean_squared_error: 0.1623\n",
      "Epoch 12: val_loss did not improve from 0.11539\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0794 - mean_squared_error: 0.1623 - val_loss: 0.1176 - val_mean_squared_error: 0.2409\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0772 - mean_squared_error: 0.1578\n",
      "Epoch 13: val_loss did not improve from 0.11539\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0772 - mean_squared_error: 0.1578 - val_loss: 0.1185 - val_mean_squared_error: 0.2431\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0755 - mean_squared_error: 0.1543\n",
      "Epoch 14: val_loss improved from 0.11539 to 0.10921, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0755 - mean_squared_error: 0.1543 - val_loss: 0.1092 - val_mean_squared_error: 0.2234\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0745 - mean_squared_error: 0.1524\n",
      "Epoch 15: val_loss did not improve from 0.10921\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0745 - mean_squared_error: 0.1524 - val_loss: 0.1102 - val_mean_squared_error: 0.2256\n",
      "Epoch 16/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - ETA: 0s - loss: 0.0729 - mean_squared_error: 0.1489\n",
      "Epoch 16: val_loss did not improve from 0.10921\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0729 - mean_squared_error: 0.1489 - val_loss: 0.1143 - val_mean_squared_error: 0.2332\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0714 - mean_squared_error: 0.1460\n",
      "Epoch 17: val_loss did not improve from 0.10921\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0714 - mean_squared_error: 0.1460 - val_loss: 0.1100 - val_mean_squared_error: 0.2253\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0699 - mean_squared_error: 0.1426\n",
      "Epoch 18: val_loss improved from 0.10921 to 0.09979, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0699 - mean_squared_error: 0.1426 - val_loss: 0.0998 - val_mean_squared_error: 0.2036\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0673 - mean_squared_error: 0.1370\n",
      "Epoch 19: val_loss improved from 0.09979 to 0.09505, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0673 - mean_squared_error: 0.1370 - val_loss: 0.0951 - val_mean_squared_error: 0.1939\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0654 - mean_squared_error: 0.1332\n",
      "Epoch 20: val_loss improved from 0.09505 to 0.09417, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0654 - mean_squared_error: 0.1332 - val_loss: 0.0942 - val_mean_squared_error: 0.1914\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0633 - mean_squared_error: 0.1288\n",
      "Epoch 21: val_loss improved from 0.09417 to 0.09067, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0633 - mean_squared_error: 0.1288 - val_loss: 0.0907 - val_mean_squared_error: 0.1845\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0610 - mean_squared_error: 0.1242\n",
      "Epoch 22: val_loss improved from 0.09067 to 0.08856, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0610 - mean_squared_error: 0.1242 - val_loss: 0.0886 - val_mean_squared_error: 0.1804\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0587 - mean_squared_error: 0.1195\n",
      "Epoch 23: val_loss did not improve from 0.08856\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0587 - mean_squared_error: 0.1195 - val_loss: 0.0902 - val_mean_squared_error: 0.1849\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0624 - mean_squared_error: 0.1272\n",
      "Epoch 24: val_loss did not improve from 0.08856\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0624 - mean_squared_error: 0.1272 - val_loss: 0.0947 - val_mean_squared_error: 0.1932\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0583 - mean_squared_error: 0.1187\n",
      "Epoch 25: val_loss improved from 0.08856 to 0.08790, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0583 - mean_squared_error: 0.1187 - val_loss: 0.0879 - val_mean_squared_error: 0.1780\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0556 - mean_squared_error: 0.1133\n",
      "Epoch 26: val_loss improved from 0.08790 to 0.08701, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0556 - mean_squared_error: 0.1133 - val_loss: 0.0870 - val_mean_squared_error: 0.1764\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0552 - mean_squared_error: 0.1124\n",
      "Epoch 27: val_loss did not improve from 0.08701\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0552 - mean_squared_error: 0.1124 - val_loss: 0.0977 - val_mean_squared_error: 0.1991\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0557 - mean_squared_error: 0.1134\n",
      "Epoch 28: val_loss did not improve from 0.08701\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0557 - mean_squared_error: 0.1134 - val_loss: 0.0952 - val_mean_squared_error: 0.1936\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0533 - mean_squared_error: 0.1086\n",
      "Epoch 29: val_loss did not improve from 0.08701\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0533 - mean_squared_error: 0.1086 - val_loss: 0.0871 - val_mean_squared_error: 0.1769\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0508 - mean_squared_error: 0.1034\n",
      "Epoch 30: val_loss improved from 0.08701 to 0.08006, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0508 - mean_squared_error: 0.1034 - val_loss: 0.0801 - val_mean_squared_error: 0.1618\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0496 - mean_squared_error: 0.1011\n",
      "Epoch 31: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0496 - mean_squared_error: 0.1011 - val_loss: 0.0852 - val_mean_squared_error: 0.1733\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0504 - mean_squared_error: 0.1027\n",
      "Epoch 32: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0504 - mean_squared_error: 0.1027 - val_loss: 0.0870 - val_mean_squared_error: 0.1763\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0480 - mean_squared_error: 0.0978\n",
      "Epoch 33: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0480 - mean_squared_error: 0.0978 - val_loss: 0.0883 - val_mean_squared_error: 0.1797\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0481 - mean_squared_error: 0.0982\n",
      "Epoch 34: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0481 - mean_squared_error: 0.0982 - val_loss: 0.0858 - val_mean_squared_error: 0.1737\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0460 - mean_squared_error: 0.0938\n",
      "Epoch 35: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0460 - mean_squared_error: 0.0938 - val_loss: 0.0858 - val_mean_squared_error: 0.1738\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0446 - mean_squared_error: 0.0911\n",
      "Epoch 36: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0446 - mean_squared_error: 0.0911 - val_loss: 0.0821 - val_mean_squared_error: 0.1657\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0453 - mean_squared_error: 0.0923\n",
      "Epoch 37: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0453 - mean_squared_error: 0.0923 - val_loss: 0.0863 - val_mean_squared_error: 0.1746\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0447 - mean_squared_error: 0.0912\n",
      "Epoch 38: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0447 - mean_squared_error: 0.0912 - val_loss: 0.0870 - val_mean_squared_error: 0.1760\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0444 - mean_squared_error: 0.0906\n",
      "Epoch 39: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0444 - mean_squared_error: 0.0906 - val_loss: 0.0828 - val_mean_squared_error: 0.1677\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0440 - mean_squared_error: 0.0898\n",
      "Epoch 40: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0440 - mean_squared_error: 0.0898 - val_loss: 0.0806 - val_mean_squared_error: 0.1627\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0439 - mean_squared_error: 0.0895\n",
      "Epoch 41: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0439 - mean_squared_error: 0.0895 - val_loss: 0.0945 - val_mean_squared_error: 0.1925\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0451 - mean_squared_error: 0.0922\n",
      "Epoch 42: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0451 - mean_squared_error: 0.0922 - val_loss: 0.0829 - val_mean_squared_error: 0.1674\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0435 - mean_squared_error: 0.0889\n",
      "Epoch 43: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0435 - mean_squared_error: 0.0889 - val_loss: 0.0845 - val_mean_squared_error: 0.1709\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0430 - mean_squared_error: 0.0879\n",
      "Epoch 44: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0430 - mean_squared_error: 0.0879 - val_loss: 0.0852 - val_mean_squared_error: 0.1725\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0415 - mean_squared_error: 0.0848\n",
      "Epoch 45: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0415 - mean_squared_error: 0.0848 - val_loss: 0.0847 - val_mean_squared_error: 0.1716\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0407 - mean_squared_error: 0.0832\n",
      "Epoch 46: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0407 - mean_squared_error: 0.0832 - val_loss: 0.0824 - val_mean_squared_error: 0.1666\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0408 - mean_squared_error: 0.0834\n",
      "Epoch 47: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0408 - mean_squared_error: 0.0834 - val_loss: 0.0830 - val_mean_squared_error: 0.1682\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0806\n",
      "Epoch 48: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0394 - mean_squared_error: 0.0806 - val_loss: 0.0849 - val_mean_squared_error: 0.1717\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0805\n",
      "Epoch 49: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0393 - mean_squared_error: 0.0805 - val_loss: 0.0836 - val_mean_squared_error: 0.1694\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0382 - mean_squared_error: 0.0782\n",
      "Epoch 50: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0382 - mean_squared_error: 0.0782 - val_loss: 0.0914 - val_mean_squared_error: 0.1857\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0387 - mean_squared_error: 0.0792\n",
      "Epoch 51: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0387 - mean_squared_error: 0.0792 - val_loss: 0.0846 - val_mean_squared_error: 0.1714\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0794\n",
      "Epoch 52: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0388 - mean_squared_error: 0.0794 - val_loss: 0.0898 - val_mean_squared_error: 0.1819\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0385 - mean_squared_error: 0.0788\n",
      "Epoch 53: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0385 - mean_squared_error: 0.0788 - val_loss: 0.0812 - val_mean_squared_error: 0.1643\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0374 - mean_squared_error: 0.0766\n",
      "Epoch 54: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0374 - mean_squared_error: 0.0766 - val_loss: 0.0832 - val_mean_squared_error: 0.1680\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0800\n",
      "Epoch 55: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0391 - mean_squared_error: 0.0800 - val_loss: 0.0993 - val_mean_squared_error: 0.2014\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0375 - mean_squared_error: 0.0767\n",
      "Epoch 56: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0375 - mean_squared_error: 0.0767 - val_loss: 0.0864 - val_mean_squared_error: 0.1747\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0361 - mean_squared_error: 0.0739\n",
      "Epoch 57: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0361 - mean_squared_error: 0.0739 - val_loss: 0.0862 - val_mean_squared_error: 0.1745\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0358 - mean_squared_error: 0.0734\n",
      "Epoch 58: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0358 - mean_squared_error: 0.0734 - val_loss: 0.0858 - val_mean_squared_error: 0.1737\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0355 - mean_squared_error: 0.0728\n",
      "Epoch 59: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0355 - mean_squared_error: 0.0728 - val_loss: 0.0893 - val_mean_squared_error: 0.1809\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0346 - mean_squared_error: 0.0709\n",
      "Epoch 60: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0346 - mean_squared_error: 0.0709 - val_loss: 0.0818 - val_mean_squared_error: 0.1659\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0347 - mean_squared_error: 0.0712\n",
      "Epoch 61: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0347 - mean_squared_error: 0.0712 - val_loss: 0.1058 - val_mean_squared_error: 0.2175\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0359 - mean_squared_error: 0.0736\n",
      "Epoch 62: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0359 - mean_squared_error: 0.0736 - val_loss: 0.0913 - val_mean_squared_error: 0.1848\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0353 - mean_squared_error: 0.0724\n",
      "Epoch 63: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0353 - mean_squared_error: 0.0724 - val_loss: 0.0819 - val_mean_squared_error: 0.1656\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0341 - mean_squared_error: 0.0698\n",
      "Epoch 64: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0341 - mean_squared_error: 0.0698 - val_loss: 0.0878 - val_mean_squared_error: 0.1787\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0339 - mean_squared_error: 0.0696\n",
      "Epoch 65: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0339 - mean_squared_error: 0.0696 - val_loss: 0.0913 - val_mean_squared_error: 0.1856\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0325 - mean_squared_error: 0.0668\n",
      "Epoch 66: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0325 - mean_squared_error: 0.0668 - val_loss: 0.0930 - val_mean_squared_error: 0.1898\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0328 - mean_squared_error: 0.0673\n",
      "Epoch 67: val_loss did not improve from 0.08006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 35s 4s/step - loss: 0.0328 - mean_squared_error: 0.0673 - val_loss: 0.1003 - val_mean_squared_error: 0.2035\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0664\n",
      "Epoch 68: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0323 - mean_squared_error: 0.0664 - val_loss: 0.0911 - val_mean_squared_error: 0.1849\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0316 - mean_squared_error: 0.0650\n",
      "Epoch 69: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0316 - mean_squared_error: 0.0650 - val_loss: 0.0866 - val_mean_squared_error: 0.1763\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0313 - mean_squared_error: 0.0642\n",
      "Epoch 70: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0313 - mean_squared_error: 0.0642 - val_loss: 0.0901 - val_mean_squared_error: 0.1831\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0309 - mean_squared_error: 0.0635\n",
      "Epoch 71: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0309 - mean_squared_error: 0.0635 - val_loss: 0.0958 - val_mean_squared_error: 0.1948\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0300 - mean_squared_error: 0.0617\n",
      "Epoch 72: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0300 - mean_squared_error: 0.0617 - val_loss: 0.0973 - val_mean_squared_error: 0.1985\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0303 - mean_squared_error: 0.0623\n",
      "Epoch 73: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0303 - mean_squared_error: 0.0623 - val_loss: 0.0945 - val_mean_squared_error: 0.1925\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0303 - mean_squared_error: 0.0624\n",
      "Epoch 74: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0303 - mean_squared_error: 0.0624 - val_loss: 0.0911 - val_mean_squared_error: 0.1849\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0600\n",
      "Epoch 75: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0292 - mean_squared_error: 0.0600 - val_loss: 0.0932 - val_mean_squared_error: 0.1895\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0304 - mean_squared_error: 0.0625\n",
      "Epoch 76: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0304 - mean_squared_error: 0.0625 - val_loss: 0.0988 - val_mean_squared_error: 0.2010\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0298 - mean_squared_error: 0.0614\n",
      "Epoch 77: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0298 - mean_squared_error: 0.0614 - val_loss: 0.0972 - val_mean_squared_error: 0.1979\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0277 - mean_squared_error: 0.0571\n",
      "Epoch 78: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0277 - mean_squared_error: 0.0571 - val_loss: 0.0951 - val_mean_squared_error: 0.1937\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0272 - mean_squared_error: 0.0562\n",
      "Epoch 79: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0272 - mean_squared_error: 0.0562 - val_loss: 0.0963 - val_mean_squared_error: 0.1962\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0270 - mean_squared_error: 0.0558\n",
      "Epoch 80: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0270 - mean_squared_error: 0.0558 - val_loss: 0.0852 - val_mean_squared_error: 0.1739\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0558\n",
      "Epoch 81: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0271 - mean_squared_error: 0.0558 - val_loss: 0.0879 - val_mean_squared_error: 0.1788\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0269 - mean_squared_error: 0.0556\n",
      "Epoch 82: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0269 - mean_squared_error: 0.0556 - val_loss: 0.0934 - val_mean_squared_error: 0.1904\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0256 - mean_squared_error: 0.0530\n",
      "Epoch 83: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0256 - mean_squared_error: 0.0530 - val_loss: 0.0960 - val_mean_squared_error: 0.1954\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0252 - mean_squared_error: 0.0522\n",
      "Epoch 84: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0252 - mean_squared_error: 0.0522 - val_loss: 0.0886 - val_mean_squared_error: 0.1800\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0247 - mean_squared_error: 0.0512\n",
      "Epoch 85: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0247 - mean_squared_error: 0.0512 - val_loss: 0.0962 - val_mean_squared_error: 0.1966\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0241 - mean_squared_error: 0.0499\n",
      "Epoch 86: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0241 - mean_squared_error: 0.0499 - val_loss: 0.0935 - val_mean_squared_error: 0.1905\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0238 - mean_squared_error: 0.0493\n",
      "Epoch 87: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0238 - mean_squared_error: 0.0493 - val_loss: 0.0938 - val_mean_squared_error: 0.1912\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0235 - mean_squared_error: 0.0487\n",
      "Epoch 88: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0235 - mean_squared_error: 0.0487 - val_loss: 0.0960 - val_mean_squared_error: 0.1955\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0231 - mean_squared_error: 0.0478\n",
      "Epoch 89: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0231 - mean_squared_error: 0.0478 - val_loss: 0.0978 - val_mean_squared_error: 0.1989\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0228 - mean_squared_error: 0.0473\n",
      "Epoch 90: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0228 - mean_squared_error: 0.0473 - val_loss: 0.0975 - val_mean_squared_error: 0.1983\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0466\n",
      "Epoch 91: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0224 - mean_squared_error: 0.0466 - val_loss: 0.0917 - val_mean_squared_error: 0.1860\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0217 - mean_squared_error: 0.0450\n",
      "Epoch 92: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0217 - mean_squared_error: 0.0450 - val_loss: 0.0965 - val_mean_squared_error: 0.1960\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0218 - mean_squared_error: 0.0453\n",
      "Epoch 93: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0218 - mean_squared_error: 0.0453 - val_loss: 0.1009 - val_mean_squared_error: 0.2052\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0214 - mean_squared_error: 0.0446\n",
      "Epoch 94: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0214 - mean_squared_error: 0.0446 - val_loss: 0.1028 - val_mean_squared_error: 0.2095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0215 - mean_squared_error: 0.0447\n",
      "Epoch 95: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0215 - mean_squared_error: 0.0447 - val_loss: 0.0910 - val_mean_squared_error: 0.1848\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0209 - mean_squared_error: 0.0436\n",
      "Epoch 96: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0209 - mean_squared_error: 0.0436 - val_loss: 0.0961 - val_mean_squared_error: 0.1958\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0211 - mean_squared_error: 0.0439\n",
      "Epoch 97: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0211 - mean_squared_error: 0.0439 - val_loss: 0.1000 - val_mean_squared_error: 0.2041\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0198 - mean_squared_error: 0.0412\n",
      "Epoch 98: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0198 - mean_squared_error: 0.0412 - val_loss: 0.0972 - val_mean_squared_error: 0.1972\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0197 - mean_squared_error: 0.0412\n",
      "Epoch 99: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0197 - mean_squared_error: 0.0412 - val_loss: 0.0991 - val_mean_squared_error: 0.2011\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0195 - mean_squared_error: 0.0406\n",
      "Epoch 100: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0195 - mean_squared_error: 0.0406 - val_loss: 0.0984 - val_mean_squared_error: 0.2003\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0190 - mean_squared_error: 0.0397\n",
      "Epoch 101: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0190 - mean_squared_error: 0.0397 - val_loss: 0.0946 - val_mean_squared_error: 0.1923\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0396\n",
      "Epoch 102: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0189 - mean_squared_error: 0.0396 - val_loss: 0.1011 - val_mean_squared_error: 0.2061\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0187 - mean_squared_error: 0.0390\n",
      "Epoch 103: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0187 - mean_squared_error: 0.0390 - val_loss: 0.0968 - val_mean_squared_error: 0.1968\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0377\n",
      "Epoch 104: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0181 - mean_squared_error: 0.0377 - val_loss: 0.1001 - val_mean_squared_error: 0.2035\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0367\n",
      "Epoch 105: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0175 - mean_squared_error: 0.0367 - val_loss: 0.0965 - val_mean_squared_error: 0.1961\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0361\n",
      "Epoch 106: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0172 - mean_squared_error: 0.0361 - val_loss: 0.1030 - val_mean_squared_error: 0.2091\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0360\n",
      "Epoch 107: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0172 - mean_squared_error: 0.0360 - val_loss: 0.0985 - val_mean_squared_error: 0.1999\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0355\n",
      "Epoch 108: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0169 - mean_squared_error: 0.0355 - val_loss: 0.1063 - val_mean_squared_error: 0.2171\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0354\n",
      "Epoch 109: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0169 - mean_squared_error: 0.0354 - val_loss: 0.0991 - val_mean_squared_error: 0.2012\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0354\n",
      "Epoch 110: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0168 - mean_squared_error: 0.0354 - val_loss: 0.1012 - val_mean_squared_error: 0.2053\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0347\n",
      "Epoch 111: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0165 - mean_squared_error: 0.0347 - val_loss: 0.1030 - val_mean_squared_error: 0.2092\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0335\n",
      "Epoch 112: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0159 - mean_squared_error: 0.0335 - val_loss: 0.1031 - val_mean_squared_error: 0.2100\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0336\n",
      "Epoch 113: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0159 - mean_squared_error: 0.0336 - val_loss: 0.1018 - val_mean_squared_error: 0.2066\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0158 - mean_squared_error: 0.0332\n",
      "Epoch 114: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0158 - mean_squared_error: 0.0332 - val_loss: 0.1013 - val_mean_squared_error: 0.2059\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0320\n",
      "Epoch 115: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0152 - mean_squared_error: 0.0320 - val_loss: 0.1039 - val_mean_squared_error: 0.2108\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0318\n",
      "Epoch 116: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0151 - mean_squared_error: 0.0318 - val_loss: 0.0996 - val_mean_squared_error: 0.2020\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0315\n",
      "Epoch 117: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0149 - mean_squared_error: 0.0315 - val_loss: 0.1076 - val_mean_squared_error: 0.2192\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0311\n",
      "Epoch 118: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0147 - mean_squared_error: 0.0311 - val_loss: 0.1037 - val_mean_squared_error: 0.2104\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0300\n",
      "Epoch 119: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0142 - mean_squared_error: 0.0300 - val_loss: 0.1040 - val_mean_squared_error: 0.2110\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0302\n",
      "Epoch 120: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0143 - mean_squared_error: 0.0302 - val_loss: 0.1025 - val_mean_squared_error: 0.2084\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0307\n",
      "Epoch 121: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0145 - mean_squared_error: 0.0307 - val_loss: 0.1007 - val_mean_squared_error: 0.2037\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0303\n",
      "Epoch 122: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0143 - mean_squared_error: 0.0303 - val_loss: 0.1015 - val_mean_squared_error: 0.2057\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0300\n",
      "Epoch 123: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0142 - mean_squared_error: 0.0300 - val_loss: 0.1022 - val_mean_squared_error: 0.2078\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0304\n",
      "Epoch 124: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0143 - mean_squared_error: 0.0304 - val_loss: 0.1015 - val_mean_squared_error: 0.2056\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0294\n",
      "Epoch 125: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0139 - mean_squared_error: 0.0294 - val_loss: 0.1042 - val_mean_squared_error: 0.2118\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0294\n",
      "Epoch 126: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0138 - mean_squared_error: 0.0294 - val_loss: 0.1049 - val_mean_squared_error: 0.2133\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0283\n",
      "Epoch 127: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0133 - mean_squared_error: 0.0283 - val_loss: 0.1023 - val_mean_squared_error: 0.2072\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0274\n",
      "Epoch 128: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0129 - mean_squared_error: 0.0274 - val_loss: 0.1021 - val_mean_squared_error: 0.2073\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0264\n",
      "Epoch 129: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0124 - mean_squared_error: 0.0264 - val_loss: 0.1011 - val_mean_squared_error: 0.2050\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0265\n",
      "Epoch 130: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0124 - mean_squared_error: 0.0265 - val_loss: 0.1044 - val_mean_squared_error: 0.2118\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0262\n",
      "Epoch 131: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0123 - mean_squared_error: 0.0262 - val_loss: 0.1035 - val_mean_squared_error: 0.2105\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0266\n",
      "Epoch 132: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0125 - mean_squared_error: 0.0266 - val_loss: 0.1036 - val_mean_squared_error: 0.2110\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0265\n",
      "Epoch 133: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0124 - mean_squared_error: 0.0265 - val_loss: 0.0999 - val_mean_squared_error: 0.2025\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0257\n",
      "Epoch 134: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0120 - mean_squared_error: 0.0257 - val_loss: 0.1061 - val_mean_squared_error: 0.2158\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0254\n",
      "Epoch 135: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0119 - mean_squared_error: 0.0254 - val_loss: 0.1036 - val_mean_squared_error: 0.2102\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0250\n",
      "Epoch 136: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0117 - mean_squared_error: 0.0250 - val_loss: 0.1075 - val_mean_squared_error: 0.2184\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0250\n",
      "Epoch 137: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0117 - mean_squared_error: 0.0250 - val_loss: 0.1039 - val_mean_squared_error: 0.2113\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0245\n",
      "Epoch 138: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0114 - mean_squared_error: 0.0245 - val_loss: 0.1057 - val_mean_squared_error: 0.2142\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0245\n",
      "Epoch 139: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0114 - mean_squared_error: 0.0245 - val_loss: 0.1060 - val_mean_squared_error: 0.2155\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0240\n",
      "Epoch 140: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0112 - mean_squared_error: 0.0240 - val_loss: 0.1064 - val_mean_squared_error: 0.2158\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0241\n",
      "Epoch 141: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0112 - mean_squared_error: 0.0241 - val_loss: 0.1070 - val_mean_squared_error: 0.2175\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0234\n",
      "Epoch 142: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0109 - mean_squared_error: 0.0234 - val_loss: 0.1068 - val_mean_squared_error: 0.2164\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0231\n",
      "Epoch 143: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0107 - mean_squared_error: 0.0231 - val_loss: 0.1054 - val_mean_squared_error: 0.2135\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0227\n",
      "Epoch 144: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0106 - mean_squared_error: 0.0227 - val_loss: 0.1068 - val_mean_squared_error: 0.2171\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0226\n",
      "Epoch 145: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0105 - mean_squared_error: 0.0226 - val_loss: 0.1064 - val_mean_squared_error: 0.2161\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0233\n",
      "Epoch 146: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0108 - mean_squared_error: 0.0233 - val_loss: 0.1046 - val_mean_squared_error: 0.2118\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0232\n",
      "Epoch 147: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0108 - mean_squared_error: 0.0232 - val_loss: 0.1122 - val_mean_squared_error: 0.2284\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0231\n",
      "Epoch 148: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0107 - mean_squared_error: 0.0231 - val_loss: 0.1065 - val_mean_squared_error: 0.2159\n",
      "Epoch 149/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0223\n",
      "Epoch 149: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0103 - mean_squared_error: 0.0223 - val_loss: 0.1081 - val_mean_squared_error: 0.2198\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0216\n",
      "Epoch 150: val_loss did not improve from 0.08006\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.0100 - mean_squared_error: 0.0216 - val_loss: 0.1074 - val_mean_squared_error: 0.2180\n",
      "5/5 [==============================] - 12s 320ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  408\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4015 - mean_squared_error: 0.9049\n",
      "Epoch 1: val_loss improved from inf to 0.27685, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 97s 5s/step - loss: 0.4015 - mean_squared_error: 0.9049 - val_loss: 0.2769 - val_mean_squared_error: 0.5932\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2343 - mean_squared_error: 0.5058\n",
      "Epoch 2: val_loss improved from 0.27685 to 0.15694, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.2343 - mean_squared_error: 0.5058 - val_loss: 0.1569 - val_mean_squared_error: 0.3236\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1264 - mean_squared_error: 0.2589\n",
      "Epoch 3: val_loss improved from 0.15694 to 0.12727, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.1264 - mean_squared_error: 0.2589 - val_loss: 0.1273 - val_mean_squared_error: 0.2588\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1083 - mean_squared_error: 0.2211\n",
      "Epoch 4: val_loss improved from 0.12727 to 0.12421, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.1083 - mean_squared_error: 0.2211 - val_loss: 0.1242 - val_mean_squared_error: 0.2531\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0972 - mean_squared_error: 0.1985\n",
      "Epoch 5: val_loss improved from 0.12421 to 0.11934, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0972 - mean_squared_error: 0.1985 - val_loss: 0.1193 - val_mean_squared_error: 0.2433\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0916 - mean_squared_error: 0.1872\n",
      "Epoch 6: val_loss improved from 0.11934 to 0.11504, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0916 - mean_squared_error: 0.1872 - val_loss: 0.1150 - val_mean_squared_error: 0.2348\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0876 - mean_squared_error: 0.1794\n",
      "Epoch 7: val_loss improved from 0.11504 to 0.11373, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0876 - mean_squared_error: 0.1794 - val_loss: 0.1137 - val_mean_squared_error: 0.2323\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0853 - mean_squared_error: 0.1745\n",
      "Epoch 8: val_loss did not improve from 0.11373\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0853 - mean_squared_error: 0.1745 - val_loss: 0.1184 - val_mean_squared_error: 0.2424\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0830 - mean_squared_error: 0.1698\n",
      "Epoch 9: val_loss improved from 0.11373 to 0.11109, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0830 - mean_squared_error: 0.1698 - val_loss: 0.1111 - val_mean_squared_error: 0.2273\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0809 - mean_squared_error: 0.1653\n",
      "Epoch 10: val_loss did not improve from 0.11109\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0809 - mean_squared_error: 0.1653 - val_loss: 0.1113 - val_mean_squared_error: 0.2279\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0799 - mean_squared_error: 0.1635\n",
      "Epoch 11: val_loss did not improve from 0.11109\n",
      "9/9 [==============================] - 5332s 666s/step - loss: 0.0799 - mean_squared_error: 0.1635 - val_loss: 0.1134 - val_mean_squared_error: 0.2322\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0784 - mean_squared_error: 0.1603\n",
      "Epoch 12: val_loss improved from 0.11109 to 0.10937, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0784 - mean_squared_error: 0.1603 - val_loss: 0.1094 - val_mean_squared_error: 0.2238\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0773 - mean_squared_error: 0.1584\n",
      "Epoch 13: val_loss improved from 0.10937 to 0.10690, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0773 - mean_squared_error: 0.1584 - val_loss: 0.1069 - val_mean_squared_error: 0.2195\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0745 - mean_squared_error: 0.1522\n",
      "Epoch 14: val_loss did not improve from 0.10690\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0745 - mean_squared_error: 0.1522 - val_loss: 0.1077 - val_mean_squared_error: 0.2202\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0729 - mean_squared_error: 0.1491\n",
      "Epoch 15: val_loss did not improve from 0.10690\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0729 - mean_squared_error: 0.1491 - val_loss: 0.1094 - val_mean_squared_error: 0.2240\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0717 - mean_squared_error: 0.1465\n",
      "Epoch 16: val_loss improved from 0.10690 to 0.10437, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0717 - mean_squared_error: 0.1465 - val_loss: 0.1044 - val_mean_squared_error: 0.2132\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0701 - mean_squared_error: 0.1432\n",
      "Epoch 17: val_loss improved from 0.10437 to 0.09993, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0701 - mean_squared_error: 0.1432 - val_loss: 0.0999 - val_mean_squared_error: 0.2042\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0695 - mean_squared_error: 0.1419\n",
      "Epoch 18: val_loss improved from 0.09993 to 0.09720, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0695 - mean_squared_error: 0.1419 - val_loss: 0.0972 - val_mean_squared_error: 0.1983\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0669 - mean_squared_error: 0.1364\n",
      "Epoch 19: val_loss improved from 0.09720 to 0.09400, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 37s 4s/step - loss: 0.0669 - mean_squared_error: 0.1364 - val_loss: 0.0940 - val_mean_squared_error: 0.1920\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0650 - mean_squared_error: 0.1324\n",
      "Epoch 20: val_loss improved from 0.09400 to 0.08736, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0650 - mean_squared_error: 0.1324 - val_loss: 0.0874 - val_mean_squared_error: 0.1780\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0627 - mean_squared_error: 0.1276\n",
      "Epoch 21: val_loss did not improve from 0.08736\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0627 - mean_squared_error: 0.1276 - val_loss: 0.0898 - val_mean_squared_error: 0.1825\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0595 - mean_squared_error: 0.1213\n",
      "Epoch 22: val_loss improved from 0.08736 to 0.08513, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0595 - mean_squared_error: 0.1213 - val_loss: 0.0851 - val_mean_squared_error: 0.1725\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0596 - mean_squared_error: 0.1215\n",
      "Epoch 23: val_loss did not improve from 0.08513\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0596 - mean_squared_error: 0.1215 - val_loss: 0.0898 - val_mean_squared_error: 0.1830\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0602 - mean_squared_error: 0.1227\n",
      "Epoch 24: val_loss did not improve from 0.08513\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0602 - mean_squared_error: 0.1227 - val_loss: 0.0970 - val_mean_squared_error: 0.1971\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0573 - mean_squared_error: 0.1168\n",
      "Epoch 25: val_loss did not improve from 0.08513\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0573 - mean_squared_error: 0.1168 - val_loss: 0.0995 - val_mean_squared_error: 0.2039\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0583 - mean_squared_error: 0.1190\n",
      "Epoch 26: val_loss did not improve from 0.08513\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0583 - mean_squared_error: 0.1190 - val_loss: 0.0900 - val_mean_squared_error: 0.1835\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0555 - mean_squared_error: 0.1132\n",
      "Epoch 27: val_loss did not improve from 0.08513\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0555 - mean_squared_error: 0.1132 - val_loss: 0.0915 - val_mean_squared_error: 0.1863\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0533 - mean_squared_error: 0.1087\n",
      "Epoch 28: val_loss did not improve from 0.08513\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0533 - mean_squared_error: 0.1087 - val_loss: 0.0894 - val_mean_squared_error: 0.1813\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0516 - mean_squared_error: 0.1053\n",
      "Epoch 29: val_loss did not improve from 0.08513\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0516 - mean_squared_error: 0.1053 - val_loss: 0.0868 - val_mean_squared_error: 0.1763\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0504 - mean_squared_error: 0.1028\n",
      "Epoch 30: val_loss did not improve from 0.08513\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0504 - mean_squared_error: 0.1028 - val_loss: 0.0895 - val_mean_squared_error: 0.1817\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0509 - mean_squared_error: 0.1038\n",
      "Epoch 31: val_loss improved from 0.08513 to 0.07969, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0509 - mean_squared_error: 0.1038 - val_loss: 0.0797 - val_mean_squared_error: 0.1615\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0513 - mean_squared_error: 0.1047\n",
      "Epoch 32: val_loss did not improve from 0.07969\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0513 - mean_squared_error: 0.1047 - val_loss: 0.0841 - val_mean_squared_error: 0.1702\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0497 - mean_squared_error: 0.1012\n",
      "Epoch 33: val_loss did not improve from 0.07969\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0497 - mean_squared_error: 0.1012 - val_loss: 0.0887 - val_mean_squared_error: 0.1800\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0495 - mean_squared_error: 0.1009\n",
      "Epoch 34: val_loss did not improve from 0.07969\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0495 - mean_squared_error: 0.1009 - val_loss: 0.0920 - val_mean_squared_error: 0.1870\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0498 - mean_squared_error: 0.1017\n",
      "Epoch 35: val_loss did not improve from 0.07969\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0498 - mean_squared_error: 0.1017 - val_loss: 0.0903 - val_mean_squared_error: 0.1837\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0477 - mean_squared_error: 0.0973\n",
      "Epoch 36: val_loss did not improve from 0.07969\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0477 - mean_squared_error: 0.0973 - val_loss: 0.0892 - val_mean_squared_error: 0.1807\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0944\n",
      "Epoch 37: val_loss did not improve from 0.07969\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0462 - mean_squared_error: 0.0944 - val_loss: 0.0857 - val_mean_squared_error: 0.1734\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0464 - mean_squared_error: 0.0946\n",
      "Epoch 38: val_loss did not improve from 0.07969\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0464 - mean_squared_error: 0.0946 - val_loss: 0.0849 - val_mean_squared_error: 0.1722\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0455 - mean_squared_error: 0.0930\n",
      "Epoch 39: val_loss did not improve from 0.07969\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0455 - mean_squared_error: 0.0930 - val_loss: 0.0830 - val_mean_squared_error: 0.1677\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.0918\n",
      "Epoch 40: val_loss did not improve from 0.07969\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0450 - mean_squared_error: 0.0918 - val_loss: 0.0818 - val_mean_squared_error: 0.1654\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.0917\n",
      "Epoch 41: val_loss did not improve from 0.07969\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0450 - mean_squared_error: 0.0917 - val_loss: 0.0851 - val_mean_squared_error: 0.1723\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0454 - mean_squared_error: 0.0927\n",
      "Epoch 42: val_loss improved from 0.07969 to 0.07783, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0454 - mean_squared_error: 0.0927 - val_loss: 0.0778 - val_mean_squared_error: 0.1573\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0437 - mean_squared_error: 0.0893\n",
      "Epoch 43: val_loss did not improve from 0.07783\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0437 - mean_squared_error: 0.0893 - val_loss: 0.0848 - val_mean_squared_error: 0.1718\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0438 - mean_squared_error: 0.0895\n",
      "Epoch 44: val_loss did not improve from 0.07783\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0438 - mean_squared_error: 0.0895 - val_loss: 0.0870 - val_mean_squared_error: 0.1761\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0426 - mean_squared_error: 0.0871\n",
      "Epoch 45: val_loss did not improve from 0.07783\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0426 - mean_squared_error: 0.0871 - val_loss: 0.0829 - val_mean_squared_error: 0.1676\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0417 - mean_squared_error: 0.0852\n",
      "Epoch 46: val_loss did not improve from 0.07783\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0417 - mean_squared_error: 0.0852 - val_loss: 0.0813 - val_mean_squared_error: 0.1644\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0430 - mean_squared_error: 0.0878\n",
      "Epoch 47: val_loss did not improve from 0.07783\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0430 - mean_squared_error: 0.0878 - val_loss: 0.0891 - val_mean_squared_error: 0.1801\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0423 - mean_squared_error: 0.0864\n",
      "Epoch 48: val_loss did not improve from 0.07783\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0423 - mean_squared_error: 0.0864 - val_loss: 0.0824 - val_mean_squared_error: 0.1660\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0423 - mean_squared_error: 0.0864\n",
      "Epoch 49: val_loss did not improve from 0.07783\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0423 - mean_squared_error: 0.0864 - val_loss: 0.0808 - val_mean_squared_error: 0.1632\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0407 - mean_squared_error: 0.0831\n",
      "Epoch 50: val_loss did not improve from 0.07783\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0407 - mean_squared_error: 0.0831 - val_loss: 0.0914 - val_mean_squared_error: 0.1851\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0400 - mean_squared_error: 0.0817\n",
      "Epoch 51: val_loss did not improve from 0.07783\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0400 - mean_squared_error: 0.0817 - val_loss: 0.0903 - val_mean_squared_error: 0.1825\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0400 - mean_squared_error: 0.0819\n",
      "Epoch 52: val_loss did not improve from 0.07783\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0400 - mean_squared_error: 0.0819 - val_loss: 0.0853 - val_mean_squared_error: 0.1732\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0406 - mean_squared_error: 0.0831\n",
      "Epoch 53: val_loss did not improve from 0.07783\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0406 - mean_squared_error: 0.0831 - val_loss: 0.0814 - val_mean_squared_error: 0.1641\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0826\n",
      "Epoch 54: val_loss did not improve from 0.07783\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0405 - mean_squared_error: 0.0826 - val_loss: 0.0786 - val_mean_squared_error: 0.1582\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0401 - mean_squared_error: 0.0819\n",
      "Epoch 55: val_loss improved from 0.07783 to 0.07493, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0401 - mean_squared_error: 0.0819 - val_loss: 0.0749 - val_mean_squared_error: 0.1508\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0786\n",
      "Epoch 56: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0384 - mean_squared_error: 0.0786 - val_loss: 0.0832 - val_mean_squared_error: 0.1679\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0800\n",
      "Epoch 57: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0391 - mean_squared_error: 0.0800 - val_loss: 0.0836 - val_mean_squared_error: 0.1686\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0795\n",
      "Epoch 58: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0389 - mean_squared_error: 0.0795 - val_loss: 0.0897 - val_mean_squared_error: 0.1821\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0367 - mean_squared_error: 0.0751\n",
      "Epoch 59: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0367 - mean_squared_error: 0.0751 - val_loss: 0.0845 - val_mean_squared_error: 0.1708\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0356 - mean_squared_error: 0.0729\n",
      "Epoch 60: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0356 - mean_squared_error: 0.0729 - val_loss: 0.0835 - val_mean_squared_error: 0.1685\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0347 - mean_squared_error: 0.0710\n",
      "Epoch 61: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0347 - mean_squared_error: 0.0710 - val_loss: 0.0822 - val_mean_squared_error: 0.1654\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0344 - mean_squared_error: 0.0705\n",
      "Epoch 62: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0344 - mean_squared_error: 0.0705 - val_loss: 0.0831 - val_mean_squared_error: 0.1675\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0337 - mean_squared_error: 0.0690\n",
      "Epoch 63: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0337 - mean_squared_error: 0.0690 - val_loss: 0.0808 - val_mean_squared_error: 0.1627\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0340 - mean_squared_error: 0.0697\n",
      "Epoch 64: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0340 - mean_squared_error: 0.0697 - val_loss: 0.0808 - val_mean_squared_error: 0.1627\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0336 - mean_squared_error: 0.0689\n",
      "Epoch 65: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0336 - mean_squared_error: 0.0689 - val_loss: 0.0860 - val_mean_squared_error: 0.1735\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0329 - mean_squared_error: 0.0675\n",
      "Epoch 66: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0329 - mean_squared_error: 0.0675 - val_loss: 0.0871 - val_mean_squared_error: 0.1756\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0325 - mean_squared_error: 0.0665\n",
      "Epoch 67: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0325 - mean_squared_error: 0.0665 - val_loss: 0.0870 - val_mean_squared_error: 0.1753\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0321 - mean_squared_error: 0.0659\n",
      "Epoch 68: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0321 - mean_squared_error: 0.0659 - val_loss: 0.0793 - val_mean_squared_error: 0.1595\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0313 - mean_squared_error: 0.0643\n",
      "Epoch 69: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0313 - mean_squared_error: 0.0643 - val_loss: 0.0788 - val_mean_squared_error: 0.1588\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0318 - mean_squared_error: 0.0653\n",
      "Epoch 70: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0318 - mean_squared_error: 0.0653 - val_loss: 0.0895 - val_mean_squared_error: 0.1818\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0319 - mean_squared_error: 0.0655\n",
      "Epoch 71: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0319 - mean_squared_error: 0.0655 - val_loss: 0.0872 - val_mean_squared_error: 0.1768\n",
      "Epoch 72/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - ETA: 0s - loss: 0.0301 - mean_squared_error: 0.0619\n",
      "Epoch 72: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0301 - mean_squared_error: 0.0619 - val_loss: 0.0791 - val_mean_squared_error: 0.1594\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0301 - mean_squared_error: 0.0617\n",
      "Epoch 73: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0301 - mean_squared_error: 0.0617 - val_loss: 0.0828 - val_mean_squared_error: 0.1671\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0291 - mean_squared_error: 0.0599\n",
      "Epoch 74: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0291 - mean_squared_error: 0.0599 - val_loss: 0.0855 - val_mean_squared_error: 0.1728\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0285 - mean_squared_error: 0.0586\n",
      "Epoch 75: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0285 - mean_squared_error: 0.0586 - val_loss: 0.0817 - val_mean_squared_error: 0.1645\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0277 - mean_squared_error: 0.0569\n",
      "Epoch 76: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0277 - mean_squared_error: 0.0569 - val_loss: 0.0834 - val_mean_squared_error: 0.1685\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0275 - mean_squared_error: 0.0567\n",
      "Epoch 77: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0275 - mean_squared_error: 0.0567 - val_loss: 0.0883 - val_mean_squared_error: 0.1792\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0278 - mean_squared_error: 0.0573\n",
      "Epoch 78: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0278 - mean_squared_error: 0.0573 - val_loss: 0.0841 - val_mean_squared_error: 0.1698\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0277 - mean_squared_error: 0.0572\n",
      "Epoch 79: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0277 - mean_squared_error: 0.0572 - val_loss: 0.0795 - val_mean_squared_error: 0.1605\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0280 - mean_squared_error: 0.0578\n",
      "Epoch 80: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0280 - mean_squared_error: 0.0578 - val_loss: 0.0787 - val_mean_squared_error: 0.1581\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0278 - mean_squared_error: 0.0573\n",
      "Epoch 81: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0278 - mean_squared_error: 0.0573 - val_loss: 0.0883 - val_mean_squared_error: 0.1786\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0262 - mean_squared_error: 0.0541\n",
      "Epoch 82: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0262 - mean_squared_error: 0.0541 - val_loss: 0.0834 - val_mean_squared_error: 0.1680\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0254 - mean_squared_error: 0.0525\n",
      "Epoch 83: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0254 - mean_squared_error: 0.0525 - val_loss: 0.0855 - val_mean_squared_error: 0.1725\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0248 - mean_squared_error: 0.0512\n",
      "Epoch 84: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0248 - mean_squared_error: 0.0512 - val_loss: 0.0791 - val_mean_squared_error: 0.1597\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0247 - mean_squared_error: 0.0510\n",
      "Epoch 85: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0247 - mean_squared_error: 0.0510 - val_loss: 0.0859 - val_mean_squared_error: 0.1743\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0236 - mean_squared_error: 0.0489\n",
      "Epoch 86: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0236 - mean_squared_error: 0.0489 - val_loss: 0.0832 - val_mean_squared_error: 0.1679\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0230 - mean_squared_error: 0.0478\n",
      "Epoch 87: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0230 - mean_squared_error: 0.0478 - val_loss: 0.0841 - val_mean_squared_error: 0.1697\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0228 - mean_squared_error: 0.0473\n",
      "Epoch 88: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0228 - mean_squared_error: 0.0473 - val_loss: 0.0851 - val_mean_squared_error: 0.1722\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0464\n",
      "Epoch 89: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0224 - mean_squared_error: 0.0464 - val_loss: 0.0903 - val_mean_squared_error: 0.1839\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0223 - mean_squared_error: 0.0463\n",
      "Epoch 90: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0223 - mean_squared_error: 0.0463 - val_loss: 0.0871 - val_mean_squared_error: 0.1762\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0219 - mean_squared_error: 0.0455\n",
      "Epoch 91: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0219 - mean_squared_error: 0.0455 - val_loss: 0.0848 - val_mean_squared_error: 0.1714\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0211 - mean_squared_error: 0.0439\n",
      "Epoch 92: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0211 - mean_squared_error: 0.0439 - val_loss: 0.0881 - val_mean_squared_error: 0.1781\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0442\n",
      "Epoch 93: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0213 - mean_squared_error: 0.0442 - val_loss: 0.0905 - val_mean_squared_error: 0.1829\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0208 - mean_squared_error: 0.0432\n",
      "Epoch 94: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0208 - mean_squared_error: 0.0432 - val_loss: 0.0861 - val_mean_squared_error: 0.1734\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0421\n",
      "Epoch 95: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0202 - mean_squared_error: 0.0421 - val_loss: 0.0880 - val_mean_squared_error: 0.1780\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0194 - mean_squared_error: 0.0405\n",
      "Epoch 96: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0194 - mean_squared_error: 0.0405 - val_loss: 0.0854 - val_mean_squared_error: 0.1729\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.0400\n",
      "Epoch 97: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0192 - mean_squared_error: 0.0400 - val_loss: 0.0870 - val_mean_squared_error: 0.1760\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.0392\n",
      "Epoch 98: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0188 - mean_squared_error: 0.0392 - val_loss: 0.0994 - val_mean_squared_error: 0.2021\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0394\n",
      "Epoch 99: val_loss did not improve from 0.07493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 37s 4s/step - loss: 0.0189 - mean_squared_error: 0.0394 - val_loss: 0.0844 - val_mean_squared_error: 0.1710\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0387\n",
      "Epoch 100: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0185 - mean_squared_error: 0.0387 - val_loss: 0.0923 - val_mean_squared_error: 0.1873\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0182 - mean_squared_error: 0.0380\n",
      "Epoch 101: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0182 - mean_squared_error: 0.0380 - val_loss: 0.0961 - val_mean_squared_error: 0.1948\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0178 - mean_squared_error: 0.0373\n",
      "Epoch 102: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0178 - mean_squared_error: 0.0373 - val_loss: 0.0916 - val_mean_squared_error: 0.1860\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0179 - mean_squared_error: 0.0375\n",
      "Epoch 103: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0179 - mean_squared_error: 0.0375 - val_loss: 0.0915 - val_mean_squared_error: 0.1850\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0365\n",
      "Epoch 104: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0174 - mean_squared_error: 0.0365 - val_loss: 0.1000 - val_mean_squared_error: 0.2036\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0170 - mean_squared_error: 0.0358\n",
      "Epoch 105: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0170 - mean_squared_error: 0.0358 - val_loss: 0.0917 - val_mean_squared_error: 0.1862\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0351\n",
      "Epoch 106: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0167 - mean_squared_error: 0.0351 - val_loss: 0.0888 - val_mean_squared_error: 0.1800\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0347\n",
      "Epoch 107: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0165 - mean_squared_error: 0.0347 - val_loss: 0.0937 - val_mean_squared_error: 0.1915\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0347\n",
      "Epoch 108: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0165 - mean_squared_error: 0.0347 - val_loss: 0.0930 - val_mean_squared_error: 0.1881\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0343\n",
      "Epoch 109: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0163 - mean_squared_error: 0.0343 - val_loss: 0.0913 - val_mean_squared_error: 0.1860\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0338\n",
      "Epoch 110: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0161 - mean_squared_error: 0.0338 - val_loss: 0.0968 - val_mean_squared_error: 0.1966\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0326\n",
      "Epoch 111: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0155 - mean_squared_error: 0.0326 - val_loss: 0.0952 - val_mean_squared_error: 0.1933\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0322\n",
      "Epoch 112: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0152 - mean_squared_error: 0.0322 - val_loss: 0.0925 - val_mean_squared_error: 0.1878\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0316\n",
      "Epoch 113: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0149 - mean_squared_error: 0.0316 - val_loss: 0.0966 - val_mean_squared_error: 0.1964\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0309\n",
      "Epoch 114: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0146 - mean_squared_error: 0.0309 - val_loss: 0.0956 - val_mean_squared_error: 0.1942\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0311\n",
      "Epoch 115: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0147 - mean_squared_error: 0.0311 - val_loss: 0.0993 - val_mean_squared_error: 0.2028\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0313\n",
      "Epoch 116: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0148 - mean_squared_error: 0.0313 - val_loss: 0.0973 - val_mean_squared_error: 0.1977\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0306\n",
      "Epoch 117: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0144 - mean_squared_error: 0.0306 - val_loss: 0.0937 - val_mean_squared_error: 0.1916\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0297\n",
      "Epoch 118: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0140 - mean_squared_error: 0.0297 - val_loss: 0.0994 - val_mean_squared_error: 0.2018\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0301\n",
      "Epoch 119: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0142 - mean_squared_error: 0.0301 - val_loss: 0.0989 - val_mean_squared_error: 0.2017\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0291\n",
      "Epoch 120: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0137 - mean_squared_error: 0.0291 - val_loss: 0.0947 - val_mean_squared_error: 0.1926\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0287\n",
      "Epoch 121: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0135 - mean_squared_error: 0.0287 - val_loss: 0.0958 - val_mean_squared_error: 0.1947\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0279\n",
      "Epoch 122: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0131 - mean_squared_error: 0.0279 - val_loss: 0.1013 - val_mean_squared_error: 0.2074\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0281\n",
      "Epoch 123: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0132 - mean_squared_error: 0.0281 - val_loss: 0.0964 - val_mean_squared_error: 0.1959\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0277\n",
      "Epoch 124: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0130 - mean_squared_error: 0.0277 - val_loss: 0.1002 - val_mean_squared_error: 0.2046\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0272\n",
      "Epoch 125: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0128 - mean_squared_error: 0.0272 - val_loss: 0.0969 - val_mean_squared_error: 0.1976\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0264\n",
      "Epoch 126: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0123 - mean_squared_error: 0.0264 - val_loss: 0.0968 - val_mean_squared_error: 0.1967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0258\n",
      "Epoch 127: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0120 - mean_squared_error: 0.0258 - val_loss: 0.0993 - val_mean_squared_error: 0.2026\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0253\n",
      "Epoch 128: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0118 - mean_squared_error: 0.0253 - val_loss: 0.0975 - val_mean_squared_error: 0.1985\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0115 - mean_squared_error: 0.0246\n",
      "Epoch 129: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0115 - mean_squared_error: 0.0246 - val_loss: 0.0987 - val_mean_squared_error: 0.2009\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0244\n",
      "Epoch 130: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0114 - mean_squared_error: 0.0244 - val_loss: 0.0954 - val_mean_squared_error: 0.1936\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0243\n",
      "Epoch 131: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0113 - mean_squared_error: 0.0243 - val_loss: 0.0976 - val_mean_squared_error: 0.1985\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0240\n",
      "Epoch 132: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0111 - mean_squared_error: 0.0240 - val_loss: 0.0976 - val_mean_squared_error: 0.1990\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0233\n",
      "Epoch 133: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0108 - mean_squared_error: 0.0233 - val_loss: 0.0962 - val_mean_squared_error: 0.1957\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0232\n",
      "Epoch 134: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0107 - mean_squared_error: 0.0232 - val_loss: 0.1023 - val_mean_squared_error: 0.2091\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0235\n",
      "Epoch 135: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0109 - mean_squared_error: 0.0235 - val_loss: 0.0962 - val_mean_squared_error: 0.1962\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0242\n",
      "Epoch 136: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0112 - mean_squared_error: 0.0242 - val_loss: 0.1038 - val_mean_squared_error: 0.2126\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0235\n",
      "Epoch 137: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0109 - mean_squared_error: 0.0235 - val_loss: 0.0990 - val_mean_squared_error: 0.2022\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0234\n",
      "Epoch 138: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0108 - mean_squared_error: 0.0234 - val_loss: 0.1023 - val_mean_squared_error: 0.2091\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0229\n",
      "Epoch 139: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0106 - mean_squared_error: 0.0229 - val_loss: 0.1019 - val_mean_squared_error: 0.2074\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0221\n",
      "Epoch 140: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0102 - mean_squared_error: 0.0221 - val_loss: 0.0994 - val_mean_squared_error: 0.2025\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0218\n",
      "Epoch 141: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0100 - mean_squared_error: 0.0218 - val_loss: 0.1004 - val_mean_squared_error: 0.2043\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0219\n",
      "Epoch 142: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0100 - mean_squared_error: 0.0219 - val_loss: 0.1024 - val_mean_squared_error: 0.2086\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0215\n",
      "Epoch 143: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0099 - mean_squared_error: 0.0215 - val_loss: 0.0999 - val_mean_squared_error: 0.2036\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0211\n",
      "Epoch 144: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0097 - mean_squared_error: 0.0211 - val_loss: 0.0997 - val_mean_squared_error: 0.2031\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0209\n",
      "Epoch 145: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0096 - mean_squared_error: 0.0209 - val_loss: 0.1028 - val_mean_squared_error: 0.2095\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0207\n",
      "Epoch 146: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0095 - mean_squared_error: 0.0207 - val_loss: 0.1014 - val_mean_squared_error: 0.2069\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0205\n",
      "Epoch 147: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0094 - mean_squared_error: 0.0205 - val_loss: 0.1031 - val_mean_squared_error: 0.2104\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0203\n",
      "Epoch 148: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0093 - mean_squared_error: 0.0203 - val_loss: 0.1009 - val_mean_squared_error: 0.2061\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0204\n",
      "Epoch 149: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0093 - mean_squared_error: 0.0204 - val_loss: 0.1017 - val_mean_squared_error: 0.2074\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0092 - mean_squared_error: 0.0201\n",
      "Epoch 150: val_loss did not improve from 0.07493\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0092 - mean_squared_error: 0.0201 - val_loss: 0.1028 - val_mean_squared_error: 0.2101\n",
      "5/5 [==============================] - 15s 355ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  432\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3945 - mean_squared_error: 0.8885\n",
      "Epoch 1: val_loss improved from inf to 0.29101, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 100s 5s/step - loss: 0.3945 - mean_squared_error: 0.8885 - val_loss: 0.2910 - val_mean_squared_error: 0.6283\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2302 - mean_squared_error: 0.4913\n",
      "Epoch 2: val_loss improved from 0.29101 to 0.15744, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 38s 4s/step - loss: 0.2302 - mean_squared_error: 0.4913 - val_loss: 0.1574 - val_mean_squared_error: 0.3232\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1232 - mean_squared_error: 0.2523\n",
      "Epoch 3: val_loss improved from 0.15744 to 0.12964, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.1232 - mean_squared_error: 0.2523 - val_loss: 0.1296 - val_mean_squared_error: 0.2643\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1049 - mean_squared_error: 0.2144\n",
      "Epoch 4: val_loss improved from 0.12964 to 0.12852, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.1049 - mean_squared_error: 0.2144 - val_loss: 0.1285 - val_mean_squared_error: 0.2621\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0990 - mean_squared_error: 0.2018\n",
      "Epoch 5: val_loss improved from 0.12852 to 0.12123, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0990 - mean_squared_error: 0.2018 - val_loss: 0.1212 - val_mean_squared_error: 0.2466\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0954 - mean_squared_error: 0.1949\n",
      "Epoch 6: val_loss improved from 0.12123 to 0.11552, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0954 - mean_squared_error: 0.1949 - val_loss: 0.1155 - val_mean_squared_error: 0.2347\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0921 - mean_squared_error: 0.1884\n",
      "Epoch 7: val_loss did not improve from 0.11552\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0921 - mean_squared_error: 0.1884 - val_loss: 0.1287 - val_mean_squared_error: 0.2643\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0899 - mean_squared_error: 0.1839\n",
      "Epoch 8: val_loss did not improve from 0.11552\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0899 - mean_squared_error: 0.1839 - val_loss: 0.1214 - val_mean_squared_error: 0.2490\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0880 - mean_squared_error: 0.1798\n",
      "Epoch 9: val_loss did not improve from 0.11552\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0880 - mean_squared_error: 0.1798 - val_loss: 0.1170 - val_mean_squared_error: 0.2397\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0839 - mean_squared_error: 0.1718\n",
      "Epoch 10: val_loss did not improve from 0.11552\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0839 - mean_squared_error: 0.1718 - val_loss: 0.1186 - val_mean_squared_error: 0.2432\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0829 - mean_squared_error: 0.1694\n",
      "Epoch 11: val_loss did not improve from 0.11552\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0829 - mean_squared_error: 0.1694 - val_loss: 0.1180 - val_mean_squared_error: 0.2417\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0808 - mean_squared_error: 0.1651\n",
      "Epoch 12: val_loss improved from 0.11552 to 0.10985, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0808 - mean_squared_error: 0.1651 - val_loss: 0.1099 - val_mean_squared_error: 0.2239\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0798 - mean_squared_error: 0.1629\n",
      "Epoch 13: val_loss did not improve from 0.10985\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0798 - mean_squared_error: 0.1629 - val_loss: 0.1117 - val_mean_squared_error: 0.2281\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0786 - mean_squared_error: 0.1610\n",
      "Epoch 14: val_loss improved from 0.10985 to 0.10646, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0786 - mean_squared_error: 0.1610 - val_loss: 0.1065 - val_mean_squared_error: 0.2163\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0776 - mean_squared_error: 0.1585\n",
      "Epoch 15: val_loss did not improve from 0.10646\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0776 - mean_squared_error: 0.1585 - val_loss: 0.1079 - val_mean_squared_error: 0.2195\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0751 - mean_squared_error: 0.1536\n",
      "Epoch 16: val_loss improved from 0.10646 to 0.10480, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0751 - mean_squared_error: 0.1536 - val_loss: 0.1048 - val_mean_squared_error: 0.2128\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0718 - mean_squared_error: 0.1465\n",
      "Epoch 17: val_loss improved from 0.10480 to 0.10430, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0718 - mean_squared_error: 0.1465 - val_loss: 0.1043 - val_mean_squared_error: 0.2114\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0715 - mean_squared_error: 0.1461\n",
      "Epoch 18: val_loss did not improve from 0.10430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0715 - mean_squared_error: 0.1461 - val_loss: 0.1186 - val_mean_squared_error: 0.2422\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0698 - mean_squared_error: 0.1425\n",
      "Epoch 19: val_loss improved from 0.10430 to 0.10425, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0698 - mean_squared_error: 0.1425 - val_loss: 0.1043 - val_mean_squared_error: 0.2117\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0670 - mean_squared_error: 0.1366\n",
      "Epoch 20: val_loss improved from 0.10425 to 0.09270, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0670 - mean_squared_error: 0.1366 - val_loss: 0.0927 - val_mean_squared_error: 0.1879\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0664 - mean_squared_error: 0.1352\n",
      "Epoch 21: val_loss did not improve from 0.09270\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0664 - mean_squared_error: 0.1352 - val_loss: 0.0928 - val_mean_squared_error: 0.1882\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0633 - mean_squared_error: 0.1291\n",
      "Epoch 22: val_loss improved from 0.09270 to 0.08419, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0633 - mean_squared_error: 0.1291 - val_loss: 0.0842 - val_mean_squared_error: 0.1710\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0613 - mean_squared_error: 0.1251\n",
      "Epoch 23: val_loss did not improve from 0.08419\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0613 - mean_squared_error: 0.1251 - val_loss: 0.0850 - val_mean_squared_error: 0.1719\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0581 - mean_squared_error: 0.1186\n",
      "Epoch 24: val_loss did not improve from 0.08419\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0581 - mean_squared_error: 0.1186 - val_loss: 0.0930 - val_mean_squared_error: 0.1882\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0573 - mean_squared_error: 0.1169\n",
      "Epoch 25: val_loss did not improve from 0.08419\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0573 - mean_squared_error: 0.1169 - val_loss: 0.0965 - val_mean_squared_error: 0.1966\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0570 - mean_squared_error: 0.1161\n",
      "Epoch 26: val_loss did not improve from 0.08419\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0570 - mean_squared_error: 0.1161 - val_loss: 0.1023 - val_mean_squared_error: 0.2087\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0565 - mean_squared_error: 0.1152\n",
      "Epoch 27: val_loss improved from 0.08419 to 0.07741, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0565 - mean_squared_error: 0.1152 - val_loss: 0.0774 - val_mean_squared_error: 0.1562\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0553 - mean_squared_error: 0.1127\n",
      "Epoch 28: val_loss did not improve from 0.07741\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0553 - mean_squared_error: 0.1127 - val_loss: 0.0778 - val_mean_squared_error: 0.1572\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0526 - mean_squared_error: 0.1074\n",
      "Epoch 29: val_loss did not improve from 0.07741\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0526 - mean_squared_error: 0.1074 - val_loss: 0.0835 - val_mean_squared_error: 0.1694\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0516 - mean_squared_error: 0.1052\n",
      "Epoch 30: val_loss improved from 0.07741 to 0.07731, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0516 - mean_squared_error: 0.1052 - val_loss: 0.0773 - val_mean_squared_error: 0.1559\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0491 - mean_squared_error: 0.1000\n",
      "Epoch 31: val_loss did not improve from 0.07731\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0491 - mean_squared_error: 0.1000 - val_loss: 0.0876 - val_mean_squared_error: 0.1771\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0481 - mean_squared_error: 0.0983\n",
      "Epoch 32: val_loss did not improve from 0.07731\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0481 - mean_squared_error: 0.0983 - val_loss: 0.0884 - val_mean_squared_error: 0.1788\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0479 - mean_squared_error: 0.0977\n",
      "Epoch 33: val_loss did not improve from 0.07731\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0479 - mean_squared_error: 0.0977 - val_loss: 0.0880 - val_mean_squared_error: 0.1786\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0476 - mean_squared_error: 0.0972\n",
      "Epoch 34: val_loss did not improve from 0.07731\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0476 - mean_squared_error: 0.0972 - val_loss: 0.0869 - val_mean_squared_error: 0.1757\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0466 - mean_squared_error: 0.0951\n",
      "Epoch 35: val_loss did not improve from 0.07731\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0466 - mean_squared_error: 0.0951 - val_loss: 0.0780 - val_mean_squared_error: 0.1572\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0463 - mean_squared_error: 0.0946\n",
      "Epoch 36: val_loss did not improve from 0.07731\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0463 - mean_squared_error: 0.0946 - val_loss: 0.0818 - val_mean_squared_error: 0.1651\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0461 - mean_squared_error: 0.0940\n",
      "Epoch 37: val_loss did not improve from 0.07731\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0461 - mean_squared_error: 0.0940 - val_loss: 0.0776 - val_mean_squared_error: 0.1565\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0442 - mean_squared_error: 0.0903\n",
      "Epoch 38: val_loss improved from 0.07731 to 0.07430, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0442 - mean_squared_error: 0.0903 - val_loss: 0.0743 - val_mean_squared_error: 0.1496\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0449 - mean_squared_error: 0.0917\n",
      "Epoch 39: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0449 - mean_squared_error: 0.0917 - val_loss: 0.0831 - val_mean_squared_error: 0.1680\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0437 - mean_squared_error: 0.0891\n",
      "Epoch 40: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0437 - mean_squared_error: 0.0891 - val_loss: 0.0850 - val_mean_squared_error: 0.1717\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0427 - mean_squared_error: 0.0871\n",
      "Epoch 41: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0427 - mean_squared_error: 0.0871 - val_loss: 0.0830 - val_mean_squared_error: 0.1671\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0416 - mean_squared_error: 0.0850\n",
      "Epoch 42: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0416 - mean_squared_error: 0.0850 - val_loss: 0.0766 - val_mean_squared_error: 0.1542\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0814\n",
      "Epoch 43: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0398 - mean_squared_error: 0.0814 - val_loss: 0.0818 - val_mean_squared_error: 0.1646\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0396 - mean_squared_error: 0.0810\n",
      "Epoch 44: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0396 - mean_squared_error: 0.0810 - val_loss: 0.0752 - val_mean_squared_error: 0.1512\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0803\n",
      "Epoch 45: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0393 - mean_squared_error: 0.0803 - val_loss: 0.0804 - val_mean_squared_error: 0.1624\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0795\n",
      "Epoch 46: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0389 - mean_squared_error: 0.0795 - val_loss: 0.0826 - val_mean_squared_error: 0.1666\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0796\n",
      "Epoch 47: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0389 - mean_squared_error: 0.0796 - val_loss: 0.0749 - val_mean_squared_error: 0.1507\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0377 - mean_squared_error: 0.0772\n",
      "Epoch 48: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0377 - mean_squared_error: 0.0772 - val_loss: 0.0790 - val_mean_squared_error: 0.1591\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0374 - mean_squared_error: 0.0765\n",
      "Epoch 49: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0374 - mean_squared_error: 0.0765 - val_loss: 0.0790 - val_mean_squared_error: 0.1592\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0373 - mean_squared_error: 0.0764\n",
      "Epoch 50: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0373 - mean_squared_error: 0.0764 - val_loss: 0.0802 - val_mean_squared_error: 0.1614\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - ETA: 0s - loss: 0.0362 - mean_squared_error: 0.0740\n",
      "Epoch 51: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0362 - mean_squared_error: 0.0740 - val_loss: 0.0770 - val_mean_squared_error: 0.1549\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0368 - mean_squared_error: 0.0753\n",
      "Epoch 52: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0368 - mean_squared_error: 0.0753 - val_loss: 0.0799 - val_mean_squared_error: 0.1618\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0816\n",
      "Epoch 53: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0398 - mean_squared_error: 0.0816 - val_loss: 0.0863 - val_mean_squared_error: 0.1762\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0360 - mean_squared_error: 0.0738\n",
      "Epoch 54: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0360 - mean_squared_error: 0.0738 - val_loss: 0.0853 - val_mean_squared_error: 0.1719\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0348 - mean_squared_error: 0.0714\n",
      "Epoch 55: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0348 - mean_squared_error: 0.0714 - val_loss: 0.0806 - val_mean_squared_error: 0.1622\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0343 - mean_squared_error: 0.0703\n",
      "Epoch 56: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0343 - mean_squared_error: 0.0703 - val_loss: 0.0834 - val_mean_squared_error: 0.1685\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0338 - mean_squared_error: 0.0693\n",
      "Epoch 57: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0338 - mean_squared_error: 0.0693 - val_loss: 0.0782 - val_mean_squared_error: 0.1577\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0326 - mean_squared_error: 0.0669\n",
      "Epoch 58: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0326 - mean_squared_error: 0.0669 - val_loss: 0.0834 - val_mean_squared_error: 0.1681\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0320 - mean_squared_error: 0.0657\n",
      "Epoch 59: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0320 - mean_squared_error: 0.0657 - val_loss: 0.0820 - val_mean_squared_error: 0.1652\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0315 - mean_squared_error: 0.0647\n",
      "Epoch 60: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0315 - mean_squared_error: 0.0647 - val_loss: 0.0811 - val_mean_squared_error: 0.1634\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0315 - mean_squared_error: 0.0647\n",
      "Epoch 61: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0315 - mean_squared_error: 0.0647 - val_loss: 0.0811 - val_mean_squared_error: 0.1632\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0313 - mean_squared_error: 0.0641\n",
      "Epoch 62: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0313 - mean_squared_error: 0.0641 - val_loss: 0.0824 - val_mean_squared_error: 0.1665\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0307 - mean_squared_error: 0.0630\n",
      "Epoch 63: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0307 - mean_squared_error: 0.0630 - val_loss: 0.0830 - val_mean_squared_error: 0.1671\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0298 - mean_squared_error: 0.0613\n",
      "Epoch 64: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0298 - mean_squared_error: 0.0613 - val_loss: 0.0809 - val_mean_squared_error: 0.1630\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0600\n",
      "Epoch 65: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0292 - mean_squared_error: 0.0600 - val_loss: 0.0811 - val_mean_squared_error: 0.1633\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0288 - mean_squared_error: 0.0592\n",
      "Epoch 66: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0288 - mean_squared_error: 0.0592 - val_loss: 0.0824 - val_mean_squared_error: 0.1659\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0601\n",
      "Epoch 67: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0292 - mean_squared_error: 0.0601 - val_loss: 0.0940 - val_mean_squared_error: 0.1907\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0294 - mean_squared_error: 0.0605\n",
      "Epoch 68: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0294 - mean_squared_error: 0.0605 - val_loss: 0.0784 - val_mean_squared_error: 0.1583\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0284 - mean_squared_error: 0.0584\n",
      "Epoch 69: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0284 - mean_squared_error: 0.0584 - val_loss: 0.0825 - val_mean_squared_error: 0.1666\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0559\n",
      "Epoch 70: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0271 - mean_squared_error: 0.0559 - val_loss: 0.0892 - val_mean_squared_error: 0.1802\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0558\n",
      "Epoch 71: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0271 - mean_squared_error: 0.0558 - val_loss: 0.0849 - val_mean_squared_error: 0.1711\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0269 - mean_squared_error: 0.0554\n",
      "Epoch 72: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0269 - mean_squared_error: 0.0554 - val_loss: 0.0842 - val_mean_squared_error: 0.1702\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0270 - mean_squared_error: 0.0557\n",
      "Epoch 73: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0270 - mean_squared_error: 0.0557 - val_loss: 0.0863 - val_mean_squared_error: 0.1742\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0254 - mean_squared_error: 0.0525\n",
      "Epoch 74: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0254 - mean_squared_error: 0.0525 - val_loss: 0.0877 - val_mean_squared_error: 0.1767\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0253 - mean_squared_error: 0.0523\n",
      "Epoch 75: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0253 - mean_squared_error: 0.0523 - val_loss: 0.0863 - val_mean_squared_error: 0.1739\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0248 - mean_squared_error: 0.0514\n",
      "Epoch 76: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0248 - mean_squared_error: 0.0514 - val_loss: 0.0899 - val_mean_squared_error: 0.1819\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0238 - mean_squared_error: 0.0494\n",
      "Epoch 77: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0238 - mean_squared_error: 0.0494 - val_loss: 0.0804 - val_mean_squared_error: 0.1621\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0239 - mean_squared_error: 0.0494\n",
      "Epoch 78: val_loss did not improve from 0.07430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 38s 4s/step - loss: 0.0239 - mean_squared_error: 0.0494 - val_loss: 0.0876 - val_mean_squared_error: 0.1769\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0230 - mean_squared_error: 0.0477\n",
      "Epoch 79: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0230 - mean_squared_error: 0.0477 - val_loss: 0.0890 - val_mean_squared_error: 0.1796\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0226 - mean_squared_error: 0.0468\n",
      "Epoch 80: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0226 - mean_squared_error: 0.0468 - val_loss: 0.0866 - val_mean_squared_error: 0.1745\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0231 - mean_squared_error: 0.0478\n",
      "Epoch 81: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0231 - mean_squared_error: 0.0478 - val_loss: 0.0831 - val_mean_squared_error: 0.1675\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0229 - mean_squared_error: 0.0475\n",
      "Epoch 82: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0229 - mean_squared_error: 0.0475 - val_loss: 0.0850 - val_mean_squared_error: 0.1719\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0233 - mean_squared_error: 0.0483\n",
      "Epoch 83: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0233 - mean_squared_error: 0.0483 - val_loss: 0.0881 - val_mean_squared_error: 0.1780\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0222 - mean_squared_error: 0.0462\n",
      "Epoch 84: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0222 - mean_squared_error: 0.0462 - val_loss: 0.0918 - val_mean_squared_error: 0.1854\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0222 - mean_squared_error: 0.0461\n",
      "Epoch 85: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0222 - mean_squared_error: 0.0461 - val_loss: 0.0950 - val_mean_squared_error: 0.1919\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0221 - mean_squared_error: 0.0459\n",
      "Epoch 86: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0221 - mean_squared_error: 0.0459 - val_loss: 0.0944 - val_mean_squared_error: 0.1909\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0217 - mean_squared_error: 0.0453\n",
      "Epoch 87: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0217 - mean_squared_error: 0.0453 - val_loss: 0.0863 - val_mean_squared_error: 0.1741\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0203 - mean_squared_error: 0.0425\n",
      "Epoch 88: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0203 - mean_squared_error: 0.0425 - val_loss: 0.0873 - val_mean_squared_error: 0.1764\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0200 - mean_squared_error: 0.0418\n",
      "Epoch 89: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0200 - mean_squared_error: 0.0418 - val_loss: 0.0873 - val_mean_squared_error: 0.1763\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0197 - mean_squared_error: 0.0411\n",
      "Epoch 90: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0197 - mean_squared_error: 0.0411 - val_loss: 0.0917 - val_mean_squared_error: 0.1853\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0396\n",
      "Epoch 91: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 39s 4s/step - loss: 0.0189 - mean_squared_error: 0.0396 - val_loss: 0.0916 - val_mean_squared_error: 0.1855\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0184 - mean_squared_error: 0.0384\n",
      "Epoch 92: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0184 - mean_squared_error: 0.0384 - val_loss: 0.0912 - val_mean_squared_error: 0.1841\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0386\n",
      "Epoch 93: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0185 - mean_squared_error: 0.0386 - val_loss: 0.0959 - val_mean_squared_error: 0.1944\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0378\n",
      "Epoch 94: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 39s 4s/step - loss: 0.0181 - mean_squared_error: 0.0378 - val_loss: 0.0899 - val_mean_squared_error: 0.1815\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0179 - mean_squared_error: 0.0375\n",
      "Epoch 95: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0179 - mean_squared_error: 0.0375 - val_loss: 0.0908 - val_mean_squared_error: 0.1840\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0176 - mean_squared_error: 0.0370\n",
      "Epoch 96: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0176 - mean_squared_error: 0.0370 - val_loss: 0.0970 - val_mean_squared_error: 0.1966\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0367\n",
      "Epoch 97: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 39s 4s/step - loss: 0.0175 - mean_squared_error: 0.0367 - val_loss: 0.0915 - val_mean_squared_error: 0.1851\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0354\n",
      "Epoch 98: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 39s 4s/step - loss: 0.0168 - mean_squared_error: 0.0354 - val_loss: 0.0981 - val_mean_squared_error: 0.1987\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0351\n",
      "Epoch 99: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 39s 4s/step - loss: 0.0166 - mean_squared_error: 0.0351 - val_loss: 0.0938 - val_mean_squared_error: 0.1899\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0348\n",
      "Epoch 100: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0166 - mean_squared_error: 0.0348 - val_loss: 0.0953 - val_mean_squared_error: 0.1931\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0350\n",
      "Epoch 101: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0166 - mean_squared_error: 0.0350 - val_loss: 0.0925 - val_mean_squared_error: 0.1872\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0344\n",
      "Epoch 102: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0163 - mean_squared_error: 0.0344 - val_loss: 0.0963 - val_mean_squared_error: 0.1953\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0344\n",
      "Epoch 103: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0163 - mean_squared_error: 0.0344 - val_loss: 0.0964 - val_mean_squared_error: 0.1957\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0342\n",
      "Epoch 104: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0163 - mean_squared_error: 0.0342 - val_loss: 0.0989 - val_mean_squared_error: 0.2006\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0156 - mean_squared_error: 0.0330\n",
      "Epoch 105: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 39s 4s/step - loss: 0.0156 - mean_squared_error: 0.0330 - val_loss: 0.0968 - val_mean_squared_error: 0.1959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0332\n",
      "Epoch 106: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0157 - mean_squared_error: 0.0332 - val_loss: 0.0945 - val_mean_squared_error: 0.1915\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0156 - mean_squared_error: 0.0329\n",
      "Epoch 107: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0156 - mean_squared_error: 0.0329 - val_loss: 0.0945 - val_mean_squared_error: 0.1920\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0326\n",
      "Epoch 108: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 39s 4s/step - loss: 0.0154 - mean_squared_error: 0.0326 - val_loss: 0.0966 - val_mean_squared_error: 0.1958\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0328\n",
      "Epoch 109: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0155 - mean_squared_error: 0.0328 - val_loss: 0.0997 - val_mean_squared_error: 0.2022\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0320\n",
      "Epoch 110: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0151 - mean_squared_error: 0.0320 - val_loss: 0.0976 - val_mean_squared_error: 0.1981\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0304\n",
      "Epoch 111: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0143 - mean_squared_error: 0.0304 - val_loss: 0.0989 - val_mean_squared_error: 0.2010\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0303\n",
      "Epoch 112: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 39s 4s/step - loss: 0.0142 - mean_squared_error: 0.0303 - val_loss: 0.0968 - val_mean_squared_error: 0.1962\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0297\n",
      "Epoch 113: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0139 - mean_squared_error: 0.0297 - val_loss: 0.0960 - val_mean_squared_error: 0.1945\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0285\n",
      "Epoch 114: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0133 - mean_squared_error: 0.0285 - val_loss: 0.0980 - val_mean_squared_error: 0.1989\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0284\n",
      "Epoch 115: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0132 - mean_squared_error: 0.0284 - val_loss: 0.0990 - val_mean_squared_error: 0.2010\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0277\n",
      "Epoch 116: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0129 - mean_squared_error: 0.0277 - val_loss: 0.1003 - val_mean_squared_error: 0.2036\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0276\n",
      "Epoch 117: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 39s 4s/step - loss: 0.0129 - mean_squared_error: 0.0276 - val_loss: 0.1012 - val_mean_squared_error: 0.2055\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0276\n",
      "Epoch 118: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0129 - mean_squared_error: 0.0276 - val_loss: 0.0988 - val_mean_squared_error: 0.2007\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0267\n",
      "Epoch 119: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0124 - mean_squared_error: 0.0267 - val_loss: 0.0998 - val_mean_squared_error: 0.2030\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0264\n",
      "Epoch 120: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0123 - mean_squared_error: 0.0264 - val_loss: 0.0995 - val_mean_squared_error: 0.2020\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0267\n",
      "Epoch 121: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0124 - mean_squared_error: 0.0267 - val_loss: 0.1013 - val_mean_squared_error: 0.2059\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0266\n",
      "Epoch 122: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0124 - mean_squared_error: 0.0266 - val_loss: 0.0953 - val_mean_squared_error: 0.1928\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0261\n",
      "Epoch 123: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0122 - mean_squared_error: 0.0261 - val_loss: 0.1024 - val_mean_squared_error: 0.2081\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0255\n",
      "Epoch 124: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0119 - mean_squared_error: 0.0255 - val_loss: 0.0998 - val_mean_squared_error: 0.2025\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0254\n",
      "Epoch 125: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0118 - mean_squared_error: 0.0254 - val_loss: 0.1004 - val_mean_squared_error: 0.2037\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0249\n",
      "Epoch 126: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0116 - mean_squared_error: 0.0249 - val_loss: 0.1023 - val_mean_squared_error: 0.2082\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0246\n",
      "Epoch 127: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0114 - mean_squared_error: 0.0246 - val_loss: 0.1014 - val_mean_squared_error: 0.2059\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0244\n",
      "Epoch 128: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0113 - mean_squared_error: 0.0244 - val_loss: 0.1028 - val_mean_squared_error: 0.2094\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0240\n",
      "Epoch 129: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 39s 4s/step - loss: 0.0111 - mean_squared_error: 0.0240 - val_loss: 0.0992 - val_mean_squared_error: 0.2012\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0239\n",
      "Epoch 130: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0110 - mean_squared_error: 0.0239 - val_loss: 0.1065 - val_mean_squared_error: 0.2170\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0234\n",
      "Epoch 131: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0108 - mean_squared_error: 0.0234 - val_loss: 0.1011 - val_mean_squared_error: 0.2058\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0231\n",
      "Epoch 132: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0107 - mean_squared_error: 0.0231 - val_loss: 0.1054 - val_mean_squared_error: 0.2146\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0233\n",
      "Epoch 133: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0108 - mean_squared_error: 0.0233 - val_loss: 0.1039 - val_mean_squared_error: 0.2114\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0236\n",
      "Epoch 134: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 39s 4s/step - loss: 0.0109 - mean_squared_error: 0.0236 - val_loss: 0.1020 - val_mean_squared_error: 0.2075\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0228\n",
      "Epoch 135: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0105 - mean_squared_error: 0.0228 - val_loss: 0.1028 - val_mean_squared_error: 0.2089\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0226\n",
      "Epoch 136: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0104 - mean_squared_error: 0.0226 - val_loss: 0.1005 - val_mean_squared_error: 0.2040\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0222\n",
      "Epoch 137: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.0102 - mean_squared_error: 0.0222 - val_loss: 0.1020 - val_mean_squared_error: 0.2076\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0219\n",
      "Epoch 138: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0101 - mean_squared_error: 0.0219 - val_loss: 0.1003 - val_mean_squared_error: 0.2037\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0222\n",
      "Epoch 139: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 16079s 2009s/step - loss: 0.0102 - mean_squared_error: 0.0222 - val_loss: 0.1037 - val_mean_squared_error: 0.2109\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0221\n",
      "Epoch 140: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0101 - mean_squared_error: 0.0221 - val_loss: 0.1021 - val_mean_squared_error: 0.2074\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0225\n",
      "Epoch 141: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0104 - mean_squared_error: 0.0225 - val_loss: 0.1067 - val_mean_squared_error: 0.2174\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0216\n",
      "Epoch 142: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0099 - mean_squared_error: 0.0216 - val_loss: 0.1031 - val_mean_squared_error: 0.2090\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0214\n",
      "Epoch 143: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0098 - mean_squared_error: 0.0214 - val_loss: 0.1054 - val_mean_squared_error: 0.2145\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0209\n",
      "Epoch 144: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0096 - mean_squared_error: 0.0209 - val_loss: 0.1021 - val_mean_squared_error: 0.2070\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0207\n",
      "Epoch 145: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0094 - mean_squared_error: 0.0207 - val_loss: 0.1056 - val_mean_squared_error: 0.2145\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0206\n",
      "Epoch 146: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0094 - mean_squared_error: 0.0206 - val_loss: 0.1034 - val_mean_squared_error: 0.2100\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0203\n",
      "Epoch 147: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0093 - mean_squared_error: 0.0203 - val_loss: 0.1030 - val_mean_squared_error: 0.2091\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0091 - mean_squared_error: 0.0201\n",
      "Epoch 148: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0091 - mean_squared_error: 0.0201 - val_loss: 0.1041 - val_mean_squared_error: 0.2113\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0090 - mean_squared_error: 0.0198\n",
      "Epoch 149: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0090 - mean_squared_error: 0.0198 - val_loss: 0.1059 - val_mean_squared_error: 0.2155\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0091 - mean_squared_error: 0.0201\n",
      "Epoch 150: val_loss did not improve from 0.07430\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.0091 - mean_squared_error: 0.0201 - val_loss: 0.1075 - val_mean_squared_error: 0.2182\n",
      "5/5 [==============================] - 12s 383ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  456\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4142 - mean_squared_error: 0.9393\n",
      "Epoch 1: val_loss improved from inf to 0.29351, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 103s 6s/step - loss: 0.4142 - mean_squared_error: 0.9393 - val_loss: 0.2935 - val_mean_squared_error: 0.6295\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2665 - mean_squared_error: 0.5820\n",
      "Epoch 2: val_loss improved from 0.29351 to 0.17442, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.2665 - mean_squared_error: 0.5820 - val_loss: 0.1744 - val_mean_squared_error: 0.3615\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1417 - mean_squared_error: 0.2922\n",
      "Epoch 3: val_loss improved from 0.17442 to 0.15791, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.1417 - mean_squared_error: 0.2922 - val_loss: 0.1579 - val_mean_squared_error: 0.3270\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1208 - mean_squared_error: 0.2478\n",
      "Epoch 4: val_loss improved from 0.15791 to 0.13738, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.1208 - mean_squared_error: 0.2478 - val_loss: 0.1374 - val_mean_squared_error: 0.2816\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1053 - mean_squared_error: 0.2154\n",
      "Epoch 5: val_loss improved from 0.13738 to 0.12352, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.1053 - mean_squared_error: 0.2154 - val_loss: 0.1235 - val_mean_squared_error: 0.2519\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0963 - mean_squared_error: 0.1971\n",
      "Epoch 6: val_loss improved from 0.12352 to 0.11836, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 42s 5s/step - loss: 0.0963 - mean_squared_error: 0.1971 - val_loss: 0.1184 - val_mean_squared_error: 0.2407\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0915 - mean_squared_error: 0.1871\n",
      "Epoch 7: val_loss improved from 0.11836 to 0.11267, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0915 - mean_squared_error: 0.1871 - val_loss: 0.1127 - val_mean_squared_error: 0.2289\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0890 - mean_squared_error: 0.1824\n",
      "Epoch 8: val_loss improved from 0.11267 to 0.10930, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0890 - mean_squared_error: 0.1824 - val_loss: 0.1093 - val_mean_squared_error: 0.2224\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0861 - mean_squared_error: 0.1763\n",
      "Epoch 9: val_loss did not improve from 0.10930\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0861 - mean_squared_error: 0.1763 - val_loss: 0.1110 - val_mean_squared_error: 0.2254\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0827 - mean_squared_error: 0.1693\n",
      "Epoch 10: val_loss improved from 0.10930 to 0.10416, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0827 - mean_squared_error: 0.1693 - val_loss: 0.1042 - val_mean_squared_error: 0.2115\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0804 - mean_squared_error: 0.1646\n",
      "Epoch 11: val_loss did not improve from 0.10416\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0804 - mean_squared_error: 0.1646 - val_loss: 0.1056 - val_mean_squared_error: 0.2145\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0771 - mean_squared_error: 0.1578\n",
      "Epoch 12: val_loss did not improve from 0.10416\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0771 - mean_squared_error: 0.1578 - val_loss: 0.1089 - val_mean_squared_error: 0.2210\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0746 - mean_squared_error: 0.1527\n",
      "Epoch 13: val_loss did not improve from 0.10416\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0746 - mean_squared_error: 0.1527 - val_loss: 0.1086 - val_mean_squared_error: 0.2203\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0717 - mean_squared_error: 0.1466\n",
      "Epoch 14: val_loss improved from 0.10416 to 0.09589, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0717 - mean_squared_error: 0.1466 - val_loss: 0.0959 - val_mean_squared_error: 0.1944\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0687 - mean_squared_error: 0.1401\n",
      "Epoch 15: val_loss did not improve from 0.09589\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0687 - mean_squared_error: 0.1401 - val_loss: 0.0991 - val_mean_squared_error: 0.2007\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0666 - mean_squared_error: 0.1359\n",
      "Epoch 16: val_loss improved from 0.09589 to 0.09342, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0666 - mean_squared_error: 0.1359 - val_loss: 0.0934 - val_mean_squared_error: 0.1897\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0627 - mean_squared_error: 0.1279\n",
      "Epoch 17: val_loss improved from 0.09342 to 0.08495, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0627 - mean_squared_error: 0.1279 - val_loss: 0.0850 - val_mean_squared_error: 0.1712\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0601 - mean_squared_error: 0.1223\n",
      "Epoch 18: val_loss improved from 0.08495 to 0.08275, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0601 - mean_squared_error: 0.1223 - val_loss: 0.0828 - val_mean_squared_error: 0.1673\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0573 - mean_squared_error: 0.1166\n",
      "Epoch 19: val_loss improved from 0.08275 to 0.07710, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0573 - mean_squared_error: 0.1166 - val_loss: 0.0771 - val_mean_squared_error: 0.1556\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0569 - mean_squared_error: 0.1160\n",
      "Epoch 20: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0569 - mean_squared_error: 0.1160 - val_loss: 0.0807 - val_mean_squared_error: 0.1623\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0544 - mean_squared_error: 0.1109\n",
      "Epoch 21: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0544 - mean_squared_error: 0.1109 - val_loss: 0.0856 - val_mean_squared_error: 0.1725\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0550 - mean_squared_error: 0.1121\n",
      "Epoch 22: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0550 - mean_squared_error: 0.1121 - val_loss: 0.0969 - val_mean_squared_error: 0.1963\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0559 - mean_squared_error: 0.1138\n",
      "Epoch 23: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0559 - mean_squared_error: 0.1138 - val_loss: 0.0908 - val_mean_squared_error: 0.1841\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0535 - mean_squared_error: 0.1091\n",
      "Epoch 24: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0535 - mean_squared_error: 0.1091 - val_loss: 0.0800 - val_mean_squared_error: 0.1610\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0510 - mean_squared_error: 0.1040\n",
      "Epoch 25: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0510 - mean_squared_error: 0.1040 - val_loss: 0.0776 - val_mean_squared_error: 0.1564\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0518 - mean_squared_error: 0.1055\n",
      "Epoch 26: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0518 - mean_squared_error: 0.1055 - val_loss: 0.0779 - val_mean_squared_error: 0.1569\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0521 - mean_squared_error: 0.1063\n",
      "Epoch 27: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0521 - mean_squared_error: 0.1063 - val_loss: 0.0893 - val_mean_squared_error: 0.1815\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0512 - mean_squared_error: 0.1044\n",
      "Epoch 28: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0512 - mean_squared_error: 0.1044 - val_loss: 0.0933 - val_mean_squared_error: 0.1886\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0503 - mean_squared_error: 0.1026\n",
      "Epoch 29: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0503 - mean_squared_error: 0.1026 - val_loss: 0.0819 - val_mean_squared_error: 0.1651\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0494 - mean_squared_error: 0.1007\n",
      "Epoch 30: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0494 - mean_squared_error: 0.1007 - val_loss: 0.0848 - val_mean_squared_error: 0.1707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0488 - mean_squared_error: 0.0996\n",
      "Epoch 31: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0488 - mean_squared_error: 0.0996 - val_loss: 0.0787 - val_mean_squared_error: 0.1581\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0480 - mean_squared_error: 0.0979\n",
      "Epoch 32: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0480 - mean_squared_error: 0.0979 - val_loss: 0.0868 - val_mean_squared_error: 0.1749\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0478 - mean_squared_error: 0.0977\n",
      "Epoch 33: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0478 - mean_squared_error: 0.0977 - val_loss: 0.0869 - val_mean_squared_error: 0.1752\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0481 - mean_squared_error: 0.0980\n",
      "Epoch 34: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0481 - mean_squared_error: 0.0980 - val_loss: 0.0850 - val_mean_squared_error: 0.1713\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0463 - mean_squared_error: 0.0946\n",
      "Epoch 35: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0463 - mean_squared_error: 0.0946 - val_loss: 0.0812 - val_mean_squared_error: 0.1635\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0458 - mean_squared_error: 0.0935\n",
      "Epoch 36: val_loss improved from 0.07710 to 0.07587, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0458 - mean_squared_error: 0.0935 - val_loss: 0.0759 - val_mean_squared_error: 0.1527\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0944\n",
      "Epoch 37: val_loss did not improve from 0.07587\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0462 - mean_squared_error: 0.0944 - val_loss: 0.0784 - val_mean_squared_error: 0.1578\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0482 - mean_squared_error: 0.0984\n",
      "Epoch 38: val_loss did not improve from 0.07587\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0482 - mean_squared_error: 0.0984 - val_loss: 0.0942 - val_mean_squared_error: 0.1904\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0454 - mean_squared_error: 0.0926\n",
      "Epoch 39: val_loss did not improve from 0.07587\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0454 - mean_squared_error: 0.0926 - val_loss: 0.0830 - val_mean_squared_error: 0.1670\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0444 - mean_squared_error: 0.0907\n",
      "Epoch 40: val_loss did not improve from 0.07587\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0444 - mean_squared_error: 0.0907 - val_loss: 0.0800 - val_mean_squared_error: 0.1611\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0438 - mean_squared_error: 0.0896\n",
      "Epoch 41: val_loss improved from 0.07587 to 0.07348, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0438 - mean_squared_error: 0.0896 - val_loss: 0.0735 - val_mean_squared_error: 0.1477\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0431 - mean_squared_error: 0.0881\n",
      "Epoch 42: val_loss did not improve from 0.07348\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0431 - mean_squared_error: 0.0881 - val_loss: 0.0751 - val_mean_squared_error: 0.1511\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0432 - mean_squared_error: 0.0883\n",
      "Epoch 43: val_loss improved from 0.07348 to 0.07309, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0432 - mean_squared_error: 0.0883 - val_loss: 0.0731 - val_mean_squared_error: 0.1469\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0427 - mean_squared_error: 0.0873\n",
      "Epoch 44: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0427 - mean_squared_error: 0.0873 - val_loss: 0.0804 - val_mean_squared_error: 0.1616\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0413 - mean_squared_error: 0.0843\n",
      "Epoch 45: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0413 - mean_squared_error: 0.0843 - val_loss: 0.0780 - val_mean_squared_error: 0.1571\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0429 - mean_squared_error: 0.0876\n",
      "Epoch 46: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0429 - mean_squared_error: 0.0876 - val_loss: 0.0784 - val_mean_squared_error: 0.1583\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0420 - mean_squared_error: 0.0859\n",
      "Epoch 47: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0420 - mean_squared_error: 0.0859 - val_loss: 0.0803 - val_mean_squared_error: 0.1618\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0417 - mean_squared_error: 0.0855\n",
      "Epoch 48: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0417 - mean_squared_error: 0.0855 - val_loss: 0.0786 - val_mean_squared_error: 0.1579\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0400 - mean_squared_error: 0.0819\n",
      "Epoch 49: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0400 - mean_squared_error: 0.0819 - val_loss: 0.0798 - val_mean_squared_error: 0.1603\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0813\n",
      "Epoch 50: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0398 - mean_squared_error: 0.0813 - val_loss: 0.0761 - val_mean_squared_error: 0.1530\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0814\n",
      "Epoch 51: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0398 - mean_squared_error: 0.0814 - val_loss: 0.0768 - val_mean_squared_error: 0.1544\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0807\n",
      "Epoch 52: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0394 - mean_squared_error: 0.0807 - val_loss: 0.0795 - val_mean_squared_error: 0.1597\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0385 - mean_squared_error: 0.0787\n",
      "Epoch 53: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0385 - mean_squared_error: 0.0787 - val_loss: 0.0787 - val_mean_squared_error: 0.1580\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0792\n",
      "Epoch 54: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0388 - mean_squared_error: 0.0792 - val_loss: 0.0808 - val_mean_squared_error: 0.1629\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0379 - mean_squared_error: 0.0776\n",
      "Epoch 55: val_loss improved from 0.07309 to 0.07268, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0379 - mean_squared_error: 0.0776 - val_loss: 0.0727 - val_mean_squared_error: 0.1459\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0374 - mean_squared_error: 0.0765\n",
      "Epoch 56: val_loss did not improve from 0.07268\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0374 - mean_squared_error: 0.0765 - val_loss: 0.0822 - val_mean_squared_error: 0.1653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.0791\n",
      "Epoch 57: val_loss did not improve from 0.07268\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0386 - mean_squared_error: 0.0791 - val_loss: 0.0727 - val_mean_squared_error: 0.1461\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0371 - mean_squared_error: 0.0759\n",
      "Epoch 58: val_loss improved from 0.07268 to 0.07097, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0371 - mean_squared_error: 0.0759 - val_loss: 0.0710 - val_mean_squared_error: 0.1424\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0370 - mean_squared_error: 0.0757\n",
      "Epoch 59: val_loss did not improve from 0.07097\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0370 - mean_squared_error: 0.0757 - val_loss: 0.0757 - val_mean_squared_error: 0.1522\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0370 - mean_squared_error: 0.0757\n",
      "Epoch 60: val_loss did not improve from 0.07097\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0370 - mean_squared_error: 0.0757 - val_loss: 0.0914 - val_mean_squared_error: 0.1848\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0799\n",
      "Epoch 61: val_loss improved from 0.07097 to 0.06952, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0391 - mean_squared_error: 0.0799 - val_loss: 0.0695 - val_mean_squared_error: 0.1398\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0780\n",
      "Epoch 62: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0381 - mean_squared_error: 0.0780 - val_loss: 0.0729 - val_mean_squared_error: 0.1464\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0365 - mean_squared_error: 0.0747\n",
      "Epoch 63: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0365 - mean_squared_error: 0.0747 - val_loss: 0.0810 - val_mean_squared_error: 0.1628\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0377 - mean_squared_error: 0.0769\n",
      "Epoch 64: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0377 - mean_squared_error: 0.0769 - val_loss: 0.0833 - val_mean_squared_error: 0.1680\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.0723\n",
      "Epoch 65: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0354 - mean_squared_error: 0.0723 - val_loss: 0.0823 - val_mean_squared_error: 0.1664\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0339 - mean_squared_error: 0.0695\n",
      "Epoch 66: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0339 - mean_squared_error: 0.0695 - val_loss: 0.0747 - val_mean_squared_error: 0.1502\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0337 - mean_squared_error: 0.0691\n",
      "Epoch 67: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0337 - mean_squared_error: 0.0691 - val_loss: 0.0787 - val_mean_squared_error: 0.1583\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0329 - mean_squared_error: 0.0674\n",
      "Epoch 68: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0329 - mean_squared_error: 0.0674 - val_loss: 0.0879 - val_mean_squared_error: 0.1776\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0316 - mean_squared_error: 0.0648\n",
      "Epoch 69: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0316 - mean_squared_error: 0.0648 - val_loss: 0.0775 - val_mean_squared_error: 0.1557\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0320 - mean_squared_error: 0.0657\n",
      "Epoch 70: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0320 - mean_squared_error: 0.0657 - val_loss: 0.0838 - val_mean_squared_error: 0.1691\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0316 - mean_squared_error: 0.0649\n",
      "Epoch 71: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0316 - mean_squared_error: 0.0649 - val_loss: 0.0799 - val_mean_squared_error: 0.1617\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0318 - mean_squared_error: 0.0652\n",
      "Epoch 72: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0318 - mean_squared_error: 0.0652 - val_loss: 0.0804 - val_mean_squared_error: 0.1621\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0316 - mean_squared_error: 0.0647\n",
      "Epoch 73: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0316 - mean_squared_error: 0.0647 - val_loss: 0.0861 - val_mean_squared_error: 0.1746\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0312 - mean_squared_error: 0.0642\n",
      "Epoch 74: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0312 - mean_squared_error: 0.0642 - val_loss: 0.0817 - val_mean_squared_error: 0.1649\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0315 - mean_squared_error: 0.0648\n",
      "Epoch 75: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0315 - mean_squared_error: 0.0648 - val_loss: 0.0795 - val_mean_squared_error: 0.1600\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0311 - mean_squared_error: 0.0638\n",
      "Epoch 76: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0311 - mean_squared_error: 0.0638 - val_loss: 0.0859 - val_mean_squared_error: 0.1734\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0311 - mean_squared_error: 0.0638\n",
      "Epoch 77: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0311 - mean_squared_error: 0.0638 - val_loss: 0.0797 - val_mean_squared_error: 0.1606\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0300 - mean_squared_error: 0.0616\n",
      "Epoch 78: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0300 - mean_squared_error: 0.0616 - val_loss: 0.0911 - val_mean_squared_error: 0.1845\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0600\n",
      "Epoch 79: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0292 - mean_squared_error: 0.0600 - val_loss: 0.0882 - val_mean_squared_error: 0.1784\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0282 - mean_squared_error: 0.0581\n",
      "Epoch 80: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0282 - mean_squared_error: 0.0581 - val_loss: 0.0769 - val_mean_squared_error: 0.1547\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0286 - mean_squared_error: 0.0588\n",
      "Epoch 81: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0286 - mean_squared_error: 0.0588 - val_loss: 0.0777 - val_mean_squared_error: 0.1569\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0281 - mean_squared_error: 0.0579\n",
      "Epoch 82: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0281 - mean_squared_error: 0.0579 - val_loss: 0.0875 - val_mean_squared_error: 0.1774\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0272 - mean_squared_error: 0.0560\n",
      "Epoch 83: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0272 - mean_squared_error: 0.0560 - val_loss: 0.0868 - val_mean_squared_error: 0.1757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0265 - mean_squared_error: 0.0546\n",
      "Epoch 84: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0265 - mean_squared_error: 0.0546 - val_loss: 0.0925 - val_mean_squared_error: 0.1875\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0269 - mean_squared_error: 0.0555\n",
      "Epoch 85: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0269 - mean_squared_error: 0.0555 - val_loss: 0.0820 - val_mean_squared_error: 0.1654\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0263 - mean_squared_error: 0.0542\n",
      "Epoch 86: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0263 - mean_squared_error: 0.0542 - val_loss: 0.0846 - val_mean_squared_error: 0.1716\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0260 - mean_squared_error: 0.0536\n",
      "Epoch 87: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0260 - mean_squared_error: 0.0536 - val_loss: 0.0875 - val_mean_squared_error: 0.1767\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0253 - mean_squared_error: 0.0522\n",
      "Epoch 88: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0253 - mean_squared_error: 0.0522 - val_loss: 0.0819 - val_mean_squared_error: 0.1647\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0257 - mean_squared_error: 0.0530\n",
      "Epoch 89: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0257 - mean_squared_error: 0.0530 - val_loss: 0.0782 - val_mean_squared_error: 0.1573\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0245 - mean_squared_error: 0.0507\n",
      "Epoch 90: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0245 - mean_squared_error: 0.0507 - val_loss: 0.0836 - val_mean_squared_error: 0.1687\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0239 - mean_squared_error: 0.0494\n",
      "Epoch 91: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0239 - mean_squared_error: 0.0494 - val_loss: 0.0826 - val_mean_squared_error: 0.1667\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0503\n",
      "Epoch 92: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0243 - mean_squared_error: 0.0503 - val_loss: 0.0890 - val_mean_squared_error: 0.1802\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0502\n",
      "Epoch 93: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0243 - mean_squared_error: 0.0502 - val_loss: 0.0911 - val_mean_squared_error: 0.1844\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0246 - mean_squared_error: 0.0508\n",
      "Epoch 94: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0246 - mean_squared_error: 0.0508 - val_loss: 0.0827 - val_mean_squared_error: 0.1665\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0240 - mean_squared_error: 0.0497\n",
      "Epoch 95: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0240 - mean_squared_error: 0.0497 - val_loss: 0.0797 - val_mean_squared_error: 0.1605\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0226 - mean_squared_error: 0.0469\n",
      "Epoch 96: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0226 - mean_squared_error: 0.0469 - val_loss: 0.0885 - val_mean_squared_error: 0.1790\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0215 - mean_squared_error: 0.0445\n",
      "Epoch 97: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0215 - mean_squared_error: 0.0445 - val_loss: 0.0872 - val_mean_squared_error: 0.1764\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0215 - mean_squared_error: 0.0446\n",
      "Epoch 98: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0215 - mean_squared_error: 0.0446 - val_loss: 0.0820 - val_mean_squared_error: 0.1652\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0211 - mean_squared_error: 0.0437\n",
      "Epoch 99: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0211 - mean_squared_error: 0.0437 - val_loss: 0.0848 - val_mean_squared_error: 0.1715\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0206 - mean_squared_error: 0.0428\n",
      "Epoch 100: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0206 - mean_squared_error: 0.0428 - val_loss: 0.0886 - val_mean_squared_error: 0.1791\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0207 - mean_squared_error: 0.0430\n",
      "Epoch 101: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0207 - mean_squared_error: 0.0430 - val_loss: 0.0850 - val_mean_squared_error: 0.1714\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0419\n",
      "Epoch 102: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0202 - mean_squared_error: 0.0419 - val_loss: 0.0836 - val_mean_squared_error: 0.1691\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0197 - mean_squared_error: 0.0410\n",
      "Epoch 103: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0197 - mean_squared_error: 0.0410 - val_loss: 0.0895 - val_mean_squared_error: 0.1812\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0195 - mean_squared_error: 0.0408\n",
      "Epoch 104: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0195 - mean_squared_error: 0.0408 - val_loss: 0.0868 - val_mean_squared_error: 0.1751\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0402\n",
      "Epoch 105: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0193 - mean_squared_error: 0.0402 - val_loss: 0.0875 - val_mean_squared_error: 0.1767\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0186 - mean_squared_error: 0.0388\n",
      "Epoch 106: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0186 - mean_squared_error: 0.0388 - val_loss: 0.0895 - val_mean_squared_error: 0.1809\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0184 - mean_squared_error: 0.0384\n",
      "Epoch 107: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0184 - mean_squared_error: 0.0384 - val_loss: 0.0903 - val_mean_squared_error: 0.1825\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0187 - mean_squared_error: 0.0390\n",
      "Epoch 108: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0187 - mean_squared_error: 0.0390 - val_loss: 0.0918 - val_mean_squared_error: 0.1857\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0182 - mean_squared_error: 0.0381\n",
      "Epoch 109: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0182 - mean_squared_error: 0.0381 - val_loss: 0.0901 - val_mean_squared_error: 0.1821\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0179 - mean_squared_error: 0.0375\n",
      "Epoch 110: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0179 - mean_squared_error: 0.0375 - val_loss: 0.0894 - val_mean_squared_error: 0.1805\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0178 - mean_squared_error: 0.0372\n",
      "Epoch 111: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0178 - mean_squared_error: 0.0372 - val_loss: 0.0878 - val_mean_squared_error: 0.1772\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0360\n",
      "Epoch 112: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0172 - mean_squared_error: 0.0360 - val_loss: 0.0896 - val_mean_squared_error: 0.1815\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0364\n",
      "Epoch 113: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0174 - mean_squared_error: 0.0364 - val_loss: 0.0852 - val_mean_squared_error: 0.1718\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0360\n",
      "Epoch 114: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0172 - mean_squared_error: 0.0360 - val_loss: 0.0897 - val_mean_squared_error: 0.1814\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0349\n",
      "Epoch 115: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0166 - mean_squared_error: 0.0349 - val_loss: 0.0914 - val_mean_squared_error: 0.1848\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0344\n",
      "Epoch 116: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0164 - mean_squared_error: 0.0344 - val_loss: 0.0931 - val_mean_squared_error: 0.1881\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0342\n",
      "Epoch 117: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0162 - mean_squared_error: 0.0342 - val_loss: 0.0925 - val_mean_squared_error: 0.1875\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0345\n",
      "Epoch 118: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0164 - mean_squared_error: 0.0345 - val_loss: 0.0917 - val_mean_squared_error: 0.1857\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0342\n",
      "Epoch 119: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0163 - mean_squared_error: 0.0342 - val_loss: 0.0859 - val_mean_squared_error: 0.1731\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0355\n",
      "Epoch 120: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0169 - mean_squared_error: 0.0355 - val_loss: 0.0978 - val_mean_squared_error: 0.1985\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0340\n",
      "Epoch 121: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0161 - mean_squared_error: 0.0340 - val_loss: 0.0912 - val_mean_squared_error: 0.1843\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0327\n",
      "Epoch 122: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0155 - mean_squared_error: 0.0327 - val_loss: 0.0911 - val_mean_squared_error: 0.1840\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0315\n",
      "Epoch 123: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0149 - mean_squared_error: 0.0315 - val_loss: 0.0918 - val_mean_squared_error: 0.1853\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0315\n",
      "Epoch 124: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0149 - mean_squared_error: 0.0315 - val_loss: 0.0997 - val_mean_squared_error: 0.2023\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0315\n",
      "Epoch 125: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0149 - mean_squared_error: 0.0315 - val_loss: 0.0907 - val_mean_squared_error: 0.1837\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0305\n",
      "Epoch 126: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0144 - mean_squared_error: 0.0305 - val_loss: 0.0939 - val_mean_squared_error: 0.1899\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0298\n",
      "Epoch 127: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0140 - mean_squared_error: 0.0298 - val_loss: 0.0934 - val_mean_squared_error: 0.1890\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0294\n",
      "Epoch 128: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0138 - mean_squared_error: 0.0294 - val_loss: 0.0953 - val_mean_squared_error: 0.1925\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0291\n",
      "Epoch 129: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0137 - mean_squared_error: 0.0291 - val_loss: 0.0982 - val_mean_squared_error: 0.1990\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0291\n",
      "Epoch 130: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0137 - mean_squared_error: 0.0291 - val_loss: 0.0943 - val_mean_squared_error: 0.1902\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0290\n",
      "Epoch 131: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0137 - mean_squared_error: 0.0290 - val_loss: 0.0973 - val_mean_squared_error: 0.1969\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0295\n",
      "Epoch 132: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0139 - mean_squared_error: 0.0295 - val_loss: 0.0938 - val_mean_squared_error: 0.1894\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0295\n",
      "Epoch 133: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0139 - mean_squared_error: 0.0295 - val_loss: 0.0991 - val_mean_squared_error: 0.2003\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0285\n",
      "Epoch 134: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0134 - mean_squared_error: 0.0285 - val_loss: 0.0950 - val_mean_squared_error: 0.1920\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0276\n",
      "Epoch 135: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0130 - mean_squared_error: 0.0276 - val_loss: 0.0980 - val_mean_squared_error: 0.1982\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0271\n",
      "Epoch 136: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0127 - mean_squared_error: 0.0271 - val_loss: 0.0996 - val_mean_squared_error: 0.2017\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0270\n",
      "Epoch 137: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0126 - mean_squared_error: 0.0270 - val_loss: 0.0964 - val_mean_squared_error: 0.1950\n",
      "Epoch 138/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0262\n",
      "Epoch 138: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0122 - mean_squared_error: 0.0262 - val_loss: 0.0969 - val_mean_squared_error: 0.1962\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0256\n",
      "Epoch 139: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0120 - mean_squared_error: 0.0256 - val_loss: 0.0992 - val_mean_squared_error: 0.2008\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0258\n",
      "Epoch 140: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0121 - mean_squared_error: 0.0258 - val_loss: 0.0962 - val_mean_squared_error: 0.1945\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0255\n",
      "Epoch 141: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0119 - mean_squared_error: 0.0255 - val_loss: 0.0978 - val_mean_squared_error: 0.1976\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0251\n",
      "Epoch 142: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0117 - mean_squared_error: 0.0251 - val_loss: 0.1000 - val_mean_squared_error: 0.2027\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0251\n",
      "Epoch 143: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0117 - mean_squared_error: 0.0251 - val_loss: 0.0997 - val_mean_squared_error: 0.2017\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0249\n",
      "Epoch 144: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0116 - mean_squared_error: 0.0249 - val_loss: 0.1008 - val_mean_squared_error: 0.2044\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0245\n",
      "Epoch 145: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0114 - mean_squared_error: 0.0245 - val_loss: 0.1018 - val_mean_squared_error: 0.2060\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0245\n",
      "Epoch 146: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0114 - mean_squared_error: 0.0245 - val_loss: 0.0977 - val_mean_squared_error: 0.1976\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0240\n",
      "Epoch 147: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0111 - mean_squared_error: 0.0240 - val_loss: 0.1000 - val_mean_squared_error: 0.2024\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0238\n",
      "Epoch 148: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0110 - mean_squared_error: 0.0238 - val_loss: 0.0989 - val_mean_squared_error: 0.2004\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0236\n",
      "Epoch 149: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0109 - mean_squared_error: 0.0236 - val_loss: 0.1000 - val_mean_squared_error: 0.2024\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0236\n",
      "Epoch 150: val_loss did not improve from 0.06952\n",
      "9/9 [==============================] - 42s 5s/step - loss: 0.0109 - mean_squared_error: 0.0236 - val_loss: 0.0981 - val_mean_squared_error: 0.1986\n",
      "5/5 [==============================] - 13s 504ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  480\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4115 - mean_squared_error: 0.9295\n",
      "Epoch 1: val_loss improved from inf to 0.31302, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 108s 7s/step - loss: 0.4115 - mean_squared_error: 0.9295 - val_loss: 0.3130 - val_mean_squared_error: 0.6639\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2710 - mean_squared_error: 0.5793\n",
      "Epoch 2: val_loss improved from 0.31302 to 0.19429, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.2710 - mean_squared_error: 0.5793 - val_loss: 0.1943 - val_mean_squared_error: 0.4003\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1444 - mean_squared_error: 0.2967\n",
      "Epoch 3: val_loss improved from 0.19429 to 0.13918, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.1444 - mean_squared_error: 0.2967 - val_loss: 0.1392 - val_mean_squared_error: 0.2853\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.2179\n",
      "Epoch 4: val_loss improved from 0.13918 to 0.11782, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.1064 - mean_squared_error: 0.2179 - val_loss: 0.1178 - val_mean_squared_error: 0.2388\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1002 - mean_squared_error: 0.2041\n",
      "Epoch 5: val_loss improved from 0.11782 to 0.11299, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.1002 - mean_squared_error: 0.2041 - val_loss: 0.1130 - val_mean_squared_error: 0.2288\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0932 - mean_squared_error: 0.1909\n",
      "Epoch 6: val_loss did not improve from 0.11299\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0932 - mean_squared_error: 0.1909 - val_loss: 0.1236 - val_mean_squared_error: 0.2526\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0885 - mean_squared_error: 0.1809\n",
      "Epoch 7: val_loss did not improve from 0.11299\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0885 - mean_squared_error: 0.1809 - val_loss: 0.1133 - val_mean_squared_error: 0.2301\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0865 - mean_squared_error: 0.1766\n",
      "Epoch 8: val_loss did not improve from 0.11299\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0865 - mean_squared_error: 0.1766 - val_loss: 0.1158 - val_mean_squared_error: 0.2354\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0842 - mean_squared_error: 0.1721\n",
      "Epoch 9: val_loss improved from 0.11299 to 0.11144, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0842 - mean_squared_error: 0.1721 - val_loss: 0.1114 - val_mean_squared_error: 0.2272\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0825 - mean_squared_error: 0.1686\n",
      "Epoch 10: val_loss improved from 0.11144 to 0.10967, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0825 - mean_squared_error: 0.1686 - val_loss: 0.1097 - val_mean_squared_error: 0.2232\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0821 - mean_squared_error: 0.1679\n",
      "Epoch 11: val_loss improved from 0.10967 to 0.10761, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0821 - mean_squared_error: 0.1679 - val_loss: 0.1076 - val_mean_squared_error: 0.2187\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0799 - mean_squared_error: 0.1634\n",
      "Epoch 12: val_loss did not improve from 0.10761\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0799 - mean_squared_error: 0.1634 - val_loss: 0.1112 - val_mean_squared_error: 0.2264\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0789 - mean_squared_error: 0.1611\n",
      "Epoch 13: val_loss did not improve from 0.10761\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0789 - mean_squared_error: 0.1611 - val_loss: 0.1097 - val_mean_squared_error: 0.2230\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0795 - mean_squared_error: 0.1623\n",
      "Epoch 14: val_loss improved from 0.10761 to 0.10175, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0795 - mean_squared_error: 0.1623 - val_loss: 0.1017 - val_mean_squared_error: 0.2069\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0775 - mean_squared_error: 0.1580\n",
      "Epoch 15: val_loss improved from 0.10175 to 0.10041, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0775 - mean_squared_error: 0.1580 - val_loss: 0.1004 - val_mean_squared_error: 0.2037\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0735 - mean_squared_error: 0.1498\n",
      "Epoch 16: val_loss improved from 0.10041 to 0.09957, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0735 - mean_squared_error: 0.1498 - val_loss: 0.0996 - val_mean_squared_error: 0.2020\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0722 - mean_squared_error: 0.1473\n",
      "Epoch 17: val_loss improved from 0.09957 to 0.09470, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0722 - mean_squared_error: 0.1473 - val_loss: 0.0947 - val_mean_squared_error: 0.1918\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0690 - mean_squared_error: 0.1405\n",
      "Epoch 18: val_loss did not improve from 0.09470\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0690 - mean_squared_error: 0.1405 - val_loss: 0.0970 - val_mean_squared_error: 0.1965\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0667 - mean_squared_error: 0.1356\n",
      "Epoch 19: val_loss improved from 0.09470 to 0.08381, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0667 - mean_squared_error: 0.1356 - val_loss: 0.0838 - val_mean_squared_error: 0.1699\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0684 - mean_squared_error: 0.1393\n",
      "Epoch 20: val_loss did not improve from 0.08381\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0684 - mean_squared_error: 0.1393 - val_loss: 0.0838 - val_mean_squared_error: 0.1703\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0653 - mean_squared_error: 0.1332\n",
      "Epoch 21: val_loss improved from 0.08381 to 0.08343, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0653 - mean_squared_error: 0.1332 - val_loss: 0.0834 - val_mean_squared_error: 0.1683\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0610 - mean_squared_error: 0.1242\n",
      "Epoch 22: val_loss did not improve from 0.08343\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0610 - mean_squared_error: 0.1242 - val_loss: 0.0869 - val_mean_squared_error: 0.1755\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0575 - mean_squared_error: 0.1171\n",
      "Epoch 23: val_loss improved from 0.08343 to 0.08329, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0575 - mean_squared_error: 0.1171 - val_loss: 0.0833 - val_mean_squared_error: 0.1680\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0605 - mean_squared_error: 0.1231\n",
      "Epoch 24: val_loss improved from 0.08329 to 0.08028, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0605 - mean_squared_error: 0.1231 - val_loss: 0.0803 - val_mean_squared_error: 0.1619\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0585 - mean_squared_error: 0.1192\n",
      "Epoch 25: val_loss did not improve from 0.08028\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0585 - mean_squared_error: 0.1192 - val_loss: 0.0814 - val_mean_squared_error: 0.1645\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0554 - mean_squared_error: 0.1129\n",
      "Epoch 26: val_loss improved from 0.08028 to 0.08013, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0554 - mean_squared_error: 0.1129 - val_loss: 0.0801 - val_mean_squared_error: 0.1615\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0537 - mean_squared_error: 0.1096\n",
      "Epoch 27: val_loss did not improve from 0.08013\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0537 - mean_squared_error: 0.1096 - val_loss: 0.0853 - val_mean_squared_error: 0.1722\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0539 - mean_squared_error: 0.1098\n",
      "Epoch 28: val_loss improved from 0.08013 to 0.07988, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0539 - mean_squared_error: 0.1098 - val_loss: 0.0799 - val_mean_squared_error: 0.1614\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0517 - mean_squared_error: 0.1054\n",
      "Epoch 29: val_loss improved from 0.07988 to 0.07813, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0517 - mean_squared_error: 0.1054 - val_loss: 0.0781 - val_mean_squared_error: 0.1572\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0506 - mean_squared_error: 0.1032\n",
      "Epoch 30: val_loss improved from 0.07813 to 0.07710, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0506 - mean_squared_error: 0.1032 - val_loss: 0.0771 - val_mean_squared_error: 0.1555\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0505 - mean_squared_error: 0.1030\n",
      "Epoch 31: val_loss did not improve from 0.07710\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0505 - mean_squared_error: 0.1030 - val_loss: 0.0815 - val_mean_squared_error: 0.1646\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0499 - mean_squared_error: 0.1018\n",
      "Epoch 32: val_loss improved from 0.07710 to 0.07501, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 44s 5s/step - loss: 0.0499 - mean_squared_error: 0.1018 - val_loss: 0.0750 - val_mean_squared_error: 0.1511\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0491 - mean_squared_error: 0.1002\n",
      "Epoch 33: val_loss did not improve from 0.07501\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0491 - mean_squared_error: 0.1002 - val_loss: 0.0785 - val_mean_squared_error: 0.1585\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0490 - mean_squared_error: 0.0999\n",
      "Epoch 34: val_loss did not improve from 0.07501\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0490 - mean_squared_error: 0.0999 - val_loss: 0.0766 - val_mean_squared_error: 0.1543\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0492 - mean_squared_error: 0.1003\n",
      "Epoch 35: val_loss did not improve from 0.07501\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0492 - mean_squared_error: 0.1003 - val_loss: 0.0777 - val_mean_squared_error: 0.1568\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0474 - mean_squared_error: 0.0966\n",
      "Epoch 36: val_loss did not improve from 0.07501\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0474 - mean_squared_error: 0.0966 - val_loss: 0.0751 - val_mean_squared_error: 0.1514\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0458 - mean_squared_error: 0.0934\n",
      "Epoch 37: val_loss did not improve from 0.07501\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0458 - mean_squared_error: 0.0934 - val_loss: 0.0772 - val_mean_squared_error: 0.1554\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0942\n",
      "Epoch 38: val_loss did not improve from 0.07501\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0462 - mean_squared_error: 0.0942 - val_loss: 0.0844 - val_mean_squared_error: 0.1703\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0475 - mean_squared_error: 0.0969\n",
      "Epoch 39: val_loss did not improve from 0.07501\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0475 - mean_squared_error: 0.0969 - val_loss: 0.0856 - val_mean_squared_error: 0.1729\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0468 - mean_squared_error: 0.0953\n",
      "Epoch 40: val_loss did not improve from 0.07501\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0468 - mean_squared_error: 0.0953 - val_loss: 0.0773 - val_mean_squared_error: 0.1554\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0456 - mean_squared_error: 0.0930\n",
      "Epoch 41: val_loss did not improve from 0.07501\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0456 - mean_squared_error: 0.0930 - val_loss: 0.0821 - val_mean_squared_error: 0.1652\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.0919\n",
      "Epoch 42: val_loss improved from 0.07501 to 0.07313, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0450 - mean_squared_error: 0.0919 - val_loss: 0.0731 - val_mean_squared_error: 0.1471\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0461 - mean_squared_error: 0.0941\n",
      "Epoch 43: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0461 - mean_squared_error: 0.0941 - val_loss: 0.0817 - val_mean_squared_error: 0.1650\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0439 - mean_squared_error: 0.0896\n",
      "Epoch 44: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0439 - mean_squared_error: 0.0896 - val_loss: 0.0800 - val_mean_squared_error: 0.1610\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0430 - mean_squared_error: 0.0877\n",
      "Epoch 45: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0430 - mean_squared_error: 0.0877 - val_loss: 0.0766 - val_mean_squared_error: 0.1541\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0414 - mean_squared_error: 0.0846\n",
      "Epoch 46: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0414 - mean_squared_error: 0.0846 - val_loss: 0.0743 - val_mean_squared_error: 0.1496\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0413 - mean_squared_error: 0.0843\n",
      "Epoch 47: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0413 - mean_squared_error: 0.0843 - val_loss: 0.0735 - val_mean_squared_error: 0.1477\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0403 - mean_squared_error: 0.0824\n",
      "Epoch 48: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0403 - mean_squared_error: 0.0824 - val_loss: 0.0748 - val_mean_squared_error: 0.1502\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0813\n",
      "Epoch 49: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0398 - mean_squared_error: 0.0813 - val_loss: 0.0799 - val_mean_squared_error: 0.1607\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0407 - mean_squared_error: 0.0830\n",
      "Epoch 50: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0407 - mean_squared_error: 0.0830 - val_loss: 0.0817 - val_mean_squared_error: 0.1642\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0419 - mean_squared_error: 0.0856\n",
      "Epoch 51: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0419 - mean_squared_error: 0.0856 - val_loss: 0.0763 - val_mean_squared_error: 0.1532\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0397 - mean_squared_error: 0.0812\n",
      "Epoch 52: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0397 - mean_squared_error: 0.0812 - val_loss: 0.0740 - val_mean_squared_error: 0.1489\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0794\n",
      "Epoch 53: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0388 - mean_squared_error: 0.0794 - val_loss: 0.0788 - val_mean_squared_error: 0.1587\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0382 - mean_squared_error: 0.0781\n",
      "Epoch 54: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0382 - mean_squared_error: 0.0781 - val_loss: 0.0790 - val_mean_squared_error: 0.1591\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0778\n",
      "Epoch 55: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0381 - mean_squared_error: 0.0778 - val_loss: 0.0833 - val_mean_squared_error: 0.1677\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0370 - mean_squared_error: 0.0756\n",
      "Epoch 56: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0370 - mean_squared_error: 0.0756 - val_loss: 0.0741 - val_mean_squared_error: 0.1490\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0360 - mean_squared_error: 0.0736\n",
      "Epoch 57: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0360 - mean_squared_error: 0.0736 - val_loss: 0.0765 - val_mean_squared_error: 0.1539\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0357 - mean_squared_error: 0.0729\n",
      "Epoch 58: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0357 - mean_squared_error: 0.0729 - val_loss: 0.0817 - val_mean_squared_error: 0.1645\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0363 - mean_squared_error: 0.0742\n",
      "Epoch 59: val_loss did not improve from 0.07313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 44s 5s/step - loss: 0.0363 - mean_squared_error: 0.0742 - val_loss: 0.0755 - val_mean_squared_error: 0.1520\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0365 - mean_squared_error: 0.0748\n",
      "Epoch 60: val_loss did not improve from 0.07313\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0365 - mean_squared_error: 0.0748 - val_loss: 0.0746 - val_mean_squared_error: 0.1502\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0367 - mean_squared_error: 0.0750\n",
      "Epoch 61: val_loss improved from 0.07313 to 0.07309, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0367 - mean_squared_error: 0.0750 - val_loss: 0.0731 - val_mean_squared_error: 0.1477\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0367 - mean_squared_error: 0.0750\n",
      "Epoch 62: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0367 - mean_squared_error: 0.0750 - val_loss: 0.0754 - val_mean_squared_error: 0.1523\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0365 - mean_squared_error: 0.0745\n",
      "Epoch 63: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0365 - mean_squared_error: 0.0745 - val_loss: 0.0775 - val_mean_squared_error: 0.1562\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0346 - mean_squared_error: 0.0708\n",
      "Epoch 64: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0346 - mean_squared_error: 0.0708 - val_loss: 0.0733 - val_mean_squared_error: 0.1475\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0336 - mean_squared_error: 0.0688\n",
      "Epoch 65: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0336 - mean_squared_error: 0.0688 - val_loss: 0.0755 - val_mean_squared_error: 0.1520\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0338 - mean_squared_error: 0.0692\n",
      "Epoch 66: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0338 - mean_squared_error: 0.0692 - val_loss: 0.0741 - val_mean_squared_error: 0.1492\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0321 - mean_squared_error: 0.0658\n",
      "Epoch 67: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0321 - mean_squared_error: 0.0658 - val_loss: 0.0771 - val_mean_squared_error: 0.1551\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0313 - mean_squared_error: 0.0642\n",
      "Epoch 68: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0313 - mean_squared_error: 0.0642 - val_loss: 0.0772 - val_mean_squared_error: 0.1554\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0308 - mean_squared_error: 0.0633\n",
      "Epoch 69: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 43s 5s/step - loss: 0.0308 - mean_squared_error: 0.0633 - val_loss: 0.0748 - val_mean_squared_error: 0.1508\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0312 - mean_squared_error: 0.0640\n",
      "Epoch 70: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0312 - mean_squared_error: 0.0640 - val_loss: 0.0779 - val_mean_squared_error: 0.1572\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0302 - mean_squared_error: 0.0619\n",
      "Epoch 71: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0302 - mean_squared_error: 0.0619 - val_loss: 0.0747 - val_mean_squared_error: 0.1504\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0289 - mean_squared_error: 0.0595\n",
      "Epoch 72: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0289 - mean_squared_error: 0.0595 - val_loss: 0.0748 - val_mean_squared_error: 0.1507\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0288 - mean_squared_error: 0.0591\n",
      "Epoch 73: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0288 - mean_squared_error: 0.0591 - val_loss: 0.0785 - val_mean_squared_error: 0.1585\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0287 - mean_squared_error: 0.0588\n",
      "Epoch 74: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0287 - mean_squared_error: 0.0588 - val_loss: 0.0736 - val_mean_squared_error: 0.1484\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0290 - mean_squared_error: 0.0595\n",
      "Epoch 75: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0290 - mean_squared_error: 0.0595 - val_loss: 0.0826 - val_mean_squared_error: 0.1669\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0293 - mean_squared_error: 0.0601\n",
      "Epoch 76: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0293 - mean_squared_error: 0.0601 - val_loss: 0.0821 - val_mean_squared_error: 0.1659\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0286 - mean_squared_error: 0.0586\n",
      "Epoch 77: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0286 - mean_squared_error: 0.0586 - val_loss: 0.0770 - val_mean_squared_error: 0.1548\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0275 - mean_squared_error: 0.0565\n",
      "Epoch 78: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0275 - mean_squared_error: 0.0565 - val_loss: 0.0793 - val_mean_squared_error: 0.1599\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0557\n",
      "Epoch 79: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0271 - mean_squared_error: 0.0557 - val_loss: 0.0763 - val_mean_squared_error: 0.1539\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0261 - mean_squared_error: 0.0538\n",
      "Epoch 80: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0261 - mean_squared_error: 0.0538 - val_loss: 0.0797 - val_mean_squared_error: 0.1606\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0263 - mean_squared_error: 0.0540\n",
      "Epoch 81: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0263 - mean_squared_error: 0.0540 - val_loss: 0.0856 - val_mean_squared_error: 0.1726\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0253 - mean_squared_error: 0.0523\n",
      "Epoch 82: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0253 - mean_squared_error: 0.0523 - val_loss: 0.0828 - val_mean_squared_error: 0.1667\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0249 - mean_squared_error: 0.0513\n",
      "Epoch 83: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0249 - mean_squared_error: 0.0513 - val_loss: 0.0827 - val_mean_squared_error: 0.1669\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0241 - mean_squared_error: 0.0498\n",
      "Epoch 84: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0241 - mean_squared_error: 0.0498 - val_loss: 0.0813 - val_mean_squared_error: 0.1639\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0238 - mean_squared_error: 0.0491\n",
      "Epoch 85: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0238 - mean_squared_error: 0.0491 - val_loss: 0.0819 - val_mean_squared_error: 0.1651\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0236 - mean_squared_error: 0.0488\n",
      "Epoch 86: val_loss did not improve from 0.07309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 44s 5s/step - loss: 0.0236 - mean_squared_error: 0.0488 - val_loss: 0.0830 - val_mean_squared_error: 0.1675\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0242 - mean_squared_error: 0.0500\n",
      "Epoch 87: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0242 - mean_squared_error: 0.0500 - val_loss: 0.0862 - val_mean_squared_error: 0.1741\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0232 - mean_squared_error: 0.0479\n",
      "Epoch 88: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0232 - mean_squared_error: 0.0479 - val_loss: 0.0793 - val_mean_squared_error: 0.1599\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0225 - mean_squared_error: 0.0465\n",
      "Epoch 89: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0225 - mean_squared_error: 0.0465 - val_loss: 0.0818 - val_mean_squared_error: 0.1651\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0463\n",
      "Epoch 90: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0224 - mean_squared_error: 0.0463 - val_loss: 0.0863 - val_mean_squared_error: 0.1742\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0214 - mean_squared_error: 0.0443\n",
      "Epoch 91: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0214 - mean_squared_error: 0.0443 - val_loss: 0.0835 - val_mean_squared_error: 0.1689\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0215 - mean_squared_error: 0.0446\n",
      "Epoch 92: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0215 - mean_squared_error: 0.0446 - val_loss: 0.0823 - val_mean_squared_error: 0.1666\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0206 - mean_squared_error: 0.0428\n",
      "Epoch 93: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0206 - mean_squared_error: 0.0428 - val_loss: 0.0834 - val_mean_squared_error: 0.1687\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0206 - mean_squared_error: 0.0427\n",
      "Epoch 94: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0206 - mean_squared_error: 0.0427 - val_loss: 0.0825 - val_mean_squared_error: 0.1672\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0206 - mean_squared_error: 0.0427\n",
      "Epoch 95: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0206 - mean_squared_error: 0.0427 - val_loss: 0.0882 - val_mean_squared_error: 0.1783\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0199 - mean_squared_error: 0.0413\n",
      "Epoch 96: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0199 - mean_squared_error: 0.0413 - val_loss: 0.0862 - val_mean_squared_error: 0.1742\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.0398\n",
      "Epoch 97: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0192 - mean_squared_error: 0.0398 - val_loss: 0.0865 - val_mean_squared_error: 0.1746\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0190 - mean_squared_error: 0.0396\n",
      "Epoch 98: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0190 - mean_squared_error: 0.0396 - val_loss: 0.0849 - val_mean_squared_error: 0.1712\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0187 - mean_squared_error: 0.0389\n",
      "Epoch 99: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0187 - mean_squared_error: 0.0389 - val_loss: 0.0879 - val_mean_squared_error: 0.1779\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.0400\n",
      "Epoch 100: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0192 - mean_squared_error: 0.0400 - val_loss: 0.0951 - val_mean_squared_error: 0.1929\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0195 - mean_squared_error: 0.0406\n",
      "Epoch 101: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0195 - mean_squared_error: 0.0406 - val_loss: 0.0843 - val_mean_squared_error: 0.1706\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0183 - mean_squared_error: 0.0381\n",
      "Epoch 102: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0183 - mean_squared_error: 0.0381 - val_loss: 0.0907 - val_mean_squared_error: 0.1834\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0180 - mean_squared_error: 0.0375\n",
      "Epoch 103: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0180 - mean_squared_error: 0.0375 - val_loss: 0.0857 - val_mean_squared_error: 0.1734\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0176 - mean_squared_error: 0.0368\n",
      "Epoch 104: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0176 - mean_squared_error: 0.0368 - val_loss: 0.0899 - val_mean_squared_error: 0.1820\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0176 - mean_squared_error: 0.0368\n",
      "Epoch 105: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0176 - mean_squared_error: 0.0368 - val_loss: 0.0898 - val_mean_squared_error: 0.1819\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0173 - mean_squared_error: 0.0361\n",
      "Epoch 106: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0173 - mean_squared_error: 0.0361 - val_loss: 0.0890 - val_mean_squared_error: 0.1804\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0364\n",
      "Epoch 107: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0174 - mean_squared_error: 0.0364 - val_loss: 0.0883 - val_mean_squared_error: 0.1786\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0354\n",
      "Epoch 108: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0169 - mean_squared_error: 0.0354 - val_loss: 0.0897 - val_mean_squared_error: 0.1818\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0346\n",
      "Epoch 109: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0165 - mean_squared_error: 0.0346 - val_loss: 0.0883 - val_mean_squared_error: 0.1790\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0347\n",
      "Epoch 110: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0165 - mean_squared_error: 0.0347 - val_loss: 0.0910 - val_mean_squared_error: 0.1845\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0335\n",
      "Epoch 111: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0160 - mean_squared_error: 0.0335 - val_loss: 0.0885 - val_mean_squared_error: 0.1791\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0345\n",
      "Epoch 112: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0165 - mean_squared_error: 0.0345 - val_loss: 0.0935 - val_mean_squared_error: 0.1896\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0336\n",
      "Epoch 113: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0160 - mean_squared_error: 0.0336 - val_loss: 0.0899 - val_mean_squared_error: 0.1822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0319\n",
      "Epoch 114: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0152 - mean_squared_error: 0.0319 - val_loss: 0.0942 - val_mean_squared_error: 0.1909\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0319\n",
      "Epoch 115: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0152 - mean_squared_error: 0.0319 - val_loss: 0.0968 - val_mean_squared_error: 0.1966\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0324\n",
      "Epoch 116: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0154 - mean_squared_error: 0.0324 - val_loss: 0.0926 - val_mean_squared_error: 0.1877\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0303\n",
      "Epoch 117: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0144 - mean_squared_error: 0.0303 - val_loss: 0.0953 - val_mean_squared_error: 0.1931\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0302\n",
      "Epoch 118: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0143 - mean_squared_error: 0.0302 - val_loss: 0.0952 - val_mean_squared_error: 0.1929\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0296\n",
      "Epoch 119: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0140 - mean_squared_error: 0.0296 - val_loss: 0.0903 - val_mean_squared_error: 0.1831\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0289\n",
      "Epoch 120: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0136 - mean_squared_error: 0.0289 - val_loss: 0.0957 - val_mean_squared_error: 0.1938\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0287\n",
      "Epoch 121: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0135 - mean_squared_error: 0.0287 - val_loss: 0.0944 - val_mean_squared_error: 0.1912\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0293\n",
      "Epoch 122: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0139 - mean_squared_error: 0.0293 - val_loss: 0.0926 - val_mean_squared_error: 0.1876\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0296\n",
      "Epoch 123: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0140 - mean_squared_error: 0.0296 - val_loss: 0.0979 - val_mean_squared_error: 0.1985\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0283\n",
      "Epoch 124: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0134 - mean_squared_error: 0.0283 - val_loss: 0.0964 - val_mean_squared_error: 0.1955\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0274\n",
      "Epoch 125: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0129 - mean_squared_error: 0.0274 - val_loss: 0.0966 - val_mean_squared_error: 0.1956\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0271\n",
      "Epoch 126: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0128 - mean_squared_error: 0.0271 - val_loss: 0.0959 - val_mean_squared_error: 0.1948\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0264\n",
      "Epoch 127: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0124 - mean_squared_error: 0.0264 - val_loss: 0.0961 - val_mean_squared_error: 0.1949\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0259\n",
      "Epoch 128: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0121 - mean_squared_error: 0.0259 - val_loss: 0.0987 - val_mean_squared_error: 0.2003\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0264\n",
      "Epoch 129: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0124 - mean_squared_error: 0.0264 - val_loss: 0.0967 - val_mean_squared_error: 0.1956\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0260\n",
      "Epoch 130: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 45s 5s/step - loss: 0.0122 - mean_squared_error: 0.0260 - val_loss: 0.0996 - val_mean_squared_error: 0.2020\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0260\n",
      "Epoch 131: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0122 - mean_squared_error: 0.0260 - val_loss: 0.0974 - val_mean_squared_error: 0.1973\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0255\n",
      "Epoch 132: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0119 - mean_squared_error: 0.0255 - val_loss: 0.0977 - val_mean_squared_error: 0.1982\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0255\n",
      "Epoch 133: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0119 - mean_squared_error: 0.0255 - val_loss: 0.0999 - val_mean_squared_error: 0.2030\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0257\n",
      "Epoch 134: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0121 - mean_squared_error: 0.0257 - val_loss: 0.0942 - val_mean_squared_error: 0.1906\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0259\n",
      "Epoch 135: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0122 - mean_squared_error: 0.0259 - val_loss: 0.0995 - val_mean_squared_error: 0.2014\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0258\n",
      "Epoch 136: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0121 - mean_squared_error: 0.0258 - val_loss: 0.0979 - val_mean_squared_error: 0.1981\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0253\n",
      "Epoch 137: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0118 - mean_squared_error: 0.0253 - val_loss: 0.0982 - val_mean_squared_error: 0.1991\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0242\n",
      "Epoch 138: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0113 - mean_squared_error: 0.0242 - val_loss: 0.0966 - val_mean_squared_error: 0.1955\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0236\n",
      "Epoch 139: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0110 - mean_squared_error: 0.0236 - val_loss: 0.0995 - val_mean_squared_error: 0.2017\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0233\n",
      "Epoch 140: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0108 - mean_squared_error: 0.0233 - val_loss: 0.0995 - val_mean_squared_error: 0.2015\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0231\n",
      "Epoch 141: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0107 - mean_squared_error: 0.0231 - val_loss: 0.1006 - val_mean_squared_error: 0.2040\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0226\n",
      "Epoch 142: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0104 - mean_squared_error: 0.0226 - val_loss: 0.1030 - val_mean_squared_error: 0.2091\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0229\n",
      "Epoch 143: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0106 - mean_squared_error: 0.0229 - val_loss: 0.1013 - val_mean_squared_error: 0.2056\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0223\n",
      "Epoch 144: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0103 - mean_squared_error: 0.0223 - val_loss: 0.1002 - val_mean_squared_error: 0.2031\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0221\n",
      "Epoch 145: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0102 - mean_squared_error: 0.0221 - val_loss: 0.1020 - val_mean_squared_error: 0.2070\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0220\n",
      "Epoch 146: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0102 - mean_squared_error: 0.0220 - val_loss: 0.0991 - val_mean_squared_error: 0.2011\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0219\n",
      "Epoch 147: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0101 - mean_squared_error: 0.0219 - val_loss: 0.1015 - val_mean_squared_error: 0.2058\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0222\n",
      "Epoch 148: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0103 - mean_squared_error: 0.0222 - val_loss: 0.0996 - val_mean_squared_error: 0.2020\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0228\n",
      "Epoch 149: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0105 - mean_squared_error: 0.0228 - val_loss: 0.0987 - val_mean_squared_error: 0.2002\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0227\n",
      "Epoch 150: val_loss did not improve from 0.07309\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0105 - mean_squared_error: 0.0227 - val_loss: 0.1025 - val_mean_squared_error: 0.2079\n",
      "5/5 [==============================] - 13s 566ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:386: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = self.plt.figure(figsize=self.figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  504\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3892 - mean_squared_error: 0.8809\n",
      "Epoch 1: val_loss improved from inf to 0.31728, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 111s 6s/step - loss: 0.3892 - mean_squared_error: 0.8809 - val_loss: 0.3173 - val_mean_squared_error: 0.6900\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2441 - mean_squared_error: 0.5328\n",
      "Epoch 2: val_loss improved from 0.31728 to 0.17258, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.2441 - mean_squared_error: 0.5328 - val_loss: 0.1726 - val_mean_squared_error: 0.3567\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1393 - mean_squared_error: 0.2877\n",
      "Epoch 3: val_loss improved from 0.17258 to 0.14365, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.1393 - mean_squared_error: 0.2877 - val_loss: 0.1437 - val_mean_squared_error: 0.2951\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1129 - mean_squared_error: 0.2309\n",
      "Epoch 4: val_loss improved from 0.14365 to 0.12543, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.1129 - mean_squared_error: 0.2309 - val_loss: 0.1254 - val_mean_squared_error: 0.2553\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1009 - mean_squared_error: 0.2061\n",
      "Epoch 5: val_loss improved from 0.12543 to 0.11813, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.1009 - mean_squared_error: 0.2061 - val_loss: 0.1181 - val_mean_squared_error: 0.2398\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0967 - mean_squared_error: 0.1974\n",
      "Epoch 6: val_loss did not improve from 0.11813\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0967 - mean_squared_error: 0.1974 - val_loss: 0.1260 - val_mean_squared_error: 0.2570\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0927 - mean_squared_error: 0.1889\n",
      "Epoch 7: val_loss improved from 0.11813 to 0.11009, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0927 - mean_squared_error: 0.1889 - val_loss: 0.1101 - val_mean_squared_error: 0.2232\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0912 - mean_squared_error: 0.1862\n",
      "Epoch 8: val_loss did not improve from 0.11009\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0912 - mean_squared_error: 0.1862 - val_loss: 0.1181 - val_mean_squared_error: 0.2410\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0887 - mean_squared_error: 0.1811\n",
      "Epoch 9: val_loss did not improve from 0.11009\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0887 - mean_squared_error: 0.1811 - val_loss: 0.1166 - val_mean_squared_error: 0.2374\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0861 - mean_squared_error: 0.1761\n",
      "Epoch 10: val_loss did not improve from 0.11009\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0861 - mean_squared_error: 0.1761 - val_loss: 0.1150 - val_mean_squared_error: 0.2345\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0836 - mean_squared_error: 0.1707\n",
      "Epoch 11: val_loss improved from 0.11009 to 0.10812, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0836 - mean_squared_error: 0.1707 - val_loss: 0.1081 - val_mean_squared_error: 0.2200\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0832 - mean_squared_error: 0.1702\n",
      "Epoch 12: val_loss improved from 0.10812 to 0.10800, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0832 - mean_squared_error: 0.1702 - val_loss: 0.1080 - val_mean_squared_error: 0.2198\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0828 - mean_squared_error: 0.1696\n",
      "Epoch 13: val_loss did not improve from 0.10800\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0828 - mean_squared_error: 0.1696 - val_loss: 0.1095 - val_mean_squared_error: 0.2226\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0790 - mean_squared_error: 0.1616\n",
      "Epoch 14: val_loss improved from 0.10800 to 0.10638, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0790 - mean_squared_error: 0.1616 - val_loss: 0.1064 - val_mean_squared_error: 0.2163\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0774 - mean_squared_error: 0.1581\n",
      "Epoch 15: val_loss did not improve from 0.10638\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0774 - mean_squared_error: 0.1581 - val_loss: 0.1069 - val_mean_squared_error: 0.2172\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0761 - mean_squared_error: 0.1557\n",
      "Epoch 16: val_loss did not improve from 0.10638\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0761 - mean_squared_error: 0.1557 - val_loss: 0.1099 - val_mean_squared_error: 0.2230\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0739 - mean_squared_error: 0.1512\n",
      "Epoch 17: val_loss improved from 0.10638 to 0.09617, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0739 - mean_squared_error: 0.1512 - val_loss: 0.0962 - val_mean_squared_error: 0.1952\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0728 - mean_squared_error: 0.1487\n",
      "Epoch 18: val_loss improved from 0.09617 to 0.09177, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0728 - mean_squared_error: 0.1487 - val_loss: 0.0918 - val_mean_squared_error: 0.1857\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0684 - mean_squared_error: 0.1399\n",
      "Epoch 19: val_loss did not improve from 0.09177\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0684 - mean_squared_error: 0.1399 - val_loss: 0.1025 - val_mean_squared_error: 0.2077\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0669 - mean_squared_error: 0.1364\n",
      "Epoch 20: val_loss improved from 0.09177 to 0.08249, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0669 - mean_squared_error: 0.1364 - val_loss: 0.0825 - val_mean_squared_error: 0.1665\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0630 - mean_squared_error: 0.1285\n",
      "Epoch 21: val_loss improved from 0.08249 to 0.08084, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0630 - mean_squared_error: 0.1285 - val_loss: 0.0808 - val_mean_squared_error: 0.1638\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0610 - mean_squared_error: 0.1245\n",
      "Epoch 22: val_loss improved from 0.08084 to 0.07985, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0610 - mean_squared_error: 0.1245 - val_loss: 0.0798 - val_mean_squared_error: 0.1610\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0591 - mean_squared_error: 0.1204\n",
      "Epoch 23: val_loss did not improve from 0.07985\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0591 - mean_squared_error: 0.1204 - val_loss: 0.0842 - val_mean_squared_error: 0.1702\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0570 - mean_squared_error: 0.1163\n",
      "Epoch 24: val_loss improved from 0.07985 to 0.07821, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0570 - mean_squared_error: 0.1163 - val_loss: 0.0782 - val_mean_squared_error: 0.1575\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0577 - mean_squared_error: 0.1175\n",
      "Epoch 25: val_loss did not improve from 0.07821\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0577 - mean_squared_error: 0.1175 - val_loss: 0.0881 - val_mean_squared_error: 0.1789\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0544 - mean_squared_error: 0.1109\n",
      "Epoch 26: val_loss did not improve from 0.07821\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0544 - mean_squared_error: 0.1109 - val_loss: 0.0850 - val_mean_squared_error: 0.1714\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0528 - mean_squared_error: 0.1075\n",
      "Epoch 27: val_loss did not improve from 0.07821\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0528 - mean_squared_error: 0.1075 - val_loss: 0.0784 - val_mean_squared_error: 0.1581\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0536 - mean_squared_error: 0.1090\n",
      "Epoch 28: val_loss did not improve from 0.07821\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0536 - mean_squared_error: 0.1090 - val_loss: 0.0834 - val_mean_squared_error: 0.1687\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0520 - mean_squared_error: 0.1060\n",
      "Epoch 29: val_loss did not improve from 0.07821\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0520 - mean_squared_error: 0.1060 - val_loss: 0.0823 - val_mean_squared_error: 0.1659\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0513 - mean_squared_error: 0.1046\n",
      "Epoch 30: val_loss improved from 0.07821 to 0.07651, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0513 - mean_squared_error: 0.1046 - val_loss: 0.0765 - val_mean_squared_error: 0.1539\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0511 - mean_squared_error: 0.1042\n",
      "Epoch 31: val_loss did not improve from 0.07651\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0511 - mean_squared_error: 0.1042 - val_loss: 0.0829 - val_mean_squared_error: 0.1670\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0505 - mean_squared_error: 0.1030\n",
      "Epoch 32: val_loss did not improve from 0.07651\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0505 - mean_squared_error: 0.1030 - val_loss: 0.0818 - val_mean_squared_error: 0.1651\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0491 - mean_squared_error: 0.1002\n",
      "Epoch 33: val_loss did not improve from 0.07651\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0491 - mean_squared_error: 0.1002 - val_loss: 0.0836 - val_mean_squared_error: 0.1686\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0483 - mean_squared_error: 0.0987\n",
      "Epoch 34: val_loss did not improve from 0.07651\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0483 - mean_squared_error: 0.0987 - val_loss: 0.0846 - val_mean_squared_error: 0.1714\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0502 - mean_squared_error: 0.1023\n",
      "Epoch 35: val_loss did not improve from 0.07651\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0502 - mean_squared_error: 0.1023 - val_loss: 0.0813 - val_mean_squared_error: 0.1634\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0496 - mean_squared_error: 0.1012\n",
      "Epoch 36: val_loss did not improve from 0.07651\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0496 - mean_squared_error: 0.1012 - val_loss: 0.0862 - val_mean_squared_error: 0.1734\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0505 - mean_squared_error: 0.1030\n",
      "Epoch 37: val_loss did not improve from 0.07651\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0505 - mean_squared_error: 0.1030 - val_loss: 0.0826 - val_mean_squared_error: 0.1660\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0479 - mean_squared_error: 0.0976\n",
      "Epoch 38: val_loss improved from 0.07651 to 0.07642, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0479 - mean_squared_error: 0.0976 - val_loss: 0.0764 - val_mean_squared_error: 0.1536\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0476 - mean_squared_error: 0.0970\n",
      "Epoch 39: val_loss did not improve from 0.07642\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0476 - mean_squared_error: 0.0970 - val_loss: 0.0896 - val_mean_squared_error: 0.1809\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0494 - mean_squared_error: 0.1009\n",
      "Epoch 40: val_loss did not improve from 0.07642\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0494 - mean_squared_error: 0.1009 - val_loss: 0.0786 - val_mean_squared_error: 0.1594\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0483 - mean_squared_error: 0.0983\n",
      "Epoch 41: val_loss did not improve from 0.07642\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0483 - mean_squared_error: 0.0983 - val_loss: 0.0849 - val_mean_squared_error: 0.1709\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0467 - mean_squared_error: 0.0954\n",
      "Epoch 42: val_loss did not improve from 0.07642\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0467 - mean_squared_error: 0.0954 - val_loss: 0.0766 - val_mean_squared_error: 0.1547\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0457 - mean_squared_error: 0.0933\n",
      "Epoch 43: val_loss did not improve from 0.07642\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0457 - mean_squared_error: 0.0933 - val_loss: 0.0810 - val_mean_squared_error: 0.1628\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0444 - mean_squared_error: 0.0905\n",
      "Epoch 44: val_loss improved from 0.07642 to 0.07453, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0444 - mean_squared_error: 0.0905 - val_loss: 0.0745 - val_mean_squared_error: 0.1498\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0424 - mean_squared_error: 0.0866\n",
      "Epoch 45: val_loss did not improve from 0.07453\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0424 - mean_squared_error: 0.0866 - val_loss: 0.0780 - val_mean_squared_error: 0.1567\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0426 - mean_squared_error: 0.0869\n",
      "Epoch 46: val_loss did not improve from 0.07453\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0426 - mean_squared_error: 0.0869 - val_loss: 0.0817 - val_mean_squared_error: 0.1646\n",
      "Epoch 47/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - ETA: 0s - loss: 0.0424 - mean_squared_error: 0.0867\n",
      "Epoch 47: val_loss did not improve from 0.07453\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0424 - mean_squared_error: 0.0867 - val_loss: 0.0918 - val_mean_squared_error: 0.1860\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0433 - mean_squared_error: 0.0884\n",
      "Epoch 48: val_loss did not improve from 0.07453\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0433 - mean_squared_error: 0.0884 - val_loss: 0.0925 - val_mean_squared_error: 0.1874\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0428 - mean_squared_error: 0.0875\n",
      "Epoch 49: val_loss did not improve from 0.07453\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0428 - mean_squared_error: 0.0875 - val_loss: 0.0786 - val_mean_squared_error: 0.1581\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0410 - mean_squared_error: 0.0837\n",
      "Epoch 50: val_loss did not improve from 0.07453\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0410 - mean_squared_error: 0.0837 - val_loss: 0.0818 - val_mean_squared_error: 0.1647\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0396 - mean_squared_error: 0.0811\n",
      "Epoch 51: val_loss improved from 0.07453 to 0.07413, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0396 - mean_squared_error: 0.0811 - val_loss: 0.0741 - val_mean_squared_error: 0.1493\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.0789\n",
      "Epoch 52: val_loss did not improve from 0.07413\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0386 - mean_squared_error: 0.0789 - val_loss: 0.0758 - val_mean_squared_error: 0.1524\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0385 - mean_squared_error: 0.0788\n",
      "Epoch 53: val_loss did not improve from 0.07413\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0385 - mean_squared_error: 0.0788 - val_loss: 0.0752 - val_mean_squared_error: 0.1512\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0780\n",
      "Epoch 54: val_loss did not improve from 0.07413\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0381 - mean_squared_error: 0.0780 - val_loss: 0.0802 - val_mean_squared_error: 0.1618\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.0788\n",
      "Epoch 55: val_loss improved from 0.07413 to 0.07246, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0386 - mean_squared_error: 0.0788 - val_loss: 0.0725 - val_mean_squared_error: 0.1458\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0378 - mean_squared_error: 0.0773\n",
      "Epoch 56: val_loss improved from 0.07246 to 0.07194, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0378 - mean_squared_error: 0.0773 - val_loss: 0.0719 - val_mean_squared_error: 0.1448\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0371 - mean_squared_error: 0.0761\n",
      "Epoch 57: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0371 - mean_squared_error: 0.0761 - val_loss: 0.0744 - val_mean_squared_error: 0.1494\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0365 - mean_squared_error: 0.0747\n",
      "Epoch 58: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0365 - mean_squared_error: 0.0747 - val_loss: 0.0796 - val_mean_squared_error: 0.1601\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0365 - mean_squared_error: 0.0747\n",
      "Epoch 59: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0365 - mean_squared_error: 0.0747 - val_loss: 0.0831 - val_mean_squared_error: 0.1682\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0373 - mean_squared_error: 0.0764\n",
      "Epoch 60: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0373 - mean_squared_error: 0.0764 - val_loss: 0.0778 - val_mean_squared_error: 0.1564\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0355 - mean_squared_error: 0.0727\n",
      "Epoch 61: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0355 - mean_squared_error: 0.0727 - val_loss: 0.0784 - val_mean_squared_error: 0.1575\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.0726\n",
      "Epoch 62: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0354 - mean_squared_error: 0.0726 - val_loss: 0.0792 - val_mean_squared_error: 0.1598\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0353 - mean_squared_error: 0.0724\n",
      "Epoch 63: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0353 - mean_squared_error: 0.0724 - val_loss: 0.0813 - val_mean_squared_error: 0.1646\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0344 - mean_squared_error: 0.0705\n",
      "Epoch 64: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0344 - mean_squared_error: 0.0705 - val_loss: 0.0800 - val_mean_squared_error: 0.1614\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0341 - mean_squared_error: 0.0700\n",
      "Epoch 65: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0341 - mean_squared_error: 0.0700 - val_loss: 0.0793 - val_mean_squared_error: 0.1600\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0338 - mean_squared_error: 0.0693\n",
      "Epoch 66: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0338 - mean_squared_error: 0.0693 - val_loss: 0.0801 - val_mean_squared_error: 0.1611\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0662\n",
      "Epoch 67: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0323 - mean_squared_error: 0.0662 - val_loss: 0.0722 - val_mean_squared_error: 0.1452\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0331 - mean_squared_error: 0.0679\n",
      "Epoch 68: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0331 - mean_squared_error: 0.0679 - val_loss: 0.0743 - val_mean_squared_error: 0.1496\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0332 - mean_squared_error: 0.0682\n",
      "Epoch 69: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0332 - mean_squared_error: 0.0682 - val_loss: 0.0803 - val_mean_squared_error: 0.1620\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0316 - mean_squared_error: 0.0650\n",
      "Epoch 70: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0316 - mean_squared_error: 0.0650 - val_loss: 0.0780 - val_mean_squared_error: 0.1567\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0314 - mean_squared_error: 0.0645\n",
      "Epoch 71: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0314 - mean_squared_error: 0.0645 - val_loss: 0.0815 - val_mean_squared_error: 0.1638\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0301 - mean_squared_error: 0.0619\n",
      "Epoch 72: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0301 - mean_squared_error: 0.0619 - val_loss: 0.0813 - val_mean_squared_error: 0.1642\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0301 - mean_squared_error: 0.0619\n",
      "Epoch 73: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0301 - mean_squared_error: 0.0619 - val_loss: 0.0814 - val_mean_squared_error: 0.1641\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0294 - mean_squared_error: 0.0604\n",
      "Epoch 74: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0294 - mean_squared_error: 0.0604 - val_loss: 0.0774 - val_mean_squared_error: 0.1556\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0291 - mean_squared_error: 0.0599\n",
      "Epoch 75: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0291 - mean_squared_error: 0.0599 - val_loss: 0.0787 - val_mean_squared_error: 0.1583\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0289 - mean_squared_error: 0.0592\n",
      "Epoch 76: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0289 - mean_squared_error: 0.0592 - val_loss: 0.0809 - val_mean_squared_error: 0.1632\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0282 - mean_squared_error: 0.0578\n",
      "Epoch 77: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0282 - mean_squared_error: 0.0578 - val_loss: 0.0783 - val_mean_squared_error: 0.1576\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0281 - mean_squared_error: 0.0579\n",
      "Epoch 78: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0281 - mean_squared_error: 0.0579 - val_loss: 0.0789 - val_mean_squared_error: 0.1589\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0275 - mean_squared_error: 0.0567\n",
      "Epoch 79: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0275 - mean_squared_error: 0.0567 - val_loss: 0.0783 - val_mean_squared_error: 0.1574\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0268 - mean_squared_error: 0.0554\n",
      "Epoch 80: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0268 - mean_squared_error: 0.0554 - val_loss: 0.0822 - val_mean_squared_error: 0.1658\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0263 - mean_squared_error: 0.0542\n",
      "Epoch 81: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0263 - mean_squared_error: 0.0542 - val_loss: 0.0767 - val_mean_squared_error: 0.1541\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0258 - mean_squared_error: 0.0531\n",
      "Epoch 82: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0258 - mean_squared_error: 0.0531 - val_loss: 0.0808 - val_mean_squared_error: 0.1628\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0261 - mean_squared_error: 0.0538\n",
      "Epoch 83: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0261 - mean_squared_error: 0.0538 - val_loss: 0.0793 - val_mean_squared_error: 0.1597\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0518\n",
      "Epoch 84: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0251 - mean_squared_error: 0.0518 - val_loss: 0.0828 - val_mean_squared_error: 0.1669\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0255 - mean_squared_error: 0.0527\n",
      "Epoch 85: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0255 - mean_squared_error: 0.0527 - val_loss: 0.0850 - val_mean_squared_error: 0.1709\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0258 - mean_squared_error: 0.0532\n",
      "Epoch 86: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0258 - mean_squared_error: 0.0532 - val_loss: 0.0806 - val_mean_squared_error: 0.1621\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0248 - mean_squared_error: 0.0513\n",
      "Epoch 87: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0248 - mean_squared_error: 0.0513 - val_loss: 0.0875 - val_mean_squared_error: 0.1769\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0244 - mean_squared_error: 0.0504\n",
      "Epoch 88: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0244 - mean_squared_error: 0.0504 - val_loss: 0.0804 - val_mean_squared_error: 0.1615\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0235 - mean_squared_error: 0.0487\n",
      "Epoch 89: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0235 - mean_squared_error: 0.0487 - val_loss: 0.0822 - val_mean_squared_error: 0.1654\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0239 - mean_squared_error: 0.0495\n",
      "Epoch 90: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0239 - mean_squared_error: 0.0495 - val_loss: 0.0833 - val_mean_squared_error: 0.1682\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0465\n",
      "Epoch 91: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0224 - mean_squared_error: 0.0465 - val_loss: 0.0823 - val_mean_squared_error: 0.1655\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0225 - mean_squared_error: 0.0465\n",
      "Epoch 92: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0225 - mean_squared_error: 0.0465 - val_loss: 0.0815 - val_mean_squared_error: 0.1641\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0220 - mean_squared_error: 0.0457\n",
      "Epoch 93: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0220 - mean_squared_error: 0.0457 - val_loss: 0.0898 - val_mean_squared_error: 0.1812\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0209 - mean_squared_error: 0.0433\n",
      "Epoch 94: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0209 - mean_squared_error: 0.0433 - val_loss: 0.0831 - val_mean_squared_error: 0.1674\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0206 - mean_squared_error: 0.0429\n",
      "Epoch 95: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0206 - mean_squared_error: 0.0429 - val_loss: 0.0858 - val_mean_squared_error: 0.1733\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0201 - mean_squared_error: 0.0418\n",
      "Epoch 96: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0201 - mean_squared_error: 0.0418 - val_loss: 0.0884 - val_mean_squared_error: 0.1785\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0199 - mean_squared_error: 0.0414\n",
      "Epoch 97: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0199 - mean_squared_error: 0.0414 - val_loss: 0.0858 - val_mean_squared_error: 0.1730\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0194 - mean_squared_error: 0.0403\n",
      "Epoch 98: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0194 - mean_squared_error: 0.0403 - val_loss: 0.0824 - val_mean_squared_error: 0.1663\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0190 - mean_squared_error: 0.0396\n",
      "Epoch 99: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0190 - mean_squared_error: 0.0396 - val_loss: 0.0882 - val_mean_squared_error: 0.1777\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.0392\n",
      "Epoch 100: val_loss did not improve from 0.07194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 47s 5s/step - loss: 0.0188 - mean_squared_error: 0.0392 - val_loss: 0.0869 - val_mean_squared_error: 0.1756\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.0392\n",
      "Epoch 101: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0188 - mean_squared_error: 0.0392 - val_loss: 0.0883 - val_mean_squared_error: 0.1785\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.0393\n",
      "Epoch 102: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0188 - mean_squared_error: 0.0393 - val_loss: 0.0876 - val_mean_squared_error: 0.1772\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0184 - mean_squared_error: 0.0384\n",
      "Epoch 103: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0184 - mean_squared_error: 0.0384 - val_loss: 0.0928 - val_mean_squared_error: 0.1876\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0184 - mean_squared_error: 0.0386\n",
      "Epoch 104: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0184 - mean_squared_error: 0.0386 - val_loss: 0.0858 - val_mean_squared_error: 0.1730\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0387\n",
      "Epoch 105: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0185 - mean_squared_error: 0.0387 - val_loss: 0.0843 - val_mean_squared_error: 0.1701\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0187 - mean_squared_error: 0.0392\n",
      "Epoch 106: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0187 - mean_squared_error: 0.0392 - val_loss: 0.0878 - val_mean_squared_error: 0.1765\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0378\n",
      "Epoch 107: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0181 - mean_squared_error: 0.0378 - val_loss: 0.0850 - val_mean_squared_error: 0.1716\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0356\n",
      "Epoch 108: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0169 - mean_squared_error: 0.0356 - val_loss: 0.0910 - val_mean_squared_error: 0.1842\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0177 - mean_squared_error: 0.0370\n",
      "Epoch 109: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0177 - mean_squared_error: 0.0370 - val_loss: 0.0827 - val_mean_squared_error: 0.1666\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0350\n",
      "Epoch 110: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0167 - mean_squared_error: 0.0350 - val_loss: 0.0873 - val_mean_squared_error: 0.1761\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0345\n",
      "Epoch 111: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0164 - mean_squared_error: 0.0345 - val_loss: 0.0866 - val_mean_squared_error: 0.1748\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0335\n",
      "Epoch 112: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0159 - mean_squared_error: 0.0335 - val_loss: 0.0896 - val_mean_squared_error: 0.1812\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0158 - mean_squared_error: 0.0332\n",
      "Epoch 113: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0158 - mean_squared_error: 0.0332 - val_loss: 0.0841 - val_mean_squared_error: 0.1695\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0156 - mean_squared_error: 0.0328\n",
      "Epoch 114: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0156 - mean_squared_error: 0.0328 - val_loss: 0.0901 - val_mean_squared_error: 0.1821\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0153 - mean_squared_error: 0.0322\n",
      "Epoch 115: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0153 - mean_squared_error: 0.0322 - val_loss: 0.0920 - val_mean_squared_error: 0.1860\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0327\n",
      "Epoch 116: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0155 - mean_squared_error: 0.0327 - val_loss: 0.0868 - val_mean_squared_error: 0.1755\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0322\n",
      "Epoch 117: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0152 - mean_squared_error: 0.0322 - val_loss: 0.0889 - val_mean_squared_error: 0.1798\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0312\n",
      "Epoch 118: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0148 - mean_squared_error: 0.0312 - val_loss: 0.0944 - val_mean_squared_error: 0.1911\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0311\n",
      "Epoch 119: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0147 - mean_squared_error: 0.0311 - val_loss: 0.0857 - val_mean_squared_error: 0.1733\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0304\n",
      "Epoch 120: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0143 - mean_squared_error: 0.0304 - val_loss: 0.0910 - val_mean_squared_error: 0.1838\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0294\n",
      "Epoch 121: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0138 - mean_squared_error: 0.0294 - val_loss: 0.0911 - val_mean_squared_error: 0.1843\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0281\n",
      "Epoch 122: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0132 - mean_squared_error: 0.0281 - val_loss: 0.0927 - val_mean_squared_error: 0.1877\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0279\n",
      "Epoch 123: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0131 - mean_squared_error: 0.0279 - val_loss: 0.0916 - val_mean_squared_error: 0.1854\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0278\n",
      "Epoch 124: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0130 - mean_squared_error: 0.0278 - val_loss: 0.0925 - val_mean_squared_error: 0.1873\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0277\n",
      "Epoch 125: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0130 - mean_squared_error: 0.0277 - val_loss: 0.0871 - val_mean_squared_error: 0.1759\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0274\n",
      "Epoch 126: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0128 - mean_squared_error: 0.0274 - val_loss: 0.0904 - val_mean_squared_error: 0.1828\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0274\n",
      "Epoch 127: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0128 - mean_squared_error: 0.0274 - val_loss: 0.0934 - val_mean_squared_error: 0.1890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0266\n",
      "Epoch 128: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0125 - mean_squared_error: 0.0266 - val_loss: 0.0912 - val_mean_squared_error: 0.1846\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0267\n",
      "Epoch 129: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0125 - mean_squared_error: 0.0267 - val_loss: 0.0966 - val_mean_squared_error: 0.1951\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0269\n",
      "Epoch 130: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0125 - mean_squared_error: 0.0269 - val_loss: 0.0918 - val_mean_squared_error: 0.1857\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0268\n",
      "Epoch 131: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0125 - mean_squared_error: 0.0268 - val_loss: 0.0947 - val_mean_squared_error: 0.1917\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0257\n",
      "Epoch 132: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0120 - mean_squared_error: 0.0257 - val_loss: 0.0910 - val_mean_squared_error: 0.1841\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0253\n",
      "Epoch 133: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0118 - mean_squared_error: 0.0253 - val_loss: 0.0904 - val_mean_squared_error: 0.1828\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0254\n",
      "Epoch 134: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0118 - mean_squared_error: 0.0254 - val_loss: 0.0974 - val_mean_squared_error: 0.1972\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0256\n",
      "Epoch 135: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0119 - mean_squared_error: 0.0256 - val_loss: 0.0893 - val_mean_squared_error: 0.1805\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0253\n",
      "Epoch 136: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0118 - mean_squared_error: 0.0253 - val_loss: 0.0901 - val_mean_squared_error: 0.1821\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0250\n",
      "Epoch 137: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0117 - mean_squared_error: 0.0250 - val_loss: 0.0943 - val_mean_squared_error: 0.1910\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0248\n",
      "Epoch 138: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0116 - mean_squared_error: 0.0248 - val_loss: 0.0929 - val_mean_squared_error: 0.1882\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0243\n",
      "Epoch 139: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0113 - mean_squared_error: 0.0243 - val_loss: 0.0922 - val_mean_squared_error: 0.1866\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0246\n",
      "Epoch 140: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0114 - mean_squared_error: 0.0246 - val_loss: 0.0936 - val_mean_squared_error: 0.1896\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0246\n",
      "Epoch 141: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0114 - mean_squared_error: 0.0246 - val_loss: 0.0911 - val_mean_squared_error: 0.1841\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0246\n",
      "Epoch 142: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0114 - mean_squared_error: 0.0246 - val_loss: 0.0932 - val_mean_squared_error: 0.1889\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0239\n",
      "Epoch 143: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0111 - mean_squared_error: 0.0239 - val_loss: 0.0913 - val_mean_squared_error: 0.1850\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0229\n",
      "Epoch 144: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0106 - mean_squared_error: 0.0229 - val_loss: 0.0956 - val_mean_squared_error: 0.1937\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0230\n",
      "Epoch 145: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0106 - mean_squared_error: 0.0230 - val_loss: 0.0941 - val_mean_squared_error: 0.1901\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0229\n",
      "Epoch 146: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0106 - mean_squared_error: 0.0229 - val_loss: 0.0949 - val_mean_squared_error: 0.1920\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0225\n",
      "Epoch 147: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0104 - mean_squared_error: 0.0225 - val_loss: 0.0944 - val_mean_squared_error: 0.1912\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0224\n",
      "Epoch 148: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0103 - mean_squared_error: 0.0224 - val_loss: 0.0926 - val_mean_squared_error: 0.1875\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0224\n",
      "Epoch 149: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0103 - mean_squared_error: 0.0224 - val_loss: 0.0929 - val_mean_squared_error: 0.1877\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0222\n",
      "Epoch 150: val_loss did not improve from 0.07194\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0102 - mean_squared_error: 0.0222 - val_loss: 0.0968 - val_mean_squared_error: 0.1963\n",
      "5/5 [==============================] - 13s 437ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  528\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4127 - mean_squared_error: 0.9407\n",
      "Epoch 1: val_loss improved from inf to 0.29208, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 108s 7s/step - loss: 0.4127 - mean_squared_error: 0.9407 - val_loss: 0.2921 - val_mean_squared_error: 0.6342\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2833 - mean_squared_error: 0.6362\n",
      "Epoch 2: val_loss improved from 0.29208 to 0.17488, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.2833 - mean_squared_error: 0.6362 - val_loss: 0.1749 - val_mean_squared_error: 0.3688\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1777 - mean_squared_error: 0.3801\n",
      "Epoch 3: val_loss improved from 0.17488 to 0.15085, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.1777 - mean_squared_error: 0.3801 - val_loss: 0.1509 - val_mean_squared_error: 0.3107\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1232 - mean_squared_error: 0.2530\n",
      "Epoch 4: val_loss improved from 0.15085 to 0.12833, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.1232 - mean_squared_error: 0.2530 - val_loss: 0.1283 - val_mean_squared_error: 0.2609\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1027 - mean_squared_error: 0.2101\n",
      "Epoch 5: val_loss improved from 0.12833 to 0.12369, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.1027 - mean_squared_error: 0.2101 - val_loss: 0.1237 - val_mean_squared_error: 0.2515\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0968 - mean_squared_error: 0.1977\n",
      "Epoch 6: val_loss improved from 0.12369 to 0.11724, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0968 - mean_squared_error: 0.1977 - val_loss: 0.1172 - val_mean_squared_error: 0.2380\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0913 - mean_squared_error: 0.1864\n",
      "Epoch 7: val_loss improved from 0.11724 to 0.11679, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0913 - mean_squared_error: 0.1864 - val_loss: 0.1168 - val_mean_squared_error: 0.2374\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0872 - mean_squared_error: 0.1785\n",
      "Epoch 8: val_loss did not improve from 0.11679\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0872 - mean_squared_error: 0.1785 - val_loss: 0.1220 - val_mean_squared_error: 0.2491\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0857 - mean_squared_error: 0.1756\n",
      "Epoch 9: val_loss did not improve from 0.11679\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0857 - mean_squared_error: 0.1756 - val_loss: 0.1188 - val_mean_squared_error: 0.2425\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0819 - mean_squared_error: 0.1675\n",
      "Epoch 10: val_loss improved from 0.11679 to 0.11205, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0819 - mean_squared_error: 0.1675 - val_loss: 0.1120 - val_mean_squared_error: 0.2287\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0802 - mean_squared_error: 0.1643\n",
      "Epoch 11: val_loss improved from 0.11205 to 0.10929, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0802 - mean_squared_error: 0.1643 - val_loss: 0.1093 - val_mean_squared_error: 0.2224\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0798 - mean_squared_error: 0.1632\n",
      "Epoch 12: val_loss improved from 0.10929 to 0.10545, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0798 - mean_squared_error: 0.1632 - val_loss: 0.1055 - val_mean_squared_error: 0.2144\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0780 - mean_squared_error: 0.1597\n",
      "Epoch 13: val_loss did not improve from 0.10545\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0780 - mean_squared_error: 0.1597 - val_loss: 0.1092 - val_mean_squared_error: 0.2220\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0763 - mean_squared_error: 0.1563\n",
      "Epoch 14: val_loss did not improve from 0.10545\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0763 - mean_squared_error: 0.1563 - val_loss: 0.1099 - val_mean_squared_error: 0.2233\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0745 - mean_squared_error: 0.1525\n",
      "Epoch 15: val_loss improved from 0.10545 to 0.10537, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0745 - mean_squared_error: 0.1525 - val_loss: 0.1054 - val_mean_squared_error: 0.2139\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0743 - mean_squared_error: 0.1518\n",
      "Epoch 16: val_loss improved from 0.10537 to 0.10257, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0743 - mean_squared_error: 0.1518 - val_loss: 0.1026 - val_mean_squared_error: 0.2084\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0733 - mean_squared_error: 0.1497\n",
      "Epoch 17: val_loss improved from 0.10257 to 0.09451, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0733 - mean_squared_error: 0.1497 - val_loss: 0.0945 - val_mean_squared_error: 0.1916\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0726 - mean_squared_error: 0.1483\n",
      "Epoch 18: val_loss improved from 0.09451 to 0.09439, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0726 - mean_squared_error: 0.1483 - val_loss: 0.0944 - val_mean_squared_error: 0.1911\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0721 - mean_squared_error: 0.1472\n",
      "Epoch 19: val_loss did not improve from 0.09439\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0721 - mean_squared_error: 0.1472 - val_loss: 0.0971 - val_mean_squared_error: 0.1961\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0683 - mean_squared_error: 0.1393\n",
      "Epoch 20: val_loss did not improve from 0.09439\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0683 - mean_squared_error: 0.1393 - val_loss: 0.0974 - val_mean_squared_error: 0.1969\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0658 - mean_squared_error: 0.1343\n",
      "Epoch 21: val_loss improved from 0.09439 to 0.08939, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0658 - mean_squared_error: 0.1343 - val_loss: 0.0894 - val_mean_squared_error: 0.1806\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0668 - mean_squared_error: 0.1361\n",
      "Epoch 22: val_loss did not improve from 0.08939\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0668 - mean_squared_error: 0.1361 - val_loss: 0.0972 - val_mean_squared_error: 0.1969\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0636 - mean_squared_error: 0.1297\n",
      "Epoch 23: val_loss did not improve from 0.08939\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0636 - mean_squared_error: 0.1297 - val_loss: 0.0956 - val_mean_squared_error: 0.1933\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0607 - mean_squared_error: 0.1237\n",
      "Epoch 24: val_loss improved from 0.08939 to 0.08419, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0607 - mean_squared_error: 0.1237 - val_loss: 0.0842 - val_mean_squared_error: 0.1704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0579 - mean_squared_error: 0.1183\n",
      "Epoch 25: val_loss improved from 0.08419 to 0.08417, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0579 - mean_squared_error: 0.1183 - val_loss: 0.0842 - val_mean_squared_error: 0.1699\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0536 - mean_squared_error: 0.1096\n",
      "Epoch 26: val_loss improved from 0.08417 to 0.07555, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0536 - mean_squared_error: 0.1096 - val_loss: 0.0756 - val_mean_squared_error: 0.1519\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0538 - mean_squared_error: 0.1098\n",
      "Epoch 27: val_loss improved from 0.07555 to 0.07439, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0538 - mean_squared_error: 0.1098 - val_loss: 0.0744 - val_mean_squared_error: 0.1496\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0519 - mean_squared_error: 0.1060\n",
      "Epoch 28: val_loss improved from 0.07439 to 0.07349, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0519 - mean_squared_error: 0.1060 - val_loss: 0.0735 - val_mean_squared_error: 0.1477\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0514 - mean_squared_error: 0.1048\n",
      "Epoch 29: val_loss did not improve from 0.07349\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0514 - mean_squared_error: 0.1048 - val_loss: 0.0794 - val_mean_squared_error: 0.1598\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0508 - mean_squared_error: 0.1035\n",
      "Epoch 30: val_loss did not improve from 0.07349\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0508 - mean_squared_error: 0.1035 - val_loss: 0.0798 - val_mean_squared_error: 0.1604\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0500 - mean_squared_error: 0.1019\n",
      "Epoch 31: val_loss did not improve from 0.07349\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0500 - mean_squared_error: 0.1019 - val_loss: 0.0817 - val_mean_squared_error: 0.1643\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0485 - mean_squared_error: 0.0990\n",
      "Epoch 32: val_loss did not improve from 0.07349\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0485 - mean_squared_error: 0.0990 - val_loss: 0.0803 - val_mean_squared_error: 0.1615\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0470 - mean_squared_error: 0.0960\n",
      "Epoch 33: val_loss did not improve from 0.07349\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0470 - mean_squared_error: 0.0960 - val_loss: 0.0801 - val_mean_squared_error: 0.1612\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0454 - mean_squared_error: 0.0928\n",
      "Epoch 34: val_loss did not improve from 0.07349\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0454 - mean_squared_error: 0.0928 - val_loss: 0.0807 - val_mean_squared_error: 0.1624\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0451 - mean_squared_error: 0.0920\n",
      "Epoch 35: val_loss improved from 0.07349 to 0.07148, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0451 - mean_squared_error: 0.0920 - val_loss: 0.0715 - val_mean_squared_error: 0.1436\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0449 - mean_squared_error: 0.0917\n",
      "Epoch 36: val_loss did not improve from 0.07148\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0449 - mean_squared_error: 0.0917 - val_loss: 0.0765 - val_mean_squared_error: 0.1535\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0455 - mean_squared_error: 0.0931\n",
      "Epoch 37: val_loss did not improve from 0.07148\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0455 - mean_squared_error: 0.0931 - val_loss: 0.0732 - val_mean_squared_error: 0.1471\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0455 - mean_squared_error: 0.0930\n",
      "Epoch 38: val_loss did not improve from 0.07148\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0455 - mean_squared_error: 0.0930 - val_loss: 0.0739 - val_mean_squared_error: 0.1484\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0429 - mean_squared_error: 0.0876\n",
      "Epoch 39: val_loss did not improve from 0.07148\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0429 - mean_squared_error: 0.0876 - val_loss: 0.0747 - val_mean_squared_error: 0.1501\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0414 - mean_squared_error: 0.0847\n",
      "Epoch 40: val_loss did not improve from 0.07148\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0414 - mean_squared_error: 0.0847 - val_loss: 0.0729 - val_mean_squared_error: 0.1463\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0410 - mean_squared_error: 0.0838\n",
      "Epoch 41: val_loss did not improve from 0.07148\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0410 - mean_squared_error: 0.0838 - val_loss: 0.0786 - val_mean_squared_error: 0.1578\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0406 - mean_squared_error: 0.0830\n",
      "Epoch 42: val_loss did not improve from 0.07148\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0406 - mean_squared_error: 0.0830 - val_loss: 0.0746 - val_mean_squared_error: 0.1499\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0410 - mean_squared_error: 0.0839\n",
      "Epoch 43: val_loss improved from 0.07148 to 0.06983, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0410 - mean_squared_error: 0.0839 - val_loss: 0.0698 - val_mean_squared_error: 0.1403\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0411 - mean_squared_error: 0.0840\n",
      "Epoch 44: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0411 - mean_squared_error: 0.0840 - val_loss: 0.0806 - val_mean_squared_error: 0.1620\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0829\n",
      "Epoch 45: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0405 - mean_squared_error: 0.0829 - val_loss: 0.0759 - val_mean_squared_error: 0.1524\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0404 - mean_squared_error: 0.0826\n",
      "Epoch 46: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0404 - mean_squared_error: 0.0826 - val_loss: 0.0742 - val_mean_squared_error: 0.1488\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0806\n",
      "Epoch 47: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0394 - mean_squared_error: 0.0806 - val_loss: 0.0741 - val_mean_squared_error: 0.1486\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0786\n",
      "Epoch 48: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0384 - mean_squared_error: 0.0786 - val_loss: 0.0756 - val_mean_squared_error: 0.1517\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0377 - mean_squared_error: 0.0771\n",
      "Epoch 49: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0377 - mean_squared_error: 0.0771 - val_loss: 0.0768 - val_mean_squared_error: 0.1542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0368 - mean_squared_error: 0.0754\n",
      "Epoch 50: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0368 - mean_squared_error: 0.0754 - val_loss: 0.0828 - val_mean_squared_error: 0.1665\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0359 - mean_squared_error: 0.0735\n",
      "Epoch 51: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0359 - mean_squared_error: 0.0735 - val_loss: 0.0821 - val_mean_squared_error: 0.1650\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0350 - mean_squared_error: 0.0718\n",
      "Epoch 52: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0350 - mean_squared_error: 0.0718 - val_loss: 0.0814 - val_mean_squared_error: 0.1635\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.0726\n",
      "Epoch 53: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0354 - mean_squared_error: 0.0726 - val_loss: 0.0794 - val_mean_squared_error: 0.1595\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0341 - mean_squared_error: 0.0700\n",
      "Epoch 54: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0341 - mean_squared_error: 0.0700 - val_loss: 0.0811 - val_mean_squared_error: 0.1630\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0339 - mean_squared_error: 0.0695\n",
      "Epoch 55: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0339 - mean_squared_error: 0.0695 - val_loss: 0.0772 - val_mean_squared_error: 0.1551\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0339 - mean_squared_error: 0.0696\n",
      "Epoch 56: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0339 - mean_squared_error: 0.0696 - val_loss: 0.0780 - val_mean_squared_error: 0.1566\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0663\n",
      "Epoch 57: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0323 - mean_squared_error: 0.0663 - val_loss: 0.0764 - val_mean_squared_error: 0.1535\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0326 - mean_squared_error: 0.0669\n",
      "Epoch 58: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0326 - mean_squared_error: 0.0669 - val_loss: 0.0763 - val_mean_squared_error: 0.1533\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0324 - mean_squared_error: 0.0665\n",
      "Epoch 59: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0324 - mean_squared_error: 0.0665 - val_loss: 0.0828 - val_mean_squared_error: 0.1664\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0314 - mean_squared_error: 0.0645\n",
      "Epoch 60: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0314 - mean_squared_error: 0.0645 - val_loss: 0.0760 - val_mean_squared_error: 0.1525\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0318 - mean_squared_error: 0.0653\n",
      "Epoch 61: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0318 - mean_squared_error: 0.0653 - val_loss: 0.0807 - val_mean_squared_error: 0.1622\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0321 - mean_squared_error: 0.0659\n",
      "Epoch 62: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0321 - mean_squared_error: 0.0659 - val_loss: 0.0893 - val_mean_squared_error: 0.1798\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0302 - mean_squared_error: 0.0621\n",
      "Epoch 63: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0302 - mean_squared_error: 0.0621 - val_loss: 0.0801 - val_mean_squared_error: 0.1608\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0294 - mean_squared_error: 0.0606\n",
      "Epoch 64: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0294 - mean_squared_error: 0.0606 - val_loss: 0.0771 - val_mean_squared_error: 0.1547\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0288 - mean_squared_error: 0.0592\n",
      "Epoch 65: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0288 - mean_squared_error: 0.0592 - val_loss: 0.0805 - val_mean_squared_error: 0.1618\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0286 - mean_squared_error: 0.0590\n",
      "Epoch 66: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0286 - mean_squared_error: 0.0590 - val_loss: 0.0832 - val_mean_squared_error: 0.1673\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0281 - mean_squared_error: 0.0580\n",
      "Epoch 67: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0281 - mean_squared_error: 0.0580 - val_loss: 0.0788 - val_mean_squared_error: 0.1582\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0278 - mean_squared_error: 0.0574\n",
      "Epoch 68: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0278 - mean_squared_error: 0.0574 - val_loss: 0.0785 - val_mean_squared_error: 0.1576\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0281 - mean_squared_error: 0.0579\n",
      "Epoch 69: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0281 - mean_squared_error: 0.0579 - val_loss: 0.0793 - val_mean_squared_error: 0.1596\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0281 - mean_squared_error: 0.0580\n",
      "Epoch 70: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0281 - mean_squared_error: 0.0580 - val_loss: 0.0806 - val_mean_squared_error: 0.1621\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0282 - mean_squared_error: 0.0581\n",
      "Epoch 71: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0282 - mean_squared_error: 0.0581 - val_loss: 0.0855 - val_mean_squared_error: 0.1721\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0560\n",
      "Epoch 72: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0271 - mean_squared_error: 0.0560 - val_loss: 0.0853 - val_mean_squared_error: 0.1719\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0262 - mean_squared_error: 0.0541\n",
      "Epoch 73: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0262 - mean_squared_error: 0.0541 - val_loss: 0.0909 - val_mean_squared_error: 0.1829\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0253 - mean_squared_error: 0.0523\n",
      "Epoch 74: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0253 - mean_squared_error: 0.0523 - val_loss: 0.0829 - val_mean_squared_error: 0.1667\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0250 - mean_squared_error: 0.0516\n",
      "Epoch 75: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0250 - mean_squared_error: 0.0516 - val_loss: 0.0829 - val_mean_squared_error: 0.1666\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0236 - mean_squared_error: 0.0490\n",
      "Epoch 76: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0236 - mean_squared_error: 0.0490 - val_loss: 0.0851 - val_mean_squared_error: 0.1709\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0237 - mean_squared_error: 0.0492\n",
      "Epoch 77: val_loss did not improve from 0.06983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 46s 5s/step - loss: 0.0237 - mean_squared_error: 0.0492 - val_loss: 0.0910 - val_mean_squared_error: 0.1832\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0229 - mean_squared_error: 0.0474\n",
      "Epoch 78: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0229 - mean_squared_error: 0.0474 - val_loss: 0.0834 - val_mean_squared_error: 0.1675\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0232 - mean_squared_error: 0.0480\n",
      "Epoch 79: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0232 - mean_squared_error: 0.0480 - val_loss: 0.0869 - val_mean_squared_error: 0.1747\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0466\n",
      "Epoch 80: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0224 - mean_squared_error: 0.0466 - val_loss: 0.0819 - val_mean_squared_error: 0.1645\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0217 - mean_squared_error: 0.0452\n",
      "Epoch 81: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0217 - mean_squared_error: 0.0452 - val_loss: 0.0848 - val_mean_squared_error: 0.1704\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0217 - mean_squared_error: 0.0451\n",
      "Epoch 82: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0217 - mean_squared_error: 0.0451 - val_loss: 0.0889 - val_mean_squared_error: 0.1788\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0210 - mean_squared_error: 0.0437\n",
      "Epoch 83: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0210 - mean_squared_error: 0.0437 - val_loss: 0.0884 - val_mean_squared_error: 0.1778\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0207 - mean_squared_error: 0.0430\n",
      "Epoch 84: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0207 - mean_squared_error: 0.0430 - val_loss: 0.0894 - val_mean_squared_error: 0.1802\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0207 - mean_squared_error: 0.0431\n",
      "Epoch 85: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0207 - mean_squared_error: 0.0431 - val_loss: 0.0842 - val_mean_squared_error: 0.1691\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0206 - mean_squared_error: 0.0430\n",
      "Epoch 86: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0206 - mean_squared_error: 0.0430 - val_loss: 0.0891 - val_mean_squared_error: 0.1791\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0201 - mean_squared_error: 0.0419\n",
      "Epoch 87: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0201 - mean_squared_error: 0.0419 - val_loss: 0.0821 - val_mean_squared_error: 0.1649\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0198 - mean_squared_error: 0.0414\n",
      "Epoch 88: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0198 - mean_squared_error: 0.0414 - val_loss: 0.0887 - val_mean_squared_error: 0.1784\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0403\n",
      "Epoch 89: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0193 - mean_squared_error: 0.0403 - val_loss: 0.0891 - val_mean_squared_error: 0.1791\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0404\n",
      "Epoch 90: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0193 - mean_squared_error: 0.0404 - val_loss: 0.0876 - val_mean_squared_error: 0.1760\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0187 - mean_squared_error: 0.0391\n",
      "Epoch 91: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0187 - mean_squared_error: 0.0391 - val_loss: 0.0893 - val_mean_squared_error: 0.1794\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0387\n",
      "Epoch 92: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0185 - mean_squared_error: 0.0387 - val_loss: 0.0911 - val_mean_squared_error: 0.1833\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0184 - mean_squared_error: 0.0384\n",
      "Epoch 93: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0184 - mean_squared_error: 0.0384 - val_loss: 0.0856 - val_mean_squared_error: 0.1718\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0186 - mean_squared_error: 0.0390\n",
      "Epoch 94: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0186 - mean_squared_error: 0.0390 - val_loss: 0.0947 - val_mean_squared_error: 0.1907\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0182 - mean_squared_error: 0.0381\n",
      "Epoch 95: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0182 - mean_squared_error: 0.0381 - val_loss: 0.0907 - val_mean_squared_error: 0.1825\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0180 - mean_squared_error: 0.0377\n",
      "Epoch 96: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0180 - mean_squared_error: 0.0377 - val_loss: 0.0890 - val_mean_squared_error: 0.1790\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0179 - mean_squared_error: 0.0376\n",
      "Epoch 97: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0179 - mean_squared_error: 0.0376 - val_loss: 0.0950 - val_mean_squared_error: 0.1912\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0177 - mean_squared_error: 0.0372\n",
      "Epoch 98: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0177 - mean_squared_error: 0.0372 - val_loss: 0.0896 - val_mean_squared_error: 0.1800\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0176 - mean_squared_error: 0.0369\n",
      "Epoch 99: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0176 - mean_squared_error: 0.0369 - val_loss: 0.0852 - val_mean_squared_error: 0.1712\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0366\n",
      "Epoch 100: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0174 - mean_squared_error: 0.0366 - val_loss: 0.0930 - val_mean_squared_error: 0.1874\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0352\n",
      "Epoch 101: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0167 - mean_squared_error: 0.0352 - val_loss: 0.0915 - val_mean_squared_error: 0.1841\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0173 - mean_squared_error: 0.0364\n",
      "Epoch 102: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0173 - mean_squared_error: 0.0364 - val_loss: 0.0912 - val_mean_squared_error: 0.1836\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0354\n",
      "Epoch 103: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0168 - mean_squared_error: 0.0354 - val_loss: 0.0934 - val_mean_squared_error: 0.1882\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0340\n",
      "Epoch 104: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0161 - mean_squared_error: 0.0340 - val_loss: 0.0890 - val_mean_squared_error: 0.1789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0336\n",
      "Epoch 105: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0159 - mean_squared_error: 0.0336 - val_loss: 0.0903 - val_mean_squared_error: 0.1817\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0327\n",
      "Epoch 106: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0155 - mean_squared_error: 0.0327 - val_loss: 0.0946 - val_mean_squared_error: 0.1904\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0322\n",
      "Epoch 107: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0152 - mean_squared_error: 0.0322 - val_loss: 0.0916 - val_mean_squared_error: 0.1845\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0321\n",
      "Epoch 108: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0152 - mean_squared_error: 0.0321 - val_loss: 0.0907 - val_mean_squared_error: 0.1825\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0325\n",
      "Epoch 109: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0154 - mean_squared_error: 0.0325 - val_loss: 0.0951 - val_mean_squared_error: 0.1915\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0314\n",
      "Epoch 110: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0148 - mean_squared_error: 0.0314 - val_loss: 0.0932 - val_mean_squared_error: 0.1876\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0312\n",
      "Epoch 111: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0147 - mean_squared_error: 0.0312 - val_loss: 0.0927 - val_mean_squared_error: 0.1868\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0307\n",
      "Epoch 112: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0145 - mean_squared_error: 0.0307 - val_loss: 0.0949 - val_mean_squared_error: 0.1911\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0300\n",
      "Epoch 113: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0141 - mean_squared_error: 0.0300 - val_loss: 0.0940 - val_mean_squared_error: 0.1893\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0297\n",
      "Epoch 114: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0140 - mean_squared_error: 0.0297 - val_loss: 0.0928 - val_mean_squared_error: 0.1869\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0295\n",
      "Epoch 115: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0139 - mean_squared_error: 0.0295 - val_loss: 0.0974 - val_mean_squared_error: 0.1961\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0291\n",
      "Epoch 116: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0137 - mean_squared_error: 0.0291 - val_loss: 0.0969 - val_mean_squared_error: 0.1950\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0289\n",
      "Epoch 117: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0135 - mean_squared_error: 0.0289 - val_loss: 0.0918 - val_mean_squared_error: 0.1848\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0282\n",
      "Epoch 118: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0132 - mean_squared_error: 0.0282 - val_loss: 0.0965 - val_mean_squared_error: 0.1945\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0279\n",
      "Epoch 119: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0131 - mean_squared_error: 0.0279 - val_loss: 0.0976 - val_mean_squared_error: 0.1967\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0275\n",
      "Epoch 120: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0129 - mean_squared_error: 0.0275 - val_loss: 0.0952 - val_mean_squared_error: 0.1915\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0279\n",
      "Epoch 121: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0131 - mean_squared_error: 0.0279 - val_loss: 0.0932 - val_mean_squared_error: 0.1876\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0273\n",
      "Epoch 122: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0127 - mean_squared_error: 0.0273 - val_loss: 0.0930 - val_mean_squared_error: 0.1870\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0266\n",
      "Epoch 123: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0124 - mean_squared_error: 0.0266 - val_loss: 0.0952 - val_mean_squared_error: 0.1915\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0265\n",
      "Epoch 124: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0124 - mean_squared_error: 0.0265 - val_loss: 0.0987 - val_mean_squared_error: 0.1988\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0263\n",
      "Epoch 125: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0123 - mean_squared_error: 0.0263 - val_loss: 0.0955 - val_mean_squared_error: 0.1921\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0265\n",
      "Epoch 126: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0124 - mean_squared_error: 0.0265 - val_loss: 0.1007 - val_mean_squared_error: 0.2027\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0264\n",
      "Epoch 127: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0123 - mean_squared_error: 0.0264 - val_loss: 0.0934 - val_mean_squared_error: 0.1879\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0261\n",
      "Epoch 128: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0122 - mean_squared_error: 0.0261 - val_loss: 0.0970 - val_mean_squared_error: 0.1954\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0257\n",
      "Epoch 129: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0120 - mean_squared_error: 0.0257 - val_loss: 0.0977 - val_mean_squared_error: 0.1966\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0250\n",
      "Epoch 130: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0116 - mean_squared_error: 0.0250 - val_loss: 0.0955 - val_mean_squared_error: 0.1922\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0245\n",
      "Epoch 131: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0114 - mean_squared_error: 0.0245 - val_loss: 0.0988 - val_mean_squared_error: 0.1990\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0244\n",
      "Epoch 132: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0113 - mean_squared_error: 0.0244 - val_loss: 0.0963 - val_mean_squared_error: 0.1939\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0242\n",
      "Epoch 133: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0112 - mean_squared_error: 0.0242 - val_loss: 0.0994 - val_mean_squared_error: 0.2002\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0239\n",
      "Epoch 134: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0111 - mean_squared_error: 0.0239 - val_loss: 0.0948 - val_mean_squared_error: 0.1906\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0237\n",
      "Epoch 135: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0109 - mean_squared_error: 0.0237 - val_loss: 0.0991 - val_mean_squared_error: 0.1997\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0236\n",
      "Epoch 136: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0109 - mean_squared_error: 0.0236 - val_loss: 0.0966 - val_mean_squared_error: 0.1944\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0233\n",
      "Epoch 137: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0108 - mean_squared_error: 0.0233 - val_loss: 0.1003 - val_mean_squared_error: 0.2023\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0227\n",
      "Epoch 138: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0105 - mean_squared_error: 0.0227 - val_loss: 0.0953 - val_mean_squared_error: 0.1917\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0224\n",
      "Epoch 139: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0103 - mean_squared_error: 0.0224 - val_loss: 0.0992 - val_mean_squared_error: 0.1999\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0221\n",
      "Epoch 140: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0102 - mean_squared_error: 0.0221 - val_loss: 0.0992 - val_mean_squared_error: 0.1999\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0219\n",
      "Epoch 141: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0101 - mean_squared_error: 0.0219 - val_loss: 0.0991 - val_mean_squared_error: 0.1997\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0221\n",
      "Epoch 142: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0102 - mean_squared_error: 0.0221 - val_loss: 0.1005 - val_mean_squared_error: 0.2024\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0220\n",
      "Epoch 143: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0101 - mean_squared_error: 0.0220 - val_loss: 0.0997 - val_mean_squared_error: 0.2008\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0215\n",
      "Epoch 144: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0099 - mean_squared_error: 0.0215 - val_loss: 0.1012 - val_mean_squared_error: 0.2038\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0210\n",
      "Epoch 145: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0096 - mean_squared_error: 0.0210 - val_loss: 0.1002 - val_mean_squared_error: 0.2018\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0205\n",
      "Epoch 146: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0094 - mean_squared_error: 0.0205 - val_loss: 0.0997 - val_mean_squared_error: 0.2009\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0205\n",
      "Epoch 147: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0094 - mean_squared_error: 0.0205 - val_loss: 0.1003 - val_mean_squared_error: 0.2020\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0203\n",
      "Epoch 148: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0093 - mean_squared_error: 0.0203 - val_loss: 0.1021 - val_mean_squared_error: 0.2057\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0203\n",
      "Epoch 149: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0093 - mean_squared_error: 0.0203 - val_loss: 0.1048 - val_mean_squared_error: 0.2114\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0203\n",
      "Epoch 150: val_loss did not improve from 0.06983\n",
      "9/9 [==============================] - 47s 5s/step - loss: 0.0093 - mean_squared_error: 0.0203 - val_loss: 0.1010 - val_mean_squared_error: 0.2036\n",
      "5/5 [==============================] - 12s 465ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  552\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3917 - mean_squared_error: 0.8888\n",
      "Epoch 1: val_loss improved from inf to 0.25171, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 110s 7s/step - loss: 0.3917 - mean_squared_error: 0.8888 - val_loss: 0.2517 - val_mean_squared_error: 0.5431\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2439 - mean_squared_error: 0.5375\n",
      "Epoch 2: val_loss improved from 0.25171 to 0.15983, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.2439 - mean_squared_error: 0.5375 - val_loss: 0.1598 - val_mean_squared_error: 0.3300\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1483 - mean_squared_error: 0.3093\n",
      "Epoch 3: val_loss improved from 0.15983 to 0.13328, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1483 - mean_squared_error: 0.3093 - val_loss: 0.1333 - val_mean_squared_error: 0.2713\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1106 - mean_squared_error: 0.2262\n",
      "Epoch 4: val_loss improved from 0.13328 to 0.12726, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.1106 - mean_squared_error: 0.2262 - val_loss: 0.1273 - val_mean_squared_error: 0.2586\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.2125\n",
      "Epoch 5: val_loss improved from 0.12726 to 0.12491, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.1040 - mean_squared_error: 0.2125 - val_loss: 0.1249 - val_mean_squared_error: 0.2550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0987 - mean_squared_error: 0.2013\n",
      "Epoch 6: val_loss improved from 0.12491 to 0.12133, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0987 - mean_squared_error: 0.2013 - val_loss: 0.1213 - val_mean_squared_error: 0.2465\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0959 - mean_squared_error: 0.1957\n",
      "Epoch 7: val_loss improved from 0.12133 to 0.11950, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0959 - mean_squared_error: 0.1957 - val_loss: 0.1195 - val_mean_squared_error: 0.2426\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0945 - mean_squared_error: 0.1927\n",
      "Epoch 8: val_loss improved from 0.11950 to 0.11945, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0945 - mean_squared_error: 0.1927 - val_loss: 0.1194 - val_mean_squared_error: 0.2427\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0938 - mean_squared_error: 0.1915\n",
      "Epoch 9: val_loss did not improve from 0.11945\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0938 - mean_squared_error: 0.1915 - val_loss: 0.1215 - val_mean_squared_error: 0.2476\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0911 - mean_squared_error: 0.1859\n",
      "Epoch 10: val_loss improved from 0.11945 to 0.11833, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0911 - mean_squared_error: 0.1859 - val_loss: 0.1183 - val_mean_squared_error: 0.2414\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0876 - mean_squared_error: 0.1789\n",
      "Epoch 11: val_loss improved from 0.11833 to 0.11684, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0876 - mean_squared_error: 0.1789 - val_loss: 0.1168 - val_mean_squared_error: 0.2385\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0845 - mean_squared_error: 0.1728\n",
      "Epoch 12: val_loss improved from 0.11684 to 0.10978, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0845 - mean_squared_error: 0.1728 - val_loss: 0.1098 - val_mean_squared_error: 0.2245\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0819 - mean_squared_error: 0.1675\n",
      "Epoch 13: val_loss did not improve from 0.10978\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0819 - mean_squared_error: 0.1675 - val_loss: 0.1106 - val_mean_squared_error: 0.2259\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0802 - mean_squared_error: 0.1638\n",
      "Epoch 14: val_loss did not improve from 0.10978\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0802 - mean_squared_error: 0.1638 - val_loss: 0.1117 - val_mean_squared_error: 0.2287\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0797 - mean_squared_error: 0.1628\n",
      "Epoch 15: val_loss did not improve from 0.10978\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0797 - mean_squared_error: 0.1628 - val_loss: 0.1101 - val_mean_squared_error: 0.2251\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0788 - mean_squared_error: 0.1612\n",
      "Epoch 16: val_loss improved from 0.10978 to 0.10597, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0788 - mean_squared_error: 0.1612 - val_loss: 0.1060 - val_mean_squared_error: 0.2166\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0778 - mean_squared_error: 0.1591\n",
      "Epoch 17: val_loss did not improve from 0.10597\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0778 - mean_squared_error: 0.1591 - val_loss: 0.1079 - val_mean_squared_error: 0.2201\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0754 - mean_squared_error: 0.1542\n",
      "Epoch 18: val_loss did not improve from 0.10597\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0754 - mean_squared_error: 0.1542 - val_loss: 0.1101 - val_mean_squared_error: 0.2267\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0749 - mean_squared_error: 0.1532\n",
      "Epoch 19: val_loss improved from 0.10597 to 0.10342, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0749 - mean_squared_error: 0.1532 - val_loss: 0.1034 - val_mean_squared_error: 0.2106\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0734 - mean_squared_error: 0.1498\n",
      "Epoch 20: val_loss improved from 0.10342 to 0.10058, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0734 - mean_squared_error: 0.1498 - val_loss: 0.1006 - val_mean_squared_error: 0.2057\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0714 - mean_squared_error: 0.1456\n",
      "Epoch 21: val_loss improved from 0.10058 to 0.09872, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0714 - mean_squared_error: 0.1456 - val_loss: 0.0987 - val_mean_squared_error: 0.2009\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0708 - mean_squared_error: 0.1444\n",
      "Epoch 22: val_loss improved from 0.09872 to 0.09448, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0708 - mean_squared_error: 0.1444 - val_loss: 0.0945 - val_mean_squared_error: 0.1914\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0673 - mean_squared_error: 0.1373\n",
      "Epoch 23: val_loss improved from 0.09448 to 0.08745, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0673 - mean_squared_error: 0.1373 - val_loss: 0.0875 - val_mean_squared_error: 0.1776\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0643 - mean_squared_error: 0.1313\n",
      "Epoch 24: val_loss improved from 0.08745 to 0.08393, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0643 - mean_squared_error: 0.1313 - val_loss: 0.0839 - val_mean_squared_error: 0.1702\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0617 - mean_squared_error: 0.1258\n",
      "Epoch 25: val_loss improved from 0.08393 to 0.07916, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0617 - mean_squared_error: 0.1258 - val_loss: 0.0792 - val_mean_squared_error: 0.1603\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0606 - mean_squared_error: 0.1234\n",
      "Epoch 26: val_loss did not improve from 0.07916\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0606 - mean_squared_error: 0.1234 - val_loss: 0.0853 - val_mean_squared_error: 0.1728\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0565 - mean_squared_error: 0.1152\n",
      "Epoch 27: val_loss improved from 0.07916 to 0.07819, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 49s 6s/step - loss: 0.0565 - mean_squared_error: 0.1152 - val_loss: 0.0782 - val_mean_squared_error: 0.1578\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0554 - mean_squared_error: 0.1131\n",
      "Epoch 28: val_loss did not improve from 0.07819\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0554 - mean_squared_error: 0.1131 - val_loss: 0.0821 - val_mean_squared_error: 0.1666\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0546 - mean_squared_error: 0.1112\n",
      "Epoch 29: val_loss did not improve from 0.07819\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0546 - mean_squared_error: 0.1112 - val_loss: 0.0899 - val_mean_squared_error: 0.1834\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0541 - mean_squared_error: 0.1104\n",
      "Epoch 30: val_loss did not improve from 0.07819\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0541 - mean_squared_error: 0.1104 - val_loss: 0.0788 - val_mean_squared_error: 0.1598\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0525 - mean_squared_error: 0.1070\n",
      "Epoch 31: val_loss improved from 0.07819 to 0.07522, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0525 - mean_squared_error: 0.1070 - val_loss: 0.0752 - val_mean_squared_error: 0.1517\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0531 - mean_squared_error: 0.1080\n",
      "Epoch 32: val_loss did not improve from 0.07522\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0531 - mean_squared_error: 0.1080 - val_loss: 0.0822 - val_mean_squared_error: 0.1669\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0532 - mean_squared_error: 0.1082\n",
      "Epoch 33: val_loss did not improve from 0.07522\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0532 - mean_squared_error: 0.1082 - val_loss: 0.0896 - val_mean_squared_error: 0.1835\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0519 - mean_squared_error: 0.1060\n",
      "Epoch 34: val_loss did not improve from 0.07522\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0519 - mean_squared_error: 0.1060 - val_loss: 0.0786 - val_mean_squared_error: 0.1595\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0490 - mean_squared_error: 0.0999\n",
      "Epoch 35: val_loss did not improve from 0.07522\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0490 - mean_squared_error: 0.0999 - val_loss: 0.0778 - val_mean_squared_error: 0.1572\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0473 - mean_squared_error: 0.0964\n",
      "Epoch 36: val_loss did not improve from 0.07522\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0473 - mean_squared_error: 0.0964 - val_loss: 0.0774 - val_mean_squared_error: 0.1562\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0471 - mean_squared_error: 0.0960\n",
      "Epoch 37: val_loss improved from 0.07522 to 0.07245, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0471 - mean_squared_error: 0.0960 - val_loss: 0.0725 - val_mean_squared_error: 0.1462\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0459 - mean_squared_error: 0.0935\n",
      "Epoch 38: val_loss did not improve from 0.07245\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0459 - mean_squared_error: 0.0935 - val_loss: 0.0766 - val_mean_squared_error: 0.1546\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0442 - mean_squared_error: 0.0902\n",
      "Epoch 39: val_loss did not improve from 0.07245\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0442 - mean_squared_error: 0.0902 - val_loss: 0.0765 - val_mean_squared_error: 0.1545\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0434 - mean_squared_error: 0.0885\n",
      "Epoch 40: val_loss did not improve from 0.07245\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0434 - mean_squared_error: 0.0885 - val_loss: 0.0773 - val_mean_squared_error: 0.1562\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0431 - mean_squared_error: 0.0880\n",
      "Epoch 41: val_loss did not improve from 0.07245\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0431 - mean_squared_error: 0.0880 - val_loss: 0.0758 - val_mean_squared_error: 0.1529\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0429 - mean_squared_error: 0.0876\n",
      "Epoch 42: val_loss did not improve from 0.07245\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0429 - mean_squared_error: 0.0876 - val_loss: 0.0760 - val_mean_squared_error: 0.1534\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0414 - mean_squared_error: 0.0845\n",
      "Epoch 43: val_loss did not improve from 0.07245\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0414 - mean_squared_error: 0.0845 - val_loss: 0.0793 - val_mean_squared_error: 0.1607\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0408 - mean_squared_error: 0.0834\n",
      "Epoch 44: val_loss did not improve from 0.07245\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0408 - mean_squared_error: 0.0834 - val_loss: 0.0772 - val_mean_squared_error: 0.1561\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0395 - mean_squared_error: 0.0805\n",
      "Epoch 45: val_loss did not improve from 0.07245\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0395 - mean_squared_error: 0.0805 - val_loss: 0.0738 - val_mean_squared_error: 0.1490\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0812\n",
      "Epoch 46: val_loss did not improve from 0.07245\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0398 - mean_squared_error: 0.0812 - val_loss: 0.0866 - val_mean_squared_error: 0.1754\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0385 - mean_squared_error: 0.0787\n",
      "Epoch 47: val_loss improved from 0.07245 to 0.07220, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0385 - mean_squared_error: 0.0787 - val_loss: 0.0722 - val_mean_squared_error: 0.1459\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0784\n",
      "Epoch 48: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0384 - mean_squared_error: 0.0784 - val_loss: 0.0779 - val_mean_squared_error: 0.1579\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0377 - mean_squared_error: 0.0770\n",
      "Epoch 49: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0377 - mean_squared_error: 0.0770 - val_loss: 0.0764 - val_mean_squared_error: 0.1543\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0793\n",
      "Epoch 50: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0389 - mean_squared_error: 0.0793 - val_loss: 0.0799 - val_mean_squared_error: 0.1615\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0791\n",
      "Epoch 51: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0388 - mean_squared_error: 0.0791 - val_loss: 0.0764 - val_mean_squared_error: 0.1549\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0747\n",
      "Epoch 52: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0366 - mean_squared_error: 0.0747 - val_loss: 0.0835 - val_mean_squared_error: 0.1698\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0367 - mean_squared_error: 0.0749\n",
      "Epoch 53: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0367 - mean_squared_error: 0.0749 - val_loss: 0.0777 - val_mean_squared_error: 0.1569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0356 - mean_squared_error: 0.0728\n",
      "Epoch 54: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0356 - mean_squared_error: 0.0728 - val_loss: 0.0806 - val_mean_squared_error: 0.1625\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0362 - mean_squared_error: 0.0740\n",
      "Epoch 55: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0362 - mean_squared_error: 0.0740 - val_loss: 0.0813 - val_mean_squared_error: 0.1644\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0348 - mean_squared_error: 0.0711\n",
      "Epoch 56: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0348 - mean_squared_error: 0.0711 - val_loss: 0.0729 - val_mean_squared_error: 0.1471\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0337 - mean_squared_error: 0.0690\n",
      "Epoch 57: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0337 - mean_squared_error: 0.0690 - val_loss: 0.0776 - val_mean_squared_error: 0.1569\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0336 - mean_squared_error: 0.0688\n",
      "Epoch 58: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0336 - mean_squared_error: 0.0688 - val_loss: 0.0852 - val_mean_squared_error: 0.1729\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0661\n",
      "Epoch 59: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0323 - mean_squared_error: 0.0661 - val_loss: 0.0759 - val_mean_squared_error: 0.1532\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0312 - mean_squared_error: 0.0640\n",
      "Epoch 60: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0312 - mean_squared_error: 0.0640 - val_loss: 0.0768 - val_mean_squared_error: 0.1549\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0316 - mean_squared_error: 0.0648\n",
      "Epoch 61: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0316 - mean_squared_error: 0.0648 - val_loss: 0.0826 - val_mean_squared_error: 0.1677\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0312 - mean_squared_error: 0.0640\n",
      "Epoch 62: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0312 - mean_squared_error: 0.0640 - val_loss: 0.0848 - val_mean_squared_error: 0.1722\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0308 - mean_squared_error: 0.0632\n",
      "Epoch 63: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0308 - mean_squared_error: 0.0632 - val_loss: 0.0880 - val_mean_squared_error: 0.1784\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0300 - mean_squared_error: 0.0615\n",
      "Epoch 64: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0300 - mean_squared_error: 0.0615 - val_loss: 0.0788 - val_mean_squared_error: 0.1594\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0294 - mean_squared_error: 0.0604\n",
      "Epoch 65: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0294 - mean_squared_error: 0.0604 - val_loss: 0.0752 - val_mean_squared_error: 0.1524\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0601\n",
      "Epoch 66: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0292 - mean_squared_error: 0.0601 - val_loss: 0.0782 - val_mean_squared_error: 0.1584\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0289 - mean_squared_error: 0.0594\n",
      "Epoch 67: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0289 - mean_squared_error: 0.0594 - val_loss: 0.0823 - val_mean_squared_error: 0.1664\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0275 - mean_squared_error: 0.0566\n",
      "Epoch 68: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0275 - mean_squared_error: 0.0566 - val_loss: 0.0794 - val_mean_squared_error: 0.1609\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0273 - mean_squared_error: 0.0561\n",
      "Epoch 69: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0273 - mean_squared_error: 0.0561 - val_loss: 0.0839 - val_mean_squared_error: 0.1695\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0261 - mean_squared_error: 0.0539\n",
      "Epoch 70: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0261 - mean_squared_error: 0.0539 - val_loss: 0.0860 - val_mean_squared_error: 0.1756\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0262 - mean_squared_error: 0.0540\n",
      "Epoch 71: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0262 - mean_squared_error: 0.0540 - val_loss: 0.0835 - val_mean_squared_error: 0.1689\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0249 - mean_squared_error: 0.0515\n",
      "Epoch 72: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0249 - mean_squared_error: 0.0515 - val_loss: 0.0833 - val_mean_squared_error: 0.1684\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0247 - mean_squared_error: 0.0511\n",
      "Epoch 73: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0247 - mean_squared_error: 0.0511 - val_loss: 0.0950 - val_mean_squared_error: 0.1939\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0254 - mean_squared_error: 0.0523\n",
      "Epoch 74: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0254 - mean_squared_error: 0.0523 - val_loss: 0.0831 - val_mean_squared_error: 0.1678\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0254 - mean_squared_error: 0.0523\n",
      "Epoch 75: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0254 - mean_squared_error: 0.0523 - val_loss: 0.0852 - val_mean_squared_error: 0.1724\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0246 - mean_squared_error: 0.0508\n",
      "Epoch 76: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0246 - mean_squared_error: 0.0508 - val_loss: 0.0915 - val_mean_squared_error: 0.1863\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0502\n",
      "Epoch 77: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0243 - mean_squared_error: 0.0502 - val_loss: 0.0817 - val_mean_squared_error: 0.1649\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0240 - mean_squared_error: 0.0495\n",
      "Epoch 78: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0240 - mean_squared_error: 0.0495 - val_loss: 0.0870 - val_mean_squared_error: 0.1762\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0231 - mean_squared_error: 0.0478\n",
      "Epoch 79: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0231 - mean_squared_error: 0.0478 - val_loss: 0.0878 - val_mean_squared_error: 0.1785\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0221 - mean_squared_error: 0.0457\n",
      "Epoch 80: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0221 - mean_squared_error: 0.0457 - val_loss: 0.0831 - val_mean_squared_error: 0.1681\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0220 - mean_squared_error: 0.0456\n",
      "Epoch 81: val_loss did not improve from 0.07220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 49s 6s/step - loss: 0.0220 - mean_squared_error: 0.0456 - val_loss: 0.0849 - val_mean_squared_error: 0.1722\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0208 - mean_squared_error: 0.0432\n",
      "Epoch 82: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0208 - mean_squared_error: 0.0432 - val_loss: 0.0847 - val_mean_squared_error: 0.1716\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0207 - mean_squared_error: 0.0430\n",
      "Epoch 83: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0207 - mean_squared_error: 0.0430 - val_loss: 0.0832 - val_mean_squared_error: 0.1684\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0204 - mean_squared_error: 0.0425\n",
      "Epoch 84: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0204 - mean_squared_error: 0.0425 - val_loss: 0.0883 - val_mean_squared_error: 0.1793\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0203 - mean_squared_error: 0.0421\n",
      "Epoch 85: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0203 - mean_squared_error: 0.0421 - val_loss: 0.0842 - val_mean_squared_error: 0.1707\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0199 - mean_squared_error: 0.0415\n",
      "Epoch 86: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0199 - mean_squared_error: 0.0415 - val_loss: 0.0877 - val_mean_squared_error: 0.1777\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0194 - mean_squared_error: 0.0404\n",
      "Epoch 87: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0194 - mean_squared_error: 0.0404 - val_loss: 0.0876 - val_mean_squared_error: 0.1778\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.0399\n",
      "Epoch 88: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0192 - mean_squared_error: 0.0399 - val_loss: 0.0899 - val_mean_squared_error: 0.1830\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0394\n",
      "Epoch 89: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0189 - mean_squared_error: 0.0394 - val_loss: 0.0893 - val_mean_squared_error: 0.1810\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0183 - mean_squared_error: 0.0382\n",
      "Epoch 90: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0183 - mean_squared_error: 0.0382 - val_loss: 0.0859 - val_mean_squared_error: 0.1739\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0182 - mean_squared_error: 0.0380\n",
      "Epoch 91: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0182 - mean_squared_error: 0.0380 - val_loss: 0.0882 - val_mean_squared_error: 0.1785\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0183 - mean_squared_error: 0.0381\n",
      "Epoch 92: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0183 - mean_squared_error: 0.0381 - val_loss: 0.0928 - val_mean_squared_error: 0.1887\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0365\n",
      "Epoch 93: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0175 - mean_squared_error: 0.0365 - val_loss: 0.0900 - val_mean_squared_error: 0.1822\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0176 - mean_squared_error: 0.0368\n",
      "Epoch 94: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 48s 5s/step - loss: 0.0176 - mean_squared_error: 0.0368 - val_loss: 0.0876 - val_mean_squared_error: 0.1777\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0365\n",
      "Epoch 95: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 48s 5s/step - loss: 0.0175 - mean_squared_error: 0.0365 - val_loss: 0.0922 - val_mean_squared_error: 0.1877\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0173 - mean_squared_error: 0.0362\n",
      "Epoch 96: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 46s 5s/step - loss: 0.0173 - mean_squared_error: 0.0362 - val_loss: 0.0894 - val_mean_squared_error: 0.1812\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0363\n",
      "Epoch 97: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0174 - mean_squared_error: 0.0363 - val_loss: 0.0880 - val_mean_squared_error: 0.1789\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0348\n",
      "Epoch 98: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0166 - mean_squared_error: 0.0348 - val_loss: 0.0876 - val_mean_squared_error: 0.1770\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0349\n",
      "Epoch 99: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0166 - mean_squared_error: 0.0349 - val_loss: 0.0911 - val_mean_squared_error: 0.1850\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0349\n",
      "Epoch 100: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0167 - mean_squared_error: 0.0349 - val_loss: 0.0939 - val_mean_squared_error: 0.1902\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0348\n",
      "Epoch 101: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0166 - mean_squared_error: 0.0348 - val_loss: 0.0925 - val_mean_squared_error: 0.1879\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0344\n",
      "Epoch 102: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 48s 5s/step - loss: 0.0164 - mean_squared_error: 0.0344 - val_loss: 0.0957 - val_mean_squared_error: 0.1937\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0347\n",
      "Epoch 103: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0166 - mean_squared_error: 0.0347 - val_loss: 0.0924 - val_mean_squared_error: 0.1882\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0348\n",
      "Epoch 104: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0166 - mean_squared_error: 0.0348 - val_loss: 0.0891 - val_mean_squared_error: 0.1805\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0352\n",
      "Epoch 105: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0168 - mean_squared_error: 0.0352 - val_loss: 0.0892 - val_mean_squared_error: 0.1809\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0333\n",
      "Epoch 106: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0159 - mean_squared_error: 0.0333 - val_loss: 0.0898 - val_mean_squared_error: 0.1818\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.0316\n",
      "Epoch 107: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0150 - mean_squared_error: 0.0316 - val_loss: 0.0945 - val_mean_squared_error: 0.1919\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.0317\n",
      "Epoch 108: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0150 - mean_squared_error: 0.0317 - val_loss: 0.0884 - val_mean_squared_error: 0.1790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0309\n",
      "Epoch 109: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0146 - mean_squared_error: 0.0309 - val_loss: 0.0920 - val_mean_squared_error: 0.1862\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0295\n",
      "Epoch 110: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0140 - mean_squared_error: 0.0295 - val_loss: 0.0900 - val_mean_squared_error: 0.1821\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0286\n",
      "Epoch 111: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0135 - mean_squared_error: 0.0286 - val_loss: 0.0927 - val_mean_squared_error: 0.1874\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0286\n",
      "Epoch 112: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0135 - mean_squared_error: 0.0286 - val_loss: 0.0921 - val_mean_squared_error: 0.1864\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0283\n",
      "Epoch 113: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0133 - mean_squared_error: 0.0283 - val_loss: 0.0920 - val_mean_squared_error: 0.1866\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0277\n",
      "Epoch 114: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0130 - mean_squared_error: 0.0277 - val_loss: 0.0895 - val_mean_squared_error: 0.1812\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0269\n",
      "Epoch 115: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0126 - mean_squared_error: 0.0269 - val_loss: 0.0908 - val_mean_squared_error: 0.1840\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0266\n",
      "Epoch 116: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0125 - mean_squared_error: 0.0266 - val_loss: 0.0922 - val_mean_squared_error: 0.1865\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0268\n",
      "Epoch 117: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0126 - mean_squared_error: 0.0268 - val_loss: 0.0939 - val_mean_squared_error: 0.1905\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0271\n",
      "Epoch 118: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0127 - mean_squared_error: 0.0271 - val_loss: 0.0928 - val_mean_squared_error: 0.1878\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0265\n",
      "Epoch 119: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0125 - mean_squared_error: 0.0265 - val_loss: 0.0910 - val_mean_squared_error: 0.1842\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0260\n",
      "Epoch 120: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0122 - mean_squared_error: 0.0260 - val_loss: 0.0907 - val_mean_squared_error: 0.1837\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0258\n",
      "Epoch 121: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0121 - mean_squared_error: 0.0258 - val_loss: 0.0945 - val_mean_squared_error: 0.1913\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0267\n",
      "Epoch 122: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0125 - mean_squared_error: 0.0267 - val_loss: 0.0928 - val_mean_squared_error: 0.1884\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0263\n",
      "Epoch 123: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0123 - mean_squared_error: 0.0263 - val_loss: 0.0944 - val_mean_squared_error: 0.1909\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0254\n",
      "Epoch 124: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0119 - mean_squared_error: 0.0254 - val_loss: 0.0908 - val_mean_squared_error: 0.1839\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0257\n",
      "Epoch 125: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0120 - mean_squared_error: 0.0257 - val_loss: 0.0913 - val_mean_squared_error: 0.1852\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0254\n",
      "Epoch 126: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0119 - mean_squared_error: 0.0254 - val_loss: 0.0931 - val_mean_squared_error: 0.1886\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0249\n",
      "Epoch 127: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0116 - mean_squared_error: 0.0249 - val_loss: 0.0889 - val_mean_squared_error: 0.1793\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0253\n",
      "Epoch 128: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0118 - mean_squared_error: 0.0253 - val_loss: 0.0920 - val_mean_squared_error: 0.1866\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0115 - mean_squared_error: 0.0248\n",
      "Epoch 129: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0115 - mean_squared_error: 0.0248 - val_loss: 0.0916 - val_mean_squared_error: 0.1855\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0245\n",
      "Epoch 130: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0114 - mean_squared_error: 0.0245 - val_loss: 0.0934 - val_mean_squared_error: 0.1898\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0238\n",
      "Epoch 131: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0111 - mean_squared_error: 0.0238 - val_loss: 0.0905 - val_mean_squared_error: 0.1837\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0234\n",
      "Epoch 132: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0109 - mean_squared_error: 0.0234 - val_loss: 0.0942 - val_mean_squared_error: 0.1906\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0230\n",
      "Epoch 133: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0106 - mean_squared_error: 0.0230 - val_loss: 0.0937 - val_mean_squared_error: 0.1895\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0223\n",
      "Epoch 134: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0103 - mean_squared_error: 0.0223 - val_loss: 0.0924 - val_mean_squared_error: 0.1869\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0223\n",
      "Epoch 135: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0103 - mean_squared_error: 0.0223 - val_loss: 0.0927 - val_mean_squared_error: 0.1881\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0226\n",
      "Epoch 136: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0105 - mean_squared_error: 0.0226 - val_loss: 0.0936 - val_mean_squared_error: 0.1894\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0219\n",
      "Epoch 137: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0101 - mean_squared_error: 0.0219 - val_loss: 0.0971 - val_mean_squared_error: 0.1967\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0224\n",
      "Epoch 138: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0104 - mean_squared_error: 0.0224 - val_loss: 0.0967 - val_mean_squared_error: 0.1956\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0225\n",
      "Epoch 139: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0104 - mean_squared_error: 0.0225 - val_loss: 0.0935 - val_mean_squared_error: 0.1893\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0217\n",
      "Epoch 140: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0100 - mean_squared_error: 0.0217 - val_loss: 0.0933 - val_mean_squared_error: 0.1888\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0214\n",
      "Epoch 141: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0099 - mean_squared_error: 0.0214 - val_loss: 0.0943 - val_mean_squared_error: 0.1912\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0210\n",
      "Epoch 142: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0097 - mean_squared_error: 0.0210 - val_loss: 0.0929 - val_mean_squared_error: 0.1880\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0205\n",
      "Epoch 143: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0094 - mean_squared_error: 0.0205 - val_loss: 0.0929 - val_mean_squared_error: 0.1880\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0206\n",
      "Epoch 144: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0095 - mean_squared_error: 0.0206 - val_loss: 0.0944 - val_mean_squared_error: 0.1910\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0203\n",
      "Epoch 145: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0093 - mean_squared_error: 0.0203 - val_loss: 0.0936 - val_mean_squared_error: 0.1895\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0092 - mean_squared_error: 0.0201\n",
      "Epoch 146: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0092 - mean_squared_error: 0.0201 - val_loss: 0.0943 - val_mean_squared_error: 0.1909\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0203\n",
      "Epoch 147: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0093 - mean_squared_error: 0.0203 - val_loss: 0.0963 - val_mean_squared_error: 0.1948\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0202\n",
      "Epoch 148: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 6s/step - loss: 0.0093 - mean_squared_error: 0.0202 - val_loss: 0.0940 - val_mean_squared_error: 0.1902\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0090 - mean_squared_error: 0.0196\n",
      "Epoch 149: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.0090 - mean_squared_error: 0.0196 - val_loss: 0.0957 - val_mean_squared_error: 0.1940\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0091 - mean_squared_error: 0.0199\n",
      "Epoch 150: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0091 - mean_squared_error: 0.0199 - val_loss: 0.0928 - val_mean_squared_error: 0.1876\n",
      "5/5 [==============================] - 16s 518ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  576\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4072 - mean_squared_error: 0.9252\n",
      "Epoch 1: val_loss improved from inf to 0.30494, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 116s 8s/step - loss: 0.4072 - mean_squared_error: 0.9252 - val_loss: 0.3049 - val_mean_squared_error: 0.6574\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2700 - mean_squared_error: 0.5944\n",
      "Epoch 2: val_loss improved from 0.30494 to 0.18686, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.2700 - mean_squared_error: 0.5944 - val_loss: 0.1869 - val_mean_squared_error: 0.3873\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1508 - mean_squared_error: 0.3134\n",
      "Epoch 3: val_loss improved from 0.18686 to 0.12732, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.1508 - mean_squared_error: 0.3134 - val_loss: 0.1273 - val_mean_squared_error: 0.2581\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1122 - mean_squared_error: 0.2296\n",
      "Epoch 4: val_loss improved from 0.12732 to 0.12227, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.1122 - mean_squared_error: 0.2296 - val_loss: 0.1223 - val_mean_squared_error: 0.2487\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1017 - mean_squared_error: 0.2076\n",
      "Epoch 5: val_loss improved from 0.12227 to 0.11393, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.1017 - mean_squared_error: 0.2076 - val_loss: 0.1139 - val_mean_squared_error: 0.2306\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0936 - mean_squared_error: 0.1909\n",
      "Epoch 6: val_loss did not improve from 0.11393\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0936 - mean_squared_error: 0.1909 - val_loss: 0.1143 - val_mean_squared_error: 0.2319\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0894 - mean_squared_error: 0.1825\n",
      "Epoch 7: val_loss improved from 0.11393 to 0.11212, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0894 - mean_squared_error: 0.1825 - val_loss: 0.1121 - val_mean_squared_error: 0.2276\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0890 - mean_squared_error: 0.1818\n",
      "Epoch 8: val_loss improved from 0.11212 to 0.10774, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0890 - mean_squared_error: 0.1818 - val_loss: 0.1077 - val_mean_squared_error: 0.2193\n",
      "Epoch 9/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - ETA: 0s - loss: 0.0852 - mean_squared_error: 0.1740\n",
      "Epoch 9: val_loss did not improve from 0.10774\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0852 - mean_squared_error: 0.1740 - val_loss: 0.1132 - val_mean_squared_error: 0.2305\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0826 - mean_squared_error: 0.1686\n",
      "Epoch 10: val_loss improved from 0.10774 to 0.10358, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0826 - mean_squared_error: 0.1686 - val_loss: 0.1036 - val_mean_squared_error: 0.2114\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0814 - mean_squared_error: 0.1659\n",
      "Epoch 11: val_loss did not improve from 0.10358\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0814 - mean_squared_error: 0.1659 - val_loss: 0.1075 - val_mean_squared_error: 0.2188\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0798 - mean_squared_error: 0.1628\n",
      "Epoch 12: val_loss did not improve from 0.10358\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0798 - mean_squared_error: 0.1628 - val_loss: 0.1073 - val_mean_squared_error: 0.2181\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0779 - mean_squared_error: 0.1587\n",
      "Epoch 13: val_loss improved from 0.10358 to 0.10216, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.0779 - mean_squared_error: 0.1587 - val_loss: 0.1022 - val_mean_squared_error: 0.2068\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0763 - mean_squared_error: 0.1555\n",
      "Epoch 14: val_loss did not improve from 0.10216\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0763 - mean_squared_error: 0.1555 - val_loss: 0.1038 - val_mean_squared_error: 0.2101\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0742 - mean_squared_error: 0.1512\n",
      "Epoch 15: val_loss did not improve from 0.10216\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0742 - mean_squared_error: 0.1512 - val_loss: 0.1112 - val_mean_squared_error: 0.2256\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0739 - mean_squared_error: 0.1506\n",
      "Epoch 16: val_loss did not improve from 0.10216\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0739 - mean_squared_error: 0.1506 - val_loss: 0.1110 - val_mean_squared_error: 0.2257\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0732 - mean_squared_error: 0.1491\n",
      "Epoch 17: val_loss did not improve from 0.10216\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0732 - mean_squared_error: 0.1491 - val_loss: 0.1081 - val_mean_squared_error: 0.2193\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0703 - mean_squared_error: 0.1434\n",
      "Epoch 18: val_loss improved from 0.10216 to 0.09355, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0703 - mean_squared_error: 0.1434 - val_loss: 0.0935 - val_mean_squared_error: 0.1891\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0663 - mean_squared_error: 0.1351\n",
      "Epoch 19: val_loss improved from 0.09355 to 0.09074, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0663 - mean_squared_error: 0.1351 - val_loss: 0.0907 - val_mean_squared_error: 0.1836\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0646 - mean_squared_error: 0.1314\n",
      "Epoch 20: val_loss improved from 0.09074 to 0.08264, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0646 - mean_squared_error: 0.1314 - val_loss: 0.0826 - val_mean_squared_error: 0.1667\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0619 - mean_squared_error: 0.1263\n",
      "Epoch 21: val_loss did not improve from 0.08264\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0619 - mean_squared_error: 0.1263 - val_loss: 0.0845 - val_mean_squared_error: 0.1706\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0588 - mean_squared_error: 0.1200\n",
      "Epoch 22: val_loss improved from 0.08264 to 0.07719, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0588 - mean_squared_error: 0.1200 - val_loss: 0.0772 - val_mean_squared_error: 0.1555\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0573 - mean_squared_error: 0.1170\n",
      "Epoch 23: val_loss did not improve from 0.07719\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0573 - mean_squared_error: 0.1170 - val_loss: 0.0887 - val_mean_squared_error: 0.1791\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0570 - mean_squared_error: 0.1163\n",
      "Epoch 24: val_loss did not improve from 0.07719\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0570 - mean_squared_error: 0.1163 - val_loss: 0.0843 - val_mean_squared_error: 0.1706\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0550 - mean_squared_error: 0.1122\n",
      "Epoch 25: val_loss did not improve from 0.07719\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0550 - mean_squared_error: 0.1122 - val_loss: 0.0852 - val_mean_squared_error: 0.1725\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0543 - mean_squared_error: 0.1106\n",
      "Epoch 26: val_loss improved from 0.07719 to 0.07469, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0543 - mean_squared_error: 0.1106 - val_loss: 0.0747 - val_mean_squared_error: 0.1504\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0548 - mean_squared_error: 0.1116\n",
      "Epoch 27: val_loss did not improve from 0.07469\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0548 - mean_squared_error: 0.1116 - val_loss: 0.0810 - val_mean_squared_error: 0.1634\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.1050\n",
      "Epoch 28: val_loss did not improve from 0.07469\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0515 - mean_squared_error: 0.1050 - val_loss: 0.0836 - val_mean_squared_error: 0.1686\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0497 - mean_squared_error: 0.1012\n",
      "Epoch 29: val_loss did not improve from 0.07469\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0497 - mean_squared_error: 0.1012 - val_loss: 0.0785 - val_mean_squared_error: 0.1580\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0499 - mean_squared_error: 0.1019\n",
      "Epoch 30: val_loss did not improve from 0.07469\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0499 - mean_squared_error: 0.1019 - val_loss: 0.0796 - val_mean_squared_error: 0.1606\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0483 - mean_squared_error: 0.0985\n",
      "Epoch 31: val_loss did not improve from 0.07469\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0483 - mean_squared_error: 0.0985 - val_loss: 0.0826 - val_mean_squared_error: 0.1670\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0482 - mean_squared_error: 0.0984\n",
      "Epoch 32: val_loss improved from 0.07469 to 0.07182, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 54s 6s/step - loss: 0.0482 - mean_squared_error: 0.0984 - val_loss: 0.0718 - val_mean_squared_error: 0.1447\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0467 - mean_squared_error: 0.0953\n",
      "Epoch 33: val_loss did not improve from 0.07182\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0467 - mean_squared_error: 0.0953 - val_loss: 0.0744 - val_mean_squared_error: 0.1497\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0460 - mean_squared_error: 0.0939\n",
      "Epoch 34: val_loss did not improve from 0.07182\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0460 - mean_squared_error: 0.0939 - val_loss: 0.0819 - val_mean_squared_error: 0.1653\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0456 - mean_squared_error: 0.0931\n",
      "Epoch 35: val_loss did not improve from 0.07182\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0456 - mean_squared_error: 0.0931 - val_loss: 0.0743 - val_mean_squared_error: 0.1495\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0443 - mean_squared_error: 0.0905\n",
      "Epoch 36: val_loss did not improve from 0.07182\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0443 - mean_squared_error: 0.0905 - val_loss: 0.0801 - val_mean_squared_error: 0.1616\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0447 - mean_squared_error: 0.0914\n",
      "Epoch 37: val_loss did not improve from 0.07182\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0447 - mean_squared_error: 0.0914 - val_loss: 0.0825 - val_mean_squared_error: 0.1664\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0441 - mean_squared_error: 0.0901\n",
      "Epoch 38: val_loss did not improve from 0.07182\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0441 - mean_squared_error: 0.0901 - val_loss: 0.0833 - val_mean_squared_error: 0.1682\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0436 - mean_squared_error: 0.0890\n",
      "Epoch 39: val_loss did not improve from 0.07182\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0436 - mean_squared_error: 0.0890 - val_loss: 0.0789 - val_mean_squared_error: 0.1590\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0440 - mean_squared_error: 0.0901\n",
      "Epoch 40: val_loss did not improve from 0.07182\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0440 - mean_squared_error: 0.0901 - val_loss: 0.0784 - val_mean_squared_error: 0.1579\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0437 - mean_squared_error: 0.0894\n",
      "Epoch 41: val_loss did not improve from 0.07182\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0437 - mean_squared_error: 0.0894 - val_loss: 0.0788 - val_mean_squared_error: 0.1589\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0427 - mean_squared_error: 0.0872\n",
      "Epoch 42: val_loss did not improve from 0.07182\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0427 - mean_squared_error: 0.0872 - val_loss: 0.0815 - val_mean_squared_error: 0.1651\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0437 - mean_squared_error: 0.0892\n",
      "Epoch 43: val_loss improved from 0.07182 to 0.07030, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0437 - mean_squared_error: 0.0892 - val_loss: 0.0703 - val_mean_squared_error: 0.1412\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0437 - mean_squared_error: 0.0893\n",
      "Epoch 44: val_loss did not improve from 0.07030\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0437 - mean_squared_error: 0.0893 - val_loss: 0.0719 - val_mean_squared_error: 0.1446\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0828\n",
      "Epoch 45: val_loss did not improve from 0.07030\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.0405 - mean_squared_error: 0.0828 - val_loss: 0.0715 - val_mean_squared_error: 0.1441\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0401 - mean_squared_error: 0.0820\n",
      "Epoch 46: val_loss improved from 0.07030 to 0.06626, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0401 - mean_squared_error: 0.0820 - val_loss: 0.0663 - val_mean_squared_error: 0.1333\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0400 - mean_squared_error: 0.0817\n",
      "Epoch 47: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0400 - mean_squared_error: 0.0817 - val_loss: 0.0781 - val_mean_squared_error: 0.1574\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0399 - mean_squared_error: 0.0817\n",
      "Epoch 48: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0399 - mean_squared_error: 0.0817 - val_loss: 0.0807 - val_mean_squared_error: 0.1624\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0395 - mean_squared_error: 0.0809\n",
      "Epoch 49: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0395 - mean_squared_error: 0.0809 - val_loss: 0.0745 - val_mean_squared_error: 0.1499\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0396 - mean_squared_error: 0.0810\n",
      "Epoch 50: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0396 - mean_squared_error: 0.0810 - val_loss: 0.0766 - val_mean_squared_error: 0.1541\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0380 - mean_squared_error: 0.0779\n",
      "Epoch 51: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0380 - mean_squared_error: 0.0779 - val_loss: 0.0683 - val_mean_squared_error: 0.1374\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0369 - mean_squared_error: 0.0757\n",
      "Epoch 52: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0369 - mean_squared_error: 0.0757 - val_loss: 0.0763 - val_mean_squared_error: 0.1539\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0360 - mean_squared_error: 0.0737\n",
      "Epoch 53: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0360 - mean_squared_error: 0.0737 - val_loss: 0.0751 - val_mean_squared_error: 0.1518\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0361 - mean_squared_error: 0.0739\n",
      "Epoch 54: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0361 - mean_squared_error: 0.0739 - val_loss: 0.0779 - val_mean_squared_error: 0.1571\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0356 - mean_squared_error: 0.0731\n",
      "Epoch 55: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0356 - mean_squared_error: 0.0731 - val_loss: 0.0776 - val_mean_squared_error: 0.1564\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0348 - mean_squared_error: 0.0715\n",
      "Epoch 56: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0348 - mean_squared_error: 0.0715 - val_loss: 0.0775 - val_mean_squared_error: 0.1562\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0363 - mean_squared_error: 0.0744\n",
      "Epoch 57: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0363 - mean_squared_error: 0.0744 - val_loss: 0.0698 - val_mean_squared_error: 0.1403\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0362 - mean_squared_error: 0.0741\n",
      "Epoch 58: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0362 - mean_squared_error: 0.0741 - val_loss: 0.0716 - val_mean_squared_error: 0.1439\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0336 - mean_squared_error: 0.0691\n",
      "Epoch 59: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0336 - mean_squared_error: 0.0691 - val_loss: 0.0723 - val_mean_squared_error: 0.1455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0332 - mean_squared_error: 0.0682\n",
      "Epoch 60: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0332 - mean_squared_error: 0.0682 - val_loss: 0.0746 - val_mean_squared_error: 0.1504\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0320 - mean_squared_error: 0.0658\n",
      "Epoch 61: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0320 - mean_squared_error: 0.0658 - val_loss: 0.0753 - val_mean_squared_error: 0.1522\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0321 - mean_squared_error: 0.0660\n",
      "Epoch 62: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0321 - mean_squared_error: 0.0660 - val_loss: 0.0723 - val_mean_squared_error: 0.1458\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0325 - mean_squared_error: 0.0668\n",
      "Epoch 63: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0325 - mean_squared_error: 0.0668 - val_loss: 0.0721 - val_mean_squared_error: 0.1454\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0314 - mean_squared_error: 0.0645\n",
      "Epoch 64: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.0314 - mean_squared_error: 0.0645 - val_loss: 0.0759 - val_mean_squared_error: 0.1530\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0304 - mean_squared_error: 0.0627\n",
      "Epoch 65: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0304 - mean_squared_error: 0.0627 - val_loss: 0.0808 - val_mean_squared_error: 0.1630\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0301 - mean_squared_error: 0.0621\n",
      "Epoch 66: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0301 - mean_squared_error: 0.0621 - val_loss: 0.0830 - val_mean_squared_error: 0.1671\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0603\n",
      "Epoch 67: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0292 - mean_squared_error: 0.0603 - val_loss: 0.0765 - val_mean_squared_error: 0.1544\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0602\n",
      "Epoch 68: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0292 - mean_squared_error: 0.0602 - val_loss: 0.0810 - val_mean_squared_error: 0.1638\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0285 - mean_squared_error: 0.0589\n",
      "Epoch 69: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0285 - mean_squared_error: 0.0589 - val_loss: 0.0835 - val_mean_squared_error: 0.1695\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0278 - mean_squared_error: 0.0573\n",
      "Epoch 70: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0278 - mean_squared_error: 0.0573 - val_loss: 0.0803 - val_mean_squared_error: 0.1622\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0281 - mean_squared_error: 0.0581\n",
      "Epoch 71: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0281 - mean_squared_error: 0.0581 - val_loss: 0.0938 - val_mean_squared_error: 0.1898\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0284 - mean_squared_error: 0.0585\n",
      "Epoch 72: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0284 - mean_squared_error: 0.0585 - val_loss: 0.0841 - val_mean_squared_error: 0.1697\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0561\n",
      "Epoch 73: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0271 - mean_squared_error: 0.0561 - val_loss: 0.0839 - val_mean_squared_error: 0.1699\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0267 - mean_squared_error: 0.0553\n",
      "Epoch 74: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0267 - mean_squared_error: 0.0553 - val_loss: 0.0810 - val_mean_squared_error: 0.1638\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0264 - mean_squared_error: 0.0546\n",
      "Epoch 75: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0264 - mean_squared_error: 0.0546 - val_loss: 0.0799 - val_mean_squared_error: 0.1619\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0261 - mean_squared_error: 0.0539\n",
      "Epoch 76: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0261 - mean_squared_error: 0.0539 - val_loss: 0.0806 - val_mean_squared_error: 0.1630\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0520\n",
      "Epoch 77: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0251 - mean_squared_error: 0.0520 - val_loss: 0.0811 - val_mean_squared_error: 0.1640\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0519\n",
      "Epoch 78: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0251 - mean_squared_error: 0.0519 - val_loss: 0.0848 - val_mean_squared_error: 0.1718\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0248 - mean_squared_error: 0.0514\n",
      "Epoch 79: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.0248 - mean_squared_error: 0.0514 - val_loss: 0.0827 - val_mean_squared_error: 0.1668\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0504\n",
      "Epoch 80: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0243 - mean_squared_error: 0.0504 - val_loss: 0.0807 - val_mean_squared_error: 0.1636\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0235 - mean_squared_error: 0.0487\n",
      "Epoch 81: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0235 - mean_squared_error: 0.0487 - val_loss: 0.0865 - val_mean_squared_error: 0.1750\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0230 - mean_squared_error: 0.0478\n",
      "Epoch 82: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0230 - mean_squared_error: 0.0478 - val_loss: 0.0830 - val_mean_squared_error: 0.1683\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0465\n",
      "Epoch 83: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0224 - mean_squared_error: 0.0465 - val_loss: 0.0899 - val_mean_squared_error: 0.1824\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0225 - mean_squared_error: 0.0469\n",
      "Epoch 84: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0225 - mean_squared_error: 0.0469 - val_loss: 0.0877 - val_mean_squared_error: 0.1774\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0466\n",
      "Epoch 85: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0224 - mean_squared_error: 0.0466 - val_loss: 0.0893 - val_mean_squared_error: 0.1816\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0225 - mean_squared_error: 0.0469\n",
      "Epoch 86: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0225 - mean_squared_error: 0.0469 - val_loss: 0.0847 - val_mean_squared_error: 0.1715\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0223 - mean_squared_error: 0.0463\n",
      "Epoch 87: val_loss did not improve from 0.06626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 53s 6s/step - loss: 0.0223 - mean_squared_error: 0.0463 - val_loss: 0.0894 - val_mean_squared_error: 0.1809\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0212 - mean_squared_error: 0.0442\n",
      "Epoch 88: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0212 - mean_squared_error: 0.0442 - val_loss: 0.0894 - val_mean_squared_error: 0.1810\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0208 - mean_squared_error: 0.0433\n",
      "Epoch 89: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0208 - mean_squared_error: 0.0433 - val_loss: 0.0900 - val_mean_squared_error: 0.1828\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0203 - mean_squared_error: 0.0423\n",
      "Epoch 90: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0203 - mean_squared_error: 0.0423 - val_loss: 0.0912 - val_mean_squared_error: 0.1848\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0198 - mean_squared_error: 0.0414\n",
      "Epoch 91: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0198 - mean_squared_error: 0.0414 - val_loss: 0.0943 - val_mean_squared_error: 0.1921\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0206 - mean_squared_error: 0.0429\n",
      "Epoch 92: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0206 - mean_squared_error: 0.0429 - val_loss: 0.0974 - val_mean_squared_error: 0.1979\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0206 - mean_squared_error: 0.0431\n",
      "Epoch 93: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0206 - mean_squared_error: 0.0431 - val_loss: 0.0924 - val_mean_squared_error: 0.1878\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0405\n",
      "Epoch 94: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0193 - mean_squared_error: 0.0405 - val_loss: 0.0857 - val_mean_squared_error: 0.1735\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.0395\n",
      "Epoch 95: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0188 - mean_squared_error: 0.0395 - val_loss: 0.0910 - val_mean_squared_error: 0.1851\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0388\n",
      "Epoch 96: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0185 - mean_squared_error: 0.0388 - val_loss: 0.0877 - val_mean_squared_error: 0.1779\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0187 - mean_squared_error: 0.0391\n",
      "Epoch 97: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0187 - mean_squared_error: 0.0391 - val_loss: 0.0909 - val_mean_squared_error: 0.1846\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0182 - mean_squared_error: 0.0382\n",
      "Epoch 98: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0182 - mean_squared_error: 0.0382 - val_loss: 0.0942 - val_mean_squared_error: 0.1916\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0183 - mean_squared_error: 0.0384\n",
      "Epoch 99: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0183 - mean_squared_error: 0.0384 - val_loss: 0.0911 - val_mean_squared_error: 0.1848\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0379\n",
      "Epoch 100: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0181 - mean_squared_error: 0.0379 - val_loss: 0.0905 - val_mean_squared_error: 0.1835\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0179 - mean_squared_error: 0.0375\n",
      "Epoch 101: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0179 - mean_squared_error: 0.0375 - val_loss: 0.0945 - val_mean_squared_error: 0.1922\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0367\n",
      "Epoch 102: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0174 - mean_squared_error: 0.0367 - val_loss: 0.0931 - val_mean_squared_error: 0.1889\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0365\n",
      "Epoch 103: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0174 - mean_squared_error: 0.0365 - val_loss: 0.0930 - val_mean_squared_error: 0.1887\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0343\n",
      "Epoch 104: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0163 - mean_squared_error: 0.0343 - val_loss: 0.0960 - val_mean_squared_error: 0.1953\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0340\n",
      "Epoch 105: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0162 - mean_squared_error: 0.0340 - val_loss: 0.0908 - val_mean_squared_error: 0.1842\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0335\n",
      "Epoch 106: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0159 - mean_squared_error: 0.0335 - val_loss: 0.0935 - val_mean_squared_error: 0.1901\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0327\n",
      "Epoch 107: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0155 - mean_squared_error: 0.0327 - val_loss: 0.0960 - val_mean_squared_error: 0.1960\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0318\n",
      "Epoch 108: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0151 - mean_squared_error: 0.0318 - val_loss: 0.0936 - val_mean_squared_error: 0.1903\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0314\n",
      "Epoch 109: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0149 - mean_squared_error: 0.0314 - val_loss: 0.0966 - val_mean_squared_error: 0.1967\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0316\n",
      "Epoch 110: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0149 - mean_squared_error: 0.0316 - val_loss: 0.0969 - val_mean_squared_error: 0.1968\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0153 - mean_squared_error: 0.0323\n",
      "Epoch 111: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0153 - mean_squared_error: 0.0323 - val_loss: 0.0953 - val_mean_squared_error: 0.1939\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0315\n",
      "Epoch 112: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0148 - mean_squared_error: 0.0315 - val_loss: 0.1021 - val_mean_squared_error: 0.2075\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0311\n",
      "Epoch 113: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0147 - mean_squared_error: 0.0311 - val_loss: 0.0967 - val_mean_squared_error: 0.1973\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0307\n",
      "Epoch 114: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0145 - mean_squared_error: 0.0307 - val_loss: 0.0956 - val_mean_squared_error: 0.1955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0315\n",
      "Epoch 115: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0148 - mean_squared_error: 0.0315 - val_loss: 0.0905 - val_mean_squared_error: 0.1841\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0314\n",
      "Epoch 116: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0148 - mean_squared_error: 0.0314 - val_loss: 0.0943 - val_mean_squared_error: 0.1920\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0315\n",
      "Epoch 117: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0149 - mean_squared_error: 0.0315 - val_loss: 0.1077 - val_mean_squared_error: 0.2201\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0327\n",
      "Epoch 118: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0155 - mean_squared_error: 0.0327 - val_loss: 0.0917 - val_mean_squared_error: 0.1869\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0303\n",
      "Epoch 119: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0143 - mean_squared_error: 0.0303 - val_loss: 0.0979 - val_mean_squared_error: 0.2003\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0295\n",
      "Epoch 120: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0139 - mean_squared_error: 0.0295 - val_loss: 0.0966 - val_mean_squared_error: 0.1967\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0281\n",
      "Epoch 121: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0132 - mean_squared_error: 0.0281 - val_loss: 0.0957 - val_mean_squared_error: 0.1950\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0271\n",
      "Epoch 122: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0127 - mean_squared_error: 0.0271 - val_loss: 0.0941 - val_mean_squared_error: 0.1917\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0274\n",
      "Epoch 123: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0128 - mean_squared_error: 0.0274 - val_loss: 0.1002 - val_mean_squared_error: 0.2048\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0274\n",
      "Epoch 124: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0129 - mean_squared_error: 0.0274 - val_loss: 0.0947 - val_mean_squared_error: 0.1928\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0275\n",
      "Epoch 125: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0129 - mean_squared_error: 0.0275 - val_loss: 0.0990 - val_mean_squared_error: 0.2022\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0271\n",
      "Epoch 126: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0126 - mean_squared_error: 0.0271 - val_loss: 0.0950 - val_mean_squared_error: 0.1931\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0264\n",
      "Epoch 127: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0123 - mean_squared_error: 0.0264 - val_loss: 0.0991 - val_mean_squared_error: 0.2022\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0261\n",
      "Epoch 128: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0121 - mean_squared_error: 0.0261 - val_loss: 0.0973 - val_mean_squared_error: 0.1980\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0256\n",
      "Epoch 129: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0119 - mean_squared_error: 0.0256 - val_loss: 0.0964 - val_mean_squared_error: 0.1964\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0250\n",
      "Epoch 130: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0116 - mean_squared_error: 0.0250 - val_loss: 0.0969 - val_mean_squared_error: 0.1980\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0242\n",
      "Epoch 131: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0112 - mean_squared_error: 0.0242 - val_loss: 0.0957 - val_mean_squared_error: 0.1948\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0239\n",
      "Epoch 132: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0110 - mean_squared_error: 0.0239 - val_loss: 0.0949 - val_mean_squared_error: 0.1941\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0235\n",
      "Epoch 133: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0109 - mean_squared_error: 0.0235 - val_loss: 0.0971 - val_mean_squared_error: 0.1981\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0233\n",
      "Epoch 134: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0108 - mean_squared_error: 0.0233 - val_loss: 0.0951 - val_mean_squared_error: 0.1937\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0233\n",
      "Epoch 135: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0108 - mean_squared_error: 0.0233 - val_loss: 0.0984 - val_mean_squared_error: 0.2005\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0230\n",
      "Epoch 136: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0106 - mean_squared_error: 0.0230 - val_loss: 0.0976 - val_mean_squared_error: 0.1993\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0232\n",
      "Epoch 137: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0107 - mean_squared_error: 0.0232 - val_loss: 0.0986 - val_mean_squared_error: 0.2016\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0229\n",
      "Epoch 138: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0106 - mean_squared_error: 0.0229 - val_loss: 0.0977 - val_mean_squared_error: 0.1991\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0228\n",
      "Epoch 139: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0105 - mean_squared_error: 0.0228 - val_loss: 0.0994 - val_mean_squared_error: 0.2029\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0229\n",
      "Epoch 140: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0106 - mean_squared_error: 0.0229 - val_loss: 0.1012 - val_mean_squared_error: 0.2059\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0228\n",
      "Epoch 141: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0105 - mean_squared_error: 0.0228 - val_loss: 0.0973 - val_mean_squared_error: 0.1986\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0228\n",
      "Epoch 142: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0105 - mean_squared_error: 0.0228 - val_loss: 0.1014 - val_mean_squared_error: 0.2067\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0227\n",
      "Epoch 143: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0105 - mean_squared_error: 0.0227 - val_loss: 0.0969 - val_mean_squared_error: 0.1980\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0221\n",
      "Epoch 144: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0102 - mean_squared_error: 0.0221 - val_loss: 0.0968 - val_mean_squared_error: 0.1975\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0224\n",
      "Epoch 145: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0103 - mean_squared_error: 0.0224 - val_loss: 0.0970 - val_mean_squared_error: 0.1979\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0224\n",
      "Epoch 146: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0104 - mean_squared_error: 0.0224 - val_loss: 0.0986 - val_mean_squared_error: 0.2014\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0224\n",
      "Epoch 147: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0103 - mean_squared_error: 0.0224 - val_loss: 0.1007 - val_mean_squared_error: 0.2053\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0220\n",
      "Epoch 148: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0101 - mean_squared_error: 0.0220 - val_loss: 0.0983 - val_mean_squared_error: 0.2005\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0224\n",
      "Epoch 149: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0103 - mean_squared_error: 0.0224 - val_loss: 0.0990 - val_mean_squared_error: 0.2024\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0219\n",
      "Epoch 150: val_loss did not improve from 0.06626\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0101 - mean_squared_error: 0.0219 - val_loss: 0.0970 - val_mean_squared_error: 0.1981\n",
      "5/5 [==============================] - 13s 613ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  600\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3890 - mean_squared_error: 0.8778\n",
      "Epoch 1: val_loss improved from inf to 0.25226, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 123s 8s/step - loss: 0.3890 - mean_squared_error: 0.8778 - val_loss: 0.2523 - val_mean_squared_error: 0.5357\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2392 - mean_squared_error: 0.5196\n",
      "Epoch 2: val_loss improved from 0.25226 to 0.15979, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.2392 - mean_squared_error: 0.5196 - val_loss: 0.1598 - val_mean_squared_error: 0.3286\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1475 - mean_squared_error: 0.3059\n",
      "Epoch 3: val_loss improved from 0.15979 to 0.13121, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.1475 - mean_squared_error: 0.3059 - val_loss: 0.1312 - val_mean_squared_error: 0.2671\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1102 - mean_squared_error: 0.2249\n",
      "Epoch 4: val_loss improved from 0.13121 to 0.12791, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.1102 - mean_squared_error: 0.2249 - val_loss: 0.1279 - val_mean_squared_error: 0.2607\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1007 - mean_squared_error: 0.2056\n",
      "Epoch 5: val_loss improved from 0.12791 to 0.12593, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.1007 - mean_squared_error: 0.2056 - val_loss: 0.1259 - val_mean_squared_error: 0.2563\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0968 - mean_squared_error: 0.1978\n",
      "Epoch 6: val_loss improved from 0.12593 to 0.11945, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0968 - mean_squared_error: 0.1978 - val_loss: 0.1195 - val_mean_squared_error: 0.2422\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0957 - mean_squared_error: 0.1950\n",
      "Epoch 7: val_loss improved from 0.11945 to 0.11835, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0957 - mean_squared_error: 0.1950 - val_loss: 0.1183 - val_mean_squared_error: 0.2399\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0940 - mean_squared_error: 0.1916\n",
      "Epoch 8: val_loss did not improve from 0.11835\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0940 - mean_squared_error: 0.1916 - val_loss: 0.1216 - val_mean_squared_error: 0.2474\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0924 - mean_squared_error: 0.1883\n",
      "Epoch 9: val_loss improved from 0.11835 to 0.11529, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0924 - mean_squared_error: 0.1883 - val_loss: 0.1153 - val_mean_squared_error: 0.2336\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0913 - mean_squared_error: 0.1860\n",
      "Epoch 10: val_loss did not improve from 0.11529\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0913 - mean_squared_error: 0.1860 - val_loss: 0.1216 - val_mean_squared_error: 0.2473\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0895 - mean_squared_error: 0.1824\n",
      "Epoch 11: val_loss improved from 0.11529 to 0.11173, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0895 - mean_squared_error: 0.1824 - val_loss: 0.1117 - val_mean_squared_error: 0.2262\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0877 - mean_squared_error: 0.1788\n",
      "Epoch 12: val_loss did not improve from 0.11173\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0877 - mean_squared_error: 0.1788 - val_loss: 0.1164 - val_mean_squared_error: 0.2367\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0825 - mean_squared_error: 0.1682\n",
      "Epoch 13: val_loss improved from 0.11173 to 0.10679, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0825 - mean_squared_error: 0.1682 - val_loss: 0.1068 - val_mean_squared_error: 0.2175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0780 - mean_squared_error: 0.1593\n",
      "Epoch 14: val_loss improved from 0.10679 to 0.09712, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0780 - mean_squared_error: 0.1593 - val_loss: 0.0971 - val_mean_squared_error: 0.1972\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0762 - mean_squared_error: 0.1554\n",
      "Epoch 15: val_loss did not improve from 0.09712\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0762 - mean_squared_error: 0.1554 - val_loss: 0.0973 - val_mean_squared_error: 0.1967\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0746 - mean_squared_error: 0.1520\n",
      "Epoch 16: val_loss did not improve from 0.09712\n",
      "9/9 [==============================] - 57s 6s/step - loss: 0.0746 - mean_squared_error: 0.1520 - val_loss: 0.1034 - val_mean_squared_error: 0.2095\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0713 - mean_squared_error: 0.1455\n",
      "Epoch 17: val_loss improved from 0.09712 to 0.09145, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0713 - mean_squared_error: 0.1455 - val_loss: 0.0915 - val_mean_squared_error: 0.1852\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0683 - mean_squared_error: 0.1391\n",
      "Epoch 18: val_loss improved from 0.09145 to 0.08810, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0683 - mean_squared_error: 0.1391 - val_loss: 0.0881 - val_mean_squared_error: 0.1781\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0689 - mean_squared_error: 0.1409\n",
      "Epoch 19: val_loss improved from 0.08810 to 0.08191, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0689 - mean_squared_error: 0.1409 - val_loss: 0.0819 - val_mean_squared_error: 0.1658\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0654 - mean_squared_error: 0.1334\n",
      "Epoch 20: val_loss did not improve from 0.08191\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0654 - mean_squared_error: 0.1334 - val_loss: 0.0820 - val_mean_squared_error: 0.1659\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0660 - mean_squared_error: 0.1344\n",
      "Epoch 21: val_loss did not improve from 0.08191\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0660 - mean_squared_error: 0.1344 - val_loss: 0.0860 - val_mean_squared_error: 0.1740\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0611 - mean_squared_error: 0.1245\n",
      "Epoch 22: val_loss improved from 0.08191 to 0.07743, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0611 - mean_squared_error: 0.1245 - val_loss: 0.0774 - val_mean_squared_error: 0.1559\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0606 - mean_squared_error: 0.1235\n",
      "Epoch 23: val_loss did not improve from 0.07743\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0606 - mean_squared_error: 0.1235 - val_loss: 0.0822 - val_mean_squared_error: 0.1663\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0575 - mean_squared_error: 0.1173\n",
      "Epoch 24: val_loss did not improve from 0.07743\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0575 - mean_squared_error: 0.1173 - val_loss: 0.0837 - val_mean_squared_error: 0.1691\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0546 - mean_squared_error: 0.1115\n",
      "Epoch 25: val_loss did not improve from 0.07743\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0546 - mean_squared_error: 0.1115 - val_loss: 0.0804 - val_mean_squared_error: 0.1627\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0544 - mean_squared_error: 0.1109\n",
      "Epoch 26: val_loss did not improve from 0.07743\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0544 - mean_squared_error: 0.1109 - val_loss: 0.0817 - val_mean_squared_error: 0.1648\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0531 - mean_squared_error: 0.1082\n",
      "Epoch 27: val_loss did not improve from 0.07743\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0531 - mean_squared_error: 0.1082 - val_loss: 0.0814 - val_mean_squared_error: 0.1645\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0523 - mean_squared_error: 0.1066\n",
      "Epoch 28: val_loss improved from 0.07743 to 0.07280, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0523 - mean_squared_error: 0.1066 - val_loss: 0.0728 - val_mean_squared_error: 0.1465\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0507 - mean_squared_error: 0.1034\n",
      "Epoch 29: val_loss did not improve from 0.07280\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0507 - mean_squared_error: 0.1034 - val_loss: 0.0822 - val_mean_squared_error: 0.1662\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0513 - mean_squared_error: 0.1047\n",
      "Epoch 30: val_loss did not improve from 0.07280\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0513 - mean_squared_error: 0.1047 - val_loss: 0.0950 - val_mean_squared_error: 0.1938\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0508 - mean_squared_error: 0.1035\n",
      "Epoch 31: val_loss did not improve from 0.07280\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0508 - mean_squared_error: 0.1035 - val_loss: 0.0866 - val_mean_squared_error: 0.1754\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0489 - mean_squared_error: 0.0996\n",
      "Epoch 32: val_loss did not improve from 0.07280\n",
      "9/9 [==============================] - 57s 6s/step - loss: 0.0489 - mean_squared_error: 0.0996 - val_loss: 0.0853 - val_mean_squared_error: 0.1723\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0486 - mean_squared_error: 0.0992\n",
      "Epoch 33: val_loss did not improve from 0.07280\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0486 - mean_squared_error: 0.0992 - val_loss: 0.0853 - val_mean_squared_error: 0.1723\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0467 - mean_squared_error: 0.0953\n",
      "Epoch 34: val_loss did not improve from 0.07280\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0467 - mean_squared_error: 0.0953 - val_loss: 0.0830 - val_mean_squared_error: 0.1673\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0474 - mean_squared_error: 0.0965\n",
      "Epoch 35: val_loss did not improve from 0.07280\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0474 - mean_squared_error: 0.0965 - val_loss: 0.0815 - val_mean_squared_error: 0.1647\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0461 - mean_squared_error: 0.0941\n",
      "Epoch 36: val_loss did not improve from 0.07280\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0461 - mean_squared_error: 0.0941 - val_loss: 0.0789 - val_mean_squared_error: 0.1591\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0451 - mean_squared_error: 0.0920\n",
      "Epoch 37: val_loss did not improve from 0.07280\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0451 - mean_squared_error: 0.0920 - val_loss: 0.0812 - val_mean_squared_error: 0.1639\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0454 - mean_squared_error: 0.0926\n",
      "Epoch 38: val_loss did not improve from 0.07280\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0454 - mean_squared_error: 0.0926 - val_loss: 0.0830 - val_mean_squared_error: 0.1680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0448 - mean_squared_error: 0.0913\n",
      "Epoch 39: val_loss did not improve from 0.07280\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0448 - mean_squared_error: 0.0913 - val_loss: 0.0748 - val_mean_squared_error: 0.1504\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0446 - mean_squared_error: 0.0912\n",
      "Epoch 40: val_loss improved from 0.07280 to 0.07220, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0446 - mean_squared_error: 0.0912 - val_loss: 0.0722 - val_mean_squared_error: 0.1452\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0428 - mean_squared_error: 0.0874\n",
      "Epoch 41: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0428 - mean_squared_error: 0.0874 - val_loss: 0.0829 - val_mean_squared_error: 0.1671\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0425 - mean_squared_error: 0.0867\n",
      "Epoch 42: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0425 - mean_squared_error: 0.0867 - val_loss: 0.0845 - val_mean_squared_error: 0.1703\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0421 - mean_squared_error: 0.0861\n",
      "Epoch 43: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0421 - mean_squared_error: 0.0861 - val_loss: 0.0822 - val_mean_squared_error: 0.1658\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0408 - mean_squared_error: 0.0834\n",
      "Epoch 44: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0408 - mean_squared_error: 0.0834 - val_loss: 0.0845 - val_mean_squared_error: 0.1702\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0397 - mean_squared_error: 0.0812\n",
      "Epoch 45: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0397 - mean_squared_error: 0.0812 - val_loss: 0.0906 - val_mean_squared_error: 0.1831\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0396 - mean_squared_error: 0.0810\n",
      "Epoch 46: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0396 - mean_squared_error: 0.0810 - val_loss: 0.0778 - val_mean_squared_error: 0.1564\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0378 - mean_squared_error: 0.0774\n",
      "Epoch 47: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 57s 6s/step - loss: 0.0378 - mean_squared_error: 0.0774 - val_loss: 0.0745 - val_mean_squared_error: 0.1497\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0383 - mean_squared_error: 0.0783\n",
      "Epoch 48: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0383 - mean_squared_error: 0.0783 - val_loss: 0.0754 - val_mean_squared_error: 0.1517\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0781\n",
      "Epoch 49: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0381 - mean_squared_error: 0.0781 - val_loss: 0.0786 - val_mean_squared_error: 0.1583\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0378 - mean_squared_error: 0.0774\n",
      "Epoch 50: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0378 - mean_squared_error: 0.0774 - val_loss: 0.0761 - val_mean_squared_error: 0.1532\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0367 - mean_squared_error: 0.0752\n",
      "Epoch 51: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0367 - mean_squared_error: 0.0752 - val_loss: 0.0774 - val_mean_squared_error: 0.1558\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0358 - mean_squared_error: 0.0733\n",
      "Epoch 52: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0358 - mean_squared_error: 0.0733 - val_loss: 0.0755 - val_mean_squared_error: 0.1519\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.0726\n",
      "Epoch 53: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0354 - mean_squared_error: 0.0726 - val_loss: 0.0811 - val_mean_squared_error: 0.1635\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0361 - mean_squared_error: 0.0739\n",
      "Epoch 54: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0361 - mean_squared_error: 0.0739 - val_loss: 0.0844 - val_mean_squared_error: 0.1703\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0358 - mean_squared_error: 0.0733\n",
      "Epoch 55: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0358 - mean_squared_error: 0.0733 - val_loss: 0.0768 - val_mean_squared_error: 0.1547\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0350 - mean_squared_error: 0.0718\n",
      "Epoch 56: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0350 - mean_squared_error: 0.0718 - val_loss: 0.0754 - val_mean_squared_error: 0.1514\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0330 - mean_squared_error: 0.0677\n",
      "Epoch 57: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0330 - mean_squared_error: 0.0677 - val_loss: 0.0765 - val_mean_squared_error: 0.1541\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0337 - mean_squared_error: 0.0692\n",
      "Epoch 58: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0337 - mean_squared_error: 0.0692 - val_loss: 0.0797 - val_mean_squared_error: 0.1604\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0663\n",
      "Epoch 59: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0323 - mean_squared_error: 0.0663 - val_loss: 0.0796 - val_mean_squared_error: 0.1601\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0315 - mean_squared_error: 0.0646\n",
      "Epoch 60: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0315 - mean_squared_error: 0.0646 - val_loss: 0.0739 - val_mean_squared_error: 0.1488\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0310 - mean_squared_error: 0.0637\n",
      "Epoch 61: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0310 - mean_squared_error: 0.0637 - val_loss: 0.0764 - val_mean_squared_error: 0.1535\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0309 - mean_squared_error: 0.0634\n",
      "Epoch 62: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0309 - mean_squared_error: 0.0634 - val_loss: 0.0815 - val_mean_squared_error: 0.1645\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0295 - mean_squared_error: 0.0607\n",
      "Epoch 63: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0295 - mean_squared_error: 0.0607 - val_loss: 0.0776 - val_mean_squared_error: 0.1562\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0290 - mean_squared_error: 0.0597\n",
      "Epoch 64: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0290 - mean_squared_error: 0.0597 - val_loss: 0.0799 - val_mean_squared_error: 0.1609\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0291 - mean_squared_error: 0.0600\n",
      "Epoch 65: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0291 - mean_squared_error: 0.0600 - val_loss: 0.0786 - val_mean_squared_error: 0.1584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0296 - mean_squared_error: 0.0609\n",
      "Epoch 66: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0296 - mean_squared_error: 0.0609 - val_loss: 0.0800 - val_mean_squared_error: 0.1613\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0296 - mean_squared_error: 0.0609\n",
      "Epoch 67: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0296 - mean_squared_error: 0.0609 - val_loss: 0.0779 - val_mean_squared_error: 0.1568\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0283 - mean_squared_error: 0.0582\n",
      "Epoch 68: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0283 - mean_squared_error: 0.0582 - val_loss: 0.0757 - val_mean_squared_error: 0.1524\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0276 - mean_squared_error: 0.0570\n",
      "Epoch 69: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0276 - mean_squared_error: 0.0570 - val_loss: 0.0762 - val_mean_squared_error: 0.1536\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0263 - mean_squared_error: 0.0543\n",
      "Epoch 70: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0263 - mean_squared_error: 0.0543 - val_loss: 0.0836 - val_mean_squared_error: 0.1688\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0273 - mean_squared_error: 0.0563\n",
      "Epoch 71: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0273 - mean_squared_error: 0.0563 - val_loss: 0.0863 - val_mean_squared_error: 0.1741\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0260 - mean_squared_error: 0.0536\n",
      "Epoch 72: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0260 - mean_squared_error: 0.0536 - val_loss: 0.0823 - val_mean_squared_error: 0.1658\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0518\n",
      "Epoch 73: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0251 - mean_squared_error: 0.0518 - val_loss: 0.0847 - val_mean_squared_error: 0.1709\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0261 - mean_squared_error: 0.0540\n",
      "Epoch 74: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0261 - mean_squared_error: 0.0540 - val_loss: 0.0824 - val_mean_squared_error: 0.1659\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0265 - mean_squared_error: 0.0547\n",
      "Epoch 75: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0265 - mean_squared_error: 0.0547 - val_loss: 0.0759 - val_mean_squared_error: 0.1527\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0254 - mean_squared_error: 0.0524\n",
      "Epoch 76: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0254 - mean_squared_error: 0.0524 - val_loss: 0.0884 - val_mean_squared_error: 0.1788\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0241 - mean_squared_error: 0.0501\n",
      "Epoch 77: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0241 - mean_squared_error: 0.0501 - val_loss: 0.0869 - val_mean_squared_error: 0.1753\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0237 - mean_squared_error: 0.0490\n",
      "Epoch 78: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0237 - mean_squared_error: 0.0490 - val_loss: 0.0776 - val_mean_squared_error: 0.1568\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0227 - mean_squared_error: 0.0471\n",
      "Epoch 79: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0227 - mean_squared_error: 0.0471 - val_loss: 0.0786 - val_mean_squared_error: 0.1584\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0223 - mean_squared_error: 0.0463\n",
      "Epoch 80: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0223 - mean_squared_error: 0.0463 - val_loss: 0.0851 - val_mean_squared_error: 0.1716\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0216 - mean_squared_error: 0.0451\n",
      "Epoch 81: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0216 - mean_squared_error: 0.0451 - val_loss: 0.0879 - val_mean_squared_error: 0.1774\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0218 - mean_squared_error: 0.0454\n",
      "Epoch 82: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0218 - mean_squared_error: 0.0454 - val_loss: 0.0881 - val_mean_squared_error: 0.1775\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0211 - mean_squared_error: 0.0441\n",
      "Epoch 83: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0211 - mean_squared_error: 0.0441 - val_loss: 0.0817 - val_mean_squared_error: 0.1646\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0214 - mean_squared_error: 0.0445\n",
      "Epoch 84: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0214 - mean_squared_error: 0.0445 - val_loss: 0.0942 - val_mean_squared_error: 0.1911\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0215 - mean_squared_error: 0.0445\n",
      "Epoch 85: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0215 - mean_squared_error: 0.0445 - val_loss: 0.0862 - val_mean_squared_error: 0.1740\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0201 - mean_squared_error: 0.0418\n",
      "Epoch 86: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0201 - mean_squared_error: 0.0418 - val_loss: 0.0797 - val_mean_squared_error: 0.1605\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0421\n",
      "Epoch 87: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0202 - mean_squared_error: 0.0421 - val_loss: 0.0848 - val_mean_squared_error: 0.1709\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0198 - mean_squared_error: 0.0413\n",
      "Epoch 88: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0198 - mean_squared_error: 0.0413 - val_loss: 0.0901 - val_mean_squared_error: 0.1817\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0199 - mean_squared_error: 0.0417\n",
      "Epoch 89: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 57s 6s/step - loss: 0.0199 - mean_squared_error: 0.0417 - val_loss: 0.0890 - val_mean_squared_error: 0.1795\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0191 - mean_squared_error: 0.0400\n",
      "Epoch 90: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0191 - mean_squared_error: 0.0400 - val_loss: 0.0850 - val_mean_squared_error: 0.1715\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0183 - mean_squared_error: 0.0384\n",
      "Epoch 91: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0183 - mean_squared_error: 0.0384 - val_loss: 0.0838 - val_mean_squared_error: 0.1688\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0380\n",
      "Epoch 92: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0181 - mean_squared_error: 0.0380 - val_loss: 0.0865 - val_mean_squared_error: 0.1745\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0369\n",
      "Epoch 93: val_loss did not improve from 0.07220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 58s 6s/step - loss: 0.0175 - mean_squared_error: 0.0369 - val_loss: 0.0880 - val_mean_squared_error: 0.1773\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0362\n",
      "Epoch 94: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0172 - mean_squared_error: 0.0362 - val_loss: 0.0879 - val_mean_squared_error: 0.1771\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0170 - mean_squared_error: 0.0357\n",
      "Epoch 95: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0170 - mean_squared_error: 0.0357 - val_loss: 0.0881 - val_mean_squared_error: 0.1776\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0352\n",
      "Epoch 96: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0167 - mean_squared_error: 0.0352 - val_loss: 0.0887 - val_mean_squared_error: 0.1788\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0356\n",
      "Epoch 97: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0169 - mean_squared_error: 0.0356 - val_loss: 0.0923 - val_mean_squared_error: 0.1863\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0348\n",
      "Epoch 98: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0165 - mean_squared_error: 0.0348 - val_loss: 0.0877 - val_mean_squared_error: 0.1770\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0341\n",
      "Epoch 99: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0161 - mean_squared_error: 0.0341 - val_loss: 0.0927 - val_mean_squared_error: 0.1871\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0341\n",
      "Epoch 100: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0161 - mean_squared_error: 0.0341 - val_loss: 0.0898 - val_mean_squared_error: 0.1811\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0332\n",
      "Epoch 101: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0157 - mean_squared_error: 0.0332 - val_loss: 0.0884 - val_mean_squared_error: 0.1784\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0339\n",
      "Epoch 102: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0161 - mean_squared_error: 0.0339 - val_loss: 0.0922 - val_mean_squared_error: 0.1863\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0346\n",
      "Epoch 103: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0164 - mean_squared_error: 0.0346 - val_loss: 0.0907 - val_mean_squared_error: 0.1831\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0333\n",
      "Epoch 104: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0157 - mean_squared_error: 0.0333 - val_loss: 0.0870 - val_mean_squared_error: 0.1752\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0320\n",
      "Epoch 105: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0151 - mean_squared_error: 0.0320 - val_loss: 0.0922 - val_mean_squared_error: 0.1861\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0310\n",
      "Epoch 106: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0146 - mean_squared_error: 0.0310 - val_loss: 0.0914 - val_mean_squared_error: 0.1846\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0305\n",
      "Epoch 107: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0143 - mean_squared_error: 0.0305 - val_loss: 0.0938 - val_mean_squared_error: 0.1896\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0303\n",
      "Epoch 108: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0142 - mean_squared_error: 0.0303 - val_loss: 0.0885 - val_mean_squared_error: 0.1784\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0298\n",
      "Epoch 109: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0140 - mean_squared_error: 0.0298 - val_loss: 0.0974 - val_mean_squared_error: 0.1972\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0299\n",
      "Epoch 110: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0140 - mean_squared_error: 0.0299 - val_loss: 0.0905 - val_mean_squared_error: 0.1828\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0290\n",
      "Epoch 111: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0136 - mean_squared_error: 0.0290 - val_loss: 0.0949 - val_mean_squared_error: 0.1920\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0286\n",
      "Epoch 112: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0134 - mean_squared_error: 0.0286 - val_loss: 0.0933 - val_mean_squared_error: 0.1886\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0280\n",
      "Epoch 113: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0131 - mean_squared_error: 0.0280 - val_loss: 0.0949 - val_mean_squared_error: 0.1918\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0273\n",
      "Epoch 114: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0127 - mean_squared_error: 0.0273 - val_loss: 0.0903 - val_mean_squared_error: 0.1822\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0272\n",
      "Epoch 115: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0127 - mean_squared_error: 0.0272 - val_loss: 0.0973 - val_mean_squared_error: 0.1965\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0265\n",
      "Epoch 116: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0124 - mean_squared_error: 0.0265 - val_loss: 0.0916 - val_mean_squared_error: 0.1849\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0261\n",
      "Epoch 117: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0122 - mean_squared_error: 0.0261 - val_loss: 0.0950 - val_mean_squared_error: 0.1921\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0256\n",
      "Epoch 118: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0119 - mean_squared_error: 0.0256 - val_loss: 0.0946 - val_mean_squared_error: 0.1913\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0257\n",
      "Epoch 119: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0119 - mean_squared_error: 0.0257 - val_loss: 0.0929 - val_mean_squared_error: 0.1875\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0253\n",
      "Epoch 120: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0117 - mean_squared_error: 0.0253 - val_loss: 0.0949 - val_mean_squared_error: 0.1917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0250\n",
      "Epoch 121: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0116 - mean_squared_error: 0.0250 - val_loss: 0.0946 - val_mean_squared_error: 0.1914\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0250\n",
      "Epoch 122: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0116 - mean_squared_error: 0.0250 - val_loss: 0.0918 - val_mean_squared_error: 0.1853\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0249\n",
      "Epoch 123: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0116 - mean_squared_error: 0.0249 - val_loss: 0.0964 - val_mean_squared_error: 0.1951\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0244\n",
      "Epoch 124: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0114 - mean_squared_error: 0.0244 - val_loss: 0.0953 - val_mean_squared_error: 0.1922\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0239\n",
      "Epoch 125: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0111 - mean_squared_error: 0.0239 - val_loss: 0.0960 - val_mean_squared_error: 0.1940\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0235\n",
      "Epoch 126: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0109 - mean_squared_error: 0.0235 - val_loss: 0.0962 - val_mean_squared_error: 0.1943\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0237\n",
      "Epoch 127: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0110 - mean_squared_error: 0.0237 - val_loss: 0.0976 - val_mean_squared_error: 0.1973\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0232\n",
      "Epoch 128: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0107 - mean_squared_error: 0.0232 - val_loss: 0.0997 - val_mean_squared_error: 0.2016\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0230\n",
      "Epoch 129: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0106 - mean_squared_error: 0.0230 - val_loss: 0.0959 - val_mean_squared_error: 0.1937\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0228\n",
      "Epoch 130: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0105 - mean_squared_error: 0.0228 - val_loss: 0.0946 - val_mean_squared_error: 0.1912\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0226\n",
      "Epoch 131: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0105 - mean_squared_error: 0.0226 - val_loss: 0.0970 - val_mean_squared_error: 0.1960\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0221\n",
      "Epoch 132: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0102 - mean_squared_error: 0.0221 - val_loss: 0.0947 - val_mean_squared_error: 0.1915\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0221\n",
      "Epoch 133: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0101 - mean_squared_error: 0.0221 - val_loss: 0.0962 - val_mean_squared_error: 0.1945\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0218\n",
      "Epoch 134: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0100 - mean_squared_error: 0.0218 - val_loss: 0.0983 - val_mean_squared_error: 0.1987\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0219\n",
      "Epoch 135: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0101 - mean_squared_error: 0.0219 - val_loss: 0.0985 - val_mean_squared_error: 0.1991\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0217\n",
      "Epoch 136: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0100 - mean_squared_error: 0.0217 - val_loss: 0.0972 - val_mean_squared_error: 0.1966\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0217\n",
      "Epoch 137: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0100 - mean_squared_error: 0.0217 - val_loss: 0.1000 - val_mean_squared_error: 0.2026\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0221\n",
      "Epoch 138: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0102 - mean_squared_error: 0.0221 - val_loss: 0.1036 - val_mean_squared_error: 0.2099\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0223\n",
      "Epoch 139: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0102 - mean_squared_error: 0.0223 - val_loss: 0.0967 - val_mean_squared_error: 0.1953\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0214\n",
      "Epoch 140: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0099 - mean_squared_error: 0.0214 - val_loss: 0.0988 - val_mean_squared_error: 0.2000\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0210\n",
      "Epoch 141: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0096 - mean_squared_error: 0.0210 - val_loss: 0.0967 - val_mean_squared_error: 0.1956\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0204\n",
      "Epoch 142: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0093 - mean_squared_error: 0.0204 - val_loss: 0.0971 - val_mean_squared_error: 0.1964\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0091 - mean_squared_error: 0.0200\n",
      "Epoch 143: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0091 - mean_squared_error: 0.0200 - val_loss: 0.0986 - val_mean_squared_error: 0.1994\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0091 - mean_squared_error: 0.0199\n",
      "Epoch 144: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0091 - mean_squared_error: 0.0199 - val_loss: 0.0998 - val_mean_squared_error: 0.2019\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0090 - mean_squared_error: 0.0198\n",
      "Epoch 145: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0090 - mean_squared_error: 0.0198 - val_loss: 0.0994 - val_mean_squared_error: 0.2012\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0089 - mean_squared_error: 0.0195\n",
      "Epoch 146: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0089 - mean_squared_error: 0.0195 - val_loss: 0.1003 - val_mean_squared_error: 0.2029\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_squared_error: 0.0193\n",
      "Epoch 147: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0088 - mean_squared_error: 0.0193 - val_loss: 0.1010 - val_mean_squared_error: 0.2041\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_squared_error: 0.0193\n",
      "Epoch 148: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0088 - mean_squared_error: 0.0193 - val_loss: 0.0993 - val_mean_squared_error: 0.2007\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0192\n",
      "Epoch 149: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0087 - mean_squared_error: 0.0192 - val_loss: 0.0985 - val_mean_squared_error: 0.1991\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0086 - mean_squared_error: 0.0190\n",
      "Epoch 150: val_loss did not improve from 0.07220\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0086 - mean_squared_error: 0.0190 - val_loss: 0.0987 - val_mean_squared_error: 0.1995\n",
      "5/5 [==============================] - 12s 484ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  624\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4061 - mean_squared_error: 0.9179\n",
      "Epoch 1: val_loss improved from inf to 0.27465, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 118s 8s/step - loss: 0.4061 - mean_squared_error: 0.9179 - val_loss: 0.2746 - val_mean_squared_error: 0.5816\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2495 - mean_squared_error: 0.5341\n",
      "Epoch 2: val_loss improved from 0.27465 to 0.16559, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.2495 - mean_squared_error: 0.5341 - val_loss: 0.1656 - val_mean_squared_error: 0.3397\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1468 - mean_squared_error: 0.3027\n",
      "Epoch 3: val_loss improved from 0.16559 to 0.13472, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.1468 - mean_squared_error: 0.3027 - val_loss: 0.1347 - val_mean_squared_error: 0.2747\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1155 - mean_squared_error: 0.2372\n",
      "Epoch 4: val_loss improved from 0.13472 to 0.12523, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.1155 - mean_squared_error: 0.2372 - val_loss: 0.1252 - val_mean_squared_error: 0.2548\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1006 - mean_squared_error: 0.2056\n",
      "Epoch 5: val_loss improved from 0.12523 to 0.11176, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.1006 - mean_squared_error: 0.2056 - val_loss: 0.1118 - val_mean_squared_error: 0.2269\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0931 - mean_squared_error: 0.1901\n",
      "Epoch 6: val_loss did not improve from 0.11176\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0931 - mean_squared_error: 0.1901 - val_loss: 0.1144 - val_mean_squared_error: 0.2324\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0895 - mean_squared_error: 0.1830\n",
      "Epoch 7: val_loss improved from 0.11176 to 0.10790, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0895 - mean_squared_error: 0.1830 - val_loss: 0.1079 - val_mean_squared_error: 0.2193\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0861 - mean_squared_error: 0.1762\n",
      "Epoch 8: val_loss did not improve from 0.10790\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0861 - mean_squared_error: 0.1762 - val_loss: 0.1085 - val_mean_squared_error: 0.2208\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0838 - mean_squared_error: 0.1715\n",
      "Epoch 9: val_loss improved from 0.10790 to 0.10635, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0838 - mean_squared_error: 0.1715 - val_loss: 0.1063 - val_mean_squared_error: 0.2162\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0825 - mean_squared_error: 0.1686\n",
      "Epoch 10: val_loss improved from 0.10635 to 0.10297, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0825 - mean_squared_error: 0.1686 - val_loss: 0.1030 - val_mean_squared_error: 0.2097\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0796 - mean_squared_error: 0.1626\n",
      "Epoch 11: val_loss did not improve from 0.10297\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0796 - mean_squared_error: 0.1626 - val_loss: 0.1052 - val_mean_squared_error: 0.2144\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0792 - mean_squared_error: 0.1625\n",
      "Epoch 12: val_loss did not improve from 0.10297\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0792 - mean_squared_error: 0.1625 - val_loss: 0.1068 - val_mean_squared_error: 0.2171\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0779 - mean_squared_error: 0.1594\n",
      "Epoch 13: val_loss improved from 0.10297 to 0.10121, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0779 - mean_squared_error: 0.1594 - val_loss: 0.1012 - val_mean_squared_error: 0.2060\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0777 - mean_squared_error: 0.1588\n",
      "Epoch 14: val_loss improved from 0.10121 to 0.09510, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0777 - mean_squared_error: 0.1588 - val_loss: 0.0951 - val_mean_squared_error: 0.1931\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0746 - mean_squared_error: 0.1525\n",
      "Epoch 15: val_loss did not improve from 0.09510\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0746 - mean_squared_error: 0.1525 - val_loss: 0.0955 - val_mean_squared_error: 0.1938\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0728 - mean_squared_error: 0.1486\n",
      "Epoch 16: val_loss did not improve from 0.09510\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0728 - mean_squared_error: 0.1486 - val_loss: 0.0965 - val_mean_squared_error: 0.1954\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0711 - mean_squared_error: 0.1452\n",
      "Epoch 17: val_loss improved from 0.09510 to 0.08653, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0711 - mean_squared_error: 0.1452 - val_loss: 0.0865 - val_mean_squared_error: 0.1748\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0681 - mean_squared_error: 0.1387\n",
      "Epoch 18: val_loss improved from 0.08653 to 0.08398, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0681 - mean_squared_error: 0.1387 - val_loss: 0.0840 - val_mean_squared_error: 0.1697\n",
      "Epoch 19/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - ETA: 0s - loss: 0.0661 - mean_squared_error: 0.1348\n",
      "Epoch 19: val_loss did not improve from 0.08398\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0661 - mean_squared_error: 0.1348 - val_loss: 0.0864 - val_mean_squared_error: 0.1745\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0630 - mean_squared_error: 0.1288\n",
      "Epoch 20: val_loss did not improve from 0.08398\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0630 - mean_squared_error: 0.1288 - val_loss: 0.0853 - val_mean_squared_error: 0.1722\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0622 - mean_squared_error: 0.1268\n",
      "Epoch 21: val_loss did not improve from 0.08398\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0622 - mean_squared_error: 0.1268 - val_loss: 0.0897 - val_mean_squared_error: 0.1820\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0611 - mean_squared_error: 0.1246\n",
      "Epoch 22: val_loss improved from 0.08398 to 0.07940, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0611 - mean_squared_error: 0.1246 - val_loss: 0.0794 - val_mean_squared_error: 0.1599\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0573 - mean_squared_error: 0.1170\n",
      "Epoch 23: val_loss did not improve from 0.07940\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0573 - mean_squared_error: 0.1170 - val_loss: 0.0837 - val_mean_squared_error: 0.1695\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0559 - mean_squared_error: 0.1141\n",
      "Epoch 24: val_loss did not improve from 0.07940\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0559 - mean_squared_error: 0.1141 - val_loss: 0.0817 - val_mean_squared_error: 0.1655\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0541 - mean_squared_error: 0.1105\n",
      "Epoch 25: val_loss did not improve from 0.07940\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0541 - mean_squared_error: 0.1105 - val_loss: 0.0795 - val_mean_squared_error: 0.1602\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0533 - mean_squared_error: 0.1088\n",
      "Epoch 26: val_loss improved from 0.07940 to 0.07013, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0533 - mean_squared_error: 0.1088 - val_loss: 0.0701 - val_mean_squared_error: 0.1410\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0522 - mean_squared_error: 0.1065\n",
      "Epoch 27: val_loss did not improve from 0.07013\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0522 - mean_squared_error: 0.1065 - val_loss: 0.0766 - val_mean_squared_error: 0.1545\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0526 - mean_squared_error: 0.1073\n",
      "Epoch 28: val_loss did not improve from 0.07013\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0526 - mean_squared_error: 0.1073 - val_loss: 0.0841 - val_mean_squared_error: 0.1697\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.1053\n",
      "Epoch 29: val_loss did not improve from 0.07013\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0515 - mean_squared_error: 0.1053 - val_loss: 0.0750 - val_mean_squared_error: 0.1510\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0516 - mean_squared_error: 0.1054\n",
      "Epoch 30: val_loss did not improve from 0.07013\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0516 - mean_squared_error: 0.1054 - val_loss: 0.0704 - val_mean_squared_error: 0.1416\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0507 - mean_squared_error: 0.1035\n",
      "Epoch 31: val_loss did not improve from 0.07013\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0507 - mean_squared_error: 0.1035 - val_loss: 0.0736 - val_mean_squared_error: 0.1480\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0485 - mean_squared_error: 0.0991\n",
      "Epoch 32: val_loss did not improve from 0.07013\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0485 - mean_squared_error: 0.0991 - val_loss: 0.0753 - val_mean_squared_error: 0.1517\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0483 - mean_squared_error: 0.0987\n",
      "Epoch 33: val_loss did not improve from 0.07013\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0483 - mean_squared_error: 0.0987 - val_loss: 0.0763 - val_mean_squared_error: 0.1539\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0486 - mean_squared_error: 0.0993\n",
      "Epoch 34: val_loss did not improve from 0.07013\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0486 - mean_squared_error: 0.0993 - val_loss: 0.0804 - val_mean_squared_error: 0.1631\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0484 - mean_squared_error: 0.0989\n",
      "Epoch 35: val_loss did not improve from 0.07013\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0484 - mean_squared_error: 0.0989 - val_loss: 0.0797 - val_mean_squared_error: 0.1604\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0485 - mean_squared_error: 0.0990\n",
      "Epoch 36: val_loss improved from 0.07013 to 0.06953, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0485 - mean_squared_error: 0.0990 - val_loss: 0.0695 - val_mean_squared_error: 0.1396\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0491 - mean_squared_error: 0.1004\n",
      "Epoch 37: val_loss did not improve from 0.06953\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0491 - mean_squared_error: 0.1004 - val_loss: 0.0699 - val_mean_squared_error: 0.1403\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0498 - mean_squared_error: 0.1018\n",
      "Epoch 38: val_loss did not improve from 0.06953\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0498 - mean_squared_error: 0.1018 - val_loss: 0.0742 - val_mean_squared_error: 0.1489\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0505 - mean_squared_error: 0.1031\n",
      "Epoch 39: val_loss did not improve from 0.06953\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0505 - mean_squared_error: 0.1031 - val_loss: 0.0774 - val_mean_squared_error: 0.1554\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0470 - mean_squared_error: 0.0959\n",
      "Epoch 40: val_loss did not improve from 0.06953\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0470 - mean_squared_error: 0.0959 - val_loss: 0.0737 - val_mean_squared_error: 0.1478\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0942\n",
      "Epoch 41: val_loss did not improve from 0.06953\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0462 - mean_squared_error: 0.0942 - val_loss: 0.0730 - val_mean_squared_error: 0.1464\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0456 - mean_squared_error: 0.0931\n",
      "Epoch 42: val_loss did not improve from 0.06953\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0456 - mean_squared_error: 0.0931 - val_loss: 0.0715 - val_mean_squared_error: 0.1434\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0444 - mean_squared_error: 0.0908\n",
      "Epoch 43: val_loss improved from 0.06953 to 0.06898, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0444 - mean_squared_error: 0.0908 - val_loss: 0.0690 - val_mean_squared_error: 0.1384\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0435 - mean_squared_error: 0.0888\n",
      "Epoch 44: val_loss improved from 0.06898 to 0.06839, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 59s 7s/step - loss: 0.0435 - mean_squared_error: 0.0888 - val_loss: 0.0684 - val_mean_squared_error: 0.1373\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0431 - mean_squared_error: 0.0881\n",
      "Epoch 45: val_loss improved from 0.06839 to 0.06821, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0431 - mean_squared_error: 0.0881 - val_loss: 0.0682 - val_mean_squared_error: 0.1370\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0423 - mean_squared_error: 0.0866\n",
      "Epoch 46: val_loss did not improve from 0.06821\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0423 - mean_squared_error: 0.0866 - val_loss: 0.0759 - val_mean_squared_error: 0.1524\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0423 - mean_squared_error: 0.0865\n",
      "Epoch 47: val_loss did not improve from 0.06821\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0423 - mean_squared_error: 0.0865 - val_loss: 0.0798 - val_mean_squared_error: 0.1606\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0420 - mean_squared_error: 0.0859\n",
      "Epoch 48: val_loss did not improve from 0.06821\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0420 - mean_squared_error: 0.0859 - val_loss: 0.0726 - val_mean_squared_error: 0.1457\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0425 - mean_squared_error: 0.0869\n",
      "Epoch 49: val_loss did not improve from 0.06821\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0425 - mean_squared_error: 0.0869 - val_loss: 0.0771 - val_mean_squared_error: 0.1550\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0409 - mean_squared_error: 0.0837\n",
      "Epoch 50: val_loss did not improve from 0.06821\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0409 - mean_squared_error: 0.0837 - val_loss: 0.0727 - val_mean_squared_error: 0.1458\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0408 - mean_squared_error: 0.0834\n",
      "Epoch 51: val_loss did not improve from 0.06821\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0408 - mean_squared_error: 0.0834 - val_loss: 0.0789 - val_mean_squared_error: 0.1587\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0411 - mean_squared_error: 0.0842\n",
      "Epoch 52: val_loss improved from 0.06821 to 0.06569, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0411 - mean_squared_error: 0.0842 - val_loss: 0.0657 - val_mean_squared_error: 0.1320\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0407 - mean_squared_error: 0.0833\n",
      "Epoch 53: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0407 - mean_squared_error: 0.0833 - val_loss: 0.0662 - val_mean_squared_error: 0.1330\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0801\n",
      "Epoch 54: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0392 - mean_squared_error: 0.0801 - val_loss: 0.0689 - val_mean_squared_error: 0.1382\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0796\n",
      "Epoch 55: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0389 - mean_squared_error: 0.0796 - val_loss: 0.0690 - val_mean_squared_error: 0.1385\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0780\n",
      "Epoch 56: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0381 - mean_squared_error: 0.0780 - val_loss: 0.0663 - val_mean_squared_error: 0.1330\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0373 - mean_squared_error: 0.0766\n",
      "Epoch 57: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0373 - mean_squared_error: 0.0766 - val_loss: 0.0679 - val_mean_squared_error: 0.1362\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0369 - mean_squared_error: 0.0754\n",
      "Epoch 58: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0369 - mean_squared_error: 0.0754 - val_loss: 0.0716 - val_mean_squared_error: 0.1437\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0361 - mean_squared_error: 0.0740\n",
      "Epoch 59: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0361 - mean_squared_error: 0.0740 - val_loss: 0.0717 - val_mean_squared_error: 0.1439\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0355 - mean_squared_error: 0.0727\n",
      "Epoch 60: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0355 - mean_squared_error: 0.0727 - val_loss: 0.0744 - val_mean_squared_error: 0.1493\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0356 - mean_squared_error: 0.0730\n",
      "Epoch 61: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0356 - mean_squared_error: 0.0730 - val_loss: 0.0680 - val_mean_squared_error: 0.1364\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.0725\n",
      "Epoch 62: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0354 - mean_squared_error: 0.0725 - val_loss: 0.0683 - val_mean_squared_error: 0.1372\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0359 - mean_squared_error: 0.0736\n",
      "Epoch 63: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0359 - mean_squared_error: 0.0736 - val_loss: 0.0709 - val_mean_squared_error: 0.1426\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0357 - mean_squared_error: 0.0732\n",
      "Epoch 64: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0357 - mean_squared_error: 0.0732 - val_loss: 0.0722 - val_mean_squared_error: 0.1451\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0337 - mean_squared_error: 0.0692\n",
      "Epoch 65: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0337 - mean_squared_error: 0.0692 - val_loss: 0.0708 - val_mean_squared_error: 0.1421\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0333 - mean_squared_error: 0.0684\n",
      "Epoch 66: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0333 - mean_squared_error: 0.0684 - val_loss: 0.0790 - val_mean_squared_error: 0.1594\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0331 - mean_squared_error: 0.0681\n",
      "Epoch 67: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0331 - mean_squared_error: 0.0681 - val_loss: 0.0748 - val_mean_squared_error: 0.1507\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0327 - mean_squared_error: 0.0673\n",
      "Epoch 68: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 6s/step - loss: 0.0327 - mean_squared_error: 0.0673 - val_loss: 0.0735 - val_mean_squared_error: 0.1475\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0325 - mean_squared_error: 0.0668\n",
      "Epoch 69: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0325 - mean_squared_error: 0.0668 - val_loss: 0.0685 - val_mean_squared_error: 0.1375\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0316 - mean_squared_error: 0.0649\n",
      "Epoch 70: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0316 - mean_squared_error: 0.0649 - val_loss: 0.0751 - val_mean_squared_error: 0.1513\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0319 - mean_squared_error: 0.0656\n",
      "Epoch 71: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0319 - mean_squared_error: 0.0656 - val_loss: 0.0762 - val_mean_squared_error: 0.1530\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0324 - mean_squared_error: 0.0666\n",
      "Epoch 72: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0324 - mean_squared_error: 0.0666 - val_loss: 0.0721 - val_mean_squared_error: 0.1450\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0319 - mean_squared_error: 0.0655\n",
      "Epoch 73: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0319 - mean_squared_error: 0.0655 - val_loss: 0.0732 - val_mean_squared_error: 0.1470\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0309 - mean_squared_error: 0.0636\n",
      "Epoch 74: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0309 - mean_squared_error: 0.0636 - val_loss: 0.0716 - val_mean_squared_error: 0.1437\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0293 - mean_squared_error: 0.0603\n",
      "Epoch 75: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0293 - mean_squared_error: 0.0603 - val_loss: 0.0754 - val_mean_squared_error: 0.1516\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0295 - mean_squared_error: 0.0607\n",
      "Epoch 76: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0295 - mean_squared_error: 0.0607 - val_loss: 0.0745 - val_mean_squared_error: 0.1498\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0296 - mean_squared_error: 0.0610\n",
      "Epoch 77: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0296 - mean_squared_error: 0.0610 - val_loss: 0.0799 - val_mean_squared_error: 0.1608\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0290 - mean_squared_error: 0.0597\n",
      "Epoch 78: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0290 - mean_squared_error: 0.0597 - val_loss: 0.0774 - val_mean_squared_error: 0.1561\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0277 - mean_squared_error: 0.0571\n",
      "Epoch 79: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0277 - mean_squared_error: 0.0571 - val_loss: 0.0750 - val_mean_squared_error: 0.1512\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0276 - mean_squared_error: 0.0570\n",
      "Epoch 80: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0276 - mean_squared_error: 0.0570 - val_loss: 0.0762 - val_mean_squared_error: 0.1534\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0276 - mean_squared_error: 0.0569\n",
      "Epoch 81: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0276 - mean_squared_error: 0.0569 - val_loss: 0.0760 - val_mean_squared_error: 0.1526\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0273 - mean_squared_error: 0.0563\n",
      "Epoch 82: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0273 - mean_squared_error: 0.0563 - val_loss: 0.0707 - val_mean_squared_error: 0.1419\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0267 - mean_squared_error: 0.0550\n",
      "Epoch 83: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0267 - mean_squared_error: 0.0550 - val_loss: 0.0857 - val_mean_squared_error: 0.1727\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0258 - mean_squared_error: 0.0533\n",
      "Epoch 84: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0258 - mean_squared_error: 0.0533 - val_loss: 0.0746 - val_mean_squared_error: 0.1501\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0259 - mean_squared_error: 0.0535\n",
      "Epoch 85: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0259 - mean_squared_error: 0.0535 - val_loss: 0.0723 - val_mean_squared_error: 0.1453\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0256 - mean_squared_error: 0.0530\n",
      "Epoch 86: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0256 - mean_squared_error: 0.0530 - val_loss: 0.0837 - val_mean_squared_error: 0.1686\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0249 - mean_squared_error: 0.0515\n",
      "Epoch 87: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0249 - mean_squared_error: 0.0515 - val_loss: 0.0823 - val_mean_squared_error: 0.1661\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0242 - mean_squared_error: 0.0501\n",
      "Epoch 88: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0242 - mean_squared_error: 0.0501 - val_loss: 0.0825 - val_mean_squared_error: 0.1664\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0241 - mean_squared_error: 0.0500\n",
      "Epoch 89: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0241 - mean_squared_error: 0.0500 - val_loss: 0.0801 - val_mean_squared_error: 0.1619\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0235 - mean_squared_error: 0.0486\n",
      "Epoch 90: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0235 - mean_squared_error: 0.0486 - val_loss: 0.0830 - val_mean_squared_error: 0.1672\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0231 - mean_squared_error: 0.0478\n",
      "Epoch 91: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0231 - mean_squared_error: 0.0478 - val_loss: 0.0851 - val_mean_squared_error: 0.1719\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0228 - mean_squared_error: 0.0473\n",
      "Epoch 92: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0228 - mean_squared_error: 0.0473 - val_loss: 0.0761 - val_mean_squared_error: 0.1529\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0221 - mean_squared_error: 0.0459\n",
      "Epoch 93: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0221 - mean_squared_error: 0.0459 - val_loss: 0.0780 - val_mean_squared_error: 0.1567\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0223 - mean_squared_error: 0.0463\n",
      "Epoch 94: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0223 - mean_squared_error: 0.0463 - val_loss: 0.0802 - val_mean_squared_error: 0.1615\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0220 - mean_squared_error: 0.0458\n",
      "Epoch 95: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0220 - mean_squared_error: 0.0458 - val_loss: 0.0826 - val_mean_squared_error: 0.1665\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0212 - mean_squared_error: 0.0440\n",
      "Epoch 96: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0212 - mean_squared_error: 0.0440 - val_loss: 0.0874 - val_mean_squared_error: 0.1772\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0210 - mean_squared_error: 0.0438\n",
      "Epoch 97: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0210 - mean_squared_error: 0.0438 - val_loss: 0.0808 - val_mean_squared_error: 0.1628\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0205 - mean_squared_error: 0.0426\n",
      "Epoch 98: val_loss did not improve from 0.06569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 59s 7s/step - loss: 0.0205 - mean_squared_error: 0.0426 - val_loss: 0.0812 - val_mean_squared_error: 0.1632\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0200 - mean_squared_error: 0.0416\n",
      "Epoch 99: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0200 - mean_squared_error: 0.0416 - val_loss: 0.0812 - val_mean_squared_error: 0.1640\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0196 - mean_squared_error: 0.0409\n",
      "Epoch 100: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0196 - mean_squared_error: 0.0409 - val_loss: 0.0834 - val_mean_squared_error: 0.1688\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0201 - mean_squared_error: 0.0418\n",
      "Epoch 101: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0201 - mean_squared_error: 0.0418 - val_loss: 0.0892 - val_mean_squared_error: 0.1809\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0200 - mean_squared_error: 0.0418\n",
      "Epoch 102: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0200 - mean_squared_error: 0.0418 - val_loss: 0.0839 - val_mean_squared_error: 0.1694\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0194 - mean_squared_error: 0.0405\n",
      "Epoch 103: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0194 - mean_squared_error: 0.0405 - val_loss: 0.0861 - val_mean_squared_error: 0.1744\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0191 - mean_squared_error: 0.0400\n",
      "Epoch 104: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0191 - mean_squared_error: 0.0400 - val_loss: 0.0855 - val_mean_squared_error: 0.1725\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0187 - mean_squared_error: 0.0391\n",
      "Epoch 105: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0187 - mean_squared_error: 0.0391 - val_loss: 0.0856 - val_mean_squared_error: 0.1729\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0182 - mean_squared_error: 0.0382\n",
      "Epoch 106: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0182 - mean_squared_error: 0.0382 - val_loss: 0.0819 - val_mean_squared_error: 0.1650\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0179 - mean_squared_error: 0.0374\n",
      "Epoch 107: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0179 - mean_squared_error: 0.0374 - val_loss: 0.0870 - val_mean_squared_error: 0.1758\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0366\n",
      "Epoch 108: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0175 - mean_squared_error: 0.0366 - val_loss: 0.0846 - val_mean_squared_error: 0.1707\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0170 - mean_squared_error: 0.0357\n",
      "Epoch 109: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0170 - mean_squared_error: 0.0357 - val_loss: 0.0867 - val_mean_squared_error: 0.1752\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0356\n",
      "Epoch 110: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0169 - mean_squared_error: 0.0356 - val_loss: 0.0939 - val_mean_squared_error: 0.1896\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0173 - mean_squared_error: 0.0363\n",
      "Epoch 111: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0173 - mean_squared_error: 0.0363 - val_loss: 0.0877 - val_mean_squared_error: 0.1774\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0355\n",
      "Epoch 112: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0169 - mean_squared_error: 0.0355 - val_loss: 0.0877 - val_mean_squared_error: 0.1776\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0347\n",
      "Epoch 113: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0165 - mean_squared_error: 0.0347 - val_loss: 0.0849 - val_mean_squared_error: 0.1716\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0341\n",
      "Epoch 114: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0162 - mean_squared_error: 0.0341 - val_loss: 0.0906 - val_mean_squared_error: 0.1832\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0337\n",
      "Epoch 115: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0160 - mean_squared_error: 0.0337 - val_loss: 0.0869 - val_mean_squared_error: 0.1761\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0337\n",
      "Epoch 116: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0160 - mean_squared_error: 0.0337 - val_loss: 0.0912 - val_mean_squared_error: 0.1849\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0326\n",
      "Epoch 117: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0155 - mean_squared_error: 0.0326 - val_loss: 0.0863 - val_mean_squared_error: 0.1744\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0327\n",
      "Epoch 118: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0155 - mean_squared_error: 0.0327 - val_loss: 0.0905 - val_mean_squared_error: 0.1834\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0320\n",
      "Epoch 119: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0152 - mean_squared_error: 0.0320 - val_loss: 0.0903 - val_mean_squared_error: 0.1826\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.0317\n",
      "Epoch 120: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0150 - mean_squared_error: 0.0317 - val_loss: 0.0866 - val_mean_squared_error: 0.1748\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0315\n",
      "Epoch 121: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0149 - mean_squared_error: 0.0315 - val_loss: 0.0915 - val_mean_squared_error: 0.1852\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0315\n",
      "Epoch 122: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0149 - mean_squared_error: 0.0315 - val_loss: 0.0869 - val_mean_squared_error: 0.1753\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0307\n",
      "Epoch 123: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0145 - mean_squared_error: 0.0307 - val_loss: 0.0969 - val_mean_squared_error: 0.1969\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0307\n",
      "Epoch 124: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0145 - mean_squared_error: 0.0307 - val_loss: 0.0929 - val_mean_squared_error: 0.1877\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0302\n",
      "Epoch 125: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0143 - mean_squared_error: 0.0302 - val_loss: 0.0928 - val_mean_squared_error: 0.1880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0298\n",
      "Epoch 126: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0141 - mean_squared_error: 0.0298 - val_loss: 0.0906 - val_mean_squared_error: 0.1836\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0292\n",
      "Epoch 127: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0137 - mean_squared_error: 0.0292 - val_loss: 0.0932 - val_mean_squared_error: 0.1882\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0299\n",
      "Epoch 128: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0141 - mean_squared_error: 0.0299 - val_loss: 0.0910 - val_mean_squared_error: 0.1842\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0287\n",
      "Epoch 129: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0135 - mean_squared_error: 0.0287 - val_loss: 0.0882 - val_mean_squared_error: 0.1782\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0281\n",
      "Epoch 130: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0132 - mean_squared_error: 0.0281 - val_loss: 0.0923 - val_mean_squared_error: 0.1863\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0278\n",
      "Epoch 131: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0131 - mean_squared_error: 0.0278 - val_loss: 0.0912 - val_mean_squared_error: 0.1847\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0276\n",
      "Epoch 132: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0129 - mean_squared_error: 0.0276 - val_loss: 0.0917 - val_mean_squared_error: 0.1855\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0273\n",
      "Epoch 133: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0128 - mean_squared_error: 0.0273 - val_loss: 0.0948 - val_mean_squared_error: 0.1916\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0270\n",
      "Epoch 134: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0127 - mean_squared_error: 0.0270 - val_loss: 0.0959 - val_mean_squared_error: 0.1944\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0270\n",
      "Epoch 135: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0126 - mean_squared_error: 0.0270 - val_loss: 0.0942 - val_mean_squared_error: 0.1907\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0263\n",
      "Epoch 136: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0123 - mean_squared_error: 0.0263 - val_loss: 0.0990 - val_mean_squared_error: 0.2008\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0261\n",
      "Epoch 137: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0122 - mean_squared_error: 0.0261 - val_loss: 0.0922 - val_mean_squared_error: 0.1865\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0258\n",
      "Epoch 138: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0121 - mean_squared_error: 0.0258 - val_loss: 0.0931 - val_mean_squared_error: 0.1884\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0263\n",
      "Epoch 139: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0122 - mean_squared_error: 0.0263 - val_loss: 0.0942 - val_mean_squared_error: 0.1908\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0258\n",
      "Epoch 140: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0121 - mean_squared_error: 0.0258 - val_loss: 0.0954 - val_mean_squared_error: 0.1933\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0251\n",
      "Epoch 141: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0116 - mean_squared_error: 0.0251 - val_loss: 0.0967 - val_mean_squared_error: 0.1959\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0243\n",
      "Epoch 142: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0113 - mean_squared_error: 0.0243 - val_loss: 0.0918 - val_mean_squared_error: 0.1856\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0241\n",
      "Epoch 143: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.0112 - mean_squared_error: 0.0241 - val_loss: 0.0961 - val_mean_squared_error: 0.1944\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0240\n",
      "Epoch 144: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0112 - mean_squared_error: 0.0240 - val_loss: 0.0927 - val_mean_squared_error: 0.1874\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0237\n",
      "Epoch 145: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0110 - mean_squared_error: 0.0237 - val_loss: 0.0948 - val_mean_squared_error: 0.1918\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0233\n",
      "Epoch 146: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0108 - mean_squared_error: 0.0233 - val_loss: 0.0984 - val_mean_squared_error: 0.1992\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0230\n",
      "Epoch 147: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0106 - mean_squared_error: 0.0230 - val_loss: 0.0970 - val_mean_squared_error: 0.1967\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0230\n",
      "Epoch 148: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0106 - mean_squared_error: 0.0230 - val_loss: 0.0958 - val_mean_squared_error: 0.1941\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0231\n",
      "Epoch 149: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0107 - mean_squared_error: 0.0231 - val_loss: 0.0974 - val_mean_squared_error: 0.1976\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0233\n",
      "Epoch 150: val_loss did not improve from 0.06569\n",
      "9/9 [==============================] - 59s 7s/step - loss: 0.0108 - mean_squared_error: 0.0233 - val_loss: 0.0944 - val_mean_squared_error: 0.1910\n",
      "5/5 [==============================] - 12s 504ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  648\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4027 - mean_squared_error: 0.9095\n",
      "Epoch 1: val_loss improved from inf to 0.25527, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 125s 8s/step - loss: 0.4027 - mean_squared_error: 0.9095 - val_loss: 0.2553 - val_mean_squared_error: 0.5398\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2750 - mean_squared_error: 0.6047\n",
      "Epoch 2: val_loss improved from 0.25527 to 0.17476, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.2750 - mean_squared_error: 0.6047 - val_loss: 0.1748 - val_mean_squared_error: 0.3608\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1696 - mean_squared_error: 0.3565\n",
      "Epoch 3: val_loss improved from 0.17476 to 0.16714, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.1696 - mean_squared_error: 0.3565 - val_loss: 0.1671 - val_mean_squared_error: 0.3461\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1269 - mean_squared_error: 0.2607\n",
      "Epoch 4: val_loss improved from 0.16714 to 0.13579, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.1269 - mean_squared_error: 0.2607 - val_loss: 0.1358 - val_mean_squared_error: 0.2776\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1055 - mean_squared_error: 0.2165\n",
      "Epoch 5: val_loss improved from 0.13579 to 0.11668, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.1055 - mean_squared_error: 0.2165 - val_loss: 0.1167 - val_mean_squared_error: 0.2383\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0934 - mean_squared_error: 0.1913\n",
      "Epoch 6: val_loss improved from 0.11668 to 0.11022, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0934 - mean_squared_error: 0.1913 - val_loss: 0.1102 - val_mean_squared_error: 0.2251\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0870 - mean_squared_error: 0.1782\n",
      "Epoch 7: val_loss improved from 0.11022 to 0.10592, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0870 - mean_squared_error: 0.1782 - val_loss: 0.1059 - val_mean_squared_error: 0.2167\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0835 - mean_squared_error: 0.1709\n",
      "Epoch 8: val_loss did not improve from 0.10592\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0835 - mean_squared_error: 0.1709 - val_loss: 0.1167 - val_mean_squared_error: 0.2392\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0834 - mean_squared_error: 0.1707\n",
      "Epoch 9: val_loss did not improve from 0.10592\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0834 - mean_squared_error: 0.1707 - val_loss: 0.1074 - val_mean_squared_error: 0.2200\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0812 - mean_squared_error: 0.1662\n",
      "Epoch 10: val_loss did not improve from 0.10592\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0812 - mean_squared_error: 0.1662 - val_loss: 0.1080 - val_mean_squared_error: 0.2206\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0814 - mean_squared_error: 0.1663\n",
      "Epoch 11: val_loss improved from 0.10592 to 0.10244, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0814 - mean_squared_error: 0.1663 - val_loss: 0.1024 - val_mean_squared_error: 0.2091\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0800 - mean_squared_error: 0.1636\n",
      "Epoch 12: val_loss did not improve from 0.10244\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0800 - mean_squared_error: 0.1636 - val_loss: 0.1039 - val_mean_squared_error: 0.2135\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0784 - mean_squared_error: 0.1605\n",
      "Epoch 13: val_loss did not improve from 0.10244\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0784 - mean_squared_error: 0.1605 - val_loss: 0.1031 - val_mean_squared_error: 0.2106\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0777 - mean_squared_error: 0.1590\n",
      "Epoch 14: val_loss did not improve from 0.10244\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0777 - mean_squared_error: 0.1590 - val_loss: 0.1062 - val_mean_squared_error: 0.2171\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0760 - mean_squared_error: 0.1552\n",
      "Epoch 15: val_loss improved from 0.10244 to 0.10239, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0760 - mean_squared_error: 0.1552 - val_loss: 0.1024 - val_mean_squared_error: 0.2103\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0746 - mean_squared_error: 0.1528\n",
      "Epoch 16: val_loss improved from 0.10239 to 0.10161, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0746 - mean_squared_error: 0.1528 - val_loss: 0.1016 - val_mean_squared_error: 0.2076\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0732 - mean_squared_error: 0.1494\n",
      "Epoch 17: val_loss improved from 0.10161 to 0.10021, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0732 - mean_squared_error: 0.1494 - val_loss: 0.1002 - val_mean_squared_error: 0.2058\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0714 - mean_squared_error: 0.1460\n",
      "Epoch 18: val_loss improved from 0.10021 to 0.09867, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0714 - mean_squared_error: 0.1460 - val_loss: 0.0987 - val_mean_squared_error: 0.2019\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0728 - mean_squared_error: 0.1487\n",
      "Epoch 19: val_loss improved from 0.09867 to 0.09794, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0728 - mean_squared_error: 0.1487 - val_loss: 0.0979 - val_mean_squared_error: 0.2004\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0697 - mean_squared_error: 0.1426\n",
      "Epoch 20: val_loss improved from 0.09794 to 0.09530, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0697 - mean_squared_error: 0.1426 - val_loss: 0.0953 - val_mean_squared_error: 0.1944\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0673 - mean_squared_error: 0.1375\n",
      "Epoch 21: val_loss did not improve from 0.09530\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0673 - mean_squared_error: 0.1375 - val_loss: 0.0957 - val_mean_squared_error: 0.1952\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0663 - mean_squared_error: 0.1355\n",
      "Epoch 22: val_loss did not improve from 0.09530\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0663 - mean_squared_error: 0.1355 - val_loss: 0.0966 - val_mean_squared_error: 0.1962\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0647 - mean_squared_error: 0.1318\n",
      "Epoch 23: val_loss did not improve from 0.09530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 65s 7s/step - loss: 0.0647 - mean_squared_error: 0.1318 - val_loss: 0.0960 - val_mean_squared_error: 0.1952\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0641 - mean_squared_error: 0.1306\n",
      "Epoch 24: val_loss improved from 0.09530 to 0.08708, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0641 - mean_squared_error: 0.1306 - val_loss: 0.0871 - val_mean_squared_error: 0.1763\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0631 - mean_squared_error: 0.1285\n",
      "Epoch 25: val_loss did not improve from 0.08708\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0631 - mean_squared_error: 0.1285 - val_loss: 0.0980 - val_mean_squared_error: 0.1985\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0613 - mean_squared_error: 0.1249\n",
      "Epoch 26: val_loss improved from 0.08708 to 0.08551, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0613 - mean_squared_error: 0.1249 - val_loss: 0.0855 - val_mean_squared_error: 0.1731\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0596 - mean_squared_error: 0.1215\n",
      "Epoch 27: val_loss did not improve from 0.08551\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0596 - mean_squared_error: 0.1215 - val_loss: 0.0920 - val_mean_squared_error: 0.1861\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0579 - mean_squared_error: 0.1182\n",
      "Epoch 28: val_loss did not improve from 0.08551\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0579 - mean_squared_error: 0.1182 - val_loss: 0.0881 - val_mean_squared_error: 0.1784\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0568 - mean_squared_error: 0.1158\n",
      "Epoch 29: val_loss improved from 0.08551 to 0.08342, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0568 - mean_squared_error: 0.1158 - val_loss: 0.0834 - val_mean_squared_error: 0.1686\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0554 - mean_squared_error: 0.1128\n",
      "Epoch 30: val_loss improved from 0.08342 to 0.08102, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0554 - mean_squared_error: 0.1128 - val_loss: 0.0810 - val_mean_squared_error: 0.1638\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0552 - mean_squared_error: 0.1127\n",
      "Epoch 31: val_loss improved from 0.08102 to 0.07567, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0552 - mean_squared_error: 0.1127 - val_loss: 0.0757 - val_mean_squared_error: 0.1526\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0530 - mean_squared_error: 0.1081\n",
      "Epoch 32: val_loss did not improve from 0.07567\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0530 - mean_squared_error: 0.1081 - val_loss: 0.0780 - val_mean_squared_error: 0.1575\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0517 - mean_squared_error: 0.1055\n",
      "Epoch 33: val_loss did not improve from 0.07567\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0517 - mean_squared_error: 0.1055 - val_loss: 0.0778 - val_mean_squared_error: 0.1570\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0494 - mean_squared_error: 0.1009\n",
      "Epoch 34: val_loss did not improve from 0.07567\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0494 - mean_squared_error: 0.1009 - val_loss: 0.0832 - val_mean_squared_error: 0.1678\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0493 - mean_squared_error: 0.1005\n",
      "Epoch 35: val_loss did not improve from 0.07567\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0493 - mean_squared_error: 0.1005 - val_loss: 0.0829 - val_mean_squared_error: 0.1680\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0494 - mean_squared_error: 0.1007\n",
      "Epoch 36: val_loss did not improve from 0.07567\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0494 - mean_squared_error: 0.1007 - val_loss: 0.0828 - val_mean_squared_error: 0.1675\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0486 - mean_squared_error: 0.0992\n",
      "Epoch 37: val_loss did not improve from 0.07567\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0486 - mean_squared_error: 0.0992 - val_loss: 0.0773 - val_mean_squared_error: 0.1563\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0475 - mean_squared_error: 0.0969\n",
      "Epoch 38: val_loss improved from 0.07567 to 0.07510, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0475 - mean_squared_error: 0.0969 - val_loss: 0.0751 - val_mean_squared_error: 0.1517\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0470 - mean_squared_error: 0.0958\n",
      "Epoch 39: val_loss improved from 0.07510 to 0.07371, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0470 - mean_squared_error: 0.0958 - val_loss: 0.0737 - val_mean_squared_error: 0.1491\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0470 - mean_squared_error: 0.0958\n",
      "Epoch 40: val_loss improved from 0.07371 to 0.07346, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0470 - mean_squared_error: 0.0958 - val_loss: 0.0735 - val_mean_squared_error: 0.1486\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0464 - mean_squared_error: 0.0947\n",
      "Epoch 41: val_loss did not improve from 0.07346\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0464 - mean_squared_error: 0.0947 - val_loss: 0.0745 - val_mean_squared_error: 0.1505\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0449 - mean_squared_error: 0.0916\n",
      "Epoch 42: val_loss did not improve from 0.07346\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0449 - mean_squared_error: 0.0916 - val_loss: 0.0760 - val_mean_squared_error: 0.1534\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0422 - mean_squared_error: 0.0861\n",
      "Epoch 43: val_loss did not improve from 0.07346\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0422 - mean_squared_error: 0.0861 - val_loss: 0.0770 - val_mean_squared_error: 0.1554\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0426 - mean_squared_error: 0.0870\n",
      "Epoch 44: val_loss did not improve from 0.07346\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0426 - mean_squared_error: 0.0870 - val_loss: 0.0752 - val_mean_squared_error: 0.1519\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0419 - mean_squared_error: 0.0856\n",
      "Epoch 45: val_loss did not improve from 0.07346\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0419 - mean_squared_error: 0.0856 - val_loss: 0.0774 - val_mean_squared_error: 0.1561\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0412 - mean_squared_error: 0.0842\n",
      "Epoch 46: val_loss did not improve from 0.07346\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0412 - mean_squared_error: 0.0842 - val_loss: 0.0771 - val_mean_squared_error: 0.1555\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0397 - mean_squared_error: 0.0812\n",
      "Epoch 47: val_loss improved from 0.07346 to 0.07284, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 65s 7s/step - loss: 0.0397 - mean_squared_error: 0.0812 - val_loss: 0.0728 - val_mean_squared_error: 0.1466\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0814\n",
      "Epoch 48: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0398 - mean_squared_error: 0.0814 - val_loss: 0.0843 - val_mean_squared_error: 0.1704\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0378 - mean_squared_error: 0.0774\n",
      "Epoch 49: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0378 - mean_squared_error: 0.0774 - val_loss: 0.0731 - val_mean_squared_error: 0.1475\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0781\n",
      "Epoch 50: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0381 - mean_squared_error: 0.0781 - val_loss: 0.0758 - val_mean_squared_error: 0.1528\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0371 - mean_squared_error: 0.0760\n",
      "Epoch 51: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0371 - mean_squared_error: 0.0760 - val_loss: 0.0799 - val_mean_squared_error: 0.1612\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0361 - mean_squared_error: 0.0740\n",
      "Epoch 52: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0361 - mean_squared_error: 0.0740 - val_loss: 0.0772 - val_mean_squared_error: 0.1554\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0350 - mean_squared_error: 0.0718\n",
      "Epoch 53: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0350 - mean_squared_error: 0.0718 - val_loss: 0.0864 - val_mean_squared_error: 0.1756\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0348 - mean_squared_error: 0.0714\n",
      "Epoch 54: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0348 - mean_squared_error: 0.0714 - val_loss: 0.0748 - val_mean_squared_error: 0.1506\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0347 - mean_squared_error: 0.0712\n",
      "Epoch 55: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0347 - mean_squared_error: 0.0712 - val_loss: 0.0785 - val_mean_squared_error: 0.1583\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0336 - mean_squared_error: 0.0690\n",
      "Epoch 56: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0336 - mean_squared_error: 0.0690 - val_loss: 0.0785 - val_mean_squared_error: 0.1582\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0333 - mean_squared_error: 0.0685\n",
      "Epoch 57: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0333 - mean_squared_error: 0.0685 - val_loss: 0.0807 - val_mean_squared_error: 0.1626\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0325 - mean_squared_error: 0.0667\n",
      "Epoch 58: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0325 - mean_squared_error: 0.0667 - val_loss: 0.0850 - val_mean_squared_error: 0.1718\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0315 - mean_squared_error: 0.0647\n",
      "Epoch 59: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0315 - mean_squared_error: 0.0647 - val_loss: 0.0755 - val_mean_squared_error: 0.1521\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0306 - mean_squared_error: 0.0630\n",
      "Epoch 60: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0306 - mean_squared_error: 0.0630 - val_loss: 0.0759 - val_mean_squared_error: 0.1531\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0302 - mean_squared_error: 0.0622\n",
      "Epoch 61: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0302 - mean_squared_error: 0.0622 - val_loss: 0.0843 - val_mean_squared_error: 0.1701\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0288 - mean_squared_error: 0.0593\n",
      "Epoch 62: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0288 - mean_squared_error: 0.0593 - val_loss: 0.0825 - val_mean_squared_error: 0.1667\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0285 - mean_squared_error: 0.0589\n",
      "Epoch 63: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0285 - mean_squared_error: 0.0589 - val_loss: 0.0760 - val_mean_squared_error: 0.1533\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0281 - mean_squared_error: 0.0579\n",
      "Epoch 64: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0281 - mean_squared_error: 0.0579 - val_loss: 0.0855 - val_mean_squared_error: 0.1731\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0282 - mean_squared_error: 0.0582\n",
      "Epoch 65: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0282 - mean_squared_error: 0.0582 - val_loss: 0.0842 - val_mean_squared_error: 0.1700\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0273 - mean_squared_error: 0.0563\n",
      "Epoch 66: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0273 - mean_squared_error: 0.0563 - val_loss: 0.0816 - val_mean_squared_error: 0.1646\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0276 - mean_squared_error: 0.0570\n",
      "Epoch 67: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0276 - mean_squared_error: 0.0570 - val_loss: 0.0831 - val_mean_squared_error: 0.1677\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0561\n",
      "Epoch 68: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0271 - mean_squared_error: 0.0561 - val_loss: 0.0853 - val_mean_squared_error: 0.1727\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0271 - mean_squared_error: 0.0559\n",
      "Epoch 69: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0271 - mean_squared_error: 0.0559 - val_loss: 0.0822 - val_mean_squared_error: 0.1657\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0264 - mean_squared_error: 0.0545\n",
      "Epoch 70: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0264 - mean_squared_error: 0.0545 - val_loss: 0.0822 - val_mean_squared_error: 0.1661\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0255 - mean_squared_error: 0.0526\n",
      "Epoch 71: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0255 - mean_squared_error: 0.0526 - val_loss: 0.0932 - val_mean_squared_error: 0.1893\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0253 - mean_squared_error: 0.0523\n",
      "Epoch 72: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0253 - mean_squared_error: 0.0523 - val_loss: 0.0802 - val_mean_squared_error: 0.1621\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0502\n",
      "Epoch 73: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0243 - mean_squared_error: 0.0502 - val_loss: 0.0853 - val_mean_squared_error: 0.1721\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0504\n",
      "Epoch 74: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0243 - mean_squared_error: 0.0504 - val_loss: 0.0947 - val_mean_squared_error: 0.1926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0242 - mean_squared_error: 0.0501\n",
      "Epoch 75: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0242 - mean_squared_error: 0.0501 - val_loss: 0.0886 - val_mean_squared_error: 0.1793\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0233 - mean_squared_error: 0.0484\n",
      "Epoch 76: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0233 - mean_squared_error: 0.0484 - val_loss: 0.0854 - val_mean_squared_error: 0.1729\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0229 - mean_squared_error: 0.0475\n",
      "Epoch 77: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0229 - mean_squared_error: 0.0475 - val_loss: 0.0858 - val_mean_squared_error: 0.1738\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0227 - mean_squared_error: 0.0471\n",
      "Epoch 78: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0227 - mean_squared_error: 0.0471 - val_loss: 0.0819 - val_mean_squared_error: 0.1651\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0228 - mean_squared_error: 0.0473\n",
      "Epoch 79: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0228 - mean_squared_error: 0.0473 - val_loss: 0.0864 - val_mean_squared_error: 0.1748\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0220 - mean_squared_error: 0.0456\n",
      "Epoch 80: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0220 - mean_squared_error: 0.0456 - val_loss: 0.0926 - val_mean_squared_error: 0.1884\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0217 - mean_squared_error: 0.0452\n",
      "Epoch 81: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0217 - mean_squared_error: 0.0452 - val_loss: 0.0877 - val_mean_squared_error: 0.1773\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0209 - mean_squared_error: 0.0437\n",
      "Epoch 82: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0209 - mean_squared_error: 0.0437 - val_loss: 0.0895 - val_mean_squared_error: 0.1809\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0201 - mean_squared_error: 0.0420\n",
      "Epoch 83: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0201 - mean_squared_error: 0.0420 - val_loss: 0.0900 - val_mean_squared_error: 0.1827\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0421\n",
      "Epoch 84: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0202 - mean_squared_error: 0.0421 - val_loss: 0.0858 - val_mean_squared_error: 0.1739\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0206 - mean_squared_error: 0.0430\n",
      "Epoch 85: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0206 - mean_squared_error: 0.0430 - val_loss: 0.0849 - val_mean_squared_error: 0.1714\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0196 - mean_squared_error: 0.0409\n",
      "Epoch 86: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0196 - mean_squared_error: 0.0409 - val_loss: 0.0897 - val_mean_squared_error: 0.1821\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0191 - mean_squared_error: 0.0400\n",
      "Epoch 87: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0191 - mean_squared_error: 0.0400 - val_loss: 0.0977 - val_mean_squared_error: 0.1987\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0396\n",
      "Epoch 88: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0189 - mean_squared_error: 0.0396 - val_loss: 0.0870 - val_mean_squared_error: 0.1768\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0182 - mean_squared_error: 0.0381\n",
      "Epoch 89: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0182 - mean_squared_error: 0.0381 - val_loss: 0.0859 - val_mean_squared_error: 0.1739\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0177 - mean_squared_error: 0.0372\n",
      "Epoch 90: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0177 - mean_squared_error: 0.0372 - val_loss: 0.0929 - val_mean_squared_error: 0.1881\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0173 - mean_squared_error: 0.0363\n",
      "Epoch 91: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0173 - mean_squared_error: 0.0363 - val_loss: 0.0967 - val_mean_squared_error: 0.1966\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0365\n",
      "Epoch 92: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0174 - mean_squared_error: 0.0365 - val_loss: 0.0954 - val_mean_squared_error: 0.1937\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0352\n",
      "Epoch 93: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0168 - mean_squared_error: 0.0352 - val_loss: 0.0923 - val_mean_squared_error: 0.1872\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0342\n",
      "Epoch 94: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0162 - mean_squared_error: 0.0342 - val_loss: 0.0956 - val_mean_squared_error: 0.1946\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0344\n",
      "Epoch 95: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0164 - mean_squared_error: 0.0344 - val_loss: 0.0934 - val_mean_squared_error: 0.1894\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0341\n",
      "Epoch 96: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0162 - mean_squared_error: 0.0341 - val_loss: 0.0944 - val_mean_squared_error: 0.1917\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0342\n",
      "Epoch 97: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0162 - mean_squared_error: 0.0342 - val_loss: 0.0931 - val_mean_squared_error: 0.1889\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0334\n",
      "Epoch 98: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0159 - mean_squared_error: 0.0334 - val_loss: 0.0964 - val_mean_squared_error: 0.1961\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0329\n",
      "Epoch 99: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0155 - mean_squared_error: 0.0329 - val_loss: 0.0958 - val_mean_squared_error: 0.1951\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0321\n",
      "Epoch 100: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0152 - mean_squared_error: 0.0321 - val_loss: 0.0905 - val_mean_squared_error: 0.1836\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0316\n",
      "Epoch 101: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0149 - mean_squared_error: 0.0316 - val_loss: 0.0992 - val_mean_squared_error: 0.2018\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0315\n",
      "Epoch 102: val_loss did not improve from 0.07284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 65s 7s/step - loss: 0.0148 - mean_squared_error: 0.0315 - val_loss: 0.0973 - val_mean_squared_error: 0.1978\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0309\n",
      "Epoch 103: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0146 - mean_squared_error: 0.0309 - val_loss: 0.0932 - val_mean_squared_error: 0.1894\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0302\n",
      "Epoch 104: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0143 - mean_squared_error: 0.0302 - val_loss: 0.0968 - val_mean_squared_error: 0.1967\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0298\n",
      "Epoch 105: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0140 - mean_squared_error: 0.0298 - val_loss: 0.0953 - val_mean_squared_error: 0.1934\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0296\n",
      "Epoch 106: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0139 - mean_squared_error: 0.0296 - val_loss: 0.0957 - val_mean_squared_error: 0.1943\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0295\n",
      "Epoch 107: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0139 - mean_squared_error: 0.0295 - val_loss: 0.0985 - val_mean_squared_error: 0.2001\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0295\n",
      "Epoch 108: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0139 - mean_squared_error: 0.0295 - val_loss: 0.0956 - val_mean_squared_error: 0.1939\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0288\n",
      "Epoch 109: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0135 - mean_squared_error: 0.0288 - val_loss: 0.1016 - val_mean_squared_error: 0.2072\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0283\n",
      "Epoch 110: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0133 - mean_squared_error: 0.0283 - val_loss: 0.0985 - val_mean_squared_error: 0.2000\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0278\n",
      "Epoch 111: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0131 - mean_squared_error: 0.0278 - val_loss: 0.0980 - val_mean_squared_error: 0.1989\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0282\n",
      "Epoch 112: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0132 - mean_squared_error: 0.0282 - val_loss: 0.0976 - val_mean_squared_error: 0.1986\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0276\n",
      "Epoch 113: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0130 - mean_squared_error: 0.0276 - val_loss: 0.1006 - val_mean_squared_error: 0.2046\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0266\n",
      "Epoch 114: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0125 - mean_squared_error: 0.0266 - val_loss: 0.0978 - val_mean_squared_error: 0.1990\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0264\n",
      "Epoch 115: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0123 - mean_squared_error: 0.0264 - val_loss: 0.0993 - val_mean_squared_error: 0.2020\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0262\n",
      "Epoch 116: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0122 - mean_squared_error: 0.0262 - val_loss: 0.1025 - val_mean_squared_error: 0.2082\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0257\n",
      "Epoch 117: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0120 - mean_squared_error: 0.0257 - val_loss: 0.0997 - val_mean_squared_error: 0.2025\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0258\n",
      "Epoch 118: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0120 - mean_squared_error: 0.0258 - val_loss: 0.1019 - val_mean_squared_error: 0.2073\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0251\n",
      "Epoch 119: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0117 - mean_squared_error: 0.0251 - val_loss: 0.1020 - val_mean_squared_error: 0.2075\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0246\n",
      "Epoch 120: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0114 - mean_squared_error: 0.0246 - val_loss: 0.0996 - val_mean_squared_error: 0.2023\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0244\n",
      "Epoch 121: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0114 - mean_squared_error: 0.0244 - val_loss: 0.1022 - val_mean_squared_error: 0.2079\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0242\n",
      "Epoch 122: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0112 - mean_squared_error: 0.0242 - val_loss: 0.1009 - val_mean_squared_error: 0.2050\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0242\n",
      "Epoch 123: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0112 - mean_squared_error: 0.0242 - val_loss: 0.1042 - val_mean_squared_error: 0.2125\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0242\n",
      "Epoch 124: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0112 - mean_squared_error: 0.0242 - val_loss: 0.1001 - val_mean_squared_error: 0.2031\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0241\n",
      "Epoch 125: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0112 - mean_squared_error: 0.0241 - val_loss: 0.1072 - val_mean_squared_error: 0.2188\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0249\n",
      "Epoch 126: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0116 - mean_squared_error: 0.0249 - val_loss: 0.1012 - val_mean_squared_error: 0.2056\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0242\n",
      "Epoch 127: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0113 - mean_squared_error: 0.0242 - val_loss: 0.1069 - val_mean_squared_error: 0.2179\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0235\n",
      "Epoch 128: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0109 - mean_squared_error: 0.0235 - val_loss: 0.1031 - val_mean_squared_error: 0.2099\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0230\n",
      "Epoch 129: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0106 - mean_squared_error: 0.0230 - val_loss: 0.1020 - val_mean_squared_error: 0.2073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0225\n",
      "Epoch 130: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0104 - mean_squared_error: 0.0225 - val_loss: 0.1044 - val_mean_squared_error: 0.2123\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0224\n",
      "Epoch 131: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0103 - mean_squared_error: 0.0224 - val_loss: 0.1026 - val_mean_squared_error: 0.2085\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0222\n",
      "Epoch 132: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0102 - mean_squared_error: 0.0222 - val_loss: 0.1036 - val_mean_squared_error: 0.2110\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0219\n",
      "Epoch 133: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0101 - mean_squared_error: 0.0219 - val_loss: 0.1043 - val_mean_squared_error: 0.2125\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0217\n",
      "Epoch 134: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0099 - mean_squared_error: 0.0217 - val_loss: 0.1056 - val_mean_squared_error: 0.2150\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0216\n",
      "Epoch 135: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0099 - mean_squared_error: 0.0216 - val_loss: 0.1028 - val_mean_squared_error: 0.2094\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0211\n",
      "Epoch 136: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0097 - mean_squared_error: 0.0211 - val_loss: 0.1029 - val_mean_squared_error: 0.2092\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0209\n",
      "Epoch 137: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0095 - mean_squared_error: 0.0209 - val_loss: 0.1048 - val_mean_squared_error: 0.2132\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0206\n",
      "Epoch 138: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0094 - mean_squared_error: 0.0206 - val_loss: 0.1032 - val_mean_squared_error: 0.2097\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0207\n",
      "Epoch 139: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0094 - mean_squared_error: 0.0207 - val_loss: 0.1058 - val_mean_squared_error: 0.2155\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0204\n",
      "Epoch 140: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0093 - mean_squared_error: 0.0204 - val_loss: 0.1042 - val_mean_squared_error: 0.2120\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0205\n",
      "Epoch 141: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0094 - mean_squared_error: 0.0205 - val_loss: 0.1029 - val_mean_squared_error: 0.2088\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0204\n",
      "Epoch 142: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0093 - mean_squared_error: 0.0204 - val_loss: 0.1055 - val_mean_squared_error: 0.2149\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0092 - mean_squared_error: 0.0202\n",
      "Epoch 143: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0092 - mean_squared_error: 0.0202 - val_loss: 0.1047 - val_mean_squared_error: 0.2131\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0091 - mean_squared_error: 0.0200\n",
      "Epoch 144: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0091 - mean_squared_error: 0.0200 - val_loss: 0.1058 - val_mean_squared_error: 0.2158\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0091 - mean_squared_error: 0.0201\n",
      "Epoch 145: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0091 - mean_squared_error: 0.0201 - val_loss: 0.1056 - val_mean_squared_error: 0.2148\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_squared_error: 0.0194\n",
      "Epoch 146: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0088 - mean_squared_error: 0.0194 - val_loss: 0.1078 - val_mean_squared_error: 0.2196\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0192\n",
      "Epoch 147: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0087 - mean_squared_error: 0.0192 - val_loss: 0.1077 - val_mean_squared_error: 0.2192\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0190\n",
      "Epoch 148: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 65s 7s/step - loss: 0.0087 - mean_squared_error: 0.0190 - val_loss: 0.1062 - val_mean_squared_error: 0.2160\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0085 - mean_squared_error: 0.0188\n",
      "Epoch 149: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0085 - mean_squared_error: 0.0188 - val_loss: 0.1087 - val_mean_squared_error: 0.2214\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0084 - mean_squared_error: 0.0186\n",
      "Epoch 150: val_loss did not improve from 0.07284\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0084 - mean_squared_error: 0.0186 - val_loss: 0.1071 - val_mean_squared_error: 0.2180\n",
      "5/5 [==============================] - 16s 523ms/step\n",
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "There are 0 NA values in the dataframe\n",
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  672\n",
      "PREDICT_STEPS :  24\n",
      "Epoch 1/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4059 - mean_squared_error: 0.9181\n",
      "Epoch 1: val_loss improved from inf to 0.27566, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 133s 9s/step - loss: 0.4059 - mean_squared_error: 0.9181 - val_loss: 0.2757 - val_mean_squared_error: 0.5849\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2601 - mean_squared_error: 0.5709\n",
      "Epoch 2: val_loss improved from 0.27566 to 0.15853, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.2601 - mean_squared_error: 0.5709 - val_loss: 0.1585 - val_mean_squared_error: 0.3261\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1489 - mean_squared_error: 0.3103\n",
      "Epoch 3: val_loss improved from 0.15853 to 0.12576, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.1489 - mean_squared_error: 0.3103 - val_loss: 0.1258 - val_mean_squared_error: 0.2555\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1097 - mean_squared_error: 0.2243\n",
      "Epoch 4: val_loss improved from 0.12576 to 0.12411, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 73s 8s/step - loss: 0.1097 - mean_squared_error: 0.2243 - val_loss: 0.1241 - val_mean_squared_error: 0.2532\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1010 - mean_squared_error: 0.2063\n",
      "Epoch 5: val_loss improved from 0.12411 to 0.12259, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.1010 - mean_squared_error: 0.2063 - val_loss: 0.1226 - val_mean_squared_error: 0.2496\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0974 - mean_squared_error: 0.1988\n",
      "Epoch 6: val_loss improved from 0.12259 to 0.11751, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0974 - mean_squared_error: 0.1988 - val_loss: 0.1175 - val_mean_squared_error: 0.2386\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0975 - mean_squared_error: 0.1992\n",
      "Epoch 7: val_loss did not improve from 0.11751\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0975 - mean_squared_error: 0.1992 - val_loss: 0.1181 - val_mean_squared_error: 0.2401\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0936 - mean_squared_error: 0.1913\n",
      "Epoch 8: val_loss did not improve from 0.11751\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0936 - mean_squared_error: 0.1913 - val_loss: 0.1193 - val_mean_squared_error: 0.2433\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0911 - mean_squared_error: 0.1858\n",
      "Epoch 9: val_loss improved from 0.11751 to 0.11428, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0911 - mean_squared_error: 0.1858 - val_loss: 0.1143 - val_mean_squared_error: 0.2325\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0883 - mean_squared_error: 0.1802\n",
      "Epoch 10: val_loss improved from 0.11428 to 0.10909, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0883 - mean_squared_error: 0.1802 - val_loss: 0.1091 - val_mean_squared_error: 0.2223\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0851 - mean_squared_error: 0.1741\n",
      "Epoch 11: val_loss did not improve from 0.10909\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0851 - mean_squared_error: 0.1741 - val_loss: 0.1131 - val_mean_squared_error: 0.2319\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0833 - mean_squared_error: 0.1703\n",
      "Epoch 12: val_loss improved from 0.10909 to 0.10862, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0833 - mean_squared_error: 0.1703 - val_loss: 0.1086 - val_mean_squared_error: 0.2216\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0804 - mean_squared_error: 0.1639\n",
      "Epoch 13: val_loss did not improve from 0.10862\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0804 - mean_squared_error: 0.1639 - val_loss: 0.1143 - val_mean_squared_error: 0.2342\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0783 - mean_squared_error: 0.1600\n",
      "Epoch 14: val_loss did not improve from 0.10862\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0783 - mean_squared_error: 0.1600 - val_loss: 0.1131 - val_mean_squared_error: 0.2314\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0768 - mean_squared_error: 0.1570\n",
      "Epoch 15: val_loss improved from 0.10862 to 0.10449, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0768 - mean_squared_error: 0.1570 - val_loss: 0.1045 - val_mean_squared_error: 0.2125\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0738 - mean_squared_error: 0.1510\n",
      "Epoch 16: val_loss improved from 0.10449 to 0.10066, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0738 - mean_squared_error: 0.1510 - val_loss: 0.1007 - val_mean_squared_error: 0.2053\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0723 - mean_squared_error: 0.1477\n",
      "Epoch 17: val_loss improved from 0.10066 to 0.09440, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0723 - mean_squared_error: 0.1477 - val_loss: 0.0944 - val_mean_squared_error: 0.1914\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0714 - mean_squared_error: 0.1457\n",
      "Epoch 18: val_loss did not improve from 0.09440\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0714 - mean_squared_error: 0.1457 - val_loss: 0.0964 - val_mean_squared_error: 0.1954\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0696 - mean_squared_error: 0.1419\n",
      "Epoch 19: val_loss improved from 0.09440 to 0.09359, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0696 - mean_squared_error: 0.1419 - val_loss: 0.0936 - val_mean_squared_error: 0.1904\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0669 - mean_squared_error: 0.1365\n",
      "Epoch 20: val_loss improved from 0.09359 to 0.08633, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0669 - mean_squared_error: 0.1365 - val_loss: 0.0863 - val_mean_squared_error: 0.1750\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0660 - mean_squared_error: 0.1345\n",
      "Epoch 21: val_loss improved from 0.08633 to 0.08528, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0660 - mean_squared_error: 0.1345 - val_loss: 0.0853 - val_mean_squared_error: 0.1730\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0634 - mean_squared_error: 0.1292\n",
      "Epoch 22: val_loss did not improve from 0.08528\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0634 - mean_squared_error: 0.1292 - val_loss: 0.0867 - val_mean_squared_error: 0.1760\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0628 - mean_squared_error: 0.1280\n",
      "Epoch 23: val_loss did not improve from 0.08528\n",
      "9/9 [==============================] - 69s 8s/step - loss: 0.0628 - mean_squared_error: 0.1280 - val_loss: 0.0895 - val_mean_squared_error: 0.1817\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0619 - mean_squared_error: 0.1259\n",
      "Epoch 24: val_loss did not improve from 0.08528\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0619 - mean_squared_error: 0.1259 - val_loss: 0.0957 - val_mean_squared_error: 0.1951\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0613 - mean_squared_error: 0.1249\n",
      "Epoch 25: val_loss improved from 0.08528 to 0.08073, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 70s 8s/step - loss: 0.0613 - mean_squared_error: 0.1249 - val_loss: 0.0807 - val_mean_squared_error: 0.1633\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0610 - mean_squared_error: 0.1245\n",
      "Epoch 26: val_loss did not improve from 0.08073\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0610 - mean_squared_error: 0.1245 - val_loss: 0.0816 - val_mean_squared_error: 0.1653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0555 - mean_squared_error: 0.1132\n",
      "Epoch 27: val_loss did not improve from 0.08073\n",
      "9/9 [==============================] - 74s 8s/step - loss: 0.0555 - mean_squared_error: 0.1132 - val_loss: 0.0833 - val_mean_squared_error: 0.1688\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0542 - mean_squared_error: 0.1105\n",
      "Epoch 28: val_loss improved from 0.08073 to 0.07965, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 87s 10s/step - loss: 0.0542 - mean_squared_error: 0.1105 - val_loss: 0.0797 - val_mean_squared_error: 0.1612\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0537 - mean_squared_error: 0.1093\n",
      "Epoch 29: val_loss did not improve from 0.07965\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0537 - mean_squared_error: 0.1093 - val_loss: 0.0919 - val_mean_squared_error: 0.1870\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0519 - mean_squared_error: 0.1059\n",
      "Epoch 30: val_loss improved from 0.07965 to 0.07502, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0519 - mean_squared_error: 0.1059 - val_loss: 0.0750 - val_mean_squared_error: 0.1513\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0487 - mean_squared_error: 0.0993\n",
      "Epoch 31: val_loss improved from 0.07502 to 0.07419, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 81s 9s/step - loss: 0.0487 - mean_squared_error: 0.0993 - val_loss: 0.0742 - val_mean_squared_error: 0.1494\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0493 - mean_squared_error: 0.1005\n",
      "Epoch 32: val_loss did not improve from 0.07419\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0493 - mean_squared_error: 0.1005 - val_loss: 0.0749 - val_mean_squared_error: 0.1513\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0494 - mean_squared_error: 0.1006\n",
      "Epoch 33: val_loss did not improve from 0.07419\n",
      "9/9 [==============================] - 70s 8s/step - loss: 0.0494 - mean_squared_error: 0.1006 - val_loss: 0.0768 - val_mean_squared_error: 0.1547\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0476 - mean_squared_error: 0.0970\n",
      "Epoch 34: val_loss did not improve from 0.07419\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0476 - mean_squared_error: 0.0970 - val_loss: 0.0762 - val_mean_squared_error: 0.1534\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0455 - mean_squared_error: 0.0928\n",
      "Epoch 35: val_loss improved from 0.07419 to 0.07043, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 71s 8s/step - loss: 0.0455 - mean_squared_error: 0.0928 - val_loss: 0.0704 - val_mean_squared_error: 0.1418\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0449 - mean_squared_error: 0.0915\n",
      "Epoch 36: val_loss did not improve from 0.07043\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0449 - mean_squared_error: 0.0915 - val_loss: 0.0803 - val_mean_squared_error: 0.1618\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0455 - mean_squared_error: 0.0928\n",
      "Epoch 37: val_loss did not improve from 0.07043\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0455 - mean_squared_error: 0.0928 - val_loss: 0.0778 - val_mean_squared_error: 0.1566\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0445 - mean_squared_error: 0.0908\n",
      "Epoch 38: val_loss did not improve from 0.07043\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0445 - mean_squared_error: 0.0908 - val_loss: 0.0734 - val_mean_squared_error: 0.1477\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0429 - mean_squared_error: 0.0878\n",
      "Epoch 39: val_loss did not improve from 0.07043\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0429 - mean_squared_error: 0.0878 - val_loss: 0.0760 - val_mean_squared_error: 0.1532\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0437 - mean_squared_error: 0.0891\n",
      "Epoch 40: val_loss did not improve from 0.07043\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0437 - mean_squared_error: 0.0891 - val_loss: 0.0768 - val_mean_squared_error: 0.1550\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0433 - mean_squared_error: 0.0886\n",
      "Epoch 41: val_loss did not improve from 0.07043\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0433 - mean_squared_error: 0.0886 - val_loss: 0.0894 - val_mean_squared_error: 0.1805\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0423 - mean_squared_error: 0.0863\n",
      "Epoch 42: val_loss did not improve from 0.07043\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0423 - mean_squared_error: 0.0863 - val_loss: 0.0730 - val_mean_squared_error: 0.1469\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0829\n",
      "Epoch 43: val_loss did not improve from 0.07043\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0405 - mean_squared_error: 0.0829 - val_loss: 0.0724 - val_mean_squared_error: 0.1455\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0397 - mean_squared_error: 0.0811\n",
      "Epoch 44: val_loss did not improve from 0.07043\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0397 - mean_squared_error: 0.0811 - val_loss: 0.0747 - val_mean_squared_error: 0.1500\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0800\n",
      "Epoch 45: val_loss did not improve from 0.07043\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0391 - mean_squared_error: 0.0800 - val_loss: 0.0754 - val_mean_squared_error: 0.1514\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0784\n",
      "Epoch 46: val_loss did not improve from 0.07043\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0384 - mean_squared_error: 0.0784 - val_loss: 0.0710 - val_mean_squared_error: 0.1426\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.0789\n",
      "Epoch 47: val_loss did not improve from 0.07043\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0386 - mean_squared_error: 0.0789 - val_loss: 0.0708 - val_mean_squared_error: 0.1421\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0396 - mean_squared_error: 0.0809\n",
      "Epoch 48: val_loss improved from 0.07043 to 0.06962, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0396 - mean_squared_error: 0.0809 - val_loss: 0.0696 - val_mean_squared_error: 0.1399\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0375 - mean_squared_error: 0.0766\n",
      "Epoch 49: val_loss did not improve from 0.06962\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0375 - mean_squared_error: 0.0766 - val_loss: 0.0815 - val_mean_squared_error: 0.1645\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0787\n",
      "Epoch 50: val_loss did not improve from 0.06962\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0384 - mean_squared_error: 0.0787 - val_loss: 0.0765 - val_mean_squared_error: 0.1539\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0376 - mean_squared_error: 0.0770\n",
      "Epoch 51: val_loss did not improve from 0.06962\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0376 - mean_squared_error: 0.0770 - val_loss: 0.0738 - val_mean_squared_error: 0.1483\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0362 - mean_squared_error: 0.0741\n",
      "Epoch 52: val_loss did not improve from 0.06962\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0362 - mean_squared_error: 0.0741 - val_loss: 0.0825 - val_mean_squared_error: 0.1661\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0347 - mean_squared_error: 0.0712\n",
      "Epoch 53: val_loss did not improve from 0.06962\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0347 - mean_squared_error: 0.0712 - val_loss: 0.0779 - val_mean_squared_error: 0.1567\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0335 - mean_squared_error: 0.0687\n",
      "Epoch 54: val_loss did not improve from 0.06962\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0335 - mean_squared_error: 0.0687 - val_loss: 0.0732 - val_mean_squared_error: 0.1472\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0333 - mean_squared_error: 0.0683\n",
      "Epoch 55: val_loss improved from 0.06962 to 0.06923, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0333 - mean_squared_error: 0.0683 - val_loss: 0.0692 - val_mean_squared_error: 0.1389\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0330 - mean_squared_error: 0.0678\n",
      "Epoch 56: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0330 - mean_squared_error: 0.0678 - val_loss: 0.0763 - val_mean_squared_error: 0.1535\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0328 - mean_squared_error: 0.0673\n",
      "Epoch 57: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0328 - mean_squared_error: 0.0673 - val_loss: 0.0792 - val_mean_squared_error: 0.1592\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0317 - mean_squared_error: 0.0650\n",
      "Epoch 58: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0317 - mean_squared_error: 0.0650 - val_loss: 0.0711 - val_mean_squared_error: 0.1429\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0315 - mean_squared_error: 0.0646\n",
      "Epoch 59: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0315 - mean_squared_error: 0.0646 - val_loss: 0.0734 - val_mean_squared_error: 0.1477\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0313 - mean_squared_error: 0.0643\n",
      "Epoch 60: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0313 - mean_squared_error: 0.0643 - val_loss: 0.0794 - val_mean_squared_error: 0.1595\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0313 - mean_squared_error: 0.0641\n",
      "Epoch 61: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0313 - mean_squared_error: 0.0641 - val_loss: 0.0784 - val_mean_squared_error: 0.1578\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0308 - mean_squared_error: 0.0633\n",
      "Epoch 62: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0308 - mean_squared_error: 0.0633 - val_loss: 0.0748 - val_mean_squared_error: 0.1502\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0297 - mean_squared_error: 0.0612\n",
      "Epoch 63: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0297 - mean_squared_error: 0.0612 - val_loss: 0.0753 - val_mean_squared_error: 0.1511\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0291 - mean_squared_error: 0.0600\n",
      "Epoch 64: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0291 - mean_squared_error: 0.0600 - val_loss: 0.0773 - val_mean_squared_error: 0.1553\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0296 - mean_squared_error: 0.0609\n",
      "Epoch 65: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0296 - mean_squared_error: 0.0609 - val_loss: 0.0837 - val_mean_squared_error: 0.1691\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0299 - mean_squared_error: 0.0615\n",
      "Epoch 66: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0299 - mean_squared_error: 0.0615 - val_loss: 0.0763 - val_mean_squared_error: 0.1536\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0290 - mean_squared_error: 0.0599\n",
      "Epoch 67: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0290 - mean_squared_error: 0.0599 - val_loss: 0.0801 - val_mean_squared_error: 0.1610\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0301 - mean_squared_error: 0.0619\n",
      "Epoch 68: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0301 - mean_squared_error: 0.0619 - val_loss: 0.0775 - val_mean_squared_error: 0.1557\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0287 - mean_squared_error: 0.0592\n",
      "Epoch 69: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0287 - mean_squared_error: 0.0592 - val_loss: 0.0736 - val_mean_squared_error: 0.1480\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0274 - mean_squared_error: 0.0565\n",
      "Epoch 70: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0274 - mean_squared_error: 0.0565 - val_loss: 0.0819 - val_mean_squared_error: 0.1654\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0268 - mean_squared_error: 0.0553\n",
      "Epoch 71: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0268 - mean_squared_error: 0.0553 - val_loss: 0.0853 - val_mean_squared_error: 0.1717\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0256 - mean_squared_error: 0.0529\n",
      "Epoch 72: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0256 - mean_squared_error: 0.0529 - val_loss: 0.0824 - val_mean_squared_error: 0.1658\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0519\n",
      "Epoch 73: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0251 - mean_squared_error: 0.0519 - val_loss: 0.0775 - val_mean_squared_error: 0.1556\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0245 - mean_squared_error: 0.0508\n",
      "Epoch 74: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0245 - mean_squared_error: 0.0508 - val_loss: 0.0762 - val_mean_squared_error: 0.1530\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0244 - mean_squared_error: 0.0505\n",
      "Epoch 75: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0244 - mean_squared_error: 0.0505 - val_loss: 0.0787 - val_mean_squared_error: 0.1584\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0240 - mean_squared_error: 0.0498\n",
      "Epoch 76: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0240 - mean_squared_error: 0.0498 - val_loss: 0.0883 - val_mean_squared_error: 0.1785\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0239 - mean_squared_error: 0.0496\n",
      "Epoch 77: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0239 - mean_squared_error: 0.0496 - val_loss: 0.0766 - val_mean_squared_error: 0.1542\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0233 - mean_squared_error: 0.0483\n",
      "Epoch 78: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0233 - mean_squared_error: 0.0483 - val_loss: 0.0808 - val_mean_squared_error: 0.1627\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - ETA: 0s - loss: 0.0230 - mean_squared_error: 0.0478\n",
      "Epoch 79: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0230 - mean_squared_error: 0.0478 - val_loss: 0.0847 - val_mean_squared_error: 0.1704\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0222 - mean_squared_error: 0.0461\n",
      "Epoch 80: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0222 - mean_squared_error: 0.0461 - val_loss: 0.0827 - val_mean_squared_error: 0.1665\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0217 - mean_squared_error: 0.0451\n",
      "Epoch 81: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0217 - mean_squared_error: 0.0451 - val_loss: 0.0796 - val_mean_squared_error: 0.1602\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0212 - mean_squared_error: 0.0442\n",
      "Epoch 82: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0212 - mean_squared_error: 0.0442 - val_loss: 0.0870 - val_mean_squared_error: 0.1752\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0210 - mean_squared_error: 0.0436\n",
      "Epoch 83: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0210 - mean_squared_error: 0.0436 - val_loss: 0.0783 - val_mean_squared_error: 0.1577\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0206 - mean_squared_error: 0.0429\n",
      "Epoch 84: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0206 - mean_squared_error: 0.0429 - val_loss: 0.0828 - val_mean_squared_error: 0.1666\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0203 - mean_squared_error: 0.0423\n",
      "Epoch 85: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0203 - mean_squared_error: 0.0423 - val_loss: 0.0859 - val_mean_squared_error: 0.1733\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0201 - mean_squared_error: 0.0418\n",
      "Epoch 86: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0201 - mean_squared_error: 0.0418 - val_loss: 0.0809 - val_mean_squared_error: 0.1631\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0200 - mean_squared_error: 0.0416\n",
      "Epoch 87: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0200 - mean_squared_error: 0.0416 - val_loss: 0.0856 - val_mean_squared_error: 0.1730\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0421\n",
      "Epoch 88: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0202 - mean_squared_error: 0.0421 - val_loss: 0.0838 - val_mean_squared_error: 0.1690\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0208 - mean_squared_error: 0.0434\n",
      "Epoch 89: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0208 - mean_squared_error: 0.0434 - val_loss: 0.0788 - val_mean_squared_error: 0.1585\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0209 - mean_squared_error: 0.0434\n",
      "Epoch 90: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0209 - mean_squared_error: 0.0434 - val_loss: 0.0866 - val_mean_squared_error: 0.1748\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0197 - mean_squared_error: 0.0411\n",
      "Epoch 91: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0197 - mean_squared_error: 0.0411 - val_loss: 0.0854 - val_mean_squared_error: 0.1724\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.0402\n",
      "Epoch 92: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0192 - mean_squared_error: 0.0402 - val_loss: 0.0888 - val_mean_squared_error: 0.1793\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.0393\n",
      "Epoch 93: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0188 - mean_squared_error: 0.0393 - val_loss: 0.0884 - val_mean_squared_error: 0.1787\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0402\n",
      "Epoch 94: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0193 - mean_squared_error: 0.0402 - val_loss: 0.0795 - val_mean_squared_error: 0.1605\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0183 - mean_squared_error: 0.0383\n",
      "Epoch 95: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0183 - mean_squared_error: 0.0383 - val_loss: 0.0915 - val_mean_squared_error: 0.1845\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0173 - mean_squared_error: 0.0363\n",
      "Epoch 96: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0173 - mean_squared_error: 0.0363 - val_loss: 0.0862 - val_mean_squared_error: 0.1738\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0355\n",
      "Epoch 97: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0169 - mean_squared_error: 0.0355 - val_loss: 0.0855 - val_mean_squared_error: 0.1728\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0342\n",
      "Epoch 98: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0162 - mean_squared_error: 0.0342 - val_loss: 0.0850 - val_mean_squared_error: 0.1720\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0337\n",
      "Epoch 99: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0160 - mean_squared_error: 0.0337 - val_loss: 0.0907 - val_mean_squared_error: 0.1833\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0158 - mean_squared_error: 0.0333\n",
      "Epoch 100: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0158 - mean_squared_error: 0.0333 - val_loss: 0.0846 - val_mean_squared_error: 0.1708\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0337\n",
      "Epoch 101: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0159 - mean_squared_error: 0.0337 - val_loss: 0.0915 - val_mean_squared_error: 0.1852\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0336\n",
      "Epoch 102: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0159 - mean_squared_error: 0.0336 - val_loss: 0.0847 - val_mean_squared_error: 0.1711\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0330\n",
      "Epoch 103: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0157 - mean_squared_error: 0.0330 - val_loss: 0.0917 - val_mean_squared_error: 0.1854\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0326\n",
      "Epoch 104: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 71s 8s/step - loss: 0.0155 - mean_squared_error: 0.0326 - val_loss: 0.0865 - val_mean_squared_error: 0.1749\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0157 - mean_squared_error: 0.0331\n",
      "Epoch 105: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0157 - mean_squared_error: 0.0331 - val_loss: 0.0910 - val_mean_squared_error: 0.1841\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0313\n",
      "Epoch 106: val_loss did not improve from 0.06923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 72s 8s/step - loss: 0.0148 - mean_squared_error: 0.0313 - val_loss: 0.0939 - val_mean_squared_error: 0.1904\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.0318\n",
      "Epoch 107: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0150 - mean_squared_error: 0.0318 - val_loss: 0.0861 - val_mean_squared_error: 0.1740\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0307\n",
      "Epoch 108: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 71s 8s/step - loss: 0.0145 - mean_squared_error: 0.0307 - val_loss: 0.0918 - val_mean_squared_error: 0.1857\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0298\n",
      "Epoch 109: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0140 - mean_squared_error: 0.0298 - val_loss: 0.0888 - val_mean_squared_error: 0.1796\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0295\n",
      "Epoch 110: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0139 - mean_squared_error: 0.0295 - val_loss: 0.0927 - val_mean_squared_error: 0.1874\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0294\n",
      "Epoch 111: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0138 - mean_squared_error: 0.0294 - val_loss: 0.0918 - val_mean_squared_error: 0.1857\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0293\n",
      "Epoch 112: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0137 - mean_squared_error: 0.0293 - val_loss: 0.0880 - val_mean_squared_error: 0.1777\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0284\n",
      "Epoch 113: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0133 - mean_squared_error: 0.0284 - val_loss: 0.0898 - val_mean_squared_error: 0.1815\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0275\n",
      "Epoch 114: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0129 - mean_squared_error: 0.0275 - val_loss: 0.0918 - val_mean_squared_error: 0.1859\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0278\n",
      "Epoch 115: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0130 - mean_squared_error: 0.0278 - val_loss: 0.0907 - val_mean_squared_error: 0.1836\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0270\n",
      "Epoch 116: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0126 - mean_squared_error: 0.0270 - val_loss: 0.0931 - val_mean_squared_error: 0.1884\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0270\n",
      "Epoch 117: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0126 - mean_squared_error: 0.0270 - val_loss: 0.0915 - val_mean_squared_error: 0.1853\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0263\n",
      "Epoch 118: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0123 - mean_squared_error: 0.0263 - val_loss: 0.0904 - val_mean_squared_error: 0.1828\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0257\n",
      "Epoch 119: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0120 - mean_squared_error: 0.0257 - val_loss: 0.0926 - val_mean_squared_error: 0.1875\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0258\n",
      "Epoch 120: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0120 - mean_squared_error: 0.0258 - val_loss: 0.0915 - val_mean_squared_error: 0.1852\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0256\n",
      "Epoch 121: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0120 - mean_squared_error: 0.0256 - val_loss: 0.0930 - val_mean_squared_error: 0.1884\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0255\n",
      "Epoch 122: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0119 - mean_squared_error: 0.0255 - val_loss: 0.0894 - val_mean_squared_error: 0.1807\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0254\n",
      "Epoch 123: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0118 - mean_squared_error: 0.0254 - val_loss: 0.0912 - val_mean_squared_error: 0.1848\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0115 - mean_squared_error: 0.0249\n",
      "Epoch 124: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0115 - mean_squared_error: 0.0249 - val_loss: 0.0949 - val_mean_squared_error: 0.1924\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0115 - mean_squared_error: 0.0247\n",
      "Epoch 125: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0115 - mean_squared_error: 0.0247 - val_loss: 0.0917 - val_mean_squared_error: 0.1858\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0239\n",
      "Epoch 126: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0111 - mean_squared_error: 0.0239 - val_loss: 0.0932 - val_mean_squared_error: 0.1887\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0237\n",
      "Epoch 127: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0110 - mean_squared_error: 0.0237 - val_loss: 0.0947 - val_mean_squared_error: 0.1919\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0233\n",
      "Epoch 128: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0108 - mean_squared_error: 0.0233 - val_loss: 0.0895 - val_mean_squared_error: 0.1811\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0233\n",
      "Epoch 129: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0108 - mean_squared_error: 0.0233 - val_loss: 0.0959 - val_mean_squared_error: 0.1942\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0234\n",
      "Epoch 130: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0108 - mean_squared_error: 0.0234 - val_loss: 0.0896 - val_mean_squared_error: 0.1814\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0236\n",
      "Epoch 131: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0109 - mean_squared_error: 0.0236 - val_loss: 0.0882 - val_mean_squared_error: 0.1785\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0231\n",
      "Epoch 132: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0107 - mean_squared_error: 0.0231 - val_loss: 0.0934 - val_mean_squared_error: 0.1893\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0228\n",
      "Epoch 133: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0105 - mean_squared_error: 0.0228 - val_loss: 0.0917 - val_mean_squared_error: 0.1857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0226\n",
      "Epoch 134: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 71s 8s/step - loss: 0.0105 - mean_squared_error: 0.0226 - val_loss: 0.0948 - val_mean_squared_error: 0.1923\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0225\n",
      "Epoch 135: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0104 - mean_squared_error: 0.0225 - val_loss: 0.0915 - val_mean_squared_error: 0.1853\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0223\n",
      "Epoch 136: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0103 - mean_squared_error: 0.0223 - val_loss: 0.0940 - val_mean_squared_error: 0.1903\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0222\n",
      "Epoch 137: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0102 - mean_squared_error: 0.0222 - val_loss: 0.0939 - val_mean_squared_error: 0.1906\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0213\n",
      "Epoch 138: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0098 - mean_squared_error: 0.0213 - val_loss: 0.0915 - val_mean_squared_error: 0.1854\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0210\n",
      "Epoch 139: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 73s 8s/step - loss: 0.0097 - mean_squared_error: 0.0210 - val_loss: 0.0926 - val_mean_squared_error: 0.1878\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0210\n",
      "Epoch 140: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0096 - mean_squared_error: 0.0210 - val_loss: 0.0938 - val_mean_squared_error: 0.1901\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0208\n",
      "Epoch 141: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0095 - mean_squared_error: 0.0208 - val_loss: 0.0935 - val_mean_squared_error: 0.1896\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0204\n",
      "Epoch 142: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0093 - mean_squared_error: 0.0204 - val_loss: 0.0919 - val_mean_squared_error: 0.1863\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0207\n",
      "Epoch 143: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0095 - mean_squared_error: 0.0207 - val_loss: 0.0937 - val_mean_squared_error: 0.1900\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0203\n",
      "Epoch 144: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0093 - mean_squared_error: 0.0203 - val_loss: 0.0930 - val_mean_squared_error: 0.1885\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0206\n",
      "Epoch 145: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0094 - mean_squared_error: 0.0206 - val_loss: 0.0935 - val_mean_squared_error: 0.1897\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0091 - mean_squared_error: 0.0200\n",
      "Epoch 146: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0091 - mean_squared_error: 0.0200 - val_loss: 0.0928 - val_mean_squared_error: 0.1880\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0089 - mean_squared_error: 0.0196\n",
      "Epoch 147: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0089 - mean_squared_error: 0.0196 - val_loss: 0.0940 - val_mean_squared_error: 0.1908\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0088 - mean_squared_error: 0.0193\n",
      "Epoch 148: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0088 - mean_squared_error: 0.0193 - val_loss: 0.0911 - val_mean_squared_error: 0.1847\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0192\n",
      "Epoch 149: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 72s 8s/step - loss: 0.0087 - mean_squared_error: 0.0192 - val_loss: 0.0934 - val_mean_squared_error: 0.1892\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0190\n",
      "Epoch 150: val_loss did not improve from 0.06923\n",
      "9/9 [==============================] - 71s 8s/step - loss: 0.0087 - mean_squared_error: 0.0190 - val_loss: 0.0909 - val_mean_squared_error: 0.1840\n",
      "4/4 [==============================] - 13s 870ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEGCAYAAABlxeIAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABAlUlEQVR4nO3dd3hUVfrA8e8bQofQe5DQBCkSICJFEUEFy4p1BQuorCiudX8WUNfFwoq69u5aUNcCC7oW7KAgimDoTaoBAggB6ZB+fn/MnTDJ3Ol98n6eJw8z5965c+Yyc997uhhjUEoppVJinQGllFLxQQOCUkopQAOCUkopiwYEpZRSgAYEpZRSltRYZyBYjRs3NhkZGbHOhlJKJZRFixbtNsY0sduWsAEhIyOD7OzsWGdDKaUSiohs9rRNq4yUUkoBGhCUUkpZfAYEEXlDRHaJyEqXtKkistT6yxGRpVZ6hogcddn2sstreovIChHZICLPiohY6dWt420QkQUikhH+j6mUUsoXf9oQpgDPA287E4wxlzkfi8gTwH6X/TcaYzJtjvMSMBb4GfgcGAZ8AYwB9hpjOojICOBR4DKb1/tUVFREbm4u+fn5wby80qhRowbp6elUrVo11llRSsURnwHBGDPX0127dZf/Z2Cwt2OISAsgzRgz33r+NnABjoAwHJho7TodeF5ExAQxyVJubi5169YlIyMDqwCiKjDGsGfPHnJzc2nbtm2ss6OUiiOhtiGcCuw0xqx3SWsrIktEZI6InGqltQJyXfbJtdKc27YCGGOKcZQ2Gtm9mYiMFZFsEcnOy8tz256fn0+jRo00GHghIjRq1EhLUUopN6EGhJHA+y7PdwDHGWN6An8D3hORNMDuCu0sAXjbVj7RmFeNMVnGmKwmTWy70Wow8IOeI6WUnaDHIYhIKnAR0NuZZowpAAqsx4tEZCNwPI4SQbrLy9OB7dbjXKA1kGsdsx7wR7D5UqFZunUfqSlCt1b1Yp0VpVSUhVJCOAP41RhTVhUkIk1EpIr1uB3QEdhkjNkBHBSRvla7wyjgY+tlnwCjrceXALODaT9Q4XHBCz9y3nPzYp0NpVQM+NPt9H1gPtBJRHJFZIy1aQTlq4sABgLLRWQZjgbiG4wxzrv9ccBrwAZgI44GZYDXgUYisgFHNdP4ED5PQqlTp47HbTk5OXTr1i2KuVFKVXb+9DIa6SH9apu0GcAMD/tnA25XOGNMPnCpr3wopZSKrISdy8iXBz5dxertB8J6zC4t0/jHn7p63H733XfTpk0bbrzxRgAmTpyIiDB37lz27t1LUVERDz/8MMOHDw/offPz8xk3bhzZ2dmkpqby5JNPcvrpp7Nq1SquueYaCgsLKS0tZcaMGbRs2ZI///nP5ObmUlJSwt///ncuuyyoYR1KqUomaQNCLIwYMYLbbrutLCBMmzaNL7/8kttvv520tDR2795N3759Of/88wPq6fPCCy8AsGLFCn799VfOOuss1q1bx8svv8ytt97KFVdcQWFhISUlJXz++ee0bNmSmTNnApC3Zy/GGO1ZpJTyKWkDgrc7+Ujp2bMnu3btYvv27eTl5dGgQQNatGjB7bffzty5c0lJSWHbtm3s3LmT5s2b+33cefPmcfPNNwPQuXNn2rRpw7p16+jXrx+TJk0iNzeXiy66iI4dO9K9e3fuuOMO7r77boaefQ6NO/Sg5EA+zevVjNTHVkolCZ3cLswuueQSpk+fztSpUxkxYgTvvvsueXl5LFq0iKVLl9KsWbOAB4V56nR1+eWX88knn1CzZk2GDh3K7NmzOf7441m0aBHdu3fnvnvv4eWnH+NgQXE4PppSKsklbQkhVkaMGMF1113H7t27mTNnDtOmTaNp06ZUrVqV7777js2bPU5F7tHAgQN59913GTx4MOvWrWPLli106tSJTZs20a5dO2655RY2bdrE8uXL6dy5Mw0bNuTKK6+kavWavPLaGx6G+SmlVHlaQgizrl27cvDgQVq1akWLFi244ooryM7OJisri3fffZfOnTsHfMwbb7yRkpISunfvzmWXXcaUKVOoXr06U6dOpVu3bmRmZvLrr78yatQoVqxYQZ8+fcjMzOSxRx/hulvuiMCnVCq8PlqSS8b4mWzfd5QNuw7y44bdsc5SpSSJOgYsKyvLVFwxbc2aNZxwwgkxylH8OVJYzIZdh6hZtQodm9Utt83TucoY72iMXvfw2VRL1fsFFR1Xvb6AH9bv5vrT2vHKnE0AfHhjf3od1yDGOUs+IrLIGJNlt01/8crW8fd94XV7flEJa3aEt1tvosnde4STJn3L1j+OxDorSWP9zkNlj/84VBjDnFROGhBibMWKFWRmZpb7O/nkk2OdLZ/+77/LOPuZH9h/pCjWWYm6nQfyKSopZfqiXPIOFvDf7K1l24wxHjsBKM/sukXrWYw+bVSOse7du7N06dKY5mHuujwa1q4W0IR22TmOGUmOFBVTj8qz0E5+UQkn/3MWF/dK5/cDRwEocQkAD362mjd/zCFn8rmxymLcW567j4W//cFfTm3ndT8NrNGnAaGSOlJYzPyNe+jXvhGj3lgIoBcxPyzavBeAGYuPLe/xx+FjVRtv/pgT7SwlnPOf/xHAZ0BQ0adVRpXUH4eLGPnvn73u4+0ObeeBAgCmZ+d63CcZXfHaArc0u9Okd7f+e+G7Dcxd577glZ1r3lzIs7PW+95RBSWpA0JRSan+MEPgz6nbulcbVO0DQvTzkage/2pt2ePZv+4qezz2nUVkjJ/JU9+sK0v7bm0eT7o8V8fs2H+UJ79ZF9I1L2kDQnFJKWt2HOD3A9FdKtLblNbR5s/sRaOt6iIVXrsOFrBky95YZyMpPKMlAgAWb9nLJS/9REFxie32G99dzLOz1vPr7weDfo/kDQiljii5R7uuUVTi+Y5hjpeiut7klrd931HbdGNzpvo+MosLX/wp0llSlcgd/11G9ua9bNh1yHb70UL7QBGIpAkIuXuPcOBokVtxqdRL8amopJSS0shc9owx3HnnnXTr1o3u3bszdepUAHbs2MHAgQPJzMykW7du/PDDD5SUlHD11VeX7fvUU0+FNS/FpaV+7berQmlqmkt3Sk/Er3JIcrh7xnLb9M17tNrMH4cKitl/tPJ1Uw6XTXmHAc/Vkc5rXUoIMxsnTS+jG/6ziFt716aguJQaVauQ+vUE2m1d5thY3f5jFhQUkyJQq5qfp6F5dzh7sl+7fvjhhyxdupRly5axe/duTjrpJAYOHMh7773H0KFDuffeeykpKeHIkSMsXbqUbdu2sXLlSgD27dvnX368KCopZdfBArf04pJSVnsYUNbnn7PKPZ/w4QpG9jkOcKy1fFzDWjSsXS3kvCUqTz/EBb/9wV/eyua10e6DP48UFvv//UoCxSWliAhVUspflDblHWLwE3Pc9i8N4IYsvyj0O+Bk9c3qnayzBvWlhHCPljQlhIKiY3fBpaXGvqEPw+HCYkpKS8uK+REqIDBv3jxGjhxJlSpVaNasGaeddhq//PILJ510Em+++SYTJ05kxYoV1K1bl3bt2rFp0yZuvvlmvvzyS9LS0kJ+/61/HCl3N+a8ewj2R3XBCz/yp+fmsSnPvrhaGXi78fp2zc6yaT9cXfLS/AjmKP50uPcLhj091y3dLhj8tGE3d3kodVW08Lc/eODTVSHnL1ld9/axaXycVUqHC4rZvOdwQMdJmlsX54+1pNSwdvdBijLvgUxH2onp9QHHCdqUd4ja1VJpXq9G2cXNuT2cPLX0Dxw4kLlz5zJz5kyuuuoq7rzzTkaNGsWyZcv46quveOGFF5g2bRpvvPFGSO9/qMKU13kHC2iWViPg4xwpLKbL/V8BsG3fUQY/MYe1Dw8r2/7lqt959JITQ8prPHH+v4VrQSFPpbFktt5DHXdFl9t04fVk96EClufuDzZLScVXJyLndPdXvr6AJVv2BTS+KGlKCM667I15hygq8a/OPJIGDhzI1KlTKSkpIS8vj7lz59KnTx82b95M06ZNue666xgzZgyLFy9m9+7dlJaWcvHFF/PQQw+xePHisOenOMhz8r8l293S3piXU/Z4/9Ein/MeJZJzn51Hh3vD+3nu/WiF18Z75Zsx3ktoye5Dl4GQFTsxVGwHdbYhLNmyL+D38RkQROQNEdklIitd0iaKyDYRWWr9neOybYKIbBCRtSIy1CW9t4issLY9K9YtmIhUF5GpVvoCEcnwN/Mbdjm6V81dl8fanX50tbLO2+HCYnYfcq9fD6cLL7yQE088kR49ejB48GAee+wxmjdvzvfff09mZiY9e/ZkxowZ3HrrrWzbto1BgwaRmZnJ1VdfzSOPPBLRvAXino9WuKU9+uWv5Z4XFsc2ABtjeOqbdWwMsTorv6iE1TsOeOxoEGyp4d0FW7R7b4gMply1cGVz70crPW6bu778zUYobQj+VBlNAZ4H3q6Q/pQx5l+uCSLSBRgBdAVaAt+KyPHGmBLgJWAs8DPwOTAM+AIYA+w1xnQQkRHAo4DPVeH3HinkjCfn0q5J7bLWd2+OFhazafexC4Zr/frhgmI25h2iU7O6VK9axeexvDl0yPEeIsLjjz/O448/Xm776NGjGT16tNvrIlEqqCz2HC7kmVnrmZa9lfkThgR9nAW//VH2eMOuQ3RoWod2E2ZyUa90/nVpj0rUnyr+vDp3k99VUcluz+HyXelLKnQrr9igHwifJQRjzFzgD1/7WYYDHxhjCowxvwEbgD4i0gJIM8bMN45K2reBC1xe85b1eDowRPy4Fdux39FF0p9gUFpqOOKlj66ztLBpd2ANMCo+OOtUnd+JcDjjyTnkF5VQamD6IkdxPdQqi/yiEm5+f4nH8QzKs8refuD63Xv0i2Ml9A27DrIojAMgQ2lDuElElltVSs5VLFoBrp3Xc620VtbjiunlXmOMKQb2A43s3lBExopItohkBzJ+YNdB7xeKYivCxkPbQ6KKxBQhizbv5b0FW3zuF+qFuqTUUFpq3EoArhPYhcOsNbv4dNl2+k+ezZgpv4T12LH06bLtTPykfA+gjPEzIzbGRx1zxpNzeen7jeXSQhmHEGxAeAloj6Mfzw7gCSvdLifGS7q317gnGvOqMSbL02o/Bvu56BPxe5lfVEKhhyHqoRHHnP1hHoccibl7Ln7pJ9s2jFDYzW/V/p7PGfvOIrfAUrHeNpxVRrNc5uxJZAXFjlLPlJ9y3Lb96+u17i8IE2MMj3yxhpzdh9mw62DSBx/X756v31rUA4IxZqcxpsQYUwr8G+hjbcoFWrvsmg5st9LTbdLLvUZEUoF6+F9FVc7mfUUUHzng9oPffaiAo2Ea1FJqTFRKEut2HgxpTpKKnL8XYwzFRw6weV94R4waHMXX+Rv3hPW44bTrQD4d7/2Ct+dvdtv27ZqdPkdd54XYESEZe8m8+N1Gj9t+iuC6yL/tPswrczYx6F/fc8aTc3n62+Se8M61Ft3XzVykG5XdiEgLY8wO6+mFgPNW6hPgPRF5EkejckdgoTGmREQOikhfYAEwCnjO5TWjgfnAJcBsE2T9w3ML9nIz0Kb+brcf904vr6uemkKB1VNmzcGaXt9jz+FCjhaWkN7A+37BOFxQjAEKiko4WuRffuwYY9i5r3w12f6qKRzaWZ2C4lIWbz3IcwvCO/GaMYYznnQMSJoxrj+92/i3Fu62fUe57YMlvDbqJOrVCm6hHX+//1uspS4/XrqN0f0z3Lb7mrl15bbEGFNQUmqYvmgrF/dKJ7VKZHuWH8wv9rit0MscWqFaW+FmaXElmkjQ19VRBJZt3RfUsX0GBBF5HxgENBaRXOAfwCARycRxY5gDXO/IqFklItOA1UAx8FerhxHAOBw9lmri6F3k7Oz9OvCOiGzAUTIYEdQnAQ4UlDJpbuB3qH3aNmSh1cPE1yAO52jU3x45J2yDlyoe21Uwi9YMevw7cirMr5PeoCbz7h7Mz5v2MGluTrBZ9Mj1O7p06z6/A8KL323gl5y9zFicy7WntC1LD2RKA3//Hyrull9UUq5TwoQPw1s95fb+FZ4XFJdQPTW0Xm123luwmb9/vIpDBSWMcTmn4WKM4bfdh2nXpI7XUk8k19we927l7ZXn/GX8tNG+BPbRkm18terYLfCCTXs4uZ1ts6wbnwHBGDPSJvl1L/tPAibZpGcD3WzS84FLfeUjkpJtjpSKwQAgd+/RiC4G7zqJYCAFvDxrvqUHP1tdLiAcieD/yeIt+yguKeXuGcv5eKn7wLtIqTh6fO/hIprXC39A2Gutc/37/sj0Zvrvolzumr6cpy/L5PV5v5Wlx3LtkWRZf+JIYTE7DxTQtnHtcunl2xAcH/b7tfaDHV2DAWA7p5knSTNSORTBdGlLxC9gxf7LYT22yzTjBwKY0fJAfjRnvzz2szpcUFK2HGa03Dm9/Lw94W7Yd9q21xEI/v3Dbz72DM4K6/dy29SlETl+MBLx92jn2im/cPq/vve6z0arVPvq3E1+HXPFNv+vbxoQgpSI379S4961Mly+WPl72eNA6o7DMX223RG27TvKx0u3eX9dAG8dqZHthwuKy63JHKote44w1Y9pyyMhlhflSAVXb9btPOg2ZXyoft7koT9NCD8TfwMHaEBIOhX7JLuK5A82nNUFm/IOMfz5eX7vv9NmnMmlL/3ErR8sLdcd0TUABHoBCXTWSH8YA0OemEOvh74J2zEHPv5d2I4VqP8ucg9EeyNYKnXl8UIaQWc9NZd+k2eH7XjeBixGq4OaBgQbRwo995xw8nQB/HjptrKRra72HyliZxSW86w4z1B5JuwN4U6TPl/j8i6hBYdnZq0vKxb746PFx0oCGeNnMn7GcrZbo5a9BapASieRCKbnPz+vbInXo4UlZXNzxTtPX6G7Z7g3yvcMY7DzpaiklINRrYJ0n1guFLd9sNSv/VrVrxnw/GEVe2V5ogGhgvcXbqHL/V/xS473Ow5PX4NbP1jKHf9d5pbeb/IsTv7nLI4WlvDCdxuCnn00FJEtIQT3OruLS8BLAVY4xge/xKbKJFC7XdpdTrj/S854cm7MJwpMZOP+s5juE7+OdTaCkjF+JgtdrjkVb2QOuHTvNcYEPMPwFa/97Nd+GhAqcHY9DHeDo3Mupae/XcfjX63lwyXe67d9+dvUpQEPxvE2n1NYBRAc7ALC16u9jRpxKCoppe8/Z/HFih1e7/RdsxJK2ShaNdTelnyNF9v3Rb6kG4xv1/j+3iSKE+7/0uMA2GAKJf6+RgOCB75+lxW3vzp3I/f9z3c/dmfXw4IQ7wQ/XLKNp79dH9BrRr2xMCqjZQPpteV6MX/g01Xs8LOr5N7Dhfx+IJ/7P/F/FS3X6rIlW/cFdC6idZ2O1vts33eUjPEz+XlT4ON2kunCG2vz1u+2XWc6v6i0bNBfOKql/O24kDQrpkVbxXryf37ure4+vLbF+WyZ8wO4yLhelN/8MYd1/qxr4SKQwO16/b/mzV9o06hWQO+ViF6du5GxA9u7pTsHYr6/cAt9/Ry0pMJr35FCrnx9Af3b259/Z7WRr+rrcNISggd7fHQz9PdO7j8/b+bm95cce10ombJ85DIL5/oAL6DxMp3Ogfwi21XEFvjoLbLrQD7H3/sFz852lI52Hyrw605/zJRfGP7Cj+XSNtsM4PMkloOuQmF3o1JYXFq2tOdXq37nfyFWX1Ym2/YdJSdM0+Q724s8XfCfm70BcL/WRLJaUQOCB6+5jMAMxX3/W8mny46Nhv3d6v2yscJiH8FecM58yn1Bc29ifVnL2X2Yhz5bzU3vLWH0GwvLRio7FfsoHn+56ncKS0r5z8++p8WGYyW5UGcXTfTJNI0xZSvK/W3a0rK+6flFpdw2dSn7j0S3d04klZQ6ptYIp7nr8li5bT8DJs9m0L++D3hNi4+XbiNj/EzbWRGKPIzbsZtBFgIbeRworTKKkSk/5TDx/K5lzw8c9d3V1ZMD+UUUFJX6dedgN9NnNN3wn0XlZnH1p1dNflEJk7/4lb+ddbzt9mleehWF62bqpveiM3dOsF12S0oNX6363XbbNW8u5DtrmoO3ru3Dlyvd9ysoLgGCm1ww3jzx9Vpe/H4jc+4cRJtGtX2/wA+jKiyBWnEaEl8e/8oxFXjewQJaN3RUVW7d6zuoGGOiOkuuBoQgBd3NMgzvXXEswYkBdLVb+3t0Z+xcuW0/6Q1qUr9WNcCmgcyPE/Lf7K1M+SmHFBEyGrvX+3ubkuO/i3K5qm+bgPJsJ5LTfoTD2/NzeODT1bbbvnOZ82b9zoO2Fxi7r/OuA/k0TasRphxGj3Mp1LyDBSEFhJzdh6ldPZUmdauHnCdnJxLXziQXv/STz9ctCXLW0mBplVGUuf4YC4tLyRg/k1fmbPR6YXxlzkbeXXDszr4ghInfUlOi+19+3nPzyn3xK16M/AmQzmmrS0pLmbUmsKqfv/9vZVA9aeLd3sOF5QZh/R7G5UPBMUNmn3/O4rPl0Zv8L9xCLRwO+tf3nDTp25CO8fS36/hwcW5Z1eibPwZWFR3tcSkaEILkT9HeV4+Zw1ax85EvPPdQKi4p5ZEvfi1bvWvCh8t51mpsCkYoC3AHYtHmvbz2g6OeemPeYfYfLeL7tbtYt7N824k/I6edk7St2LbftiHalxGv+jcoJ5H0fOgb+kyaFdRr7cZtVExZtd1RkszOSbx1Bpyf5arXF4TleAEPlLTsPlTA09+u52/Tjg1UzS8K7AJvTHQ7gmiVkRfXTvmFN64+CYBvVu8s1zi890gRtap5P31/fmW+1+3+3MFU3Of9haGNwo1SPHArDvd4IPQRpIu37Av5GIluWvZWalR1TJkd7CqAhTYDnv44UkiTutV9BuhgplCf/Wtsxi0EevH1JNgZeYttGoudN5Lfr/WvpGs8rkAcuDU7DnBCizSv+2gJwYvZVs+UnN2Hue7tbD5xCQgDJs8um+nwaw+NeUU+inv+FPM73ntsiPqmvENe9kxMG3Yl32cKh8Vb9tL9H1+5TQ531/Tl3OLSjdkp1OqRYU//wH+z3efgKvcexnDqY4FPnnftlOxgsxWUbD9mGRj+wo+8OtfzRJCufLUXFhaX2s6GaxtbDeTuPcLVb/7i13tj/F8Aypezn/nB5z4aEPzgacqHnQccX4Kx7yzy+1iujUquDawVu1/aGfzEHL/fx5NlQaz9oKJn+76jPPrlr/zj41UcLCj2OSipsLiUl77f6PcUx94ubnPXe6+O89UlOJEs27rP78Gkvtqgbp+6lKyH3dsaPMQDvlhhfwNpJ9pnXKuMQhBMF8Ef1tsve3dPhJdvVInBuS61nXfm57ilBTrJmS8H8ovYf6So7O72SGEx2/YdpUZqCmk1E69b6u/789m276jfS7ra8VW9M3OFY3n5HfuP0qKe9zXQ56zLo2tL79U2rowJbN2OUGkJwYdNeYd4xUPR0lsdZf9HZvks6rn2ZV4YxeHpKnG4NqL//WP/520K1vDnf+TUx77j/YWOgX/TsnMZMHk2vW3ugBNB/8mzytqz1u886NYeYDeBnDGm3OJK/s471u+R2ZSWGu75aAXz1u8um9rc1R+HC3l45hqbV9szGC592XtbZDhpQPBh8BNzPK67663ReLsf7QMvfh98byFVOditrREKb6VaYygb4VuxN1iicq3lOvOpuVz+b989zr5fm8etLmsTbN3rf0P6lJ9yeG/BFq58fQHnP/+j7xf4EO0ZU3wGBBF5Q0R2ichKl7THReRXEVkuIh+JSH0rPUNEjorIUuvvZZfX9BaRFSKyQUSeFev2WUSqi8hUK32BiGSE/2PGhq/RjJ6mt1XKKZrTYTurPjzJ9WNkbbx64FNH6WrltvIDM5/4eh079h8tN6aj4uyjdv8Fnsr+D35mPzgwWNFuQ/CnhDAFGFYh7RugmzHmRGAdMMFl20ZjTKb1d4NL+kvAWKCj9ec85hhgrzGmA/AU8GjAnyKGJoRQ9x+LZf9UYvE0z00s+Fr8PZ69+WOObfrLczbS75HZnPfcsSVb3QZP2lz97bruRkK0J1X0GRCMMXOBPyqkfW2Mcd7+/gykezuGiLQA0owx843jE74NXGBtHg68ZT2eDgyRcPWzigJnXatSkWI3IVqwEnTS1ohzzny7eMte/v6/leW22Z2zZwJciyRY8VhC8OVawLWrQ1sRWSIic0TkVCutFeBaGZprpTm3bQWwgsx+wHaCcBEZKyLZIhLdjs1KxdB9/1vJ/I3JN/1GPLroxZ/KLVcJ9gFhR5inCvEoyhEhpG6nInIvUAy8ayXtAI4zxuwRkd7A/0SkK5675OJjW/lEY14FXgWo3qKj3uuoSmH6otywNy6r0Ow6GJ2AEOzst8EKOiCIyGjgPGCIVQ2EMaYAKLAeLxKRjcDxOEoErtVK6YCz604u0BrIFZFUoB4VqqiUUuGhd1Hh4RyUGmnhruLLGD/T6/agqoxEZBhwN3C+MeaIS3oTEaliPW6Ho/F4kzFmB3BQRPpa7QOjgI+tl30CjLYeXwLMNom6PJVSKu7tOxLfU5m7ivbgcJ8lBBF5HxgENBaRXOAfOHoVVQe+sdp/f7Z6FA0EHhSRYqAEuMEY47zbH4ejx1JNHG0OznaH14F3RGQDjpLBiLB8MqWUspH54De26Vs8LKlame5OfQYEY8xIm+TXPew7A5jhYVs20M0mPR+41Fc+lFIqkgY+HvjEfZE2N4jp3kOhI5WVUsqLNTuiu8qgq3d+ju6StxoQlKpEtHVOeaMBQalKJJpTYajEowFBceuQjrHOgoqSUNbjVslPA4Ii1WVdzSZ1q8cwJyriEmRWmKcvy4x1FiolDQiVXOuGNctdI2pU1a+EJ7WrVYl1FkL22TL7qdzjzQU9W/neSYWd/voruWZ1a3D1gLYAfHbzKXRsWheA287QaqSK/u+sTrHOQsg2WesdJIJex9WPdRYqHQ0Ildh9557Ai1f0ok71VHImn0u3VvV4ZkQm74zpw21nHE/O5HN9HqNu9cqzCmvF5tiT2zaMST6SXY/0egB8eOMAnr+8Z4xzU7lUyoCgP2SHv5zajqZpNcql1a1RlVM7NvH7GOdntgx3tuJWaYV5BM7q2tzr/toeEySXOsxaSVBNl0gqZUB48Ypesc5CzP1nzMkB7T/weP+DRLIqqdBl0xjDN7cP9Lh/SmK038Yd19N2eqemMctHZVQpA0KVSvRLnXf36bbpxzerE9Bx/j2qdziyk9C6t6rnltaifk2P+w9o3ziS2Ularp0cRIR6NavGLjMJpGcY2lwqZUAQjyuiJp/0BrXsNwR4ClJT7L8qCdKLMSzSapS/MPka43X5ycdFMDfJ66q+bco9b1ynWoxyklg+unFAyMdIioDw6U2nMKpfG987OlWii5gndav7d9flvOuoWKo6rqGHQJPEKo7yNRiv1UKuwbJz87oRylX8eegCtzkseeziE/16bc7kc7moV/kVeXu0rh+ObCk/JEVAaNekdkABobLc1VZsPH/lqmPVPjX9bKx7/7q+LLx3iFv6dae2DS1zCajYZnL6WtXse1md1aUZrkuDX9k3gBuWBGc3XiOtpufeaA+c39Xr8SrTuYu1pAgIBujQtK5f3SSh8hQQ7jnnhHLPu7RIA6CVl3rvimpUrULTujXc0l0vjclYx3tWl2ZuafVrVWXhPUO4un8G4LnK6JbBHXjlqt5Uq+L4eZ3SoXFY6ncThd15Gdq1ORf1sh9sNto6n55Ult9rME6zOnvcd+4JttvfvrZPQMdL6IDgnHKhRqr/H+OHu+wbWZORp6J2OEtIgvDZzaeE74BxwrU05dS+SR2aptWgmvV9s4sHp3ZszM1DOiIidG2ZxoSzO/PUZZk0rF156sHtzouIcFlWa8C+Q8PLV/Zi+g39Ipyz5OO8BoqHH/XA45sw8U9d/D5eQgeEK/u2IWfyuaRW8f9jtG5Yq+zkaR9n5YnrD2zmLacwY9yxi5Vzi92d8OV9jqOq9X0UEa4/rT1N6lanRb2aTLnmJGbeknzBsyJjDMO9jE+xK1EO69aCrIzAxgfZ9fpKJnal1Jb1ypfW69cK741GQgcEb6pW8Xwb7O0Hncya16tB7zYNeOwS/xr4PPnkpvK9GVxvTpKpR+/UsX35YGxfurasR+82Lhcr6zMam3vhYd08D1Yb1KkpXVsm90UMHN+zawa4tzE1snoLnWBVXQJ87WUch5MzOJ+YXq9cN+r0Bv5XfSaiqwdkuKU1q1ejXNV43RqOthlvPztPpQc7CR0QvM3tntGotsdtlaFR+ZQO7n3gq1ZJYca4/vQPsX/8ien1PQbTz24+NaRjxwNnaeDkdo3o266R23Znt2W7cxDIjy+Z3HNOZwDO7NLM40j3Dk3rMmNcf+4791gVxvHNfPe+amRVt2W2rk+dSjRVSmtPXcZtOL+KofZm8xkQROQNEdklIitd0hqKyDcist76t4HLtgkiskFE1orIUJf03iKywtr2rFi/HBGpLiJTrfQFIpLhb+Z9fZl8/TYNhmX/OMvft0sobRsfC4hPX5ZZ9oMNN5FjF8EW9WrQpWWaj1fEn9YNa/J/Zx5f9rxcacBGxe/VF7c6guCjF3cP6H07Ng1scGC86pPRkLED2/PpTafwypWOthfj4Y6hd5sGVEtNYcE9Q/h5gnvvNTutG9bi81tO5b5zu4S9iiSetW5Yi4usWV/TrJJAu8aO78xLV/Ti47+6jztwNjL3aduQ0zs5Hgdyj+JPCWEKMKxC2nhgljGmIzDLeo6IdAFGAF2t17woIs6K+peAsUBH6895zDHAXmNMB+Ap4FF/Mt6hSR2usBn48/51fcsed6tQPL/Y6t/sOjAtmao4PLmgZyvGDmwfseM3qVOdVvVrMtFH98F4JQg3B7BI0LEqR8dF74QWaeRMPpfLTgpsINo3fzstoP3j0cg+rZly7UkAdE+vR4r1g3KtFrrWpvqoWVoNmtdz773mSZeWaWWN+U4VnycjZ2eEmwZ34K1r+/CwNcbj7O4tynUacX4n7xzaiVn/dxrTru/Hm9cE1sMI/AgIxpi5wB8VkocDb1mP3wIucEn/wBhTYIz5DdgA9BGRFkCaMWa+cfyK3q7wGuexpgNDxI9yd81qVWyL541cRjW+M6YPU8ceCxBP/LlHhc9WeYv44WKM44f54/jBDPUx2Vu8smsL8Mb5lalsbVB2MhrVth2LUaNqFdY9fDbXD2zH7WdGZir1u4ZFptQbT5wB1hjH3b+v8UOpVVJo36R8ydN5hfOnE02wIbaZMWYHgPWvcwaqVsBWl/1yrbRW1uOK6eVeY4wpBvYD7hW3gIiMFZFsEcnOy8vzmcn6tapxsk0dsPPOYuzAdlRJ0oAQyN1XpFzaO535EwbHOhs+BXphL2tDCPL9/tSjJWMHtgvy1fElxcvvp1pqChPOOYG6NSIzTqVV/Zr8I4AulYnIeXZtxkQC0K+94/p2YrrvzgoX9mxFszTvM/CGu4XG7tthvKR7e417ojGvAq8CZGVl2e7jPJi3L2qVFClrqS8oTr41Zru3qsf1Ubrg2J3mDk3rsGHXIa4b2I4W9WrSLK06Ow8URCU/wQg4IIRYQnhuZPLM8R+L+6nv7hjEofxiAK4Z0JYHPl0d/UxEyZV92/D16p0eB/UN7dqcZf84y+vg0DpW+0O9mlV9zuMWbEDYKSItjDE7rOqgXVZ6LtDaZb90YLuVnm6T7vqaXBFJBerhXkXlt/ZN6vCXU9qWG+4+sk9rqqfaF5eSsYRwdvfmAY3NCDdn3brzzE6/oT/zN+3hrunLY5ancCprQwi6jHDM/AmD6ffI7JCPEyuxqHJ17TCR7Fo3rMV3dwzyuo+vmQKG92jF/iNFjOhzHB8t2eZ132ADwifAaGCy9e/HLunviciTQEscjccLjTElInJQRPoCC4BRwHMVjjUfuASYbTx1UfBDSopw33nli5GPXOS53723qbBPTK/H8tz9wWYlZryVjqKhrOhnZaN1w1q0bliLDk3r8NHibbzz8+aY5c1OwI2T4rnbaaBa1EvuvvQq9lJSpGyZXF9XBn+6nb6P42LdSURyRWQMjkBwpoisB860nmOMWQVMA1YDXwJ/NcY462TGAa/haGjeCHxhpb8ONBKRDcDfsHosRYvrHc4Npx3riTPzllOYdr0OpQ9K2YWy/Nev13EN4q7u/NYhHXnz6pMCes2xEoKKh/J1jaqJ29vIOZ1HtPgq0fksIRhjRnrYZNuJ2BgzCZhkk54NuM2La4zJBy71lY9ouHtYJ3bsP8oVJ7epFCNKQ+FPIS4RauNudxl/4K+UshJCeELCrw8NI0WEMW/9wg/rd4flmCoxPHJRdxZv2cv6XYfKpXeI0BiV2XecRo0JnrcnbmiNABHhmRE96ZPgay5H8zps916XZDmaixrXTqw1ha/un+HXdAgntnbcLPRIrx+W961RtQrVUlMSchRuIgT9eNWyXg1SUoT//MV9Odv/Rqh2wlNbqpMGBBwjeV++MnGXiKw4QC/WVRnjTmvP+klnU6+We2NXPE8oOPH8rsy723c32dM7NeXnCUM4w2bysVA4uxAmkniIB3YFtWdGZEY9H8FqllaDdQ+fXTZPU42qKTSI0ey4GhBwjOT1NilZvPr8llO54bT2PDS8W7kL7RknxHZhchEpm/GzokZ1EqvU4Ekkxnkk4ncwHtgFhLQEWKPDNdvVUlNobP02YjngUQNCApp39+m8clVvurRMY/zZnUlJkXJTB3tcRzmMwvGdHTcoctNpePPhjf1j8r4qMly7/zaqXY2Jf+rCoOPtJ9iLZ/EwAl4Dgg9X9o2/hdLTG9RymyYi1aX7bI2q0auWCaUf+t0xmnqgWgzHaPjrlsEdbNN1fWF3rhfQG05rz9UD2ibElDQVL/zOQWPeZnGOtPj/ZcRYtSruF9dbrYnQ7CbtipWsjAa+d0pwL13RK6D9/z0qK0I5ibwhJzRj7p3uq/u5zs0VD+Lhwuvr8hnoLLTRUnFgY9UqwphT2jJ9XOxKsBoQfKiaeuwL/9fTHVUct53RkZzJ53J/APOoOF8bqCGd/WsPuMGafnjZ/Yk1nfeLV/QqW+vZ1ZN/7sH3LiM0rx/YjrO7t/B6rD9npZd77tp1z+7iGm9cpxWoWa0KxzVyr/qLZunPH3EQDxje49jqbHb5aVI39u1W9W06WFRcq1xE+Pt5XciMYSlQA4IPrtULdw7tTM7kc8vdFZ1xgu+eJo3rVGNkn+CqnprUre7XvEQpKUL39Hq2PXsiIVyl2nO6t3Dr4fXaqCwu6pVORuPaZLVpwMg+xzHhHMci4tn3nUG7JvZTF9gNelt6/5m8eEWvchdXEZj1f6fxrk13v1hyXXfZ23V2dL82dGpWl5PjoHt0HMQD/nVpD4/fCQhf9+BQ2P3+X786/kqwGhB8OPdEx12pp3rn10Zncd+5J9guyg6OO9vs+84MuqFXJHZ17bHiOoX59HH9eeSiY0X+xnWqc96J9uv1dmhafsGkBrWqUr9WNc6pULIwxjHn1QCbVeViyXUaFW933g8M78ZXfiw9GS4/jR/MnUM78WSF6eOBuCgipKQI53Rz/B9XtylBNapTndn/Fz9rT5zfoyVTrjnJrYQQDxJvJEyUdW6expvXnOT1LuMvp7Zj3c6Dbumj+rXhzqGd3NJP7djY7xGpNaumls2JnqwCvab4s/uLV/RK8NW1yn/Ki3ul8+GS3PJ7ROlr0bJ+Tf56uqOR+2/TlpXPQ3Sy4NNNgztQPTWFEScdmwriuZE9OVzgmBXVbs2GaHI9T38/r0tcVGPZ0YDgh9M7Bdev/8HhbjN1AIE1xJ0UR43FN5zWnraNI9+ltV0T78P2W9mMJnYG3h/uOp0Gtat5HfWbXxT/U54f17D8eX7izz3cFnjq374xP28KemJgv7SIg3U1/FGjahW3Ve/+5KNtIZpOatuQ1LmbKC41Mc+LN1plFCaB/B8P7HisqsLbbKtz7hzk1pC6fGLsGo3Hn925bJnISHSMS29Qk5zJ5/qczvf8Hu5VRs472NYNa/mcAiIR5qlynYG1dxv7m4KbTrfvmhpOtT2cy+6tHOcwni9usfSXU8r3QOzVukHZ9zqeV9rTEkKY+HPXf1lWa6Zmb6V/+2MBIUXA7n71P2NOpk2jYw1lS+8/ExEhLUKrTwUrFheEitN7nxJgW4CvZQhjKb1BTXL3Hi17vuTvZ3rMb0qKsOqBoZQaQ/eJX4ctDx//dQDTF+XSqkFNzjux/A3JsvvPonrVFCZ+sooV2/b7XHClsrrvvC68Nu+3suc1q1Vh0oXdeeiz1bY9juKFBoQwae+ll4PTpAu7cdewTuw7WlSWllajKnsOFwKOeX6OFJYwoEMjTulY/iKX2PXh4VWxVPXa6PjrrRGsmbecyv4jx74fvua08XQHH6xBnZrQo3V9jwPgnL3YBnVqyge/bPVr6cbK6t2/nIwA/a0blmHdmsf99CRaZRQm/pQQUquk0KhO9XL3VO+MOdb1cZy1HoNrCUK5c40HL13RK+765oeiXs2qtuMPosXfADOsW3PWPDiMbq0SIyDE4jsyoEPjsmCQKLSEEEbf3zGI9bsOcd3b2eV6O1TkDB5tGtWiS8tjg7KuG9iOw4UljKlQ/xiPwrUWABwbtHNJ73Qfezq4Bl9fg9VcTb+hH6t3HAgsc5VNAP+t8Vz1VpGvdilf7j+vCw9+lrxrNztpQAijjMa1yWhcm+cv78mQzp4HrFUsS7SqX5NTOzamRtUqjD87scYchKMOuW6Nqqx9eFjE5xjKymhYbhLAZLfygaEUl5SS+eA3fr9GG4ntXXtKW68B4Z0xfTAGDuQXxcVAuGBpQIgATwOnKnLeZP843vcc/MnO18IdyrvrTm3Lv3/4rVyavwvu3Dm0E7l7j/L+wi0xX487kp4b2ZOb318SkWN3bp4Wt2MLAqFtCDGQxL+5qLnjrOP55KYBsc5G3Lj3XP/n1XJ146D2jDutPbed4ejDP7p/m3BmK678qUdLNv7zHN66tk+ssxK3tIQQQxVnO6wsnh3Zk7o1Qvvq3TS4o++dKpl+7Roxf9OegF5zlzUtSrO0GuRMPjcS2YorVVKE0yKwVkLt6slRwg36VykinYCpLkntgPuB+sB1QJ6Vfo8x5nPrNROAMTi63t9ijPnKSu8NTAFqAp8Dt5pwtlrGmWOLtMc4IzFiN7BMhe610Vn8tvsw78zfzF3D3KdMUeG38Z/ncCi/OOZTY4RL0FVGxpi1xphMY0wm0Bs4AnxkbX7Kuc0lGHQBRgBdgWHAiyLiDKsvAWOBjtbfsGDzlUiSISBo9Vf8qF09lW6t6vHoJSeWW6rUdlI6FRZVUiRqMwxHQ7jaEIYAG40xm73sMxz4wBhTYIz5DdgA9BGRFkCaMWa+VSp4G7ggTPlSqtK7qFd6pagOCrf3r/O+GNH1p/melj7RhCsgjADed3l+k4gsF5E3RMQ5EUsrYKvLPrlWWivrccV0NyIyVkSyRSQ7Ly/PbpeEUMvqv921pfvCMEpFyn/GlF//4aKetj+zSuH7OwZ5XX1uzp2D6Ne+ke22i3ulM+fOQUw4+4RIZS9mQq74EpFqwPnABCvpJeAhHENcHgKeAK7Ffv434yXdPdGYV4FXAbKyshK2wqVRnerMGNefE1rU9b1znEqG6q7KxnU6lB/uOp3WDWM3IjrWnGOGnM44oSmTLuzOyf+cBVBuHjGn+RMGU82abSBZhaMl5GxgsTFmJ4DzXwAR+TfwmfU0F3AdvpsObLfS023Sk5qnGSwTjTYhJCZt+6lIaJZWgxnj+lFSar9Hi3ru064nm3BUGY3EpbrIahNwuhBYaT3+BBghItVFpC2OxuOFxpgdwEER6SuOOQlGAR+HIV9KKQ8CWZOjMnCejt5tGtInDpYmjZWQSggiUgs4E7jeJfkxEcnEUe2T49xmjFklItOA1UAx8FdjjHPm53Ec63b6hfWnlIoQDQfl1UyiCRJDEVJAMMYcARpVSLvKy/6TgEk26dmA/fJiKi5V1kF1yaJUG4EAuHVIR56ZtZ7GSdwuEAidukKFRGseEpPGA4dQR8wnGw0ISlVCGhAczunegjrVU7n8ZM/T1VcmGh6VqoS0ZOfQsn5NVj4w1OP24Zkt+eW3P6KYo9jSgKCConeYiS29QfJ3oQyHZ0b0jHUWokqrjFRItPtiYtL/N2VHA4JSSilAA4JSSimLtiGooGgTQmJ6/JITWbFtf6yzoeKUBgQVEq2JTiyXZrXm0iztYqnsaZWRUkopQAOCUkopiwYEpZRSgAYEFSQdmKZU8tGAoEKjrcpKJQ0NCEoppQANCEoppSwaEFRQdIEcpZKPBgQVEtFGBKWShgYEpZRSQIgBQURyRGSFiCwVkWwrraGIfCMi661/G7jsP0FENojIWhEZ6pLe2zrOBhF5VnRuXqWUirpwlBBON8ZkGmOyrOfjgVnGmI7ALOs5ItIFGAF0BYYBL4pIFes1LwFjgY7W37Aw5EtFkI5DUCr5RKLKaDjwlvX4LeACl/QPjDEFxpjfgA1AHxFpAaQZY+YbYwzwtstrVJzTspxSySPUgGCAr0VkkYiMtdKaGWN2AFj/NrXSWwFbXV6ba6W1sh5XTFdKKRVFoU5/PcAYs11EmgLfiMivXva1u5c0XtLdD+AIOmMBjjvuuEDzqpRSyouQSgjGmO3Wv7uAj4A+wE6rGgjr313W7rmA60Ts6cB2Kz3dJt3u/V41xmQZY7KaNGkSStaVUkpVEHRAEJHaIlLX+Rg4C1gJfAKMtnYbDXxsPf4EGCEi1UWkLY7G44VWtdJBEelr9S4a5fIaFee0CUGp5BFKlVEz4COrh2gq8J4x5ksR+QWYJiJjgC3ApQDGmFUiMg1YDRQDfzXGlFjHGgdMAWoCX1h/SimloijogGCM2QT0sEnfAwzx8JpJwCSb9GygW7B5UUopFTodqayCYnQgglJJRwOCComOQ1AqeWhAUEopBWhAUEopZdGAoJRSCgh9pLKqpK44uQ0Lc/ZyzYC2sc6KUipMNCCooDSoXY23r+0T62wopcJIq4yUUkoBGhCUUkpZNCAopZQCNCAopZSyaEBQSikFaEBQSill0YCglFIK0ICglFLKogFBKaUUoAFBKaWURQOCUkopQAOCUkopiwYEpZRSQAgBQURai8h3IrJGRFaJyK1W+kQR2SYiS62/c1xeM0FENojIWhEZ6pLeW0RWWNueFdGFGZVSKtpCmf66GPg/Y8xiEakLLBKRb6xtTxlj/uW6s4h0AUYAXYGWwLcicrwxpgR4CRgL/Ax8DgwDvgghb0oppQIUdAnBGLPDGLPYenwQWAO08vKS4cAHxpgCY8xvwAagj4i0ANKMMfONMQZ4G7gg2HwppZQKTljaEEQkA+gJLLCSbhKR5SLyhog0sNJaAVtdXpZrpbWyHldMt3ufsSKSLSLZeXl54ci6UkopS8gBQUTqADOA24wxB3BU/7QHMoEdwBPOXW1ebrykuyca86oxJssYk9WkSZNQs66UUspFSAFBRKriCAbvGmM+BDDG7DTGlBhjSoF/A851FnOB1i4vTwe2W+npNulKKaWiKJReRgK8Dqwxxjzpkt7CZbcLgZXW40+AESJSXUTaAh2BhcaYHcBBEelrHXMU8HGw+VJKKRWcUHoZDQCuAlaIyFIr7R5gpIhk4qj2yQGuBzDGrBKRacBqHD2U/mr1MAIYB0wBauLoXaQ9jJRSKsrE0bEn8WRlZZns7OxYZ0MppRKKiCwyxmTZbdORykoppQANCEoppSwaEJRSSgEaEJRSSlk0ICillAI0ICillLJoQFBKKQVoQFBKKWXRgKCUUgrQgKCUUsqiAUEppRSgAUEppZRFA4JSSilAA4JSSimLBgSllFKABgSllFIWDQhKKaUADQhKKaUsGhCUUkoBGhCUUkpZ4iYgiMgwEVkrIhtEZHys86OUUpVNXAQEEakCvACcDXQBRopIl9jmSimlKpe4CAhAH2CDMWaTMaYQ+AAYHuM8KaVUpRIvAaEVsNXlea6VVo6IjBWRbBHJzsvLi1rmlFKqMoiXgCA2acYtwZhXjTFZxpisJk2aRCFbSilVecRLQMgFWrs8Twe2xygvSilVKcVLQPgF6CgibUWkGjAC+CTGeVJKqUolNdYZADDGFIvITcBXQBXgDWPMqhhnSymlKpW4CAgAxpjPgc9jnQ+llKqs4qXKSCmlVIxpQFBKKQVoQFBKKWXRgKCUUgoAMcZt/FdCEJGDwNowHrIesD8OjxWJ4zUGdofpWPH+WfXcxcfxwnneIL4/azx/5wA6GWPq2m4xxiTkH5Ad5uO9Go/HitDxwnbuEuCz6rmLg+PF8+81Ap81br9zvo6nVUbHfBqnx4rE8cIp3j+rnrv4OV44xfNnjefz5lUiVxllG2OyYp2PRKTnLnh67oKj5y144T533o6XyCWEV2OdgQSm5y54eu6Co+cteOE+dx6Pl7AlBKWUUuGVyCUEpZRSYaQBQSmlFKABISmISGsR+U5E1ojIKhG51UpvKCLfiMh6698GVnoja/9DIvK8y3HqishSl7/dIvJ0jD5WVITr3FnbRorIChFZLiJfikjjWHymaAjzebvMOmerROSxWHyeaAri3J0pIous79YiERnscqzeVvoGEXlWROwWG/NfOPu36l9s/oAWQC/rcV1gHdAFeAwYb6WPBx61HtcGTgFuAJ73ctxFwMBYf75EOHc4Zg7eBTS2nj8GTIz150uA89YI2AI0sZ6/BQyJ9eeLs3PXE2hpPe4GbHM51kKgH45VJ78Azg4lb1pCSALGmB3GmMXW44PAGhxrUg/H8QPD+vcCa5/Dxph5QL6nY4pIR6Ap8EPkch57YTx3Yv3Vtu7S0kjiVf/CeN7aAeuMMc5F0r8FLo5s7mMriHO3xBjj/C6tAmqISHURaQGkGWPmG0d0eNv5mmBpQEgyIpKB445iAdDMGLMDHF9CHBd4f40EplpftEohlHNnjCkCxgErcASCLsDrkcxvvAjxO7cB6CwiGSKSiuOC1tr7S5JHEOfuYmCJMaYARxDJddmWa6UFTQNCEhGROsAM4DZjzIEQDzcCeD/0XCWGUM+diFTFERB6Ai2B5cCEsGYyDoV63owxe3Gct6k4SqM5QHE48xivAj13ItIVeBS43plks1tIN3AaEJKEdUGaAbxrjPnQSt5pFSux/t3l57F6AKnGmEURyWycCdO5ywQwxmy0SlXTgP6RyXF8CNd3zhjzqTHmZGNMPxwTVq6PVJ7jRaDnTkTSgY+AUcaYjVZyLpDucth0Qqym1ICQBKw669eBNcaYJ102fQKMth6PBj7285AjqSSlgzCeu21AFxFpYj0/E0fdcFIK53dORJpa/zYAbgReC29u40ug505E6gMzgQnGmB+dO1vVSgdFpK91zFH4/xu3F+sWd/0LS6+FU3AUFZcDS62/c3D04JiF445rFtDQ5TU5wB/AIRx3Gl1ctm0COsf6cyXaucPRg2aNdaxPgUax/nwJct7eB1ZbfyNi/dni7dwB9wGHXfZdCjS1tmUBK4GNwPNYs08E+6dTVyillAK0ykgppZRFA4JSSilAA4JSSimLBgSllFKABgSllFIWDQhKRYmIDBKRz2KdD6U80YCglFIK0ICglBsRuVJEFlprQrwiIlWsefyfEJHFIjLLOSJZRDJF5GdrPv+PXOaw7yAi34rIMus17a3D1xGR6SLyq4i865y/XkQmi8hq6zj/itFHV5WcBgSlXIjICcBlwABjTCZQAlyBYz7/xcaYXsAc4B/WS94G7jbGnIhjplNn+rvAC8aYHjjmNNphpfcEbsMxG2o7YICINAQuBLpax3k4kp9RKU80IChV3hCgN/CLiCy1nrcDSnHMyAnwH+AUEakH1DfGzLHS3wIGikhdoJUx5iMAY0y+MeaItc9CY0yuMaYUxxQEGcABHOsEvCYiFwHOfZWKKg0ISpUnwFvGmEzrr5MxZqLNft7mfPG2jGGBy+MSHLPKFgN9cMx+eQHwZWBZVio8NCAoVd4s4BKXGTgbikgbHL+VS6x9LgfmGWP2A3tF5FQr/SpgjnHMbZ8rIhdYx6guIrU8vaE1L349Y8znOKqTMsP+qZTyQ2qsM6BUPDHGrBaR+4CvRSQFKAL+imO2ya4isgjYj6OdARzTFL9sXfA3AddY6VcBr4jIg9YxLvXytnWBj0WkBo7Sxe1h/lhK+UVnO1XKDyJyyBhTJ9b5UCqStMpIKaUUoCUEpZRSFi0hKKWUAjQgKKWUsmhAUEopBWhAUEopZdGAoJRSCoD/B3ptWCi4b1C2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEGCAYAAABlxeIAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABAlUlEQVR4nO3dd3hUVfrA8e8bQofQe5DQBCkSICJFEUEFy4p1BQuorCiudX8WUNfFwoq69u5aUNcCC7oW7KAgimDoTaoBAggB6ZB+fn/MnTDJ3Ol98n6eJw8z5965c+Yyc997uhhjUEoppVJinQGllFLxQQOCUkopQAOCUkopiwYEpZRSgAYEpZRSltRYZyBYjRs3NhkZGbHOhlJKJZRFixbtNsY0sduWsAEhIyOD7OzsWGdDKaUSiohs9rRNq4yUUkoBGhCUUkpZfAYEEXlDRHaJyEqXtKkistT6yxGRpVZ6hogcddn2sstreovIChHZICLPiohY6dWt420QkQUikhH+j6mUUsoXf9oQpgDPA287E4wxlzkfi8gTwH6X/TcaYzJtjvMSMBb4GfgcGAZ8AYwB9hpjOojICOBR4DKb1/tUVFREbm4u+fn5wby80qhRowbp6elUrVo11llRSsURnwHBGDPX0127dZf/Z2Cwt2OISAsgzRgz33r+NnABjoAwHJho7TodeF5ExAQxyVJubi5169YlIyMDqwCiKjDGsGfPHnJzc2nbtm2ss6OUiiOhtiGcCuw0xqx3SWsrIktEZI6InGqltQJyXfbJtdKc27YCGGOKcZQ2Gtm9mYiMFZFsEcnOy8tz256fn0+jRo00GHghIjRq1EhLUUopN6EGhJHA+y7PdwDHGWN6An8D3hORNMDuCu0sAXjbVj7RmFeNMVnGmKwmTWy70Wow8IOeI6WUnaDHIYhIKnAR0NuZZowpAAqsx4tEZCNwPI4SQbrLy9OB7dbjXKA1kGsdsx7wR7D5UqFZunUfqSlCt1b1Yp0VpVSUhVJCOAP41RhTVhUkIk1EpIr1uB3QEdhkjNkBHBSRvla7wyjgY+tlnwCjrceXALODaT9Q4XHBCz9y3nPzYp0NpVQM+NPt9H1gPtBJRHJFZIy1aQTlq4sABgLLRWQZjgbiG4wxzrv9ccBrwAZgI44GZYDXgUYisgFHNdP4ED5PQqlTp47HbTk5OXTr1i2KuVFKVXb+9DIa6SH9apu0GcAMD/tnA25XOGNMPnCpr3wopZSKrISdy8iXBz5dxertB8J6zC4t0/jHn7p63H733XfTpk0bbrzxRgAmTpyIiDB37lz27t1LUVERDz/8MMOHDw/offPz8xk3bhzZ2dmkpqby5JNPcvrpp7Nq1SquueYaCgsLKS0tZcaMGbRs2ZI///nP5ObmUlJSwt///ncuuyyoYR1KqUomaQNCLIwYMYLbbrutLCBMmzaNL7/8kttvv520tDR2795N3759Of/88wPq6fPCCy8AsGLFCn799VfOOuss1q1bx8svv8ytt97KFVdcQWFhISUlJXz++ee0bNmSmTNnApC3Zy/GGO1ZpJTyKWkDgrc7+Ujp2bMnu3btYvv27eTl5dGgQQNatGjB7bffzty5c0lJSWHbtm3s3LmT5s2b+33cefPmcfPNNwPQuXNn2rRpw7p16+jXrx+TJk0iNzeXiy66iI4dO9K9e3fuuOMO7r77boaefQ6NO/Sg5EA+zevVjNTHVkolCZ3cLswuueQSpk+fztSpUxkxYgTvvvsueXl5LFq0iKVLl9KsWbOAB4V56nR1+eWX88knn1CzZk2GDh3K7NmzOf7441m0aBHdu3fnvnvv4eWnH+NgQXE4PppSKsklbQkhVkaMGMF1113H7t27mTNnDtOmTaNp06ZUrVqV7777js2bPU5F7tHAgQN59913GTx4MOvWrWPLli106tSJTZs20a5dO2655RY2bdrE8uXL6dy5Mw0bNuTKK6+kavWavPLaGx6G+SmlVHlaQgizrl27cvDgQVq1akWLFi244ooryM7OJisri3fffZfOnTsHfMwbb7yRkpISunfvzmWXXcaUKVOoXr06U6dOpVu3bmRmZvLrr78yatQoVqxYQZ8+fcjMzOSxRx/hulvuiMCnVCq8PlqSS8b4mWzfd5QNuw7y44bdsc5SpSSJOgYsKyvLVFwxbc2aNZxwwgkxylH8OVJYzIZdh6hZtQodm9Utt83TucoY72iMXvfw2VRL1fsFFR1Xvb6AH9bv5vrT2vHKnE0AfHhjf3od1yDGOUs+IrLIGJNlt01/8crW8fd94XV7flEJa3aEt1tvosnde4STJn3L1j+OxDorSWP9zkNlj/84VBjDnFROGhBibMWKFWRmZpb7O/nkk2OdLZ/+77/LOPuZH9h/pCjWWYm6nQfyKSopZfqiXPIOFvDf7K1l24wxHjsBKM/sukXrWYw+bVSOse7du7N06dKY5mHuujwa1q4W0IR22TmOGUmOFBVTj8qz0E5+UQkn/3MWF/dK5/cDRwEocQkAD362mjd/zCFn8rmxymLcW567j4W//cFfTm3ndT8NrNGnAaGSOlJYzPyNe+jXvhGj3lgIoBcxPyzavBeAGYuPLe/xx+FjVRtv/pgT7SwlnPOf/xHAZ0BQ0adVRpXUH4eLGPnvn73u4+0ObeeBAgCmZ+d63CcZXfHaArc0u9Okd7f+e+G7Dcxd577glZ1r3lzIs7PW+95RBSWpA0JRSan+MEPgz6nbulcbVO0DQvTzkage/2pt2ePZv+4qezz2nUVkjJ/JU9+sK0v7bm0eT7o8V8fs2H+UJ79ZF9I1L2kDQnFJKWt2HOD3A9FdKtLblNbR5s/sRaOt6iIVXrsOFrBky95YZyMpPKMlAgAWb9nLJS/9REFxie32G99dzLOz1vPr7weDfo/kDQiljii5R7uuUVTi+Y5hjpeiut7klrd931HbdGNzpvo+MosLX/wp0llSlcgd/11G9ua9bNh1yHb70UL7QBGIpAkIuXuPcOBokVtxqdRL8amopJSS0shc9owx3HnnnXTr1o3u3bszdepUAHbs2MHAgQPJzMykW7du/PDDD5SUlHD11VeX7fvUU0+FNS/FpaV+7berQmlqmkt3Sk/Er3JIcrh7xnLb9M17tNrMH4cKitl/tPJ1Uw6XTXmHAc/Vkc5rXUoIMxsnTS+jG/6ziFt716aguJQaVauQ+vUE2m1d5thY3f5jFhQUkyJQq5qfp6F5dzh7sl+7fvjhhyxdupRly5axe/duTjrpJAYOHMh7773H0KFDuffeeykpKeHIkSMsXbqUbdu2sXLlSgD27dvnX368KCopZdfBArf04pJSVnsYUNbnn7PKPZ/w4QpG9jkOcKy1fFzDWjSsXS3kvCUqTz/EBb/9wV/eyua10e6DP48UFvv//UoCxSWliAhVUspflDblHWLwE3Pc9i8N4IYsvyj0O+Bk9c3qnayzBvWlhHCPljQlhIKiY3fBpaXGvqEPw+HCYkpKS8uK+REqIDBv3jxGjhxJlSpVaNasGaeddhq//PILJ510Em+++SYTJ05kxYoV1K1bl3bt2rFp0yZuvvlmvvzyS9LS0kJ+/61/HCl3N+a8ewj2R3XBCz/yp+fmsSnPvrhaGXi78fp2zc6yaT9cXfLS/AjmKP50uPcLhj091y3dLhj8tGE3d3kodVW08Lc/eODTVSHnL1ld9/axaXycVUqHC4rZvOdwQMdJmlsX54+1pNSwdvdBijLvgUxH2onp9QHHCdqUd4ja1VJpXq9G2cXNuT2cPLX0Dxw4kLlz5zJz5kyuuuoq7rzzTkaNGsWyZcv46quveOGFF5g2bRpvvPFGSO9/qMKU13kHC2iWViPg4xwpLKbL/V8BsG3fUQY/MYe1Dw8r2/7lqt959JITQ8prPHH+v4VrQSFPpbFktt5DHXdFl9t04fVk96EClufuDzZLScVXJyLndPdXvr6AJVv2BTS+KGlKCM667I15hygq8a/OPJIGDhzI1KlTKSkpIS8vj7lz59KnTx82b95M06ZNue666xgzZgyLFy9m9+7dlJaWcvHFF/PQQw+xePHisOenOMhz8r8l293S3piXU/Z4/9Ein/MeJZJzn51Hh3vD+3nu/WiF18Z75Zsx3ktoye5Dl4GQFTsxVGwHdbYhLNmyL+D38RkQROQNEdklIitd0iaKyDYRWWr9neOybYKIbBCRtSIy1CW9t4issLY9K9YtmIhUF5GpVvoCEcnwN/Mbdjm6V81dl8fanX50tbLO2+HCYnYfcq9fD6cLL7yQE088kR49ejB48GAee+wxmjdvzvfff09mZiY9e/ZkxowZ3HrrrWzbto1BgwaRmZnJ1VdfzSOPPBLRvAXino9WuKU9+uWv5Z4XFsc2ABtjeOqbdWwMsTorv6iE1TsOeOxoEGyp4d0FW7R7b4gMply1cGVz70crPW6bu778zUYobQj+VBlNAZ4H3q6Q/pQx5l+uCSLSBRgBdAVaAt+KyPHGmBLgJWAs8DPwOTAM+AIYA+w1xnQQkRHAo4DPVeH3HinkjCfn0q5J7bLWd2+OFhazafexC4Zr/frhgmI25h2iU7O6VK9axeexvDl0yPEeIsLjjz/O448/Xm776NGjGT16tNvrIlEqqCz2HC7kmVnrmZa9lfkThgR9nAW//VH2eMOuQ3RoWod2E2ZyUa90/nVpj0rUnyr+vDp3k99VUcluz+HyXelLKnQrr9igHwifJQRjzFzgD1/7WYYDHxhjCowxvwEbgD4i0gJIM8bMN45K2reBC1xe85b1eDowRPy4Fdux39FF0p9gUFpqOOKlj66ztLBpd2ANMCo+OOtUnd+JcDjjyTnkF5VQamD6IkdxPdQqi/yiEm5+f4nH8QzKs8refuD63Xv0i2Ml9A27DrIojAMgQ2lDuElElltVSs5VLFoBrp3Xc620VtbjiunlXmOMKQb2A43s3lBExopItohkBzJ+YNdB7xeKYivCxkPbQ6KKxBQhizbv5b0FW3zuF+qFuqTUUFpq3EoArhPYhcOsNbv4dNl2+k+ezZgpv4T12LH06bLtTPykfA+gjPEzIzbGRx1zxpNzeen7jeXSQhmHEGxAeAloj6Mfzw7gCSvdLifGS7q317gnGvOqMSbL02o/Bvu56BPxe5lfVEKhhyHqoRHHnP1hHoccibl7Ln7pJ9s2jFDYzW/V/p7PGfvOIrfAUrHeNpxVRrNc5uxJZAXFjlLPlJ9y3Lb96+u17i8IE2MMj3yxhpzdh9mw62DSBx/X756v31rUA4IxZqcxpsQYUwr8G+hjbcoFWrvsmg5st9LTbdLLvUZEUoF6+F9FVc7mfUUUHzng9oPffaiAo2Ea1FJqTFRKEut2HgxpTpKKnL8XYwzFRw6weV94R4waHMXX+Rv3hPW44bTrQD4d7/2Ct+dvdtv27ZqdPkdd54XYESEZe8m8+N1Gj9t+iuC6yL/tPswrczYx6F/fc8aTc3n62+Se8M61Ft3XzVykG5XdiEgLY8wO6+mFgPNW6hPgPRF5EkejckdgoTGmREQOikhfYAEwCnjO5TWjgfnAJcBsE2T9w3ML9nIz0Kb+brcf904vr6uemkKB1VNmzcGaXt9jz+FCjhaWkN7A+37BOFxQjAEKiko4WuRffuwYY9i5r3w12f6qKRzaWZ2C4lIWbz3IcwvCO/GaMYYznnQMSJoxrj+92/i3Fu62fUe57YMlvDbqJOrVCm6hHX+//1uspS4/XrqN0f0z3Lb7mrl15bbEGFNQUmqYvmgrF/dKJ7VKZHuWH8wv9rit0MscWqFaW+FmaXElmkjQ19VRBJZt3RfUsX0GBBF5HxgENBaRXOAfwCARycRxY5gDXO/IqFklItOA1UAx8FerhxHAOBw9lmri6F3k7Oz9OvCOiGzAUTIYEdQnAQ4UlDJpbuB3qH3aNmSh1cPE1yAO52jU3x45J2yDlyoe21Uwi9YMevw7cirMr5PeoCbz7h7Mz5v2MGluTrBZ9Mj1O7p06z6/A8KL323gl5y9zFicy7WntC1LD2RKA3//Hyrull9UUq5TwoQPw1s95fb+FZ4XFJdQPTW0Xm123luwmb9/vIpDBSWMcTmn4WKM4bfdh2nXpI7XUk8k19we927l7ZXn/GX8tNG+BPbRkm18terYLfCCTXs4uZ1ts6wbnwHBGDPSJvl1L/tPAibZpGcD3WzS84FLfeUjkpJtjpSKwQAgd+/RiC4G7zqJYCAFvDxrvqUHP1tdLiAcieD/yeIt+yguKeXuGcv5eKn7wLtIqTh6fO/hIprXC39A2Gutc/37/sj0Zvrvolzumr6cpy/L5PV5v5Wlx3LtkWRZf+JIYTE7DxTQtnHtcunl2xAcH/b7tfaDHV2DAWA7p5knSTNSORTBdGlLxC9gxf7LYT22yzTjBwKY0fJAfjRnvzz2szpcUFK2HGa03Dm9/Lw94W7Yd9q21xEI/v3Dbz72DM4K6/dy29SlETl+MBLx92jn2im/cPq/vve6z0arVPvq3E1+HXPFNv+vbxoQgpSI379S4961Mly+WPl72eNA6o7DMX223RG27TvKx0u3eX9dAG8dqZHthwuKy63JHKote44w1Y9pyyMhlhflSAVXb9btPOg2ZXyoft7koT9NCD8TfwMHaEBIOhX7JLuK5A82nNUFm/IOMfz5eX7vv9NmnMmlL/3ErR8sLdcd0TUABHoBCXTWSH8YA0OemEOvh74J2zEHPv5d2I4VqP8ucg9EeyNYKnXl8UIaQWc9NZd+k2eH7XjeBixGq4OaBgQbRwo995xw8nQB/HjptrKRra72HyliZxSW86w4z1B5JuwN4U6TPl/j8i6hBYdnZq0vKxb746PFx0oCGeNnMn7GcrZbo5a9BapASieRCKbnPz+vbInXo4UlZXNzxTtPX6G7Z7g3yvcMY7DzpaiklINRrYJ0n1guFLd9sNSv/VrVrxnw/GEVe2V5ogGhgvcXbqHL/V/xS473Ow5PX4NbP1jKHf9d5pbeb/IsTv7nLI4WlvDCdxuCnn00FJEtIQT3OruLS8BLAVY4xge/xKbKJFC7XdpdTrj/S854cm7MJwpMZOP+s5juE7+OdTaCkjF+JgtdrjkVb2QOuHTvNcYEPMPwFa/97Nd+GhAqcHY9DHeDo3Mupae/XcfjX63lwyXe67d9+dvUpQEPxvE2n1NYBRAc7ALC16u9jRpxKCoppe8/Z/HFih1e7/RdsxJK2ShaNdTelnyNF9v3Rb6kG4xv1/j+3iSKE+7/0uMA2GAKJf6+RgOCB75+lxW3vzp3I/f9z3c/dmfXw4IQ7wQ/XLKNp79dH9BrRr2xMCqjZQPpteV6MX/g01Xs8LOr5N7Dhfx+IJ/7P/F/FS3X6rIlW/cFdC6idZ2O1vts33eUjPEz+XlT4ON2kunCG2vz1u+2XWc6v6i0bNBfOKql/O24kDQrpkVbxXryf37ure4+vLbF+WyZ8wO4yLhelN/8MYd1/qxr4SKQwO16/b/mzV9o06hWQO+ViF6du5GxA9u7pTsHYr6/cAt9/Ry0pMJr35FCrnx9Af3b259/Z7WRr+rrcNISggd7fHQz9PdO7j8/b+bm95cce10ombJ85DIL5/oAL6DxMp3Ogfwi21XEFvjoLbLrQD7H3/sFz852lI52Hyrw605/zJRfGP7Cj+XSNtsM4PMkloOuQmF3o1JYXFq2tOdXq37nfyFWX1Ym2/YdJSdM0+Q724s8XfCfm70BcL/WRLJaUQOCB6+5jMAMxX3/W8mny46Nhv3d6v2yscJiH8FecM58yn1Bc29ifVnL2X2Yhz5bzU3vLWH0GwvLRio7FfsoHn+56ncKS0r5z8++p8WGYyW5UGcXTfTJNI0xZSvK/W3a0rK+6flFpdw2dSn7j0S3d04klZQ6ptYIp7nr8li5bT8DJs9m0L++D3hNi4+XbiNj/EzbWRGKPIzbsZtBFgIbeRworTKKkSk/5TDx/K5lzw8c9d3V1ZMD+UUUFJX6dedgN9NnNN3wn0XlZnH1p1dNflEJk7/4lb+ddbzt9mleehWF62bqpveiM3dOsF12S0oNX6363XbbNW8u5DtrmoO3ru3Dlyvd9ysoLgGCm1ww3jzx9Vpe/H4jc+4cRJtGtX2/wA+jKiyBWnEaEl8e/8oxFXjewQJaN3RUVW7d6zuoGGOiOkuuBoQgBd3NMgzvXXEswYkBdLVb+3t0Z+xcuW0/6Q1qUr9WNcCmgcyPE/Lf7K1M+SmHFBEyGrvX+3ubkuO/i3K5qm+bgPJsJ5LTfoTD2/NzeODT1bbbvnOZ82b9zoO2Fxi7r/OuA/k0TasRphxGj3Mp1LyDBSEFhJzdh6ldPZUmdauHnCdnJxLXziQXv/STz9ctCXLW0mBplVGUuf4YC4tLyRg/k1fmbPR6YXxlzkbeXXDszr4ghInfUlOi+19+3nPzyn3xK16M/AmQzmmrS0pLmbUmsKqfv/9vZVA9aeLd3sOF5QZh/R7G5UPBMUNmn3/O4rPl0Zv8L9xCLRwO+tf3nDTp25CO8fS36/hwcW5Z1eibPwZWFR3tcSkaEILkT9HeV4+Zw1ax85EvPPdQKi4p5ZEvfi1bvWvCh8t51mpsCkYoC3AHYtHmvbz2g6OeemPeYfYfLeL7tbtYt7N824k/I6edk7St2LbftiHalxGv+jcoJ5H0fOgb+kyaFdRr7cZtVExZtd1RkszOSbx1Bpyf5arXF4TleAEPlLTsPlTA09+u52/Tjg1UzS8K7AJvTHQ7gmiVkRfXTvmFN64+CYBvVu8s1zi890gRtap5P31/fmW+1+3+3MFU3Of9haGNwo1SPHArDvd4IPQRpIu37Av5GIluWvZWalR1TJkd7CqAhTYDnv44UkiTutV9BuhgplCf/Wtsxi0EevH1JNgZeYttGoudN5Lfr/WvpGs8rkAcuDU7DnBCizSv+2gJwYvZVs+UnN2Hue7tbD5xCQgDJs8um+nwaw+NeUU+inv+FPM73ntsiPqmvENe9kxMG3Yl32cKh8Vb9tL9H1+5TQ531/Tl3OLSjdkp1OqRYU//wH+z3efgKvcexnDqY4FPnnftlOxgsxWUbD9mGRj+wo+8OtfzRJCufLUXFhaX2s6GaxtbDeTuPcLVb/7i13tj/F8Aypezn/nB5z4aEPzgacqHnQccX4Kx7yzy+1iujUquDawVu1/aGfzEHL/fx5NlQaz9oKJn+76jPPrlr/zj41UcLCj2OSipsLiUl77f6PcUx94ubnPXe6+O89UlOJEs27rP78Gkvtqgbp+6lKyH3dsaPMQDvlhhfwNpJ9pnXKuMQhBMF8Ef1tsve3dPhJdvVInBuS61nXfm57ilBTrJmS8H8ovYf6So7O72SGEx2/YdpUZqCmk1E69b6u/789m276jfS7ra8VW9M3OFY3n5HfuP0qKe9zXQ56zLo2tL79U2rowJbN2OUGkJwYdNeYd4xUPR0lsdZf9HZvks6rn2ZV4YxeHpKnG4NqL//WP/520K1vDnf+TUx77j/YWOgX/TsnMZMHk2vW3ugBNB/8mzytqz1u886NYeYDeBnDGm3OJK/s471u+R2ZSWGu75aAXz1u8um9rc1R+HC3l45hqbV9szGC592XtbZDhpQPBh8BNzPK67663ReLsf7QMvfh98byFVOditrREKb6VaYygb4VuxN1iicq3lOvOpuVz+b989zr5fm8etLmsTbN3rf0P6lJ9yeG/BFq58fQHnP/+j7xf4EO0ZU3wGBBF5Q0R2ichKl7THReRXEVkuIh+JSH0rPUNEjorIUuvvZZfX9BaRFSKyQUSeFev2WUSqi8hUK32BiGSE/2PGhq/RjJ6mt1XKKZrTYTurPjzJ9WNkbbx64FNH6WrltvIDM5/4eh079h8tN6aj4uyjdv8Fnsr+D35mPzgwWNFuQ/CnhDAFGFYh7RugmzHmRGAdMMFl20ZjTKb1d4NL+kvAWKCj9ec85hhgrzGmA/AU8GjAnyKGJoRQ9x+LZf9UYvE0z00s+Fr8PZ69+WOObfrLczbS75HZnPfcsSVb3QZP2lz97bruRkK0J1X0GRCMMXOBPyqkfW2Mcd7+/gykezuGiLQA0owx843jE74NXGBtHg68ZT2eDgyRcPWzigJnXatSkWI3IVqwEnTS1ohzzny7eMte/v6/leW22Z2zZwJciyRY8VhC8OVawLWrQ1sRWSIic0TkVCutFeBaGZprpTm3bQWwgsx+wHaCcBEZKyLZIhLdjs1KxdB9/1vJ/I3JN/1GPLroxZ/KLVcJ9gFhR5inCvEoyhEhpG6nInIvUAy8ayXtAI4zxuwRkd7A/0SkK5675OJjW/lEY14FXgWo3qKj3uuoSmH6otywNy6r0Ow6GJ2AEOzst8EKOiCIyGjgPGCIVQ2EMaYAKLAeLxKRjcDxOEoErtVK6YCz604u0BrIFZFUoB4VqqiUUuGhd1Hh4RyUGmnhruLLGD/T6/agqoxEZBhwN3C+MeaIS3oTEaliPW6Ho/F4kzFmB3BQRPpa7QOjgI+tl30CjLYeXwLMNom6PJVSKu7tOxLfU5m7ivbgcJ8lBBF5HxgENBaRXOAfOHoVVQe+sdp/f7Z6FA0EHhSRYqAEuMEY47zbH4ejx1JNHG0OznaH14F3RGQDjpLBiLB8MqWUspH54De26Vs8LKlame5OfQYEY8xIm+TXPew7A5jhYVs20M0mPR+41Fc+lFIqkgY+HvjEfZE2N4jp3kOhI5WVUsqLNTuiu8qgq3d+ju6StxoQlKpEtHVOeaMBQalKJJpTYajEowFBceuQjrHOgoqSUNbjVslPA4Ii1WVdzSZ1q8cwJyriEmRWmKcvy4x1FiolDQiVXOuGNctdI2pU1a+EJ7WrVYl1FkL22TL7qdzjzQU9W/neSYWd/voruWZ1a3D1gLYAfHbzKXRsWheA287QaqSK/u+sTrHOQsg2WesdJIJex9WPdRYqHQ0Ildh9557Ai1f0ok71VHImn0u3VvV4ZkQm74zpw21nHE/O5HN9HqNu9cqzCmvF5tiT2zaMST6SXY/0egB8eOMAnr+8Z4xzU7lUyoCgP2SHv5zajqZpNcql1a1RlVM7NvH7GOdntgx3tuJWaYV5BM7q2tzr/toeEySXOsxaSVBNl0gqZUB48Ypesc5CzP1nzMkB7T/weP+DRLIqqdBl0xjDN7cP9Lh/SmK038Yd19N2eqemMctHZVQpA0KVSvRLnXf36bbpxzerE9Bx/j2qdziyk9C6t6rnltaifk2P+w9o3ziS2Ularp0cRIR6NavGLjMJpGcY2lwqZUAQjyuiJp/0BrXsNwR4ClJT7L8qCdKLMSzSapS/MPka43X5ycdFMDfJ66q+bco9b1ynWoxyklg+unFAyMdIioDw6U2nMKpfG987OlWii5gndav7d9flvOuoWKo6rqGHQJPEKo7yNRiv1UKuwbJz87oRylX8eegCtzkseeziE/16bc7kc7moV/kVeXu0rh+ObCk/JEVAaNekdkABobLc1VZsPH/lqmPVPjX9bKx7/7q+LLx3iFv6dae2DS1zCajYZnL6WtXse1md1aUZrkuDX9k3gBuWBGc3XiOtpufeaA+c39Xr8SrTuYu1pAgIBujQtK5f3SSh8hQQ7jnnhHLPu7RIA6CVl3rvimpUrULTujXc0l0vjclYx3tWl2ZuafVrVWXhPUO4un8G4LnK6JbBHXjlqt5Uq+L4eZ3SoXFY6ncThd15Gdq1ORf1sh9sNto6n55Ult9rME6zOnvcd+4JttvfvrZPQMdL6IDgnHKhRqr/H+OHu+wbWZORp6J2OEtIgvDZzaeE74BxwrU05dS+SR2aptWgmvV9s4sHp3ZszM1DOiIidG2ZxoSzO/PUZZk0rF156sHtzouIcFlWa8C+Q8PLV/Zi+g39Ipyz5OO8BoqHH/XA45sw8U9d/D5eQgeEK/u2IWfyuaRW8f9jtG5Yq+zkaR9n5YnrD2zmLacwY9yxi5Vzi92d8OV9jqOq9X0UEa4/rT1N6lanRb2aTLnmJGbeknzBsyJjDMO9jE+xK1EO69aCrIzAxgfZ9fpKJnal1Jb1ypfW69cK741GQgcEb6pW8Xwb7O0Hncya16tB7zYNeOwS/xr4PPnkpvK9GVxvTpKpR+/UsX35YGxfurasR+82Lhcr6zMam3vhYd08D1Yb1KkpXVsm90UMHN+zawa4tzE1snoLnWBVXQJ87WUch5MzOJ+YXq9cN+r0Bv5XfSaiqwdkuKU1q1ejXNV43RqOthlvPztPpQc7CR0QvM3tntGotsdtlaFR+ZQO7n3gq1ZJYca4/vQPsX/8ien1PQbTz24+NaRjxwNnaeDkdo3o266R23Znt2W7cxDIjy+Z3HNOZwDO7NLM40j3Dk3rMmNcf+4791gVxvHNfPe+amRVt2W2rk+dSjRVSmtPXcZtOL+KofZm8xkQROQNEdklIitd0hqKyDcist76t4HLtgkiskFE1orIUJf03iKywtr2rFi/HBGpLiJTrfQFIpLhb+Z9fZl8/TYNhmX/OMvft0sobRsfC4hPX5ZZ9oMNN5FjF8EW9WrQpWWaj1fEn9YNa/J/Zx5f9rxcacBGxe/VF7c6guCjF3cP6H07Ng1scGC86pPRkLED2/PpTafwypWOthfj4Y6hd5sGVEtNYcE9Q/h5gnvvNTutG9bi81tO5b5zu4S9iiSetW5Yi4usWV/TrJJAu8aO78xLV/Ti47+6jztwNjKf3LYhp3dyPA7kHsWfEsIUYFiFtPHALGNMR2CW9RwR6QKMALpar3lRRJwV9S8BY4GO1p/zmGOAvcaYDsBTwKP+ZLxDkzpcYTPw5/3r+pY97laheH6x1b/ZdWBaMlVxeHJBz1aMHdg+YsdvUqc6rerXZKKP7oPxShBuDmCRoGNVjo6L3gkt0siZfC6XnRTYQLRv/nZaQPvHo5F9WjPl2pMA6J5ejxTrB+VaLXStTfVRs7QaNK/n3nvNky4t08oa850qPk9Gzs4INw3uwFvX9uFha4zH2d1blOs04vxO3jm0E7P+7zSmXt+PN68JrIcR+BEQjDFzgT8qJA8H3rIevwVc4JL+gTGmwBjzG7AB6CMiLYA0Y8x84/gVvV3hNc5jTQeGiB/l7prVqtgWzxu5jGp8Z0wfpo49FiCe+HOPCp+t8hbxw8UYxw/zx/GDGepjsrd4ZdcW4I3zK1PZ2qDsZDSqbTsWo0bVKqx7+GyuH9iO28+MzFTqdw2LTKk3njgDrDGOu39f44dSq6TQvkn5kqfzCudPJ5pgQ2wzY8wOAOtf5wxUrYCtLvvlWmmtrMcV08u9xhhTDOwH3CtuAREZKyLZIpKdl5fnM5P1a1XjZJs6YOedxdiB7aiSpAEhkLuvSLm0dzrzJwyOdTZ8CvTCXtaGEOT7/alHS8YObBfkq+NLipffT7XUFCaccwJ1a0RmnEqr+jX5RwBdKhOR8+zajIkEoF97x/XtxHTfnRUu7NmKZmneZ+ANdwuN3bfDeEn39hr3RGNeBV4FyMrKst3HeTBvX9QqKVLWUl9QnHxrzHZvVY/ro3TBsTvNHZrWYcOuQ1w3sB0t6tWkWVp1dh4oiEp+ghFwQAixhPDcyOSZ4z8W91Pf3TGIQ/nFAFwzoC0PfLo6+pmIkiv7tuHr1Ts9Duob2rU5y/5xltfBoXWs9od6Nav6nMct2ICwU0RaGGN2WNVBu6z0XKC1y37pwHYrPd0m3fU1uSKSCtTDvYrKb+2b1OEvp7QtN9x9ZJ/WVE+1Ly4lYwnh7O7NAxqbEW7OunXnmZ1+Q3/mb9rDXdOXxyxP4VTWhhB0GeGY+RMG0++R2SEfJ1ZiUeXq2mEi2bVuWIvv7hjkdR9fMwUM79GK/UeKGNHnOD5ass3rvsEGhE+A0cBk69+PXdLfE5EngZY4Go8XGmNKROSgiPQFFgCjgOcqHGs+cAkw23jqouCHlBThvvPKFyMfuchzv3tvU2GfmF6P5bn7g81KzHgrHUVDWdHPykbrhrVo3bAWHZrW4aPF23jn580xy5udgBsnxXO300C1qJfcfelV7KWkSNkyub6uDP50O30fx8W6k4jkisgYHIHgTBFZD5xpPccYswqYBqwGvgT+aoxx1smMA17D0dC8EfjCSn8daCQiG4C/YfVYihbXO5wbTjvWE2fmLacw7XodSh+Usgtl+a9fr+MaxF3d+a1DOvLm1ScF9JpjJQQVD+XrGlUTt7eRczqPaPFVovNZQjDGjPSwybYTsTFmEjDJJj0bcJsX1xiTD1zqKx/RcPewTuzYf5QrTm5TKUaUhsKfQlwi1Mbd7jL+wF8pZSWE8ISEXx8aRooIY976hR/W7w7LMVVieOSi7izespf1uw6VS+8QoTEqs+84jRoTPG9P3NAaASLCMyN60ifB11yO5nXY7r0uyXI0FzWunVhrCl/dP8Ov6RBObO24WeiRXj8s71ujahWqpaYk5CjcRAj68aplvRqkpAj/+Yv7crb/jVDthKe2VCcNCDhG8r58ZeIuEVlxgF6sqzLGndae9ZPOpl4t98aueJ5QcOL5XZl3t+9usqd3asrPE4Zwhs3kY6FwdiFMJPEQD+wKas+MyIx6PoLVLK0G6x4+u2yephpVU2gQo9lxNSDgGMnrbVKyePX5Ladyw2nteWh4t3IX2jNOiO3C5CJSNuNnRY3qJFapwZNIjPNIxO9gPLALCGkJsEaHa7arpabQ2PptxHLAowaEBDTv7tN55aredGmZxvizO5OSIuWmDva4jnIYheM7O25Q5KbT8ObDG/vH5H1VZLh2/21UuxoT/9SFQcfbT7AXz+JhBLwGBB+u7Bt/C6WnN6jlNk1Eqkv32RpVo1ctE0o/9LtjNPVAtRiO0fDXLYM72Kbr+sLuXC+gN5zWnqsHtE2IKWkqXvidg8a8zeIcafH/y4ixalXcL663WhOh2U3aFStZGQ1875TgXrqiV0D7/3tUVoRyEnlDTmjG3DvdV/dznZsrHsTDhdfX5TPQWWijpeLAxqpVhDGntGX6uNiVYDUg+FA19dgX/q+nO6o4bjujIzmTz+X+AOZRcb42UEM6+9cecIM1/fCy+xNrOu8Xr+hVttazqyf/3IPvXUZoXj+wHWd3b+H1WH/OSi/33LXrnt3FNd64TitQs1oVjmvkXvUXzdKfP+IgHjC8x7HV2ezy06Ru7Nut6tt0sKi4VrmI8PfzupAZw1KgBgQfXKsX7hzamZzJ55a7KzrjBN89TRrXqcbIPsFVPTWpW92veYlSUoTu6fVse/ZEQrhKted0b+HWw+u1UVlc1CudjMa1yWrTgJF9jmPCOY5FxLPvO4N2TeynLrAb9Lb0/jN58Ype5S6uIjDr/07jXZvufrHkuu6yt+vs6H5t6NSsLifHQffoOIgH/OvSHh6/ExC+7sGhsPv9v351/JVgNSD4cO6JjrtST/XOr43O4r5zT7BdlB0cd7bZ950ZdEOvSOzq2mPFdQrz6eP688hFx4r8jetU57wT7dfr7dC0/IJJDWpVpX6tapxToWRhjGPOqwE2q8rFkus0Kt7uvB8Y3o2v/Fh6Mlx+Gj+YO4d24skK08cDcVFESEkRzunm+D+ublOCalSnOrP/L37Wnji/R0umXHOSWwkhHiTeSJgo69w8jTevOcnrXcZfTm3Hup0H3dJH9WvDnUM7uaWf2rGx3yNSa1ZNLZsTPVkFek3xZ/cXr+iV4Ktrlf+UF/dK58MlueX3iNLXomX9mvz1dEcj99+mLSufh+hkwaebBnegemoKI046NhXEcyN7crjAMSuq3ZoN0eR6nv5+Xpe4qMayowHBD6d3Cq5f/4PD3WbqAAJriDspjhqLbzitPW0bR75La7sm3oftt7IZTewMvD/cdToNalfzOuo3vyj+pzw/rmH58/zEn3u4LfDUv31jft4U9MTAfmkRB+tq+KNG1Spuq979yUfbQjSd1LYhqXM3UVxqYp4Xb7TKKEwC+T8e2PFYVYW32Vbn3DnIrSF1+cTYNRqPP7tz2TKRkegYl96gJjmTz/U5ne/5PdyrjJx3sK0b1vI5BUQizFPlOgNr7zb2NwU3nW7fNTWcans4l91bOc5hPF/cYukvp5TvgdirdYOy73U8r7SnJYQw8eeu/7Ks1kzN3kr/9scCQoqA3f3qf8acTJtGxxrKlt5/JiJCWoRWnwpWLC4IFaf3PiXAtgBfyxDGUnqDmuTuPVr2fMnfz/SY35QUYdUDQyk1hu4Tvw5bHj7+6wCmL8qlVYOanHdi+RuSZfefRfWqKUz8ZBUrtu33ueBKZXXfeV14bd5vZc9rVqvCpAu789Bnq217HMULDQhh0t5LLwenSRd2465hndh3tKgsLa1GVfYcLgQc8/wcKSxhQIdGnNKx/EUusevDw6tiqeq10fHXWyNYM285lf1Hjn0/fM1p4+kOPliDOjWhR+v6HgfAOXuxDerUlA9+2erX0o2V1bt/ORkB+ls3LMO6NY/76Um0yihM/CkhpFZJoVGd6uXuqd4Zc6zr4zhrPQbXEoRy5xoPXrqiV9z1zQ9FvZpVbccfRIu/AWZYt+aseXAY3VolRkCIxXdkQIfGZcEgUWgJIYy+v2MQ63cd4rq3s8v1dqjIGTzaNKpFl5bHBmVdN7AdhwtLGFOh/jEehWstADg2aOeS3uk+9nRwDb6+Bqu5mn5DP1bvOBBY5iqbAP5b47nqrSJf7VK+3H9eFx78LHnXbnbSgBBGGY1rk9G4Ns9f3pMhnT0PWKtYlmhVvyandmxMjapVGH92Yo05CEcdct0aVVn78LCIzzGUldGw3CSAyW7lA0MpLikl88Fv/H6NNhLbu/aUtl4Dwjtj+mAMHMgviouBcMHSgBABngZOVeS8yf5xvO85+JOdr4U7lHfXndqWf//wW7k0fxfcuXNoJ3L3HuX9hVtivh53JD03sic3v78kIsfu3DwtbscWBELbEGIgiX9zUXPHWcfzyU0DYp2NuHHvuf7Pq+XqxkHtGXdae247w9GHf3T/NuHMVlz5U4+WbPznObx1bZ9YZyVuaQkhhirOdlhZPDuyJ3VrhPbVu2lwR987VTL92jVi/qY9Ab3mLmtalGZpNciZfG4kshVXqqQIp0VgrYTa1ZOjhBv0r1JEOgFTXZLaAfcD9YHrgDwr/R5jzOfWayYAY3B0vb/FGPOVld4bmALUBD4HbjXhbLWMM8cWaY9xRmLEbmCZCt1ro7P4bfdh3pm/mbuGuU+ZosJv4z/P4VB+ccynxgiXoKuMjDFrjTGZxphMoDdwBPjI2vyUc5tLMOgCjAC6AsOAF0XEGVZfAsYCHa2/YcHmK5EkQ0DQ6q/4Ubt6Kt1a1ePRS04st1Sp7aR0KiyqpEjUZhiOhnC1IQwBNhpjNnvZZzjwgTGmwBjzG7AB6CMiLYA0Y8x8q1TwNnBBmPKlVKV3Ua/0SlEdFG7vX+d9MaLrT/M9LX2iCVdAGAG87/L8JhFZLiJviIhzIpZWwFaXfXKttFbW44rpbkRkrIhki0h2Xl6e3S4JoZbVf7trS/eFYZSKlP+MKb/+w0U9bX9mlcL3dwzyuvrcnDsH0a99I9ttF/dKZ86dg5hw9gmRyl7MhFzxJSLVgPOBCVbSS8BDOIa4PAQ8AVyL/fxvxku6e6IxrwKvAmRlZSVshUujOtWZMa4/J7So63vnOJUM1V2Vjet0KD/cdTqtG8ZuRHSsOccMOZ1xQlMmXdidk/85C6DcPGJO8ycMppo120CyCkdLyNnAYmPMTgDnvwAi8m/gM+tpLuA6fDcd2G6lp9ukJzVPM1gmGm1CSEza9lOR0CytBjPG9aOk1H6PFvXcp11PNuGoMhqJS3WR1SbgdCGw0nr8CTBCRKqLSFscjccLjTE7gIMi0lcccxKMAj4OQ76UUh4EsiZHZeA8Hb3bNKRPHCxNGishlRBEpBZwJnC9S/JjIpKJo9onx7nNGLNKRKYBq4Fi4K/GGOfMz+M41u30C+tPKRUhGg7Kq5lEEySGIqSAYIw5AjSqkHaVl/0nAZNs0rMB++XFVFyqrIPqkkWpNgIBcOuQjjwzaz2Nk7hdIBA6dYUKidY8JCaNBw6hjphPNhoQlKqENCA4nNO9BXWqp3L5yZ6nq69MNDwqVQlpyc6hZf2arHxgqMftwzNb8stvf0QxR7GlAUEFRe8wE1t6g+TvQhkOz4zoGessRJVWGamQaPfFxKT/b8qOBgSllFKABgSllFIWbUNQQdEmhMT0+CUnsmLb/lhnQ8UpDQgqJFoTnVguzWrNpVnaxVLZ0yojpZRSgAYEpZRSFg0ISimlAA0IKkg6ME2p5KMBQYVGW5WVShoaEJRSSgEaEJRSSlk0IKig6AI5SiUfDQgqJKKNCEolDQ0ISimlgBADgojkiMgKEVkqItlWWkMR+UZE1lv/NnDZf4KIbBCRtSIy1CW9t3WcDSLyrOjcvEopFXXhKCGcbozJNMZkWc/HA7OMMR2BWdZzRKQLMALoCgwDXhSRKtZrXgLGAh2tv2FhyJeKIB2HoFTyiUSV0XDgLevxW8AFLukfGGMKjDG/ARuAPiLSAkgzxsw3xhjgbZfXqDinZTmlkkeoAcEAX4vIIhEZa6U1M8bsALD+bWqltwK2urw210prZT2umK6UUiqKQp3+eoAxZruINAW+EZFfvexrdy9pvKS7H8ARdMYCHHfccYHmVSmllBchlRCMMdutf3cBHwF9gJ1WNRDWv7us3XMB14nY04HtVnq6Tbrd+71qjMkyxmQ1adIklKwrpZSqIOiAICK1RaSu8zFwFrAS+AQYbe02GvjYevwJMEJEqotIWxyNxwutaqWDItLX6l00yuU1Ks5pE4JSySOUKqNmwEdWD9FU4D1jzJci8gswTUTGAFuASwGMMatEZBqwGigG/mqMKbGONQ6YAtQEvrD+lFJKRVHQAcEYswnoYZO+Bxji4TWTgEk26dlAt2DzopRSKnQ6UlkFxehABKWSjgYEFRIdh6BU8tCAoJRSCtCAoJRSyqIBQSmlFBD6SGVVSV1xchsW5uzlmgFtY50VpVSYaEBQQWlQuxpvX9sn1tlQSoWRVhkppZQCNCAopZSyaEBQSikFaEBQSill0YCglFIK0ICglFLKogFBKaUUoAFBKaWURQOCUkopQAOCUkopiwYEpZRSgAYEpZRSFg0ISimlgBACgoi0FpHvRGSNiKwSkVut9Ikisk1Ellp/57i8ZoKIbBCRtSIy1CW9t4issLY9K6ILMyqlVLSFMv11MfB/xpjFIlIXWCQi31jbnjLG/Mt1ZxHpAowAugItgW9F5HhjTAnwEjAW+Bn4HBgGfBFC3pRSSgUo6BKCMWaHMWax9fggsAZo5eUlw4EPjDEFxpjfgA1AHxFpAaQZY+YbYwzwNnBBsPlSSikVnLC0IYhIBtATWGAl3SQiy0XkDRFpYKW1Ara6vCzXSmtlPa6Ybvc+Y0UkW0Sy8/LywpF1pZRSlpADgojUAWYAtxljDuCo/mkPZAI7gCecu9q83HhJd0805lVjTJYxJqtJkyahZl0ppZSLkAKCiFTFEQzeNcZ8CGCM2WmMKTHGlAL/BpzrLOYCrV1eng5st9LTbdKVUkpFUSi9jAR4HVhjjHnSJb2Fy24XAiutx58AI0Skuoi0BToCC40xO4CDItLXOuYo4ONg86WUUio4ofQyGgBcBawQkaVW2j3ASBHJxFHtkwNcD2CMWSUi04DVOHoo/dXqYQQwDpgC1MTRu0h7GCmlVJSJo2NP4snKyjLZ2dmxzoZSSiUUEVlkjMmy26YjlZVSSgEaEJRSSlk0ICillAI0ICillLJoQFBKKQVoQFBKKWXRgKCUUgrQgKCUUsqiAUEppRSgAUEppZRFA4JSSilAA4JSSimLBgSllFKABgSllFIWDQhKKaUADQhKKaUsGhCUUkoBGhCUUkpZNCAopZQCNCAopZSyxE1AEJFhIrJWRDaIyPhY50cppSqbuAgIIlIFeAE4G+gCjBSRLrHNlVJKVS5xERCAPsAGY8wmY0wh8AEwPMZ5UkqpSiVeAkIrYKvL81wrrRwRGSsi2SKSnZeXF7XMKaVUZRAvAUFs0oxbgjGvGmOyjDFZTZo0iUK2lFKq8oiXgJALtHZ5ng5sj1FelFKqUoqXgPAL0FFE2opINWAE8EmM86SUUpVKaqwzAGCMKRaRm4CvgCrAG8aYVTHOllJKVSpxERAAjDGfA5/HOh9KKVVZxUuVkVJKqRjTgKCUUgrQgKCUUsqiAUEppRQAYozb+K+EICIHgbVhPGQ9YH8cHisSx2sM7A7TseL9s+q5i4/jhfO8QXx/1nj+zgF0MsbUtd1ijEnIPyA7zMd7NR6PFaHjhe3cJcBn1XMXB8eL599rBD5r3H7nfB1Pq4yO+TROjxWJ44VTvH9WPXfxc7xwiufPGs/nzatErjLKNsZkxTofiUjPXfD03AVHz1vwwn3uvB0vkUsIr8Y6AwlMz13w9NwFR89b8MJ97jweL2FLCEoppcIrkUsISimlwkgDglJKKUADQlIQkdYi8p2IrBGRVSJyq5XeUES+EZH11r8NrPRG1v6HROR5l+PUFZGlLn+7ReTpGH2sqAjXubO2jRSRFSKyXES+FJHGsfhM0RDm83aZdc5Wichjsfg80RTEuTtTRBZZ361FIjLY5Vi9rfQNIvKsiNgtNua/cPZv1b/Y/AEtgF7W47rAOqAL8Bgw3kofDzxqPa4NnALcADzv5biLgIGx/nyJcO5wzBy8C2hsPX8MmBjrz5cA560RsAVoYj1/CxgS688XZ+euJ9DSetwN2OZyrIVAPxyrTn4BnB1K3rSEkASMMTuMMYutxweBNTjWpB6O4weG9e8F1j6HjTHzgHxPxxSRjkBT4IfI5Tz2wnjuxPqrbd2lpZHEq/6F8by1A9YZY5yLpH8LXBzZ3MdWEOduiTHG+V1aBdQQkeoi0gJIM8bMN47o8LbzNcHSgJBkRCQDxx3FAqCZMWYHOL6EOC7w/hoJTLW+aJVCKOfOGFMEjANW4AgEXYDXI5nfeBHid24D0FlEMkQkFccFrbX3lySPIM7dxcASY0wBjiCS67It10oLmgaEJCIidYAZwG3GmAMhHm4E8H7ouUoMoZ47EamKIyD0BFoCy4EJYc1kHAr1vBlj9uI4b1NxlEZzgOJw5jFeBXruRKQr8ChwvTPJZreQbuA0ICQJ64I0A3jXGPOhlbzTKlZi/bvLz2P1AFKNMYsiktk4E6ZzlwlgjNlolaqmAf0jk+P4EK7vnDHmU2PMycaYfjgmrFwfqTzHi0DPnYikAx8Bo4wxG63kXCDd5bDphFhNqQEhCVh11q8Da4wxT7ps+gQYbT0eDXzs5yFHUklKB2E8d9uALiLSxHp+Jo664aQUzu+ciDS1/m0A3Ai8Ft7cxpdAz52I1AdmAhOMMT86d7aqlQ6KSF/rmKPw/zduL9Yt7voXll4Lp+AoKi4Hllp/5+DowTELxx3XLKChy2tygD+AQzjuNLq4bNsEdI7150q0c4ejB80a61ifAo1i/fkS5Ly9D6y2/kbE+rPF27kD7gMOu+y7FGhqbcsCVgIbgeexZp8I9k+nrlBKKQVolZFSSimLBgSllFKABgSllFIWDQhKKaUADQhKKaUsGhCUihIRGSQin8U6H0p5ogFBKaUUoAFBKTcicqWILLTWhHhFRKpY8/g/ISKLRWSWc0SyiGSKyM/WfP4fucxh30FEvhWRZdZr2luHryMi00XkVxF51zl/vYhMFpHV1nH+FaOPrio5DQhKuRCRE4DLgAHGmEygBLgCx3z+i40xvYA5wD+sl7wN3G2MORHHTKfO9HeBF4wxPXDMabTDSu8J3IZjNtR2wAARaQhcCHS1jvNwJD+jUp5oQFCqvCFAb+AXEVlqPW8HlOKYkRPgP8ApIlIPqG+MmWOlvwUMFJG6QCtjzEcAxph8Y8wRa5+FxphcY0wpjikIMoADONYJeE1ELgKc+yoVVRoQlCpPgLeMMZnWXydjzESb/bzN+eJtGcMCl8clOGaVLQb64Jj98gLgy8CyrFR4aEBQqrxZwCUuM3A2FJE2OH4rl1j7XA7MM8bsB/aKyKlW+lXAHOOY2z5XRC6wjlFdRGp5ekNrXvx6xpjPcVQnZYb9Uynlh9RYZ0CpeGKMWS0i9wFfi0gKUAT8Fcdsk11FZBGwH0c7AzimKX7ZuuBvAq6x0q8CXhGRB61jXOrlbesCH4tIDRyli9vD/LGU8ovOdqqUH0TkkDGmTqzzoVQkaZWRUkopQEsISimlLFpCUEopBWhAUEopZdGAoJRSCtCAoJRSyqIBQSmlFAD/D4B+WCgwO/K4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEGCAYAAABlxeIAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABAlklEQVR4nO3dd3hUVfrA8e8bQofQe5DQBCkSICJFEUEFy4p1BQuorCiudX8WUNfFwoq69u5aUNcCC7oW7KAgimDoTaoBAggB6ZB+fn/MnTDJ3Ol98n6eJw8z5965c+Yyc997uhhjUEoppVJinQGllFLxQQOCUkopQAOCUkopiwYEpZRSgAYEpZRSltRYZyBYjRs3NhkZGbHOhlJKJZRFixbtNsY0sduWsAEhIyOD7OzsWGdDKaUSiohs9rRNq4yUUkoBGhCUUkpZfAYEEXlDRHaJyEqXtKkistT6yxGRpVZ6hogcddn2sstreovIChHZICLPiohY6dWt420QkQUikhH+j6mUUsoXf9oQpgDPA287E4wxlzkfi8gTwH6X/TcaYzJtjvMSMBb4GfgcGAZ8AYwB9hpjOojICOBR4DKb1/tUVFREbm4u+fn5wby80qhRowbp6elUrVo11llRSsURnwHBGDPX0127dZf/Z2Cwt2OISAsgzRgz33r+NnABjoAwHJho7TodeF5ExAQxyVJubi5169YlIyMDqwCiKjDGsGfPHnJzc2nbtm2ss6OUiiOhtiGcCuw0xqx3SWsrIktEZI6InGqltQJyXfbJtdKc27YCGGOKcZQ2Gtm9mYiMFZFsEcnOy8tz256fn0+jRo00GHghIjRq1EhLUUopN6EGhJHA+y7PdwDHGWN6An8D3hORNMDuCu0sAXjbVj7RmFeNMVnGmKwmTWy70Wow8IOeI6WUnaDHIYhIKnAR0NuZZowpAAqsx4tEZCNwPI4SQbrLy9OB7dbjXKA1kGsdsx7wR7D5UqFZunUfqSlCt1b1Yp0VpVSUhVJCOAP41RhTVhUkIk1EpIr1uB3QEdhkjNkBHBSRvla7wyjgY+tlnwCjrceXALODaT9Q4XHBCz9y3nPzYp0NpVQM+NPt9H1gPtBJRHJFZIy1aQTlq4sABgLLRWQZjgbiG4wxzrv9ccBrwAZgI44GZYDXgUYisgFHNdP4ED5PQqlTp47HbTk5OXTr1i2KuVFKVXb+9DIa6SH9apu0GcAMD/tnA25XOGNMPnCpr3wopZSKrISdy8iXBz5dxertB8J6zC4t0/jHn7p63H733XfTpk0bbrzxRgAmTpyIiDB37lz27t1LUVERDz/8MMOHDw/offPz8xk3bhzZ2dmkpqby5JNPcvrpp7Nq1SquueYaCgsLKS0tZcaMGbRs2ZI///nP5ObmUlJSwt///ncuuyyoYR1KqUomaQNCLIwYMYLbbrutLCBMmzaNL7/8kttvv520tDR2795N3759Of/88wPq6fPCCy8AsGLFCn799VfOOuss1q1bx8svv8ytt97KFVdcQWFhISUlJXz++ee0bNmSmTNnApC3Zy/GGO1ZpJTyKWkDgrc7+Ujp2bMnu3btYvv27eTl5dGgQQNatGjB7bffzty5c0lJSWHbtm3s3LmT5s2b+33cefPmcfPNNwPQuXNn2rRpw7p16+jXrx+TJk0iNzeXiy66iI4dO9K9e3fuuOMO7r77boaefQ6NO/Sg5EA+zevVjNTHVkolCZ3cLswuueQSpk+fztSpUxkxYgTvvvsueXl5LFq0iKVLl9KsWbOAB4V56nR1+eWX88knn1CzZk2GDh3K7NmzOf7441m0aBHdu3fnvnvv4eWnH+NgQXE4PppSKsklbQkhVkaMGMF1113H7t27mTNnDtOmTaNp06ZUrVqV7777js2bPU5F7tHAgQN59913GTx4MOvWrWPLli106tSJTZs20a5dO2655RY2bdrE8uXL6dy5Mw0bNuTKK6+kavWavPLaGx6G+SmlVHlaQgizrl27cvDgQVq1akWLFi244ooryM7OJisri3fffZfOnTsHfMwbb7yRkpISunfvzmWXXcaUKVOoXr06U6dOpVu3bmRmZvLrr78yatQoVqxYQZ8+fcjMzOSxRx/hulvuiMCnVCq8PlqSS8b4mWzfd5QNuw7y44bdsc5SpSSJOgYsKyvLVFwxbc2aNZxwwgkxylH8OVJYzIZdh6hZtQodm9Utt83TucoY72iMXvfw2VRL1fsFFR1Xvb6AH9bv5vrT2vHKnE0AfHhjf3od1yDGOUs+IrLIGJNlt01/8crW8fd94XV7flEJa3aEt1tvosnde4STJn3L1j+OxDorSWP9zkNlj/84VBjDnFROGhBibMWKFWRmZpb7O/nkk2OdLZ/+77/LOPuZH9h/pCjWWYm6nQfyKSopZfqiXPIOFvDf7K1l24wxHjsBKM/sukXrWYw+bVSOse7du7N06dKY5mHuujwa1q4W0IR22TmOGUmOFBVTj8qz0E5+UQkn/3MWF/dK5/cDRwEocQkAD362mjd/zCFn8rmxymLcW567j4W//cFfTm3ndT8NrNGnAaGSOlJYzPyNe+jXvhGj3lgIoBcxPyzavBeAGYuPLe/xx+FjVRtv/pgT7SwlnPOf/xHAZ0BQ0adVRpXUH4eLGPnvn73u4+0ObeeBAgCmZ+d63CcZXfHaArc0u9Okd7f+e+G7Dcxd577glZ1r3lzIs7PW+95RBSWpA0JRSan+MEPgz6nbulcbVO0DQvTzkage/2pt2ePZv+4qezz2nUVkjJ/JU9+sK0v7bm0eT7o8V8fs2H+UJ79ZF9I1L2kDQnFJKWt2HOD3A9FdKtLblNbR5s/sRaOt6iIVXrsOFrBky95YZyMpPKMlAgAWb9nLJS/9REFxie32G99dzLOz1vPr7weDfo/kDQiljii5R7uuUVTi+Y5hjpeiut7klrd931HbdGNzpvo+MosLX/wp0llSlcgd/11G9ua9bNh1yHb70UL7QBGIpAkIuXuPcOBokVtxqdRL8amopJSS0shc9owx3HnnnXTr1o3u3bszdepUAHbs2MHAgQPJzMykW7du/PDDD5SUlHD11VeX7fvUU0+FNS/FpaV+7berQmlqmkt3Sk/Er3JIcrh7xnLb9M17tNrMH4cKitl/tPJ1Uw6XTXmHAc/Vkc5rXUoIMxsnTS+jG/6ziFt716aguJQaVauQ+vUE2m1d5thY3f5jFhQUkyJQq5qfp6F5dzh7sl+7fvjhhyxdupRly5axe/duTjrpJAYOHMh7773H0KFDuffeeykpKeHIkSMsXbqUbdu2sXLlSgD27dvnX368KCopZdfBArf04pJSVnsYUNbnn7PKPZ/w4QpG9jkOcKy1fFzDWjSsXS3kvCUqTz/EBb/9wV/eyua10e6DP48UFvv//UoCxSWliAhVUspflDblHWLwE3Pc9i8N4IYsvyj0O+Bk9c3qnayzBvWlhHCPljQlhIKiY3fBpaXGvqEPw+HCYkpKS8uK+REqIDBv3jxGjhxJlSpVaNasGaeddhq//PILJ510Em+++SYTJ05kxYoV1K1bl3bt2rFp0yZuvvlmvvzyS9LS0kJ+/61/HCl3N+a8ewj2R3XBCz/yp+fmsSnPvrhaGXi78fp2zc6yaT9cXfLS/AjmKP50uPcLhj091y3dLhj8tGE3d3kodVW08Lc/eODTVSHnL1ld9/axaXycVUqHC4rZvOdwQMdJmlsX54+1pNSwdvdBijLvgUxH2onp9QHHCdqUd4ja1VJpXq9G2cXNuT2cPLX0Dxw4kLlz5zJz5kyuuuoq7rzzTkaNGsWyZcv46quveOGFF5g2bRpvvPFGSO9/qMKU13kHC2iWViPg4xwpLKbL/V8BsG3fUQY/MYe1Dw8r2/7lqt959JITQ8prPHH+v4VrQSFPpbFktt5DHXdFl9t04fVk96EClufuDzZLScVXJyLndPdXvr6AJVv2BTS+KGlKCM667I15hygq8a/OPJIGDhzI1KlTKSkpIS8vj7lz59KnTx82b95M06ZNue666xgzZgyLFy9m9+7dlJaWcvHFF/PQQw+xePHisOenOMhz8r8l293S3piXU/Z4/9Ein/MeJZJzn51Hh3vD+3nu/WiF18Z75Zsx3ktoye5Dl4GQFTsxVGwHdbYhLNmyL+D38RkQROQNEdklIitd0iaKyDYRWWr9neOybYKIbBCRtSIy1CW9t4issLY9K9YtmIhUF5GpVvoCEcnwN/Mbdjm6V81dl8fanX50tbLO2+HCYnYfcq9fD6cLL7yQE088kR49ejB48GAee+wxmjdvzvfff09mZiY9e/ZkxowZ3HrrrWzbto1BgwaRmZnJ1VdfzSOPPBLRvAXino9WuKU9+uWv5Z4XFsc2ABtjeOqbdWwMsTorv6iE1TsOeOxoEGyp4d0FW7R7b4gMply1cGVz70crPW6bu778zUYobQj+VBlNAZ4H3q6Q/pQx5l+uCSLSBRgBdAVaAt+KyPHGmBLgJWAs8DPwOTAM+AIYA+w1xnQQkRHAo4DPVeH3HinkjCfn0q5J7bLWd2+OFhazafexC4Zr/frhgmI25h2iU7O6VK9axeexvDl0yPEeIsLjjz/O448/Xm776NGjGT16tNvrIlEqqCz2HC7kmVnrmZa9lfkThgR9nAW//VH2eMOuQ3RoWod2E2ZyUa90/nVpj0rUnyr+vDp3k99VUcluz+HyXelLKnQrr9igHwifJQRjzFzgD1/7WYYDHxhjCowxvwEbgD4i0gJIM8bMN45K2reBC1xe85b1eDowRPy4Fdux39FF0p9gUFpqOOKlj66ztLBpd2ANMCo+OOtUnd+JcDjjyTnkF5VQamD6IkdxPdQqi/yiEm5+f4nH8QzKs8refuD63Xv0i2Ml9A27DrIojAMgQ2lDuElElltVSs5VLFoBrp3Xc620VtbjiunlXmOMKQb2A43s3lBExopItohkBzJ+YNdB7xeKYivCxkPbQ6KKxBQhizbv5b0FW3zuF+qFuqTUUFpq3EoArhPYhcOsNbv4dNl2+k+ezZgpv4T12LH06bLtTPykfA+gjPEzIzbGRx1zxpNzeen7jeXSQhmHEGxAeAloj6Mfzw7gCSvdLifGS7q317gnGvOqMSbL02o/Bvu56BPxe5lfVEKhhyHqoRHHnP1hHoccibl7Ln7pJ9s2jFDYzW/V/p7PGfvOIrfAUrHeNpxVRrNc5uxJZAXFjlLPlJ9y3Lb96+u17i8IE2MMj3yxhpzdh9mw62DSBx/X756v31rUA4IxZqcxpsQYUwr8G+hjbcoFWrvsmg5st9LTbdLLvUZEUoF6+F9FVc7mfUUUHzng9oPffaiAo2Ea1FJqTFRKEut2HgxpTpKKnL8XYwzFRw6weV94R4waHMXX+Rv3hPW44bTrQD4d7/2Ct+dvdtv27ZqdPkdd54XYESEZe8m8+N1Gj9t+iuC6yL/tPswrczYx6F/fc8aTc3n62+Se8M61Ft3XzVykG5XdiEgLY8wO6+mFgPNW6hPgPRF5EkejckdgoTGmREQOikhfYAEwCnjO5TWjgfnAJcBsE2T9w3ML9nIz0Kb+brcf904vr6uemkKB1VNmzcGaXt9jz+FCjhaWkN7A+37BOFxQjAEKiko4WuRffuwYY9i5r3w12f6qKRzaWZ2C4lIWbz3IcwvCO/GaMYYznnQMSJoxrj+92/i3Fu62fUe57YMlvDbqJOrVCm6hHX+//1uspS4/XrqN0f0z3Lb7mrl15bbEGFNQUmqYvmgrF/dKJ7VKZHuWH8wv9rit0MscWqFaW+FmaXElmkjQ19VRBJZt3RfUsX0GBBF5HxgENBaRXOAfwCARycRxY5gDXO/IqFklItOA1UAx8FerhxHAOBw9lmri6F3k7Oz9OvCOiGzAUTIYEdQnAQ4UlDJpbuB3qH3aNmSh1cPE1yAO52jU3x45J2yDlyoe21Uwi9YMevw7cirMr5PeoCbz7h7Mz5v2MGluTrBZ9Mj1O7p06z6/A8KL323gl5y9zFicy7WntC1LD2RKA3//Hyrull9UUq5TwoQPw1s95fb+FZ4XFJdQPTW0Xm123luwmb9/vIpDBSWMcTmn4WKM4bfdh2nXpI7XUk8k19we927l7ZXn/GX8tNG+BPbRkm18terYLfCCTXs4uZ1ts6wbnwHBGDPSJvl1L/tPAibZpGcD3WzS84FLfeUjkpJtjpSKwQAgd+/RiC4G7zqJYCAFvDxrvqUHP1tdLiAcieD/yeIt+yguKeXuGcv5eKn7wLtIqTh6fO/hIprXC39A2Gutc/37/sj0Zvrvolzumr6cpy/L5PV5v5Wlx3LtkWRZf+JIYTE7DxTQtnHtcunl2xAcH/b7tfaDHV2DAWA7p5knSTNSORTBdGlLxC9gxf7LYT22yzTjBwKY0fJAfjRnvzz2szpcUFK2HGa03Dm9/Lw94W7Yd9q21xEI/v3Dbz72DM4K6/dy29SlETl+MBLx92jn2im/cPq/vve6z0arVPvq3E1+HXPFNv+vbxoQgpSI379S4961Mly+WPl72eNA6o7DMX223RG27TvKx0u3eX9dAG8dqZHthwuKy63JHKote44w1Y9pyyMhlhflSAVXb9btPOg2ZXyoft7koT9NCD8TfwMHaEBIOhX7JLuK5A82nNUFm/IOMfz5eX7vv9NmnMmlL/3ErR8sLdcd0TUABHoBCXTWSH8YA0OemEOvh74J2zEHPv5d2I4VqP8ucg9EeyNYKnXl8UIaQWc9NZd+k2eH7XjeBixGq4OaBgQbRwo995xw8nQB/HjptrKRra72HyliZxSW86w4z1B5JuwN4U6TPl/j8i6hBYdnZq0vKxb746PFx0oCGeNnMn7GcrZbo5a9BapASieRCKbnPz+vbInXo4UlZXNzxTtPX6G7Z7g3yvcMY7DzpaiklINRrYJ0n1guFLd9sNSv/VrVrxnw/GEVe2V5ogGhgvcXbqHL/V/xS473Ow5PX4NbP1jKHf9d5pbeb/IsTv7nLI4WlvDCdxuCnn00FJEtIQT3OruLS8BLAVY4xge/xKbKJFC7XdpdTrj/S854cm7MJwpMZOP+s5juE7+OdTaCkjF+JgtdrjkVb2QOuHTvNcYEPMPwFa/97Nd+GhAqcHY9DHeDo3Mupae/XcfjX63lwyXe67d9+dvUpQEPxvE2n1NYBRAc7ALC16u9jRpxKCoppe8/Z/HFih1e7/RdsxJK2ShaNdTelnyNF9v3Rb6kG4xv1/j+3iSKE+7/0uMA2GAKJf6+RgOCB75+lxW3vzp3I/f9z3c/dmfXw4IQ7wQ/XLKNp79dH9BrRr2xMCqjZQPpteV6MX/g01Xs8LOr5N7Dhfx+IJ/7P/F/FS3X6rIlW/cFdC6idZ2O1vts33eUjPEz+XlT4ON2kunCG2vz1u+2XWc6v6i0bNBfOKql/O24kDQrpkVbxXryf37ure4+vLbF+WyZ8wO4yLhelN/8MYd1/qxr4SKQwO16/b/mzV9o06hWQO+ViF6du5GxA9u7pTsHYr6/cAt9/Ry0pMJr35FCrnx9Af3b259/Z7WRr+rrcNISggd7fHQz9PdO7j8/b+bm95cce10ombJ85DIL5/oAL6DxMp3Ogfwi21XEFvjoLbLrQD7H3/sFz852lI52Hyrw605/zJRfGP7Cj+XSNtsM4PMkloOuQmF3o1JYXFq2tOdXq37nfyFWX1Ym2/YdJSdM0+Q724s8XfCfm70BcL/WRLJaUQOCB6+5jMAMxX3/W8mny46Nhv3d6v2yscJiH8FecM58yn1Bc29ifVnL2X2Yhz5bzU3vLWH0GwvLRio7FfsoHn+56ncKS0r5z8++p8WGYyW5UGcXTfTJNI0xZSvK/W3a0rK+6flFpdw2dSn7j0S3d04klZQ6ptYIp7nr8li5bT8DJs9m0L++D3hNi4+XbiNj/EzbWRGKPIzbsZtBFgIbeRworTKKkSk/5TDx/K5lzw8c9d3V1ZMD+UUUFJX6dedgN9NnNN3wn0XlZnH1p1dNflEJk7/4lb+ddbzt9mleehWF62bqpveiM3dOsF12S0oNX6363XbbNW8u5DtrmoO3ru3Dlyvd9ysoLgGCm1ww3jzx9Vpe/H4jc+4cRJtGtX2/wA+jKiyBWnEaEl8e/8oxFXjewQJaN3RUVW7d6zuoGGOiOkuuBoQgBd3NMgzvXXEswYkBdLVb+3t0Z+xcuW0/6Q1qUr9WNcCmgcyPE/Lf7K1M+SmHFBEyGrvX+3ubkuO/i3K5qm+bgPJsJ5LTfoTD2/NzeODT1bbbvnOZ82b9zoO2Fxi7r/OuA/k0TasRphxGj3Mp1LyDBSEFhJzdh6ldPZUmdauHnCdnJxLXziQXv/STz9ctCXLW0mBplVGUuf4YC4tLyRg/k1fmbPR6YXxlzkbeXXDszr4ghInfUlOi+19+3nPzyn3xK16M/AmQzmmrS0pLmbUmsKqfv/9vZVA9aeLd3sOF5QZh/R7G5UPBMUNmn3/O4rPl0Zv8L9xCLRwO+tf3nDTp25CO8fS36/hwcW5Z1eibPwZWFR3tcSkaEILkT9HeV4+Zw1ax85EvPPdQKi4p5ZEvfi1bvWvCh8t51mpsCkYoC3AHYtHmvbz2g6OeemPeYfYfLeL7tbtYt7N824k/I6edk7St2LbftiHalxGv+jcoJ5H0fOgb+kyaFdRr7cZtVExZtd1RkszOSbx1Bpyf5arXF4TleAEPlLTsPlTA09+u52/Tjg1UzS8K7AJvTHQ7gmiVkRfXTvmFN64+CYBvVu8s1zi890gRtap5P31/fmW+1+3+3MFU3Of9haGNwo1SPHArDvd4IPQRpIu37Av5GIluWvZWalR1TJkd7CqAhTYDnv44UkiTutV9BuhgplCf/Wtsxi0EevH1JNgZeYttGoudN5Lfr/WvpGs8rkAcuDU7DnBCizSv+2gJwYvZVs+UnN2Hue7tbD5xCQgDJs8um+nwaw+NeUU+inv+FPM73ntsiPqmvENe9kxMG3Yl32cKh8Vb9tL9H1+5TQ531/Tl3OLSjdkp1OqRYU//wH+z3efgKvcexnDqY4FPnnftlOxgsxWUbD9mGRj+wo+8OtfzRJCufLUXFhaX2s6GaxtbDeTuPcLVb/7i13tj/F8Aypezn/nB5z4aEPzgacqHnQccX4Kx7yzy+1iujUquDawVu1/aGfzEHL/fx5NlQaz9oKJn+76jPPrlr/zj41UcLCj2OSipsLiUl77f6PcUx94ubnPXe6+O89UlOJEs27rP78Gkvtqgbp+6lKyH3dsaPMQDvlhhfwNpJ9pnXKuMQhBMF8Ef1tsve3dPhJdvVInBuS61nXfm57ilBTrJmS8H8ovYf6So7O72SGEx2/YdpUZqCmk1E69b6u/789m276jfS7ra8VW9M3OFY3n5HfuP0qKe9zXQ56zLo2tL79U2rowJbN2OUGkJwYdNeYd4xUPR0lsdZf9HZvks6rn2ZV4YxeHpKnG4NqL//WP/520K1vDnf+TUx77j/YWOgX/TsnMZMHk2vW3ugBNB/8mzytqz1u886NYeYDeBnDGm3OJK/s471u+R2ZSWGu75aAXz1u8um9rc1R+HC3l45hqbV9szGC592XtbZDhpQPBh8BNzPK67663ReLsf7QMvfh98byFVOditrREKb6VaYygb4VuxN1iicq3lOvOpuVz+b989zr5fm8etLmsTbN3rf0P6lJ9yeG/BFq58fQHnP/+j7xf4EO0ZU3wGBBF5Q0R2ichKl7THReRXEVkuIh+JSH0rPUNEjorIUuvvZZfX9BaRFSKyQUSeFev2WUSqi8hUK32BiGSE/2PGhq/RjJ6mt1XKKZrTYTurPjzJ9WNkbbx64FNH6WrltvIDM5/4eh079h8tN6aj4uyjdv8Fnsr+D35mPzgwWNFuQ/CnhDAFGFYh7RugmzHmRGAdMMFl20ZjTKb1d4NL+kvAWKCj9ec85hhgrzGmA/AU8GjAnyKGJoRQ9x+LZf9UYvE0z00s+Fr8PZ69+WOObfrLczbS75HZnPfcsSVb3QZP2lz97bruRkK0J1X0GRCMMXOBPyqkfW2Mcd7+/gykezuGiLQA0owx843jE74NXGBtHg68ZT2eDgyRcPWzigJnXatSkWI3IVqwEnTS1ohzzny7eMte/v6/leW22Z2zZwJciyRY8VhC8OVawLWrQ1sRWSIic0TkVCutFeBaGZprpTm3bQWwgsx+wHaCcBEZKyLZIhLdjs1KxdB9/1vJ/I3JN/1GPLroxZ/KLVcJ9gFhR5inCvEoyhEhpG6nInIvUAy8ayXtAI4zxuwRkd7A/0SkK5675OJjW/lEY14FXgWo3qKj3uuoSmH6otywNy6r0Ow6GJ2AEOzst8EKOiCIyGjgPGCIVQ2EMaYAKLAeLxKRjcDxOEoErtVK6YCz604u0BrIFZFUoB4VqqiUUuGhd1Hh4RyUGmnhruLLGD/T6/agqoxEZBhwN3C+MeaIS3oTEaliPW6Ho/F4kzFmB3BQRPpa7QOjgI+tl30CjLYeXwLMNom6PJVSKu7tOxLfU5m7ivbgcJ8lBBF5HxgENBaRXOAfOHoVVQe+sdp/f7Z6FA0EHhSRYqAEuMEY47zbH4ejx1JNHG0OznaH14F3RGQDjpLBiLB8MqWUspH54De26Vs8LKlame5OfQYEY8xIm+TXPew7A5jhYVs20M0mPR+41Fc+lFIqkgY+HvjEfZE2N4jp3kOhI5WVUsqLNTuiu8qgq3d+ju6StxoQlKpEtHVOeaMBQalKJJpTYajEowFBceuQjrHOgoqSUNbjVslPA4Ii1WVdzSZ1q8cwJyriEmRWmKcvy4x1FiolDQiVXOuGNctdI2pU1a+EJ7WrVYl1FkL22TL7qdzjzQU9W/neSYWd/voruWZ1a3D1gLYAfHbzKXRsWheA287QaqSK/u+sTrHOQsg2WesdJIJex9WPdRYqHQ0Ildh9557Ai1f0ok71VHImn0u3VvV4ZkQm74zpw21nHE/O5HN9HqNu9cqzCmvF5tiT2zaMST6SXY/0egB8eOMAnr+8Z4xzU7lUyoCgP2SHv5zajqZpNcql1a1RlVM7NvH7GOdntgx3tuJWaYV5BM7q2tzr/toeEySXOsxaSVBNl0gqZUB48Ypesc5CzP1nzMkB7T/weP+DRLIqqdBl0xjDN7cP9Lh/SmK038Yd19N2eqemMctHZVQpA0KVSvRLnXf36bbpxzerE9Bx/j2qdziyk9C6t6rnltaifk2P+w9o3ziS2Ularp0cRIR6NavGLjMJpGcY2lwqZUAQjyuiJp/0BrXsNwR4ClJT7L8qCdKLMSzSapS/MPka43X5ycdFMDfJ66q+bco9b1ynWoxyklg+unFAyMdIioDw6U2nMKpfG987OlWii5gndav7d9flvOuoWKo6rqGHQJPEKo7yNRiv1UKuwbJz87oRylX8eegCtzkseeziE/16bc7kc7moV/kVeXu0rh+ObCk/JEVAaNekdkABobLc1VZsPH/lqmPVPjX9bKx7/7q+LLx3iFv6dae2DS1zCajYZnL6WtXse1md1aUZrkuDX9k3gBuWBGc3XiOtpufeaA+c39Xr8SrTuYu1pAgIBujQtK5f3SSh8hQQ7jnnhHLPu7RIA6CVl3rvimpUrULTujXc0l0vjclYx3tWl2ZuafVrVWXhPUO4un8G4LnK6JbBHXjlqt5Uq+L4eZ3SoXFY6ncThd15Gdq1ORf1sh9sNto6n55Ult9rME6zOnvcd+4JttvfvrZPQMdL6IDgnHKhRqr/H+OHu+wbWZORp6J2OEtIgvDZzaeE74BxwrU05dS+SR2aptWgmvV9s4sHp3ZszM1DOiIidG2ZxoSzO/PUZZk0rF156sHtzouIcFlWa8C+Q8PLV/Zi+g39Ipyz5OO8BoqHH/XA45sw8U9d/D5eQgeEK/u2IWfyuaRW8f9jtG5Yq+zkaR9n5YnrD2zmLacwY9yxi5Vzi92d8OV9jqOq9X0UEa4/rT1N6lanRb2aTLnmJGbeknzBsyJjDMO9jE+xK1EO69aCrIzAxgfZ9fpKJnal1Jb1ypfW69cK741GQgcEb6pW8Xwb7O0Hncya16tB7zYNeOwS/xr4PPnkpvK9GVxvTpKpR+/UsX35YGxfurasR+82Lhcr6zMam3vhYd08D1Yb1KkpXVsm90UMHN+zawa4tzE1snoLnWBVXQJ87WUch5MzOJ+YXq9cN+r0Bv5XfSaiqwdkuKU1q1ejXNV43RqOthlvPztPpQc7CR0QvM3tntGotsdtlaFR+ZQO7n3gq1ZJYca4/vQPsX/8ien1PQbTz24+NaRjxwNnaeDkdo3o266R23Znt2W7cxDIjy+Z3HNOZwDO7NLM40j3Dk3rMmNcf+4791gVxvHNfPe+amRVt2W2rk+dSjRVSmtPXcZtOL+KofZm8xkQROQNEdklIitd0hqKyDcist76t4HLtgkiskFE1orIUJf03iKywtr2rFi/HBGpLiJTrfQFIpLhb+Z9fZl8/TYNhmX/OMvft0sobRsfC4hPX5ZZ9oMNN5FjF8EW9WrQpWWaj1fEn9YNa/J/Zx5f9rxcacBGxe/VF7c6guCjF3cP6H07Ng1scGC86pPRkLED2/PpTafwypWOthfj4Y6hd5sGVEtNYcE9Q/h5gnvvNTutG9bi81tO5b5zu4S9iiSetW5Yi4usWV/TrJJAu8aO78xLV/Ti47+6jztwNjKf3LYhp3dyPA7kHsWfEsIUYFiFtPHALGNMR2CW9RwR6QKMALpar3lRRJwV9S8BY4GO1p/zmGOAvcaYDsBTwKP+ZLxDkzpcYTPw5/3r+pY97laheH6x1b/ZdWBaMlVxeHJBz1aMHdg+YsdvUqc6rerXZKKP7oPxShBuDmCRoGNVjo6L3gkt0siZfC6XnRTYQLRv/nZaQPvHo5F9WjPl2pMA6J5ejxTrB+VaLXStTfVRs7QaNK/n3nvNky4t08oa850qPk9Gzs4INw3uwFvX9uFha4zH2d1blOs04vxO3jm0E7P+7zSmXt+PN68JrIcR+BEQjDFzgT8qJA8H3rIevwVc4JL+gTGmwBjzG7AB6CMiLYA0Y8x84/gVvV3hNc5jTQeGiB/l7prVqtgWzxu5jGp8Z0wfpo49FiCe+HOPCp+t8hbxw8UYxw/zx/GDGepjsrd4ZdcW4I3zK1PZ2qDsZDSqbTsWo0bVKqx7+GyuH9iO28+MzFTqdw2LTKk3njgDrDGOu39f44dSq6TQvkn5kqfzCudPJ5pgQ2wzY8wOAOtf5wxUrYCtLvvlWmmtrMcV08u9xhhTDOwH3CtuAREZKyLZIpKdl5fnM5P1a1XjZJs6YOedxdiB7aiSpAEhkLuvSLm0dzrzJwyOdTZ8CvTCXtaGEOT7/alHS8YObBfkq+NLipffT7XUFCaccwJ1a0RmnEqr+jX5RwBdKhOR8+zajIkEoF97x/XtxHTfnRUu7NmKZmneZ+ANdwuN3bfDeEn39hr3RGNeBV4FyMrKst3HeTBvX9QqKVLWUl9QnHxrzHZvVY/ro3TBsTvNHZrWYcOuQ1w3sB0t6tWkWVp1dh4oiEp+ghFwQAixhPDcyOSZ4z8W91Pf3TGIQ/nFAFwzoC0PfLo6+pmIkiv7tuHr1Ts9Duob2rU5y/5xltfBoXWs9od6Nav6nMct2ICwU0RaGGN2WNVBu6z0XKC1y37pwHYrPd0m3fU1uSKSCtTDvYrKb+2b1OEvp7QtN9x9ZJ/WVE+1Ly4lYwnh7O7NAxqbEW7OunXnmZ1+Q3/mb9rDXdOXxyxP4VTWhhB0GeGY+RMG0++R2SEfJ1ZiUeXq2mEi2bVuWIvv7hjkdR9fMwUM79GK/UeKGNHnOD5ass3rvsEGhE+A0cBk69+PXdLfE5EngZY4Go8XGmNKROSgiPQFFgCjgOcqHGs+cAkw23jqouCHlBThvvPKFyMfuchzv3tvU2GfmF6P5bn7g81KzHgrHUVDWdHPykbrhrVo3bAWHZrW4aPF23jn580xy5udgBsnxXO300C1qJfcfelV7KWkSNkyub6uDP50O30fx8W6k4jkisgYHIHgTBFZD5xpPccYswqYBqwGvgT+aoxx1smMA17D0dC8EfjCSn8daCQiG4C/YfVYihbXO5wbTjvWE2fmLacw7XodSh+Usgtl+a9fr+MaxF3d+a1DOvLm1ScF9JpjJQQVD+XrGlUTt7eRczqPaPFVovNZQjDGjPSwybYTsTFmEjDJJj0bcJsX1xiTD1zqKx/RcPewTuzYf5QrTm5TKUaUhsKfQlwi1Mbd7jL+wF8pZSWE8ISEXx8aRooIY976hR/W7w7LMVVieOSi7izespf1uw6VS+8QoTEqs+84jRoTPG9P3NAaASLCMyN60ifB11yO5nXY7r0uyXI0FzWunVhrCl/dP8Ov6RBObO24WeiRXj8s71ujahWqpaYk5CjcRAj68aplvRqkpAj/+Yv7crb/jVDthKe2VCcNCDhG8r58ZeIuEVlxgF6sqzLGndae9ZPOpl4t98aueJ5QcOL5XZl3t+9usqd3asrPE4Zwhs3kY6FwdiFMJPEQD+wKas+MyIx6PoLVLK0G6x4+u2yephpVU2gQo9lxNSDgGMnrbVKyePX5Ladyw2nteWh4t3IX2jNOiO3C5CJSNuNnRY3qJFapwZNIjPNIxO9gPLALCGkJsEaHa7arpabQ2PptxHLAowaEBDTv7tN55aredGmZxvizO5OSIuWmDva4jnIYheM7O25Q5KbT8ObDG/vH5H1VZLh2/21UuxoT/9SFQcfbT7AXz+JhBLwGBB+u7Bt/C6WnN6jlNk1Eqkv32RpVo1ctE0o/9LtjNPVAtRiO0fDXLYM72Kbr+sLuXC+gN5zWnqsHtE2IKWkqXvidg8a8zeIcafH/y4ixalXcL663WhOh2U3aFStZGQ1875TgXrqiV0D7/3tUVoRyEnlDTmjG3DvdV/dznZsrHsTDhdfX5TPQWWijpeLAxqpVhDGntGX6uNiVYDUg+FA19dgX/q+nO6o4bjujIzmTz+X+AOZRcb42UEM6+9cecIM1/fCy+xNrOu8Xr+hVttazqyf/3IPvXUZoXj+wHWd3b+H1WH/OSi/33LXrnt3FNd64TitQs1oVjmvkXvUXzdKfP+IgHjC8x7HV2ezy06Ru7Nut6tt0sKi4VrmI8PfzupAZw1KgBgQfXKsX7hzamZzJ55a7KzrjBN89TRrXqcbIPsFVPTWpW92veYlSUoTu6fVse/ZEQrhKted0b+HWw+u1UVlc1CudjMa1yWrTgJF9jmPCOY5FxLPvO4N2TeynLrAb9Lb0/jN58Ype5S6uIjDr/07jXZvufrHkuu6yt+vs6H5t6NSsLifHQffoOIgH/OvSHh6/ExC+7sGhsPv9v351/JVgNSD4cO6JjrtST/XOr43O4r5zT7BdlB0cd7bZ950ZdEOvSOzq2mPFdQrz6eP688hFx4r8jetU57wT7dfr7dC0/IJJDWpVpX6tapxToWRhjGPOqwE2q8rFkus0Kt7uvB8Y3o2v/Fh6Mlx+Gj+YO4d24skK08cDcVFESEkRzunm+D+ublOCalSnOrP/L37Wnji/R0umXHOSWwkhHiTeSJgo69w8jTevOcnrXcZfTm3Hup0H3dJH9WvDnUM7uaWf2rGx3yNSa1ZNLZsTPVkFek3xZ/cXr+iV4Ktrlf+UF/dK58MlueX3iNLXomX9mvz1dEcj99+mLSufh+hkwaebBnegemoKI046NhXEcyN7crjAMSuq3ZoN0eR6nv5+Xpe4qMayowHBD6d3Cq5f/4PD3WbqAAJriDspjhqLbzitPW0bR75La7sm3oftt7IZTewMvD/cdToNalfzOuo3vyj+pzw/rmH58/zEn3u4LfDUv31jft4U9MTAfmkRB+tq+KNG1Spuq979yUfbQjSd1LYhqXM3UVxqYp4Xb7TKKEwC+T8e2PFYVYW32Vbn3DnIrSF1+cTYNRqPP7tz2TKRkegYl96gJjmTz/U5ne/5PdyrjJx3sK0b1vI5BUQizFPlOgNr7zb2NwU3nW7fNTWcans4l91bOc5hPF/cYukvp5TvgdirdYOy73U8r7SnJYQw8eeu/7Ks1kzN3kr/9scCQoqA3f3qf8acTJtGxxrKlt5/JiJCWoRWnwpWLC4IFaf3PiXAtgBfyxDGUnqDmuTuPVr2fMnfz/SY35QUYdUDQyk1hu4Tvw5bHj7+6wCmL8qlVYOanHdi+RuSZfefRfWqKUz8ZBUrtu33ueBKZXXfeV14bd5vZc9rVqvCpAu789Bnq217HMULDQhh0t5LLwenSRd2465hndh3tKgsLa1GVfYcLgQc8/wcKSxhQIdGnNKx/EUusevDw6tiqeq10fHXWyNYM285lf1Hjn0/fM1p4+kOPlind2pCj9b1PQ6Ac/ZiG9SpKR/8stWvpRsrq3f/cjIC9LduWIZ1ax7305NolVGY+FNCSK2SQqM61cvdU70z5ljXx3HWegyuJQjlzjUevHRFr7jrmx+KejWr2o4/iJZafgaYYd2as+bBYXRrlRgBIRbfkQEdGpcFg0ShJYQw+v6OQazfdYjr3s4u19uhImfwaNOoFl1aHhuUdd3AdhwuLGFMhfrHeBSutQDg2KCdS3qn+9jTwTX4+hqs5mr6Df1YveNAYJmrbAL4b43nqreKfLVL+XL/eV148LPkXbvZSQNCGGU0rk1G49o8f3lPhnT2PGCtYlmiVf2anNqxMTWqVmH82Yk15iAcdch1a1Rl7cPDIj7HUFZGw3KTACa7lQ8MpbiklMwHv/H7NdpIbO/aU9p6DQjvjOmDMXAgvyguBsIFSwNCBHgaOFWR8yb7x/G+5+BPdr4W7lDeXXdqW/79w2/l0vxdcOfOoZ3I3XuU9xduifl63JH03Mie3Pz+kogcu3PztLgdWxAIbUOIgST+zUXNHWcdzyc3DYh1NuLGvef6P6+WqxsHtWfcae257QxHH/7R/duEM1tx5U89WrLxn+fw1rV9Yp2VuKUlhBiqONthZfHsyJ7UrRHaV++mwR1971TJ9GvXiPmb9gT0mrusaVGapdUgZ/K5kchWXKmSIpwWgbUSaldPjhJu0L9KEekETHVJagfcD9QHrgPyrPR7jDGfW6+ZAIzB0fX+FmPMV1Z6b2AKUBP4HLjVhLPVMs4cW6Q9xhmJEbuBZSp0r43O4rfdh3ln/mbuGuY+ZYoKv43/PIdD+cUxnxojXIKuMjLGrDXGZBpjMoHewBHgI2vzU85tLsGgCzAC6AoMA14UEWdYfQkYC3S0/oYFm69EkgwBQau/4kft6ql0a1WPRy85sdxSpbaT0qmwqJIiUZthOBrC1YYwBNhojNnsZZ/hwAfGmAJjzG/ABqCPiLQA0owx861SwdvABWHKl1KV3kW90itFdVC4vX+d98WIrj/N97T0iSZcAWEE8L7L85tEZLmIvCEizolYWgFbXfbJtdJaWY8rprsRkbEiki0i2Xl5eXa7JIRaVv/tri3dF4ZRKlL+M6b8+g8X9bT9mVUK398xyOvqc3PuHES/9o1st13cK505dw5iwtknRCp7MRNyxZeIVAPOByZYSS8BD+EY4vIQ8ARwLfbzvxkv6e6JxrwKvAqQlZWVsBUujepUZ8a4/pzQoq7vneNUMlR3VTau06H8cNfptG4YuxHRseYcM+R0xglNmXRhd07+5yyAcvOIOc2fMJhq1mwDySocLSFnA4uNMTsBnP8CiMi/gc+sp7mA6/DddGC7lZ5uk57UPM1gmWi0CSExadtPRUKztBrMGNePklL7PVrUc592PdmEo8poJC7VRVabgNOFwErr8SfACBGpLiJtcTQeLzTG7AAOikhfccxJMAr4OAz5Ukp5EMiaHJWB83T0btOQPnGwNGmshFRCEJFawJnA9S7Jj4lIJo5qnxznNmPMKhGZBqwGioG/GmOcMz+P41i30y+sP6VUhGg4KK9mEk2QGIqQAoIx5gjQqELaVV72nwRMsknPBuyXF1NxqbIOqksWpdoIBMCtQzryzKz1NE7idoFA6NQVKiRa85CYNB44hDpiPtloQFCqEtKA4HBO9xbUqZ7K5Sd7nq6+MtHwqFQlpCU7h5b1a7LygaEetw/PbMkvv/0RxRzFlgYEFRS9w0xs6Q2SvwtlODwzomessxBVWmWkQqLdFxOT/r8pOxoQlFJKARoQlFJKWbQNQQVFmxAS0+OXnMiKbftjnQ0VpzQgqJBoTXRiuTSrNZdmaRdLZU+rjJRSSgEaEJRSSlk0ICillAI0IKgg6cA0pZKPBgQVGm1VVippaEBQSikFaEBQSill0YCggqIL5CiVfDQgqJCINiIolTQ0ICillAJCDAgikiMiK0RkqYhkW2kNReQbEVlv/dvAZf8JIrJBRNaKyFCX9N7WcTaIyLOic/MqpVTUhaOEcLoxJtMYk2U9Hw/MMsZ0BGZZzxGRLsAIoCswDHhRRKpYr3kJGAt0tP6GhSFfKoJ0HIJSyScSVUbDgbesx28BF7ikf2CMKTDG/AZsAPqISAsgzRgz3xhjgLddXqPinJbllEoeoQYEA3wtIotEZKyV1swYswPA+repld4K2Ory2lwrrZX1uGK6UkqpKAp1+usBxpjtItIU+EZEfvWyr929pPGS7n4AR9AZC3DccccFmlellFJehFRCMMZst/7dBXwE9AF2WtVAWP/usnbPBVwnYk8Htlvp6Tbpdu/3qjEmyxiT1aRJk1CyrpRSqoKgA4KI1BaRus7HwFnASuATYLS122jgY+vxJ8AIEakuIm1xNB4vtKqVDopIX6t30SiX16g4p00ISiWPUKqMmgEfWT1EU4H3jDFfisgvwDQRGQNsAS4FMMasEpFpwGqgGPirMabEOtY4YApQE/jC+lNKKRVFQQcEY8wmoIdN+h5giIfXTAIm2aRnA92CzYtSSqnQ6UhlFRSjAxGUSjoaEFRIdByCUslDA4JSSilAA4JSSimLBgSllFJA6COVVSV1xcltWJizl2sGtI11VpRSYaIBQQWlQe1qvH1tn1hnQykVRlplpJRSCtCAoJRSyqIBQSmlFKABQSmllEUDglJKKUADglJKKYsGBKWUUoAGBKWUUhYNCEoppQANCEoppSwaEJRSSgEaEJRSSlk0ICillAJCCAgi0lpEvhORNSKySkRutdInisg2EVlq/Z3j8poJIrJBRNaKyFCX9N4issLa9qyILsyolFLRFsr018XA/xljFotIXWCRiHxjbXvKGPMv151FpAswAugKtAS+FZHjjTElwEvAWOBn4HNgGPBFCHlTSikVoKBLCMaYHcaYxdbjg8AaoJWXlwwHPjDGFBhjfgM2AH1EpAWQZoyZb4wxwNvABcHmSymlVHDC0oYgIhlAT2CBlXSTiCwXkTdEpIGV1grY6vKyXCutlfW4Yrrd+4wVkWwRyc7LywtH1pVSSllCDggiUgeYAdxmjDmAo/qnPZAJ7ACecO5q83LjJd090ZhXjTFZxpisJk2ahJp1pZRSLkIKCCJSFUcweNcY8yGAMWanMabEGFMK/BtwrrOYC7R2eXk6sN1KT7dJV0opFUWh9DIS4HVgjTHmSZf0Fi67XQistB5/AowQkeoi0hboCCw0xuwADopIX+uYo4CPg82XUkqp4ITSy2gAcBWwQkSWWmn3ACNFJBNHtU8OcD2AMWaViEwDVuPoofRXq4cRwDhgClATR+8i7WGklFJRJo6OPYknKyvLZGdnxzobSimVUERkkTEmy26bjlRWSikFaEBQSill0YCglFIK0ICglFLKogFBKaUUoAFBKaWURQOCUkopQAOCUkopiwYEpZRSgAYEpZRSFg0ISimlAA0ISimlLBoQlFJKARoQlFJKWTQgKKWUAjQgKKWUsmhAUEopBWhAUEopZdGAoJRSCtCAoJRSyhI3AUFEhonIWhHZICLjY50fpZSqbOIiIIhIFeAF4GygCzBSRLrENldKKVW5xEVAAPoAG4wxm4wxhcAHwPAY50kppSqVeAkIrYCtLs9zrbRyRGSsiGSLSHZeXl7UMqeUUpVBvAQEsUkzbgnGvGqMyTLGZDVp0iQK2VJKqcojXgJCLtDa5Xk6sD1GeVFKqUopXgLCL0BHEWkrItWAEcAnMc6TUkpVKqmxzgCAMaZYRG4CvgKqAG8YY1bFOFtKKVWpxEVAADDGfA58Hut8KKVUZRUvVUZKKaViTAOCUkopQAOCUkopiwYEpZRSAIgxbuO/EoKIHATWhvGQ9YD9cXisSByvMbA7TMeK98+q5y4+jhfO8wbx/Vnj+TsH0MkYU9d2izEmIf+A7DAf79V4PFaEjhe2c5cAn1XPXRwcL55/rxH4rHH7nfN1PK0yOubTOD1WJI4XTvH+WfXcxc/xwimeP2s8nzevErnKKNsYkxXrfCQiPXfB03MXHD1vwQv3ufN2vEQuIbwa6wwkMD13wdNzFxw9b8EL97nzeLyELSEopZQKr0QuISillAojDQhKKaUADQhJQURai8h3IrJGRFaJyK1WekMR+UZE1lv/NrDSG1n7HxKR512OU1dElrr87RaRp2P0saIiXOfO2jZSRFaIyHIR+VJEGsfiM0VDmM/bZdY5WyUij8Xi80RTEOfuTBFZZH23FonIYJdj9bbSN4jIsyJit9iY/8LZv1X/YvMHtAB6WY/rAuuALsBjwHgrfTzwqPW4NnAKcAPwvJfjLgIGxvrzJcK5wzFz8C6gsfX8MWBirD9fApy3RsAWoIn1/C1gSKw/X5ydu55AS+txN2Cby7EWAv1wrDr5BXB2KHnTEkISMMbsMMYsth4fBNbgWJN6OI4fGNa/F1j7HDbGzAPyPR1TRDoCTYEfIpfz2AvjuRPrr7Z1l5ZGEq/6F8bz1g5YZ4xxLpL+LXBxZHMfW0GcuyXGGOd3aRVQQ0Sqi0gLIM0YM984osPbztcESwNCkhGRDBx3FAuAZsaYHeD4EuK4wPtrJDDV+qJVCqGcO2NMETAOWIEjEHQBXo9kfuNFiN+5DUBnEckQkVQcF7TW3l+SPII4dxcDS4wxBTiCSK7LtlwrLWgaEJKIiNQBZgC3GWMOhHi4EcD7oecqMYR67kSkKo6A0BNoCSwHJoQ1k3Eo1PNmjNmL47xNxVEazQGKw5nHeBXouRORrsCjwPXOJJvdQrqB04CQJKwL0gzgXWPMh1byTqtYifXvLj+P1QNINcYsikhm40yYzl0mgDFmo1Wqmgb0j0yO40O4vnPGmE+NMScbY/rhmLByfaTyHC8CPXcikg58BIwyxmy0knOBdJfDphNiNaUGhCRg1Vm/DqwxxjzpsukTYLT1eDTwsZ+HHEklKR2E8dxtA7qISBPr+Zk46oaTUji/cyLS1Pq3AXAj8Fp4cxtfAj13IlIfmAlMMMb86NzZqlY6KCJ9rWOOwv/fuL1Yt7jrX1h6LZyCo6i4HFhq/Z2DowfHLBx3XLOAhi6vyQH+AA7huNPo4rJtE9A51p8r0c4djh40a6xjfQo0ivXnS5Dz9j6w2vobEevPFm/nDrgPOOyy71KgqbUtC1gJbASex5p9Itg/nbpCKaUUoFVGSimlLBoQlFJKARoQlFJKWTQgKKWUAjQgKKWUsmhAUCpKRGSQiHwW63wo5YkGBKWUUoAGBKXciMiVIrLQWhPiFRGpYs3j/4SILBaRWc4RySKSKSI/W/P5f+Qyh30HEflWRJZZr2lvHb6OiEwXkV9F5F3n/PUiMllEVlvH+VeMPrqq5DQgKOVCRE4ALgMGGGMygRLgChzz+S82xvQC5gD/sF7yNnC3MeZEHDOdOtPfBV4wxvTAMafRDiu9J3AbjtlQ2wEDRKQhcCHQ1TrOw5H8jEp5ogFBqfKGAL2BX0RkqfW8HVCKY0ZOgP8Ap4hIPaC+MWaOlf4WMFBE6gKtjDEfARhj8o0xR6x9Fhpjco0xpTimIMgADuBYJ+A1EbkIcO6rVFRpQFCqPAHeMsZkWn+djDETbfbzNueLt2UMC1wel+CYVbYY6INj9ssLgC8Dy7JS4aEBQanyZgGXuMzA2VBE2uD4rVxi7XM5MM8Ysx/YKyKnWulXAXOMY277XBG5wDpGdRGp5ekNrXnx6xljPsdRnZQZ9k+llB9SY50BpeKJMWa1iNwHfC0iKUAR8Fccs012FZFFwH4c7QzgmKb4ZeuCvwm4xkq/CnhFRB60jnGpl7etC3wsIjVwlC5uD/PHUsovOtupUn4QkUPGmDqxzodSkaRVRkoppQAtISillLJoCUEppRSgAUEppZRFA4JSSilAA4JSSimLBgSllFIA/D+Gj1go5Cn+igAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import datetime as dt\n",
    "import random\n",
    "import os \n",
    "import h5py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, GRU,LSTM, Dense,Lambda,Conv1D\n",
    "\n",
    "def pre_process(sample):\n",
    "    '''\n",
    "    Takes a dataframe and \n",
    "            \n",
    "    - replaces NA values by forward filling\n",
    "    \n",
    "    '''\n",
    "    ## Use the below line of code to sample data based on hours \n",
    "    ##sample = sample[(sample.index.dayofweek<5) & ((of_da_fi.index.hour>4) & (of_da_fi.index.hour<19))]\n",
    "    \n",
    "    #using forward filling method to fill the missing data \n",
    "        \n",
    "    sample = sample.fillna(method='ffill')\n",
    "    \n",
    "    ## This line of code checks for NA values \n",
    "    \n",
    "    check_na = int(sample.isnull().sum().sum())\n",
    "    \n",
    "    print('There are {} NA values in the dataframe'.format(check_na))\n",
    "    \n",
    "    #plt.figure(figsize=(3,3))\n",
    "    \n",
    "    #sns.violinplot(data=sample)\n",
    "    \n",
    "    #plt.xticks(rotation=90)\n",
    "        \n",
    "    return sample\n",
    "\n",
    "def rolling_window(array_data,input_size,output_size,offset):\n",
    "    '''\n",
    "    The function takes a series array_data of size (size,) \n",
    "\n",
    "    and generates\n",
    "    \n",
    "    a array of size (input_size,((array_size-(input_size+output_size)/stride)+1)) as inputs \n",
    "    \n",
    "    and array of size (array_size-(input_size+output_size)/stride)+1)as output \n",
    "    \n",
    "    '''\n",
    "        \n",
    "    # Normalizing the dataset\n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    scaler = scaler.fit(array_data)\n",
    "    \n",
    "    array_data = scaler.transform(array_data)\n",
    "    \n",
    "#     lab_data = array_data[:,0]\n",
    "    \n",
    "#     for i in range(input_size,len(array_data)-output_size+1,offset):\n",
    "            \n",
    "#             data.append(array_data[i-input_size:i,0:array_data.shape[1]])\n",
    "    \n",
    "#             labels.append(lab_data[i:i+output_size])\n",
    "\n",
    "        \n",
    "    data_idx = sliding_window_view(np.arange(array_data.shape[0]).reshape(-1),window_shape=input_size)[::offset][:-1]\n",
    "    \n",
    "    data = array_data[data_idx]\n",
    "\n",
    "    labels = sliding_window_view(array_data[input_size:,0].reshape(-1),window_shape=output_size)[::offset]\n",
    "    \n",
    "    input_decoder = np.zeros((data.shape[0],1,LSTM_DIM+OUTPUT_FEATURES))\n",
    "\n",
    "    \n",
    "    assert data.shape[0] == labels.shape[0],\"Training rows and labels are unequal\"    \n",
    "    \n",
    "#    if output_size == offset:\n",
    "        \n",
    "#        ra_in = random.randint(0,data.shape[0]-2) \n",
    "        \n",
    "#        a = data[ra_in+1,-offset:]\n",
    "        \n",
    "#        b = labels[ra_in]\n",
    "        \n",
    "#        np.alltrue(a == b)\n",
    "    \n",
    "#    data = np.expand_dims(data,axis=2)\n",
    "    \n",
    "#    labels = np.expand_dims(labels,axis=2)\n",
    "    \n",
    "#    data = np.array(data)\n",
    "    \n",
    "#    labels = np.array(labels)\n",
    "        \n",
    "    return data,labels,scaler,array_data,input_decoder\n",
    "\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, verbose=0):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        self.verbose= verbose\n",
    "\n",
    "    def call(self, query, values):\n",
    "        if self.verbose:\n",
    "            print('\\n******* Bahdanau Attention STARTS******')\n",
    "            print('query (decoder hidden state): (batch_size, hidden size) ', query.shape)\n",
    "            print('values (encoder all hidden state): (batch_size, max_len, hidden size) ', values.shape)\n",
    "\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        if self.verbose:\n",
    "            print('query_with_time_axis:(batch_size, 1, hidden size) ', query_with_time_axis.shape)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "        if self.verbose:\n",
    "            print('score: (batch_size, max_length, 1) ',score.shape)\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        if self.verbose:\n",
    "            print('attention_weights: (batch_size, max_length, 1) ',attention_weights.shape)\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        if self.verbose:\n",
    "            print('context_vector before reduce_sum: (batch_size, max_length, hidden_size) ',context_vector.shape)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        if self.verbose:\n",
    "            print('context_vector after reduce_sum: (batch_size, hidden_size) ',context_vector.shape)\n",
    "            print('\\n******* Bahdanau Attention ENDS******')\n",
    "        \n",
    "        return context_vector, attention_weights\n",
    "\n",
    "for i in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28]:\n",
    "\n",
    "    BATCH_SIZE = 128\n",
    "    PATIENCE = 20\n",
    "    MAX_EPOCH = 150\n",
    "    TRAIN_STEPS = i * 24\n",
    "    PREDICT_STEPS = 24\n",
    "    WINDOW_SIZE = TRAIN_STEPS + PREDICT_STEPS \n",
    "\n",
    "    LSTM_DIM = 128\n",
    "    INPUT_FEATURES = 10\n",
    "    OUTPUT_FEATURES = 1\n",
    "    filters = 16\n",
    "    krnl_sz = 2\n",
    "    DECOD_DENSE = 24\n",
    "\n",
    "\n",
    "    FILE_DIR = 'C:\\\\Users\\\\Zain Ahmed\\\\Desktop\\\\Literature review\\\\Project Folder\\\\Data.xlsx'\n",
    "\n",
    "    data = pd.read_excel(FILE_DIR)\n",
    "    \n",
    "    data['Time']=data['Time'].astype(int)-1\n",
    "    \n",
    "    data = data.loc[:,('DATE','Time',' Load(KW)   ','Temp (C)','Dew Point Temp (C)','Rel Hum (%)','Wind Dir (10s deg)','Wind Spd (km/h)','Visibility (km)','Stn Press (kPa)')]\n",
    "    \n",
    "    data['datetime'] = data['DATE'].astype('str') + '-' + data['Time'].astype('str')\n",
    "    \n",
    "    data['datetime']=pd.to_datetime(data['datetime'],format='%Y-%m-%d-%H')\n",
    "    data['is_weekday'] = (data['datetime'].dt.weekday<=5).astype('int')\n",
    "    data['month'] = (data['datetime']).dt.month\n",
    "    \n",
    "    data = data.set_index('datetime')\n",
    "    data = data.drop(columns=['DATE','Time'])\n",
    "    num_of_bre = (data.asfreq(freq='1H').shape[0]) - (data.shape[0])\n",
    "    percen = ((num_of_bre)/data.shape[0])*100\n",
    "    print('The number of breaks in the data are {} which is {:0.2} percent of the total data'.format(num_of_bre,percen))\n",
    "    data = data.asfreq(freq='1H')\n",
    "    \n",
    "    data.plot(y=' Load(KW)   ')\n",
    "    \n",
    "    tr_id = int((data.shape[0]*0.75)/24)*24\n",
    "    val_id = int((data.shape[0]*0.90)/24)*24\n",
    "    tra_data = data.iloc[:tr_id,:]\n",
    "    val_data = data.iloc[tr_id:val_id,:]\n",
    "    tes_data = data.iloc[val_id:,:]\n",
    "    \n",
    "    train_data = pre_process(tra_data)\n",
    "    vali_data = pre_process(val_data)\n",
    "    test_data = pre_process(tes_data)\n",
    "\n",
    "    tes_data.fillna(method='ffill').isnull().sum()\n",
    "    \n",
    "    tra_data_sli,tra_lab,tra_sca,tra_stan,tra_decod = rolling_window(train_data,input_size=TRAIN_STEPS,output_size=24,offset=24)\n",
    "    val_data_sli,val_lab,val_sca,val_stan,val_decod = rolling_window(vali_data,input_size=TRAIN_STEPS,output_size=24,offset=24)\n",
    "    tes_data_sli,tes_lab,test_scaler,tes_stan,tes_decod = rolling_window(test_data,input_size=TRAIN_STEPS,output_size=24,offset=24)\n",
    "    \n",
    "    print('****Model Hyperparameters****')\n",
    "\n",
    "    print('BATCH_SIZE : ',BATCH_SIZE)\n",
    "\n",
    "    print('LSTM_DIM : ',LSTM_DIM)\n",
    "    \n",
    "    print('INPUT_FEATURES : ',INPUT_FEATURES)\n",
    "\n",
    "    print('OUTPUT_FEATURES : ',OUTPUT_FEATURES)\n",
    "\n",
    "    print('TRAIN_STEPS : ',TRAIN_STEPS)\n",
    "\n",
    "    print('PREDICT_STEPS : ',PREDICT_STEPS)\n",
    "    \n",
    "    \n",
    "    def create_enc_dec_att_model(BATCH_SIZE):\n",
    "    ## Enoder Model\n",
    "\n",
    "        encoder_input = Input(shape = (TRAIN_STEPS,INPUT_FEATURES),name='encoder_input')\n",
    "\n",
    "        conv_layer = Conv1D(filters=filters,kernel_size=krnl_sz)\n",
    "\n",
    "        pool_layer = tf.keras.layers.MaxPool1D(2)\n",
    "    #    conv_flat_layer = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())\n",
    "\n",
    "        encoder_lstm = GRU(LSTM_DIM , return_sequences=True,return_state=True,name='encoder_lstm')\n",
    "\n",
    "        one_d_conv = conv_layer(encoder_input)\n",
    "        pool = pool_layer(one_d_conv)\n",
    "    #    conv_flat = conv_flat_layer(pool)\n",
    "\n",
    "        encoder_output , en_h  = encoder_lstm(pool)\n",
    "\n",
    "        encoder_states = [en_h]\n",
    "\n",
    "        attention_layer = BahdanauAttention(LSTM_DIM)\n",
    "\n",
    "        ## Decoder_Model\n",
    "\n",
    "        decoder_input = Input(shape = (1 , OUTPUT_FEATURES+LSTM_DIM) , name='decoder_input')\n",
    "\n",
    "        decoder_lstm_2 = GRU(LSTM_DIM, return_sequences=True, return_state = True, name = 'decoder_lstm_2')\n",
    "\n",
    "        decoder_dense_1 = Dense(DECOD_DENSE,name='decoder_dense')\n",
    "\n",
    "        decoder_output_layer = Dense(1,name='decoder_output')\n",
    "\n",
    "        all_outputs = []\n",
    "\n",
    "        ## Decoder input starting vector \n",
    "\n",
    "        inputs = np.zeros((BATCH_SIZE,1,OUTPUT_FEATURES),dtype=np.float32)\n",
    "\n",
    "        ##for attention\n",
    "\n",
    "        decoder_output = en_h\n",
    "\n",
    "        states = encoder_states\n",
    "\n",
    "        for _ in range(PREDICT_STEPS):\n",
    "\n",
    "            context_vector , attention_weights = attention_layer(decoder_output,encoder_output)\n",
    "\n",
    "        #    print(\"Context Vector Shape : \",context_vector.shape)\n",
    "\n",
    "        #    print(\"Attention Weights : \",attention_weights.shape)\n",
    "\n",
    "        #    print(\"Decoder Output Before Concat : \",decoder_output.shape)\n",
    "\n",
    "            context_vector = tf.expand_dims(context_vector,1)\n",
    "\n",
    "        #    context_vector = tf.cast(context_vector,tf.float64)\n",
    "\n",
    "        #    print(\"Reshaped Context Vector : \",context_vector.shape)\n",
    "\n",
    "        #    print(\"Input Shape : \",inputs.shape)\n",
    "\n",
    "            inputs = tf.concat([context_vector,inputs],axis=-1)\n",
    "\n",
    "        #    print(\"New Input Shape: \",inputs.shape)\n",
    "\n",
    "    #        x = decoder_lstm_1(decoder_input,initial_state=states)\n",
    "\n",
    "            decoder_outputs, state_h  = decoder_lstm_2(decoder_input,initial_state=states)\n",
    "\n",
    "            output = decoder_output_layer(decoder_outputs)\n",
    "\n",
    "        #    print(\"Decoder Output : \",output.shape)\n",
    "\n",
    "        #    output = tf.expand_dims(output,1)\n",
    "\n",
    "            all_outputs.append(output)\n",
    "\n",
    "            inputs = output\n",
    "\n",
    "            states = [state_h]\n",
    "\n",
    "        all_out = Lambda(lambda x: tf.keras.backend.concatenate(x, axis=1))(all_outputs)\n",
    "\n",
    "        ##Flatten layer\n",
    "\n",
    "        flat_layer = tf.keras.layers.Flatten()\n",
    "\n",
    "        all_out = flat_layer(all_out)\n",
    "\n",
    "        ###Defining Fullyy connected layer \n",
    "\n",
    "        fc_layer = Dense(128,name='FC_LAYER'\n",
    "    #                     ,kernel_regularizer=tf.keras.regularizers.L2(0.01)\n",
    "                        )\n",
    "\n",
    "        output_layer = Dense(24,name='output_layer')\n",
    "\n",
    "        fc_layer_1 = fc_layer(all_out)\n",
    "\n",
    "        final_output = output_layer(fc_layer_1)\n",
    "\n",
    "        model = Model([encoder_input,decoder_input], final_output, name='model_encoder_decoder')\n",
    "\n",
    "        model.compile(optimizer='adam', loss=tf.keras.losses.Huber(), metrics=['mean_squared_error'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    My_Model = create_enc_dec_att_model(BATCH_SIZE)\n",
    "    \n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.1,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.5)\n",
    "\n",
    "    model_chk = tf.keras.callbacks.ModelCheckpoint(\n",
    "            '1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_regu_lstm_dim_128.h5',monitor=\"val_loss\",mode='min',verbose=1,save_best_only=True\n",
    ")\n",
    "\n",
    "    history = My_Model.fit(x=[tra_data_sli,tra_decod],y=tra_lab, epochs=MAX_EPOCH, batch_size=BATCH_SIZE,validation_data=([val_data_sli,val_decod], val_lab), verbose=1,callbacks=[model_chk])\n",
    "\n",
    "    predict = My_Model.predict(x=[tes_data_sli,tes_decod])\n",
    "    \n",
    "    prediction = test_scaler.inverse_transform(np.repeat(predict.flatten().reshape(-1,1),10,axis=1))\n",
    "\n",
    "    grou_tru = test_scaler.inverse_transform(np.repeat(tes_lab.flatten().reshape(-1,1),10,axis=1))\n",
    "    \n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(['val_loss', 'loss'], loc='upper left')\n",
    "    \n",
    "    file_ = open('result_log.txt','a') \n",
    "#file_.write('TRAIN_STEPS,MSE,MAE,R2,MAPE\\n'.format(TRAIN_STEPS))\n",
    "    file_.write('{},{},{},{},{}\\n'.format(TRAIN_STEPS,mean_squared_error(grou_tru[:,0],prediction[:,0]),mean_absolute_error(grou_tru[:,0],prediction[:,0]),r2_score(grou_tru[:,0],prediction[:,0]),mean_absolute_percentage_error(grou_tru[:,0],prediction[:,0])))\n",
    "    file_.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8f7a1032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37224, 10)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6c34698f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1135, 672, 10)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra_data_sli.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bdb0dc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27912"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0cc8cc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27912, 10)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7982e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb0fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4358618c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf30e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf37b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d7f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97385cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f954ceb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f26134c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6000e60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3228e8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6562dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60987e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93a09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5341bd07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f63d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d2635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ecd32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970f5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2568d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f77d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839d31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222dec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c5509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576c70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a5830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee6a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf19db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a0aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c31b703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b21b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bef3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2dc972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fdbf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aad762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67a4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b59ac38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b31d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a74901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a2feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89383ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4603c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7946cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941e7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d8ece5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff0292e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac348c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5b268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1548d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00acc11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79886eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c659d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb425a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be228e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb743eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69282fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490a815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c683d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54224b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
